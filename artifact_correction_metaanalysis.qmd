---
title-block-banner: true
title-block-style: default
description: " <br>Author: Matthew B. Jan√©, NAME (CRediT)"
crossref:
  chapters: true
---

# Artifact Correction Meta-Analysis {#sec-artifact}

## Introduction

Artifact correction meta-analysis, also referred to as psychometric meta-analysis, is a form of meta-analysis where effect sizes are systematically corrected for sources of bias. These sources of bias have been discussed in previous chapters 4-10. Methodology for conducting artifact correction style meta-analyses were originally pioneered by Frank Schmidt and John Hunter [@hunter1990a; @schmidt1977] and then reviewed more recently by Brenton Wiernik and Jeffrey Dahlke [@wiernik2020]. There has also been powerful R packages developed to aide in the application of artifact correction meta-analyses that we have used in previous chapters [@dahlke2019]. You will notice that in this secti on, we do not discuss standardized mean differences. This is due to the fact that the artifact correction model is designed for pearson correlations, in order to use this method for standardized mean differences, convert to pearson correlations using the methods described in chapter 11, and then use the correction methods used below. Once you apply the corrections to the converted correlations they can then be converted back to a standardized mean difference.

## Bare Bones vs Artifact Correction Meta-Analysis

This is because even if the estimates are biased relative to our estimand (i.e., the thing we are trying to estimate), the observed value still has its own population value. Chapter 11 focused on bare-bones meta-analysis, that is, meta-analyses that do not correct for biases in effect size estimates. This section will be dedicated to the artifact correction style of meta-analysis that does aim to correct for such artifactual biases. The choice between these two types of meta-analyses depends on the research question, the available data, and the assumptions researchers are willing to make. If the goal is to investigate the state of the quantitative evidence while avoiding additional assumptions about the data, then a bare-bones meta-analysis might be the way to go. On the other hand, if the goal is to obtain a more accurate estimate of the true effect size by accounting for biases induced by statistical artifacts, an artifact correction meta-analysis is preferable.

1.  Bare-Bones Meta-Analysis: In a bare-bones meta-analysis, the focus is on aggregating effect sizes from various studies without explicitly correcting for potential biases in these effect size estimates.

2.  Artifact Correction Meta-Analysis: In contrast, an artifact correction meta-analysis takes into account and attempts to correct for biases that may be present in the effect size estimates from individual studies. This involves addressing potential sources of bias, such as measurement error or selection effects, through statistical techniques or adjustments. By doing so, the meta-analysis aims to provide a more accurate and unbiased estimate of the true effect size. Although it is important to note that this method will require additional assumptions about the nature of the data.

Note that the bare-bones model does not assume that there is no bias, rather, the bare-bones model is estimating something else entirely, that is, the observed population effect size.

![](figure/correction_forest.png)

## Individual Artifact Correction Model

The individual artifact correction model corrects each effect size individually prior to conducting the meta-analysis. This method is ideal if we have high-quality artifact estimates for most/all studies in the meta-analysis. If there is a substantial amount of missingness in the artifact values, then the artifact distribution model may be a better choice.

### The General Case

Let us recall the random effects model in chapter 11, where $\theta_i=\vartheta_i+\varepsilon_i$. This model would be considered a bare-bones meta-analytic model; we can re-write it slightly to denote that these are observed values: $\theta_{o_i}=\vartheta_{o_i}+\varepsilon_{o_i}$. Ultimately, observed values tend to be biased relative to true values due to many artifactual factors, some that we can account for and some we can not. If we decide that corrections to observed effect sizes are necessary to answer our research question, then we can construct an artifact correction model. In the artifact correction framework, we can incorporate a compound artifact biasing factor, $A$, to the bare-bones formula such that,

$$
\theta_{o_i} = A_i\vartheta_i + \varepsilon_{o_i}
$$ {#eq-art-mdl}

So now instead of the model being in terms of the observed population value ($\vartheta_{o_i}$), it is now in terms of the *true* population value ($\vartheta_{i}$).The compound biasing factor, $A_i$ is a product of $K$ independent artifact values (e.g., unreliability and range restriction),

$$
A_i = a_{1i} a_{2i} ... a_{Ki}
$$

This compound artifact formula assumes that the values are independent of one another, which is not always the case, see chapter 11 on independence of artifacts. Therefore adjustments must be made to ensure independence. eq-art-mdl can be re-arranged to obtain unbiased estimates of the true population effect size:

$$
\frac{\theta_{o_i}}{A_i} = \vartheta_i + \frac{\varepsilon_{o_i}}{A_i}
$$ {#eq-correction-mdl}

This division of $A_i$ will provide us with our corrected effect size estimates that we can denote with the subscript, $c$,

$$
\theta_{c_i} = \frac{\theta_{o_i}}{A_i}
$$ 

and the corresponding error term must also be corrected

$$
\varepsilon_{c_i} = \frac{\varepsilon_{o_i}}{A_i}.
$$ {#eq-error}

Therefore @eq-correction-mdl can be reformulated as,

$$
\theta_{c_i} = \vartheta_i + \varepsilon_{c_i} 
$$ {#eq-correction-formula}

These corrections cause changes in the point estimate and the error variance of the study effect sizes. Like we saw in chapter 11, we can breakdown the variance components of the model,

$$
\sigma^2_{\theta_c} = \sigma^2_{\vartheta} + \sigma^2_{\varepsilon_c}
$$ {#eq-corrected-var}

To obtain these variance components, we can start by correcting the observed sampling variances from each study. We can calculate the corrected sampling variance ($\sigma^2_{\varepsilon_c}$) by first correcting each study-level sampling variance estimate,

$$
\sigma^2_{\varepsilon_ci} = \frac{\sigma^2_{\varepsilon_oi}}{A^2_i}
$$ This may also be done by using the corrected effect size and the observed effect size to correct the sampling variance:

$$
\sigma^2_{\varepsilon_ci} = \sigma^2_{\varepsilon_oi} \left(\frac{\theta_{c_i}}{\theta_{o_i}}\right)^2
$$

The next step is to obtain the random effects weights of the study, we can do this with the inverse corrected variance for each study, $w_i=1/(\sigma^2_{\varepsilon_ci}+\sigma^2_\rho)$. From here we can calculate our estimate of the mean of true population correlations,

$$
\hat{\bar{\vartheta}}=\frac{\sum^k_{i=1}n_i\theta_{c_i}}{\sum^k_{i=1}n_i}
$$ 

Remember that because this is a random effects model, $\hat{\bar{\vartheta}}$ is not an estimate of the true population effect size, instead it is an estimate of the mean of a distribution of true population effect sizes. Now that we have an estimate of the mean and the corrected sampling variances, the variance components from @eq-corrected-var can be easily calculated as follows:

$$
\sigma^2_{\theta_c} = \frac{\sum^k_{i=1}n_i(\theta_{c_i} - \hat{\bar{\vartheta}})^2}{\sum^k_{i=1}n_i}
$$

$$
\sigma^2_{\varepsilon_c} = \frac{\sum^k_{i=1}n_i\sigma^2_{\varepsilon_c i}}{\sum^k_{i=1}n_i}
$$

$$
\sigma^2_{\vartheta}  = \sigma^2_{\theta_c} - \sigma^2_{\varepsilon_c}
$$ 

The standard deviation of true effects is a useful measure of heterogeneity and is simply the square root of the variance of true population effect sizes ($\sigma_{\vartheta}$). From the standard deviation in true effects, we can also calculate a credibility (prediction) interval that shows the range of plausible values for which a true effect size is likely to fall,

$$
\vartheta_{\text{Upper}} = \hat{\bar{\vartheta}} + 1.645\sigma_\vartheta
$$

$$
\vartheta_{\text{Lower}} = \hat{\bar{\vartheta}} - 1.645\sigma_\vartheta\, .
$$

Note that this is not to be confused with *confidence* intervals which denotes the range of plausible values that the *mean* of true effects can take on. This differentiation is akin to understanding the disparity between the standard error of the mean and the standard deviation in the context of a normal distribution. We can also see how the corrections reduced the heterogeneity in the effect size estimates by comparing variance in true effect sizes ($\sigma^2_{\vartheta_o}$) to the variance in observed effect sizes ($\sigma^2_{\vartheta_o}$; this can be calculated by conducting a bare-bones random effects meta-analysis described in chapter 11). The percent reduction in heterogeneity can be computed by taking the ratio of the two, $\sigma^2_{\vartheta}/\sigma^2_{\vartheta_o}$. @hunter1990a suggest that if 75% of the heterogeneity is accounted for by artifact corrections, then we can assume that the remaining heterogeneity is attributable to remaining artifacts that have not been addressed in the current meta-analysis. Although it is important to point out that this is simply a rule of thumb rather than a mathematical property.

### Individual Corrections in Correlations

For correlation coefficients we can define the model similarly to @eq-art-mdl, with the only difference being that we will use the notation for pearson correlations,

$$
r_{o_i} = A_i\rho_i + \varepsilon_{o_i}
$$ 

The artifact correction formulation of this, corresponding to @eq-correction-formula, would be

$$
r_{c_i} = \rho_i + \varepsilon_{c_i}
$$ 

The corresponding variance components would then be,

$$
\sigma^2_{r_c} = \sigma^2_\rho + \sigma^2_{\varepsilon_c}
$$ 

In order to compute the variance components as well as the mean true population correlation, we first need to calculate the study weights. We will follow a similar procedure for calculating random effects weights in chapter 11. Lets define the corrected random effects weights as,

$$

w_i = \frac{1}{\sigma^2_{\varepsilon_ci}+\sigma_\rho^2}.

$$
However the variance components, $\sigma^2_{\varepsilon_ci}$ and $\sigma^2_\rho$, require the weights themselves to actually estimate them, so instead we can approximate the variance components using the sample size as the weights such that,
$$
w_i =\frac{1}{\sigma^2_{\varepsilon_ci}+\sigma_\rho^2}= \frac{1}{\sigma^2_{\varepsilon_ci}+(\sigma^2_{r_c}-\sigma^2_{\varepsilon})} \approx \frac{1}{\sigma^2_{\varepsilon_ci}+\left(\frac{\sum^k_{i=1}n_i(r_{c_i} - \bar{r}_c)^2}{\sum^k_{i=1}n_i}-\frac{\sum^k_{i=1}n_i\sigma^2_{\varepsilon_ci}}{\sum^k_{i=1}n_i}\right)}
$$

Where $\bar{r}_c$ is the sample size weighted average corrected correlation. These weights can then be used to obtain a more precise estimate of the true population correlation,

$$
\hat{\bar{\rho}}=\frac{\sum_{i=1}^k w_i r_{c_i}}{\sum_{i=1}^k w_i}
$$
Now we can compute each of the three variance components:


1)  Variance in corrected correlations:

$$
\sigma^2_{r_c}=\frac{\sum^k_{i=1}w_i(r_{c_i} - \hat{\bar{\rho}})}{\sum^k_{i=1}w_i}.
$$
2)  Sampling error variance: 
$$
\sigma^2_{\varepsilon_c} = \frac{\sum^k_{i=1}w_i\sigma^2_{\varepsilon_ci}}{\sum^k_{i=1}w_i}.
$$
3)  Variance in population correlations: 
$$
\sigma^2_\rho = \sigma^2_r - \sigma^2_{\varepsilon}.
$$
Now lets use these variance components to calculate the 90% credibility (prediction) interval and the 95% confidence interval. The 90% credibility interval can be calculated with the following equations:

$$
\rho_\text{Upper} = \hat{\bar{\rho}} + 1.645\sigma_\rho
$$

$$
\rho_\text{Lower} = \hat{\bar{\rho}} - 1.645\sigma_\rho
$$

We can also calculate the standard error of the mean of true population effect sizes ($SE_{\hat{\bar{\rho}}}$) by dividing the sampling error variance component by the number of studies, $k$,

$$
SE_\hat{\bar{\rho}} = \sqrt{\frac{\sigma^2_{r_c}}{k}}
$$

Which can then be used to calculate 95% confidence intervals:

$$
\bar{\rho}_\text{Upper} = \hat{\bar{\rho}} + 1.96\cdot SE_\hat{\bar{\rho}}
$$

$$
\bar{\rho}_\text{Lower} = \hat{\bar{\rho}} - 1.96\cdot SE_\hat{\bar{\rho}}
$$


### Applied Example in R

Lets conduct an individual correction meta-analysis in r using the data set by @roth2015. This data set consists of correlations between school grades and intelligence test scores. It also contains information on the reliability of the intelligence test scores and the extent of range restriction in test scores. We can conduct a meta-analysis correcting for univariate indirect range restriction and measurement error in test scores. The compound artifact biasing factor for the correlation would be: 
$$
A_i=\sqrt{r_{o_i}^2 + \frac{u_{x_i}^2 r_{xx'_i}(r_{xx'_i} - r_{o_i}^2) }{1 - u_{x_i}^2 (1-r_{xx'_i})} }
$$ 
Sticking with our theme of doing everything in base R first, lets use the equations from the previous section to conduct the meta-analysis.

```{r,message=FALSE}
# Load in packages (we need the development version of psychmeta)
# install.packages("devtools")
# devtools::install_github("psychmeta/psychmeta")
library(psychmeta)

# obtain artifact values
rxx <- data_r_roth_2015$rxxi
ux <- data_r_roth_2015$ux
ro <- data_r_roth_2015$rxyi
n <- data_r_roth_2015$n
k <- length(ro)

# fill in missing artifact values with mean
rxx[is.na(rxx)] <- mean(rxx,na.rm=TRUE)
ux[is.na(ux)] <- mean(ux,na.rm=TRUE)

# calculate compound artifact biasing factor for univariate direct range restriction with measurement error
A <- sqrt(ro^2 + (ux^2*rxx*(rxx - ro^2)) / (1 - ux^2*(1-rxx)))

# calculate the sample size weighted average of r
ro_bar <- sum(ro*n) / sum(n)

# calculate the observed sampling variance for each study
var_eoi <- (1-ro_bar^2)^2 / (n-1)

# correct sampling variance
var_eci <- var_eoi / A^2

# calculate corrected correlations
rc <- ro / A

# calculate weights
w <- 1/var_eci

# calculate population effect size estimate
mean_rho_hat <- sum(rc*w) / sum(w)

# calculate the variance in corrected correlations (rc)
var_rc <- sum(w*(rc - mean_rho_hat)^2) / sum(w)

# calculate average corrected sampling variance
var_ec <- sum(var_eci*w) / sum(w)

# calculate the variance in true population correlations
var_rho <- var_rc - var_ec

# calculate standard error of rho estimate
SE_rho = sqrt(var_rc/k)

# print results
data.frame(k = k,
           n = sum(n),
           mean_rho_hat,
           SE = SE_rho,
           SD_rho = sqrt(var_rho))
```

The estimated mean correlation of .540 is precisely what is precisely what the original paper reported [@roth2015]. Lets conduct the meta-analysis using the the `psychmeta` package [@dahlke2019]. The function `ma_r_ic` is designed to conduct an individual correction meta-analysis on correlation coefficients.

```{r,message=FALSE}
# install.packages('psychmeta')
library(psychmeta)

# conduct individual correction meta-analysis
mdl_ic <- ma_r_ic(rxyi = ro, n = n,
            correction_method = "uvirr",
            rxx = rxx,
            ux = ux,
            ux_observed = TRUE,
            rxx_restricted = TRUE)

summary_stats <- data.frame(k = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$k,
                            n = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$N,
                            mean_rho = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$mean_rho,
                            SE = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$se_r_c,
                            SD_rho = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$sd_rho)
summary_stats 
```

We can also obtain credibility intervals by using the `credibility` function in the `psychmeta` package. The interval defaults to 80% intervals, however we can change that to 90% by inputting .90 into the `cred_level` argument.

```{r}
credibility(mean = summary_stats$mean_rho_hat,
            sd = summary_stats$SD_rho,
            cred_method = "norm",
            cred_level = .90)

```

Lets compare these results to the bare-bones model. In `psychmeta` the bare-bones model can be conduced using `ma_r_bb`. However, the `ma_r_ic` function also reports the bare-bones results as well. Therefore we can just extract the necessary statistics from the model.

```{r}
data.frame(
  k = mdl_ic$meta_tables$`analysis_id: 1`$barebones$k,
  n = mdl_ic$meta_tables$`analysis_id: 1`$barebones$N,
  mean_rho_obs = mdl_ic$meta_tables$`analysis_id: 1`$barebones$mean_r,
  SE = mdl_ic$meta_tables$`analysis_id: 1`$barebones$se_r,
  SD_rho_obs = mdl_ic$meta_tables$`analysis_id: 1`$barebones$sd_r)

```

We can see that the estimate of the population correlation is largely attenuated in the observed values. This is due to the fact tests of intelligence are not perfectly reliable and the scores were restricted in their range.

## Artifact Distribution Model

When we observe a lot of missingness in artifact values (e.g., studies not reporting reliability), we may choose to use an artifact distribution model. The artifact distribution model conducts a meta-analysis on the observed effect sizes and artifact values separately, and then uses the aggregate artifact values to correct for the observed mean effect size. Since the artifact distribution method uses Taylor series approximations [@dahlke2020] that are custom-tailored to estimate the sampling variance of corrected correlations, we will skip the general case to focus on its application to correlations.

### The Correlational Case

The model here can be broken down into two parts, the first part aggregates the observed effect sizes and the second part aggregates the artifact values. The artifact values we will focus on here are the reliability coefficients (see chapter 5 and 6), however other artifact values like $u$-ratios will follow similar procedures. We can start with the bare-bones meta-analysis model: $r_{o_i} = \rho_{o_i} + \varepsilon_{o_i}$. We can estimate the observed population correlation ($\vartheta_{o_i}$) by first calculating the weights (using the $n$-weighted mean correlation in the formula for sampling variance, $\bar{r}$):

$$
\sigma^2_{\varepsilon_oi} \approx \frac{(1-\bar{r}^2)^2}{n_i-1} 
$$

$$
w_i = \frac{1}{\sigma^2_{\varepsilon_i}+\sigma_\vartheta^2} = \frac{1}{\sigma^2_{\varepsilon_i}+(\sigma^2_{\theta}-\sigma^2_{\varepsilon})} \approx \frac{1}{\sigma^2_{\varepsilon_i}+\left(\frac{\sum^k_{i=1}n_i(\theta_i - \bar{\theta})^2}{\sum^k_{i=1}n_i}-\frac{\sum^k_{i=1}n_i\sigma^2_{\varepsilon_oi}}{\sum^k_{i=1}n_i}\right)}
$$

Taking the mean of the observed study correlations weighted by the inverse sampling variance,

$$
\hat{\bar{\rho}}_o=\frac{\sum^k_{i=1}w_i r_{o_i}}{\sum^k_{i=1}w_i}
$$

Then lets get the variance in observed population correlations, in order to do this we need the v

$$
\sigma^2_{\rho_o}=\sigma^2_{r_o} - \sigma^2_{\varepsilon_o} = \frac{\sum^k_{i=1}w_i (r_{o_i}-\hat{\bar{\rho}}_o)^2}{\sum^k_{i=1}w_i} - \frac{\sum^k_{i=1}w_i \sigma^2_{\varepsilon_oi}}{\sum^k_{i=1}w_i}
$$

With the weights we can also take the weighted average of the artifact values (such as $u$-ratios or reliabilities) that are available. For our example here, we will correct only for measurement error, therefore the weighted means for reliability in $x$ and $y$ will be:

$$
\bar{r}_{xx'}=\frac{\sum^k_{i=1}w_i r_{xx'_i}}{\sum^k_{i=1}w_i}
$$

$$
\bar{r}_{yy'}=\frac{\sum^k_{i=1}w_i r_{yy'_i}}{\sum^k_{i=1}w_i}
$$

Now recall from chapter 5 that the square root of the reliability is equal to the correlation between observed scores and true scores. We can denote the mean correlation as follows: $\bar{r}_{xT}=\sqrt{\bar{r}_{xx'}}$ and $\bar{r}_{yU}=\sqrt{\bar{r}_{xx'}}$. We then must also compute the average sampling variances of $r_{xT_i}$ and $r_{yU_i}$ between studies. These sampling variance of these correlations can be computed the same way as a pearson correlation:

$$
\sigma^2_{r_{xT}i} \approx \frac{(1-\bar{r}_{xT}^2)^2}{n_i-1} 
$$

$$
\sigma^2_{r_{yU}i} \approx \frac{(1-\bar{r}_{yU}^2)^2}{n_i-1} 
$$ 

Then weighted average of these sampling variances is

$$
\sigma^2_{r_{xT}} = \frac{\sum^k_{i=1}w_i r_{xT_i}}{\sum^k_{i=1}w_i}
$$ 

$$
\sigma^2_{r_{yU}} = \frac{\sum^k_{i=1}w_i r_{yU_i}}{\sum^k_{i=1}w_i}
$$ 
Now that we have the point-estimate of the population observed correlation, the variance of observed population correlations, the sampling variance of observed correlations, and the sampling variance of the square root of the reliability for $x$ and $y$, we can now attempt to correct the point-estimate and the variance of population correlations.

##### Correcting Using Summary Values {.unnumbered}

First, we can start by correcting the overall point-estimate for the observed population correlation in order to remove bias due to measurement error. Recall from chapter 5 the correction formula:

$$
\hat{\bar{\rho}} = \frac{\hat{\bar{\rho}}_o}{\bar{A}} = \frac{\hat{\bar{\rho}}_o}{\bar{r}_{xT} \bar{r}_{yU}} = \frac{\hat{\bar{\rho}}_o}{\sqrt{\bar{r}_{xx'}} \sqrt{\bar{r}_{yy'}}}
$$

Note that the artifact biasing factor, $A$, is the product of the two sources of attenuation. Correcting the variance in observed population correlations ($\sigma^2_{\rho_o}$), so that it is accurately estimating the variance of true population effect sizes ($\sigma^2_{\rho}$), we must use a Taylor series approximation. This formula can become fairly complex with more types of artifacts involved. The taylor series approximation is for estimating specifically the amount of sampling variance within the correction factor we apply to the observed correlation. The first step is lay out our attenuation formula (the equation where observed effect size is on the left side of the equation and the artifact values and true effect size is on the right hand side of the equation). In the case of correcting only for measurement error, the attenuation formula is relatively simple

$$
\hat{\bar{\rho}}_o = \hat{\bar{\rho}}\cdot \bar{r}_{xT}\cdot \bar{r}_{yU}
$$ 

For the taylor series approximation, we want to first find the partial derivitive with respect to each artifact component:

$$
B_{r_{xT}}=\frac{\partial}{\partial r_{xT}} (\hat{\bar{\rho}}\cdot \bar{r}_{xT}\cdot \bar{r}_{yU}) = \hat{\bar{\rho}}\cdot \bar{r}_{yU}
$$ 
$$
B_{r_{yU}}=\frac{\partial}{\partial r_{yU}} (\hat{\bar{\rho}}\cdot \bar{r}_{xT}\cdot \bar{r}_{yU}) = \hat{\bar{\rho}}\cdot \bar{r}_{xT}
$$

The variance due to artifacts is then approximately,

$$
\sigma^2_A\approx B^2_{r_{xT}} \sigma^2_{r_{xT}} + B^2_{r_{yU}} \sigma^2_{r_{yU}}
$$

Now we can approximate the variance in true population correlations,

$$
\sigma_\rho^2= \frac{\sigma^2_{\rho_o} - \sigma^2_A}{\bar{A}^2}
$$ 

Where the artifact biasing factor is: $\bar{A}=\bar{r}_{xT}\cdot \bar{r}_{yU}$. See the supplementary materials of @dahlke2020 for detailed Taylor series approximation derivations for the immensely more complicated bivariate indirect range restriction plus measurement error correction.

### Applied Example in R

Lets conduct an artifact distribution correction meta-analysis in R, instead using data from the meta-analysis by @mcdaniel1994. This dataset contains correlations between employment interviews and job performance. This data set has a lot of missing values for reliability coefficients and $u$-ratios which might suggest that the artifact distribution approach is a better choice compared to the individual correction approach. We can conduct a meta-analysis correcting for univariate indirect range restriction and measurement error in both job performance and employment interviews. The attenuation formula will be important for calculating the Taylro series approximation can be defined as

$$
\bar{\rho}_o=\bar{\rho}\sqrt{\bar{r}_{o_i}^2 + \frac{\bar{u}_{x_i}^2 \bar{r}_{xx'_i}(\bar{r}_{xx'_i}\bar{r}_{yy'_i} - \bar{r}_{o_i}^2) }{1 - \bar{u}_{x_i}^2 (1-\bar{r}_{xx'_i})} }
$$ 
Instead of conducting a taylor series approximation by hand, we will simply use the `psychmeta` package to perform the artifact distribution meta-analysis. The function `ma_r_ad` is designed to conduct an artifact distribution meta-analysis on correlation coefficients. The function also reports the bare-bones model allowing us to compare the corrected estimates to the uncorrected.

```{r,message=FALSE}
# Load in packages (we need the development version of psychmeta)
# install.packages("devtools")
# devtools::install_github("psychmeta/psychmeta")
library(psychmeta)

# obtain artifact values
rxx <- data_r_roth_2015$rxxi
ux <- data_r_roth_2015$ux
ro <- data_r_roth_2015$rxyi
n <- data_r_roth_2015$n
k <- length(ro)

# compute barebones meta-analysis
ma_obj <- ma_r_bb(r = rxyi, 
                  n = n, 
                  correct_bias = FALSE, 
                  wt_type = "REML",
                  data = data_r_mcdaniel_1994)

# construct artifact distribution for x
ad_obj_x <- create_ad(ad_type = "tsa", 
                      mean_rxxi = data_r_mcdaniel_1994$Mrxxi[1],
                      var_rxxi = data_r_mcdaniel_1994$SDrxxi[1]^2,
                      ux = data_r_mcdaniel_1994$ux,
                      wt_ux = data_r_mcdaniel_1994$`ux frequency`)

# construct artifact distribution for y
ad_obj_y <- create_ad(ad_type = "tsa", 
                      rxxi = data_r_mcdaniel_1994$ryyi,
                      wt_rxxi = data_r_mcdaniel_1994$`ryyi frequency`)

# compute artifact-distribution meta-analysis, correcting for measurement error only
mdl_ad <- ma_r_ad(ma_obj = ma_obj, 
                  ad_obj_x = ad_obj_x, 
                  ad_obj_y = ad_obj_y, 
                  correction_method = "meas")


# summary table of meta-analysis
summary_stats <- data.frame(
  type = c('Artifact Distribution', 'Bare-Bones'),
  k = c(mdl_ad$meta_tables$`analysis_id: 1`$artifact_distribution$true_score$k,mdl_ad$meta_tables$`analysis_id: 1`$barebones$k),
  n = c(mdl_ad$meta_tables$`analysis_id: 1`$artifact_distribution$true_score$N,mdl_ad$meta_tables$`analysis_id: 1`$barebones$N),
  mean_rho = c(mdl_ad$meta_tables$`analysis_id: 1`$artifact_distribution$true_score$mean_rho,mdl_ad$meta_tables$`analysis_id: 1`$barebones$mean_r),
  SE = c(mdl_ad$meta_tables$`analysis_id: 1`$artifact_distribution$true_score$se_r_c,mdl_ad$meta_tables$`analysis_id: 1`$barebones$se_r),
  SD_rho = c(mdl_ad$meta_tables$`analysis_id: 1`$artifact_distribution$true_score$sd_rho,0))

summary_stats 
```

We can also obtain credibility intervals by using the `credibility` function in the `psychmeta` package. The interval defaults to 80% intervals, however we can change that to 90% by inputting .90 into the `cred_level` argument.

```{r}
credibility(mean = summary_stats$mean_rho[1],
            sd = summary_stats$SD_rho[1],
            cred_method = "norm",
            cred_level = .90)

```

Lets compare these results to the bare-bones model. In `psychmeta` the bare-bones model can be conduced using `ma_r_bb`. However, the `ma_r_ic` function also reports the bare-bones results as well. Therefore we can just extract the necessary statistics from the model.


[@hunter1990a]

[@wiernik2020]

[@schmidt1977]

[@murphy2003]

[@viswesvaran1995]

[@raju1983]

[@callender1980]
