[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Artifact Corrections for Effect Sizes",
    "section": "",
    "text": "1 Greetings\nWelcome to the living open source textbook Study Artifacts and Their Corrections. This book is designed to assist social/clinical/behavioral/cognitive researchers in understanding the nature of study artifacts, their impact on effect sizes, and proper correction methods. Each chapter includes practical examples, R code, and equations for seamlessly implementing these corrections into your own research projects.\n\n\nWhat are Study Artifacts?\nIn this book, artifacts will be defined broadly as any source of methodological contamination that induce bias in research findings. In an ideal world where studies are conducted perfectly, this book would not exist. Hopefully one day, we reach a point where studies contain only small, inconsequential imperfections and this book becomes obsolete, a relic of a darker past. Until that day, artifact corrections can provide a temporary band-aid to some methodological flaws.\n\n\nOpen and Living Textbook\nA living textbook is one that continuously updates with new features and is open to changes from others. This book will contain modern methods and cutting-edge techniques for artifact corrections, so in order to keep this book up-to-date it needs to grow as the research grows.\n\n\nSupport My Work\nPlease help keep this book maintained and free for everyone by supporting me through buymeacoffee.com/matthewbjane\n\n\nCitation and License\nIt is important that this book is both open-source and open-access. All the figures, code, and documents are available in a github repository. The current maintainer of the book is Matthew B. Jané. This work is under a CC-BY license, therefore if you use any part of this work in your own work, it is important that you acknowledge it and cite it as follows:\n\nAPA\nJané, M. B. (2024). Artifact Corrections for Effect Sizes: Seeing Reality for What It Is. (n.p.). https://matthewbjane.quarto.pub/artifact-corrections-for-effect-sizes/\n\n\nBibTeX\n@book{MatthewBJane2023,\n  title     = \"Artifact Corrections for Effect Sizes: Seeing Reality for What It Is\",\n  author    = \"Jané, Matthew B.\",\n  year      = 2024,\n  publisher = \"(n.p.)\",\n  url      = {https://matthewbjane.quarto.pub/artifact-corrections-for-effect-sizes/}\n}\n\n\n\nContributions\nPlease feel free to contribute to this textbook, if your contribution makes it to the published version of this book, your name will be included in the contributor list below with a description of your work.\n\n\n\n\n\n\n\n\nName\nAffiliation\nRole\n\n\n\n\nBlair T. Johnson\nUniversity of Connecticut\nReviewing, editing, & consulting\n\n\nEdward Kroc\nUniversity of British Columbia\nReviewing, editing, & consulting\n\n\nChristopher Rhoads\nUniversity of Connecticut\nReviewing & editing & consulting\n\n\nElizibeth Schifano\nUniversity of Connecticut\nReviewing & editing & consulting\n\n\nVelu Immonen\nSolent University\nDesigned cover and twitter preview.\n\n\nPeter Licari\nN/A\nReviewing & editing\n\n\nShane Tutwiler\nUniversity of Rhode Island\nReviewing & Editing\n\n\nAshley E. Mullan\nVanderbilt University Medical Center\nReviewing & editing\n\n\nVinícius Litvinoff Justus\nUniversity of Campinas\nReviewing & editing\n\n\nRafael Valdece Sousa Bastos\nN/A\nReviewing & editing\n\n\nRyan Panela\nUniversity of Toronto\nReviewing & editing\n\n\nVilgot Huhn\nKarolinska Institutet\nReviewing & editing\n\n\nJonathan Whitmore\nN/A\nReviewing & editing\n\n\nRana Mallah\nMckinsey\nReviewing & editing",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Greetings</span>"
    ]
  },
  {
    "objectID": "00-dedication/00-dedication.html",
    "href": "00-dedication/00-dedication.html",
    "title": "2  Dedication",
    "section": "",
    "text": "In Loving Memory of Haley Jané\n\n\nMy companion, whose love and presence have filled my life with joy and comfort.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Dedication</span>"
    ]
  },
  {
    "objectID": "01-definitions/01-definitions.html",
    "href": "01-definitions/01-definitions.html",
    "title": "3  Samples, Random Variables, and Expectations",
    "section": "",
    "text": "3.1 Introduction\nThis section is meant to provide a foundation for the rest of the book by defining concepts like populations, probability distributions, and (conditional) expectations. This section will be dense and may require some basic understanding of measure theory. This chapter does not need to be entirely understood in order to understand the rest of the book, however some of the notation used in later chapters will be introduced here. I make sure to frequently reiterate what the meaning of the notation throughout the book, so not much should be lost if this chapter is skipped.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Samples, Random Variables, and Expectations</span>"
    ]
  },
  {
    "objectID": "01-definitions/01-definitions.html#the-sample-space-and-target-population",
    "href": "01-definitions/01-definitions.html#the-sample-space-and-target-population",
    "title": "3  Samples, Random Variables, and Expectations",
    "section": "3.2 The Sample Space and Target Population",
    "text": "3.2 The Sample Space and Target Population\nLet \\((\\Psi,\\mathcal{F}_\\Psi)\\) be a measurable space. The set \\(\\Psi\\) is a sample space and, in our case, the population of interest. Each \\(\\psi \\in \\Psi\\) is an experimental object of study such as an individual person or animal. Throughout the text \\(\\psi\\) will most often be referred to as an “individual”, but take note that this encompasses any experimental object of interest. The \\(\\sigma\\)-field \\(\\mathcal{F}_\\Psi\\) is a collection of measurable subsets of \\(\\Psi\\) that is closed under complement as well as countable unions and intersections.\nLet \\((\\Omega,\\mathcal{F}_\\Omega)\\) also be a measurable space. The set \\(\\Omega\\) is the outcome space where each \\(\\omega\\in\\Omega\\) is a possible outcome. The \\(\\sigma\\)–field \\(\\mathcal{F}_\\Omega\\) is the collection of measurable subsets.\n\n\n\n\n\n\nFigure 3.1: Spaces \\(\\Omega\\) and \\(\\Psi\\). The sample space \\(\\Omega\\) is the space of all possible outcomes whereas the space \\(\\Psi\\) is the population of interest (i.e., the space of all possible individuals). Each dot denotes the elements \\(\\omega\\in\\Omega\\) and \\(\\psi\\in\\Psi\\).\n\n\n\nLet \\(\\ell\\) be an assignment-to-individual function that maps the sample space \\(\\Omega\\) to the population of interest \\(\\Psi\\) (Zimmerman 1975; Kroc and Zumbo 2020),\n\\[\n\\ell: (\\Omega,\\mathcal{F}_\\Omega) \\rightarrow (\\Psi,\\mathcal{F}_\\Psi).\n\\]\nThe function \\(\\ell\\) is \\(\\mathcal{F}\\)-measurable such that \\(\\ell^{-1}(\\psi) \\in \\mathcal{F}_{\\Omega}\\). The preimage of an individual \\(\\psi\\in\\Psi\\) under the assignment-to-individual function is also known as a fiber and encapsulates all possible outcomes for given individual (see Figure 3.2). We can union the fibers of \\(\\ell\\) to recover the total sample space such that \\(\\Omega = \\bigcup_{\\psi\\in\\Psi}\\ell^{-1}(\\psi)\\).\n\n\n\n\n\n\nFigure 3.2: Assignment-to-individual function and it’s fibers. The top panels show the function \\(\\ell\\) mapping elements of \\(\\Omega\\) to a single element of \\(\\Psi\\). The bottom panels shows a fiber of \\(\\psi\\) under \\(\\ell\\) which is a subset of \\(\\Omega\\) and an element of \\(\\mathcal{F}_\\Omega\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Samples, Random Variables, and Expectations</span>"
    ]
  },
  {
    "objectID": "01-definitions/01-definitions.html#random-variables-and-measurement-error",
    "href": "01-definitions/01-definitions.html#random-variables-and-measurement-error",
    "title": "3  Samples, Random Variables, and Expectations",
    "section": "3.3 Random Variables and Measurement Error",
    "text": "3.3 Random Variables and Measurement Error\nThe sample units in the sample space are arbitrarily valued, but we can convert them to real number values by defining a random variable, that is, a function that takes each \\(\\omega\\in\\Omega\\) and assigns it a real-valued quantity. A real-valued random variable \\(V\\) is a measurable function that maps the probability space \\((\\Omega,\\mathcal{F}_\\Omega,{\\Pr}_V)\\) equipped with a probability measure \\({\\Pr}_V\\) to the set of real numbers equipped with the Borel \\(\\sigma\\)–field (i.e., the smallest \\(\\sigma\\)–field containing all open sets; see Figure 3.3),\n\\[\nV: (\\Omega,\\mathcal{F}_\\Omega,{\\Pr}_V) \\rightarrow (\\mathbb{R},\\mathcal{B}_\\mathbb{R}).\n\\]\nWhere the probability of the sample space is \\({\\Pr}_V(\\Omega)=1\\). The random variable is \\((\\mathcal{F}_\\Omega,\\mathcal{B}_\\mathbb{R})\\)–measurable such that \\(V^{-1}(B)\\in\\mathcal{F}_\\Omega\\) for all \\(B\\in\\mathcal{B}_\\mathbb{R}\\).\n\n\n\n\n\n\nFigure 3.3: Random variable. Three elements of \\(\\Omega\\) labeled \\(\\omega_a,\\) \\(\\omega_b,\\) and \\(\\omega_c\\) are assigned real-valued quantities under the random variable \\(V\\).\n\n\n\nWe can now define the relevant random variables that will be used over the course of the book. Let \\(Y\\) be a random variable of scientific interest (i.e., the measurand) denoting our dependent variable (i.e., the outcome variable). For real-world studies, we often are unable to observe the true value of \\(Y\\) directly and instead we must rely on drawing inferences about the true value from a error-prone proxy \\(\\widetilde{Y}\\) that is obtained from a measurement procedure. Clearly if the measurement procedure does not produce any error then \\(\\widetilde{Y}(\\omega) = Y(\\omega)\\) for each \\(\\omega\\in\\Omega\\). If the measurement procedure contains measurement error then there will be differences between the true value \\(Y\\) and outcomes of the measurement \\(\\widetilde{Y}\\). We can specify an algebraic structure relating the proxy \\(\\widetilde{Y}\\) to the true value \\(Y\\),\n\\[\n\\widetilde{Y} = Y + E_Y\n\\tag{3.1}\\]\nWhere \\(E_Y\\) is the measurement error term defined as the difference between the error-prone proxy and the true value \\(E_Y = \\widetilde{Y} - Y\\) (see Figure 3.4).For this book, the random variable \\(Y\\) will be continuous such that for any outcome \\(\\omega\\in\\Omega\\) the random variables take on real values, \\(Y(\\omega) \\in \\mathbb{R}\\).\nThe set of all possible measurement outcomes for an individual \\(\\psi\\in\\Psi\\) can be written as \\(\\widetilde{Y}(\\ell^{-1}(\\psi))\\in\\mathcal{F}_\\Omega\\). Over these possible measurement outcomes, we will assume that the dependent variable of interest \\(Y\\) stays constant across all outcomes for an individual such that \\(Y(\\omega_\\mathsf{a})=Y(\\omega_\\mathsf{b})\\) if \\(\\omega_\\mathsf{a},\\omega_\\mathsf{b} \\in \\ell^{-1}(\\psi)\\) whereas the measured proxy variable may not, \\(\\widetilde{Y}(\\omega_\\mathsf{a})\\neq \\widetilde{Y}(\\omega_\\mathsf{b})\\). This is a property of true scores most often associated with Classical Test Theory (Kroc and Zumbo 2020), which may not be optimal for many applications such as longitudinal studies where true scores are expected to change over time within a person.\n\n\n\n\n\n\nFigure 3.4: Measurement error. Each of the components of Equation 3.1 shown with respect to the real line.\n\n\n\nWe also want to define two independent variables \\(X\\) and \\(G\\) of interest and structure them in an algebraically similar manner to Equation 3.1,\n\\[\n\\widetilde{X} = X + E_X\n\\tag{3.2}\\]\n\\[\n\\widetilde{G} = G + E_G\n\\tag{3.3}\\]\nWhere \\(X\\) is a continuous random variable similar to \\(Y\\) and thus also takes on real values whereas \\(G\\) is a Bernoulli random variable and takes the value of either 0 or 1, \\(G(\\omega)\\in\\{0,1\\}\\). Measurement errors for Bernoulli random variables are usually referred to as misclassifications (see chapter on group misclassification).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Samples, Random Variables, and Expectations</span>"
    ]
  },
  {
    "objectID": "01-definitions/01-definitions.html#probability-distributions-and-density-functions",
    "href": "01-definitions/01-definitions.html#probability-distributions-and-density-functions",
    "title": "3  Samples, Random Variables, and Expectations",
    "section": "3.4 Probability Distributions and Density Functions",
    "text": "3.4 Probability Distributions and Density Functions\nThe probability distribution of a random variable allows us to assign probabilities to most subsets of the real line. The probability distribution of a continuous random variable \\(V\\) can often (except in mostly pathological cases) be described by a probability density function \\(f_V\\) (see Figure 3.5). The probability density function \\(f_V\\) is a nonnegative function that satisfies,\n\\[\n{\\Pr}_V(V\\in\\mathbb{R}) = \\int_\\mathbb{R} f_V(v)\\, dv = 1.\n\\tag{3.4}\\]\nIn other words, the probability of \\(V\\) taking on a value anywhere on the real line is 1 (i.e., no uncertainty in that statement). To obtain the probability that \\(V\\) exists in some Borel subset \\(B \\subset \\mathbb{R}\\) of the real line (e.g., an interval), we can integrate the probability density function \\(f_V\\) over \\(B\\),\n\\[\n{\\Pr}_V(V\\in B) = \\int_{B\\subset \\mathbb{R}} f_V(v)\\, dv.\n\\tag{3.5}\\]\n\n\n\n\n\n\nFigure 3.5: Probability Distributions. The outcome space \\(\\Omega\\) is mapped to the real line. How the values are distributed across the real line is described by the probability density function \\(f_{V}(v)\\).\n\n\n\nAssume random variables \\(X\\) and \\(Y\\) (along with the associated proxies and errors) are continuous and their probability distributions can both be described by their respective probability density functions \\(f_X\\) and \\(f_Y\\). However the distribution of a Bernoulli random variable \\(G\\) is be described by a probability mass function (Figure 3.6),\n\\[\nf_G(g) = p_G^g (1-p_G)^{1-g}\n\\tag{3.6}\\]\nWhere the parameter \\(p_G\\) denotes the probability that \\(G=1\\). Therefore the probability distribution of 0 or 1 can explicitly written out as,\n\\[\n{\\Pr}_G(G = 1) = p_G \\;\\;\\; \\text{and} \\;\\;\\;\n{\\Pr}_G(G = 0) = 1-p_G.\n\\]\n\n\n\n\n\n\nFigure 3.6: Probability Distributions. The sample space \\(\\Omega\\) is mapped to the real line with the value of the random variable \\(V\\) only taking on values of 0 or 1.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Samples, Random Variables, and Expectations</span>"
    ]
  },
  {
    "objectID": "01-definitions/01-definitions.html#study-samples",
    "href": "01-definitions/01-definitions.html#study-samples",
    "title": "3  Samples, Random Variables, and Expectations",
    "section": "3.5 Study Samples",
    "text": "3.5 Study Samples\nFor a researcher to make inferences about parameters in the population of interest, they must draw a sample of individuals from the population. Ideally, sampling is done at random in order to produce unbiased estimates of the population parameters. In practice however, this is usually not possible. In cognitive and behavioral sciences, many studies are conducted on convenience samples that are sampled from a narrow subset of the population of interest. A non-random sample may not (on average) share the same composition of characteristics as the population of interest and thus may produce biased estimates of population parameters. Here we define a study sample \\(\\mathcal{S}\\) as a subset of the sample space consisting of the possible outcomes of individuals drawn from the set of eligible individuals (i.e., individuals the researcher has access to). Let \\(\\mathcal{E}\\subseteq \\Psi\\) be the study population, that is, full set of eligible individuals. The study sample \\(\\mathcal{S}\\) is the set of possible values from a random draw of \\(n\\) eligible individuals,\n\\[\n\\mathcal{S} := \\bigcup^{n}_{i=1} \\ell^{-1}(\\psi_i)\\, ,\\;\\;\\;\\; \\psi_i = \\psi_1...\\psi_n \\in_\\text{R} \\mathcal{E}\\subseteq{\\Psi}\n\\] where \\(\\in_\\text{R}\\) denotes a random draw from a set. The eligibility of an individual (i.e., the members that constitute the study population \\(\\mathcal{E}\\)) will be defined more precisely in the chapters on selection effects.\n\n\n\n\n\n\nFigure 3.7: Study samples. The study is the set of possible outcomes from individuals randomly drawn from the pool of eligible individuals.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Samples, Random Variables, and Expectations</span>"
    ]
  },
  {
    "objectID": "01-definitions/01-definitions.html#conditional-expectations-and-variance-of-random-variables",
    "href": "01-definitions/01-definitions.html#conditional-expectations-and-variance-of-random-variables",
    "title": "3  Samples, Random Variables, and Expectations",
    "section": "3.6 Conditional Expectations and Variance of Random Variables",
    "text": "3.6 Conditional Expectations and Variance of Random Variables\nThe expectation of a random variable is a probability weighted average (i.e., the mean) over all possible sample units in the sample space. This can be defined with the Lebesgue integral of \\(V\\) with respect to the probability measure \\({\\Pr_V}\\),\n\\[\n\\mathbb{E}\\left[V\\right]  = \\int_\\Omega V \\, d\\,{\\Pr}_V.\n\\tag{3.7}\\]\nThe expected value can be interpreted as the population mean which will be denoted as \\(\\mu_{V}:=\\mathbb{E}(V)\\). The population variance \\(\\sigma^2_{V}\\) is the expectation of the squared deviation from it’s mean of the random variable \\(V\\) and can be expressed as,\n\\[\n\\sigma^2_{V} := \\mathbb{E}\\left[V^2\\right] - \\mathbb{E}\\left[V\\vphantom{^2}\\right]^2.\n\\]\nThe standard deviation of a random variable is the square root of the variance, \\(\\sigma_V\\). The conditional expectation on the other hand is the mean over a subset of the sample space. For example, the expectation of \\(Y\\) given the subset of the sample space \\(\\Omega\\) where \\(G=1\\) can be expressed as,\n\\[\n\\mu_{Y|G=1} :=\\mathbb{E}\\left[ Y \\mid G^{-1}(1)\\right] = \\int_{G^{-1}(1)} Y \\, d\\,{\\Pr}_{Y|G},\n\\]\nwhere \\({\\Pr}_{Y|G}\\) is the conditional probability measure.Then the conditional variance of \\(Y\\) given \\(G=1\\) is,\n\\[\n\\sigma^2_{Y|G=1} := \\mathbb{E}\\left[Y^2\\mid G^{-1}(1) \\right] - \\mathbb{E}\\left[Y\\mid G^{-1}(1) \\right]^2.\n\\] The study population mean of \\(V\\) is the the expectation over the possible outcomes of all individuals in the study population \\(\\mathcal{E}\\) can be defined as,\n\\[\n\\mu_{V|\\mathcal{E}} := \\mathbb{E}\\left[V\\mid \\ell^{-1}(\\mathcal{E})\\right]\n\\]\nand the study population variance of \\(V\\) is,\n\\[\n\\sigma^2_{Y|\\mathcal{E}} := \\mathbb{E}\\left[Y^2\\mid \\ell^{-1}(\\mathcal{E}) \\right] - \\mathbb{E}\\left[Y\\mid \\ell^{-1}(\\mathcal{E})\\right]^2.\n\\]\nIt is worth noting that if the study population encompasses all individuals in the population of interest (i.e., all individuals in the population of interest are eligible to be sampled), then \\(\\mathcal{E}=\\Psi\\). This would indicate that the study population mean is equal to the target population mean \\(\\mu_{V} = \\mu_{V|\\mathcal{E}}\\).\nThe expectation conditioned on a study sample \\(\\mathbb{E}[\\,\\cdot\\,|\\mathcal{S}]\\) can be construed as a random variable that has its own probability distribution due to the random action in the study sample (i.e., the study sample is created from \\(n\\) random draws from the eligible pool of individuals). The expectation over a sample is interpreted as a sample estimate of the mean,\n\\[\nm_{V} := \\mathbb{E}\\left[V \\mid \\mathcal{S}\\right] = \\frac{1}{n}\\sum_{1...n} V_i  .\n\\]\nWhere \\(V_i\\) denotes the value of the random variable for each individual drawn from the population. Where the sample variance is,\n\\[\ns_{V} := \\mathbb{E}\\left[V^2\\,|\\,\\mathcal{S}\\right] - \\mathbb{E}\\left[V\\,|\\,\\mathcal{S}\\vphantom{S^2}\\right]^2.\n\\]\nSample estimates of parameters will always be denoted as English letters. The covariance between two random variables \\(X\\) and \\(Y\\) is the product of the differences from the mean for each respective variable and can be expressed as,\n\\[\n\\sigma_{XY} := \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n\\]\nThe sample covariance can similarly defined using conditional expectations,\n\\[\ns_{XY} := \\mathbb{E}[XY\\,|\\,\\mathcal{S}] - \\mathbb{E}[X\\,|\\,\\mathcal{S}]\\,\\mathbb{E}[Y\\,|\\,\\mathcal{S}]\n\\]\n\n\n\n\n\nKroc, Edward, and Bruno D. Zumbo. 2020. “A Transdisciplinary View of Measurement Error Models and the Variations of x=t+e.” Journal of Mathematical Psychology 98 (September): 102372. https://doi.org/10.1016/j.jmp.2020.102372.\n\n\nZimmerman, Donald W. 1975. “Probability Spaces, Hilbert Spaces, and the Axioms of Test Theory.” Psychometrika 40 (3): 395–412. https://doi.org/10.1007/BF02291765.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Samples, Random Variables, and Expectations</span>"
    ]
  },
  {
    "objectID": "02-effect-sizes/02-effect-sizes.html",
    "href": "02-effect-sizes/02-effect-sizes.html",
    "title": "4  Effect Sizes and Artifacts",
    "section": "",
    "text": "4.1 Effect Sizes\nAn effect size is a parameter that describes the degree of association of two random variables1 (e.g., \\(X\\) and \\(Y\\)). Effect sizes are often used to quantitatively summarize research findings. We can define two types of effect sizes that will be of primary focus throughout the book: correlations and standardized mean differences (SMDs). Both correlations and SMDs are standardized effect sizes which means that they are without respect to location and scale of random variables. Standardized effect sizes allow for comparability across studies, in particular, they facilitate research syntheses and meta-analyses.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Sizes and Artifacts</span>"
    ]
  },
  {
    "objectID": "02-effect-sizes/02-effect-sizes.html#correlations",
    "href": "02-effect-sizes/02-effect-sizes.html#correlations",
    "title": "4  Effect Sizes and Artifacts",
    "section": "4.2 Correlations",
    "text": "4.2 Correlations\nA correlation is defined as the standardized covariance between two variables (see Figure 4.1). For two continuous random variables, \\(X\\) and \\(Y\\), the correlation \\(\\rho_{XY}\\) can be expressed as,\n\\[\n\\rho_{XY} := \\frac{\\sigma_{XY}}{\\sigma_X\\sigma_Y}.\n\\tag{4.1}\\]\nWhere \\(\\sigma_{XY}\\) is the covariance between \\(X\\) and \\(Y\\), \\(\\sigma_X\\) and \\(\\sigma_Y\\) are the standard deviations of \\(X\\) and \\(Y\\), respectively. A correlation does not have to be between two continuous variables. Typically, a correlation between a Bernoulli random variable and a continuous random variable is referred to as a point-biserial correlation and it is expressed similarly to Equation 4.1,\n\\[\n\\rho_{GY} := \\frac{\\sigma_{GY}}{\\sigma_G\\sigma_Y}.\n\\tag{4.2}\\]\nA correlation (whether point-biserial or continuous) is bounded between -1 and 1, where -1 is a perfectly negative correlation, 1 is a perfectly positive correlation, and 0 indicates no correlation. Note that a correlation of zero does not necessarily mean that the two variables are independent.\n\n\n\n\n\n\n\n\nFigure 4.1: A correlation between two variables (\\(X\\) and \\(Y\\)). The left panel shows a negative correlation and the right panel shows a positive correlation. The ellipses show the contour of a joint distribution.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Sizes and Artifacts</span>"
    ]
  },
  {
    "objectID": "02-effect-sizes/02-effect-sizes.html#standardized-mean-difference",
    "href": "02-effect-sizes/02-effect-sizes.html#standardized-mean-difference",
    "title": "4  Effect Sizes and Artifacts",
    "section": "4.3 Standardized Mean Difference",
    "text": "4.3 Standardized Mean Difference\nThe relationship between a Bernoulli random variable and a continuous random variable can alternatively be expressed as a standardized mean difference. A standardized mean difference is the difference between the means of two groups standardized by the within-group standard deviation (see Figure 4.2). The groups are defined by the values of a Bernoulli random variable and the standardized mean difference,\n\\[\n\\delta_{GY} :=  \\frac{\\mu_{Y|G=1}-\\mu_{Y|G=0}}{\\sigma_{Y|G}},\n\\tag{4.3}\\]\nwhere \\(\\mu_{Y|G=0}\\) and \\(\\mu_{Y|G=1}\\) is the population mean of \\(Y\\) for group 0 and 1, respectively. The within-group standard deviation \\(\\sigma_{Y|G}\\) is assumed to be equal between groups such that, \\(\\sigma_{Y|G}=\\sigma_{Y|G=1}=\\sigma_{Y|G=0}\\).\n\n\n\n\n\n\n\n\nFigure 4.2: A standardized mean difference in the population between two distributions. The mean and standard deviation of group 0 is \\(\\mu_{Y|G=0}=9\\) and \\(\\sigma_{Y|G=0}=4\\), respectively. Whereas mean and standard deviation of group \\(B\\) is \\(\\mu_{Y|G=1}=12\\) and \\(\\sigma_{Y|G=1}=4\\), respectively. Therefore the standardized mean difference is \\(\\delta_{GY} = (9-12)/4=0.75\\). Note that \\(\\sigma_{Y|G=0}=\\sigma_{Y|G=1}=\\sigma_{Y|G}\\).\n\n\n\n\n\n\n4.3.1 Sample Estimates of Effect Sizes\nThe effect size in the population of interest is a fixed value that does not change from sample to sample. However, an estimate of the effect size from sample data will vary from sample to sample. We will denote sample estimates of effect sizes with English letters as opposed to the Greek letters we used for population effect sizes.\n\nCorrelations\nThe sample estimate of a correlation is computed as follows (Pearson 1895),\n\\[\nr_{XY} := \\frac{s_{XY}}{s_{X}s_{Y}}\n\\tag{4.4}\\]\nWhere \\(s_X\\) and \\(s_Y\\) are the sample standard deviations and \\(s_{XY}\\) is the covariance. See Example 11.1 for an example of a correlation between standardized test scores.\n\nExample 4.1 (Relationship between Test Scores) In the United States, universities frequently require prospective students to take one of two standardized tests assessing academic ability, the Scholastic Achievement Test (SAT) and the American College Test (ACT). Since these tests are used interchangeably in university admission decisions, it is good to know how related the scores of these tests really are. A data set from Revelle, Wilt, and Rosenthal (2010) consists of 668 individuals who took both the SAT and the ACT. The data set splits the SAT test into Quantitative (SATQ) and Verbal (SATV) subtests which each range from 200-800, whereas the ACT is reported as a score from 1-36. We can plot out the relationship between the total SAT score (SATV + SATQ) and the ACT scores with a scatter plot2 (see Figure 4.3)\n\n\n\n\n\n\n\n\nFigure 4.3\n\n\n\n\n\nThe resulting covariance matrix between variables is displayed in Table 4.1. The covariance matrix shows the covariance between all the variables in the model. Note that the covariance between a variable and itself is equal to the variance (e.g., \\(\\sigma_{XX}=\\sigma^2_{X}\\)). Therefore the diagonal (from top-left number to bottom-right number) of the matrix are the variances of each of the variable whereas the off-diagonal is are the covariances between pairs of variables.\n\n\n\n\nTable 4.1: Covariance matrix.\n\n\n\n \n\n  \n    \n    \n    tinytable_llihsqzvugo8kkend6qp\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                Test\n                ACT\n                SATQ\n                SATV\n                SAT\n              \n        \n        \n        \n                \n                  ACT \n                   21.68\n                    299.49\n                    276.13\n                    575.61\n                \n                \n                  SATQ\n                  299.49\n                  11179.27\n                   6515.60\n                  17694.86\n                \n                \n                  SATV\n                  276.13\n                   6515.60\n                  10699.90\n                  17215.50\n                \n                \n                  SAT \n                  575.61\n                  17694.86\n                  17215.50\n                  34910.36\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\nThe correlation coefficient between total SAT (the last column) and ACT (first column) can be computed using the formula in Equation 4.4. Let’s treat SAT as our \\(X\\) variable and the ACT as our \\(Y\\) variable:\n\\[\nr_{XY} = \\frac{s_{XY}}{s_X s_Y} = \\frac{625.69}{\\sqrt{40074.40} \\times \\sqrt{22.37}} = .66\n\\]\n\n\n\nStandardized Mean Differences (SMDs)\nFor an SMD, the commonly used estimate for comparison between two independent groups is Cohen’s estimator (Cohen 1988),\n\\[\nd_{GY} = \\frac{m_{Y|G=1} - m_{Y|G=0}}{s_{Y|G}}.\n\\]\nThis is commonly referred to as Cohen’s d or simply the d statistic. The sample estimate of the standard deviation of \\(Y\\) given \\(G\\) is the pooled within-group standard deviation,\n\\[\ns_{Y|G} = \\sqrt{\\frac{(n_0 - 1)s^2_{Y|G=0} + (n_1 - 1)s^2_{Y|G=1}}{n_0 + n_1 -2}}.\n\\]\nThe within-group sample size is denoted by \\(n_0\\) and \\(n_1\\) for \\(G=0\\) and \\(G=1\\), respectively. If there is reason to believe that the variances differ between groups, such that \\(s_{Y|G=0}\\neq s_{Y|G=1}\\), then it may be best to standardize the mean difference with just one of the groups (usually a control/reference group).\n\nExample 4.2 (Gender Differences in Agreeableness) In personality psychology, the Big 5 personality traits are five dimensions where preferences and attitudes tend to vary (Agreeableness, Openness, Conscientiousness, Extraversion, and Neuroticism). Agreeableness reflects a person’s cooperativeness, politeness, kindness, friendliness, and compassion. Agreeableness also tends to differ on average between men and women, with women generally scoring higher. Using a data set from Goldberg (1999) consisting of 2800 participants, we can calculate the standardized mean difference from 2709 individuals who answered all of the items pertaining to agreeableness. The data set consists of 896 men and 1813 women who all responded to five statements related to agreeableness (e.g., “Inquire about others’ well-being”). Each participant self assessed the accuracy (from 1-Very Inaccurate to 6-Very Accurate) of each of the five statements with respect to themselves. Agreeableness is scored based on the average of their responses to all of the statements and POMP scored so 0 is the minimum possible score (very disagreeable) and 100 is the maximum possible score (very agreeable). The distributions within men and women are displayed in Figure 4.4.\n\n\n\n\n\n\n\n\nFigure 4.4: Histograms of agreeableness scores for men and women. Dark lines denote the mean for each group.\n\n\n\n\n\nThe descriptive statistics for both groups are presented in Table 4.2. We find the mean agreeableness score of women in the sample is 75.50, whereas the mean for men is 67.55. We also find the standard deviation to be 17.10 and 18.63 in women and men, respectively.\n\n\n\n\nTable 4.2: Descriptive statistics.\n\n\n\n \n\n  \n    \n    \n    tinytable_57kn2dqci2s4oudzjuc2\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                Gender\n                n\n                mean\n                sd\n              \n        \n        \n        \n                \n                  Women\n                  1813\n                  75.50\n                  17.10\n                \n                \n                  Men  \n                   896\n                  67.55\n                  18.63\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\nThe sample estimate of the SMD can be computed with the following procedure:\n\nCalculate the mean difference (denoting \\(G=1\\) as women and \\(G=0\\) as men):\n\n\\[\nm_{Y|G=1} - m_{Y|G=0} = 75.50 - 67.55 = 7.95\n\\]\n\nThen we can calculate the pooled standard deviation:\n\n\\[\\begin{align}\n        s_{Y|G} &= \\sqrt{\\frac{(n_0 - 1)s^2_{Y|G=0} + (n_1 - 1)s^2_{Y|G=1}}{n_0 + n_1 -2}} \\\\[.3em] &= \\sqrt{\\frac{(1812)17.10^2 + (895)18.63^2}{1812 + 895 -2}}\\\\[.3em] &= 17.63\n\\end{align}\\]\n\nThen we can calculate the standardized mean difference:\n\n\\[\nd_{GY} = \\frac{m_{Y|G=1} - m_{Y|G=0}}{s_{Y|G}} = \\frac{7.95}{17.63} = 0.45\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Sizes and Artifacts</span>"
    ]
  },
  {
    "objectID": "02-effect-sizes/02-effect-sizes.html#errors-in-effect-sizes",
    "href": "02-effect-sizes/02-effect-sizes.html#errors-in-effect-sizes",
    "title": "4  Effect Sizes and Artifacts",
    "section": "4.4 Errors in Effect Sizes",
    "text": "4.4 Errors in Effect Sizes\n\n4.4.1 Target Population Effect Size\nThe target population effect size is the effect size between the random variables of interest among in the population of interest. This can also be termed the statistical estimand, that is, the quantity of inferential and scientific interest.\n\n\n4.4.2 Random (Sampling) Errors\nA population effect size is a constant, unchanging value that remains fixed across repeated samples. However, a sample estimate of an effect size varies from sample to sample and does not exactly reflect the population value. This is due to the fact that randomly taking a subset of the population will contain inherent variability in the composition of the sample. Sampling errors describe the random deviations that we observe in effect size estimates between samples (Barraza et al. 2019). We can define sampling errors as the difference between the sample estimate of the effect size and the population effect size. We can define sampling errors for a sample correlation as \\(\\varepsilon_r = r_{XY} - \\rho_{XY}\\) and then we can model the sample correlation as,\n\\[\nr_{XY} = \\rho_{XY} + \\varepsilon_r.\n\\tag{4.5}\\]\nSimilarly, the SMD sample estimate can be modeled as,\n\\[\nd_{GY} = \\delta_{GY} + \\varepsilon_d.\n\\tag{4.6}\\]\nWe can quantify sampling errors by the variance of the effect size estimator, which is mostly a function of sample size3 (i.e., larger samples tend to have smaller variances). To estimate sampling variance, we have to include assumptions about the joint distribution (unless we use a non-parametric approach, e.g., bootstrap). Note that the variance of the error term is the same as the variance of the sample effect size (e.g., \\(\\mathrm{var}(r_{XY})=\\mathrm{var}(\\varepsilon_r)\\)). Although it is not necessary for the X and Y to be bivariate normal to compute a Pearson correlation, the traditional formula for sampling variance does require us to make this assumption. Let \\(X\\) and \\(Y\\) follow a bivariate normal distribution,\n\\[\nX,Y\\sim\\mathcal{N}_2\\left(\\begin{bmatrix} \\mu_{X} \\\\ \\mu_Y\\end{bmatrix},\\begin{bmatrix} \\sigma^2_{X} & \\sigma_{XY} \\\\ \\sigma_{XY}&\\sigma^2_{Y} \\end{bmatrix}\\right),\n\\]\nwhere \\(\\mathcal{N}_D\\) denotes the \\(D\\)-variate normal distribution parameterized by a mean vector and a covariance matrix. The asymptotic sampling variance of the estimator is,\n\\[\n\\mathrm{var}(r_{XY}) \\overset{_\\infty}{=} \\frac{\\left(1 - \\rho_{XY}^2\\right)^2}{n}.\n\\tag{4.7}\\]\nwhere \\(\\overset{_\\infty}{=}\\) denotes equivalency as \\(n\\rightarrow \\infty\\), hence the asymptotic sampling variance. The issue with Equation 4.7 is that it contains the population correlation which is unknown in practice. Therefore we can substitute the population correlation with the sample correlation (Bonett 2008, 174),\n\\[\n\\widehat{\\mathrm{var}}(r_{XY})= \\frac{\\left(1 - r_{XY}^2\\right)^2}{n-1}.\n\\tag{4.8}\\]\nThe denominator now uses \\(n-1\\) to adjust for the slight bias in small sample sizes. To stay consistent with many software packages we will continue to use \\(n-1\\) for the denominator, however it is worth noting that a recent simulation study by Gnambs (2023) found that the denominator of \\(n-3\\) provides slightly better variance estimates especially in small sample sizes. This difference is negligible in moderate to large samples.\nTo obtain the sampling variance for Cohen’s SMD estimator, we must assume that the conditional distribution of \\(Y\\) given \\(G\\) is normal such that,\n\\[\nY|G^{-1}(1)\\sim\\mathcal{N}_1\\left(\\mu_{Y|G=1},\\sigma^2_{Y|G}\\right),\n\\]\n\\[\nY|G^{-1}(0)\\sim\\mathcal{N}_1\\left(\\mu_{Y|G=0},\\sigma^2_{Y|G}\\right).\n\\]\nwhere \\(G^{-1}(0)\\) denotes all possible outcomes \\(\\omega\\in\\Omega\\) where \\(G(\\omega)=0\\). Notice that the variance of \\(Y\\) within \\(G=0\\) and \\(G=1\\) are equivalent in the two distributions, yet the means are allowed to differ. Given these assumptions, the asymptotic sampling variance for the SMD estimator is,\n\\[\n\\mathrm{var}\\left(d_{GY}\\right) \\overset{_\\infty}{=} \\frac{n}{n_0 n_1} + \\frac{\\delta^2_{GY}}{2n}\n\\tag{4.9}\\]\nSimilar to Equation 4.7, the population SMD \\(\\delta_{GY}\\) is not known and must be replaced with the sample estimate \\(d_{GY}\\) (J. E. Hunter and Schmidt 2015 eq. 7.23),\n\\[\n\\mathrm{var}\\left(d_{GY}\\right) = \\left(\\frac{n-1}{n-3}\\right)\\left(\\frac{n}{n_0 n_1} + \\frac{d^2_{GY}}{2n}\\right) ,\n\\tag{4.10}\\]\nwhere the term \\((n-1)/(n-3)\\) is added to account for slight bias in small samples. The sampling variances allow us to quantify how variable effect sizes are over repeated samples (\\(\\mathcal{S}_1,\\mathcal{S}_2,...\\)). For an illustration of sampling error, see Figure 4.5.\n\n\n\n\n\n\n\n\nFigure 4.5: This figure shows the distribution of sample estimates. The blue diamonds denotes the population effect size, which stays constant across samples. The black dots denote the sample effect size estimate. The grey lines denote random sampling errors, which represent the difference between the estimates and the population value. The sampling distribution on the right shows the probability distribution of estimates across repeated samples, the width of this distribution is described by the variance of the estimator. Note the illustration shows a normally distributed estimator, but this is not a requirement.\n\n\n\n\n\n\n\n4.4.3 Systematic Errors\nSampling errors produce random errors in effect sizes, however, we can also observe systematic errors. Systematic errors are deviations from the target population value that are consistent across samples and produce bias in effect size estimates. In other words, effect size estimates will be on average larger or smaller than the target population value (Barraza et al. 2019). Random sampling errors, on the other hand, will be larger or smaller than the target population value only by chance. There are two population effect sizes we need to consider: the target population effect size and the study population effect size. The target population effect size as described earlier relates the variables of interest within the population of interest. However, the study population effect size is the expectation of the effect size estimate over infinite study replications. Attenuation describes a type of systematic error where the study effect size is biased toward the null (i.e., effect size = 0). On the other hand, inflation describes the situation where the study effect size is biased away from the null. An unbiased effect size would be one where there is no systematic errors and therefore, the study population effect size is equivalent to the target population effect size. As we will see in future chapters, study artifacts such as selection effects and measurement error can produce effect sizes that contain systematic errors.\nLet’s suppose we are interested in the correlation between \\(X\\) and \\(Y\\), yet we are limited to error-prone proxies \\(\\widetilde{X}\\) and \\(\\widetilde{Y}\\). Given the potential impact of measurement error on correlations, the target population correlation \\(\\rho_{XY}\\) does not necessarily equal the study population correlation \\(\\rho_{\\widetilde{X}\\widetilde{Y}}\\). Instead we can relate them with an artifact attenuation/inflation factor \\(\\alpha\\),\n\\[\n\\rho_{\\widetilde{X}\\widetilde{Y}} = \\alpha \\rho_{XY}\n\\tag{4.11}\\]\nTherefore \\(\\alpha\\) is mathematically defined as the ratio of the study population correlation and the target population correlation,\n\\[\n\\alpha = \\frac{\\rho_{\\widetilde{X}\\widetilde{Y}}}{\\rho_{XY}}\n\\tag{4.12}\\]\nAn attenuated study population effect size would indicate that \\(\\alpha &lt; 1\\), whereas an inflated study effect size would suggest that \\(\\alpha &gt; 1\\). If the the study population correlation perfectly reflects the target population correlation, then \\(\\alpha = 1\\) which would reduce Equation 4.11 to \\(\\rho_{\\widetilde{X}\\widetilde{Y}} = \\rho_{XY}\\). A study effect size estimate denotes the estimate produced within a single study which can contain both systematic and random errors. Continuing with our example, we can model a study correlation estimate in a similar fashion to Equation 4.5,\n\\[\nr_{\\widetilde{X}\\widetilde{Y}} = \\rho_{\\widetilde{X}\\widetilde{Y}} + \\varepsilon_r\n\\]\nNotice in Figure 4.6 that the sampling distributions do not become wider or smaller with systematic errors (this may occur indirectly if the sampling variance depends on the effect size itself), instead the whole sampling distribution shifts downward or upward depending on whether the effect size estimates are attenuated or inflated, respectively.\n\n\n\n\n\n\n\n\nFigure 4.6: Three sampling distributions representing estimators that are unbiased, attenuated, and inflated. The blue line indicates the the location of the target population effect size, whereas the black dots show the effect size estimates.\n\n\n\n\n\n\n\n4.4.4 Combining Systematic and Random Errors\nAccording to Section 4.4.3, Section 12.3, and Section 4.4.1, a study effect size estimate has three components:\n\n\n\n\n\nflowchart TD\n   Z(\"target population&lt;br&gt;effect size (estimand)\") --&gt; E[\"observed effect &lt;br&gt;size estimate\"]\n   X(\"systematic &lt;br&gt;error (bias)\") --&gt; E\n   Y(\"random (sampling)&lt;br&gt;error\") --&gt; E\n\n\n\n\n\n\n\nSticking with the example of the correlation between proxies \\(\\widetilde{X}\\) and \\(\\widetilde{Y}\\), let’s construct a statistical model for a study correlation that encompasses the target population effect size, systematic error, and random sampling error,\n\\[\nr_{\\widetilde{X}\\widetilde{Y}} = \\alpha \\rho_{XY} + \\varepsilon_r\n\\tag{4.13}\\]\nNotice that we have only defined \\(\\alpha\\) in terms of the target population correlation and the study population correlation, yet of course both of these values are not available in practice. Calculating \\(\\alpha\\) is one of the primary purposes of this book as it’s value will vary depending on the types of artifact(s), the type of effect size, along with what information is available.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Sizes and Artifacts</span>"
    ]
  },
  {
    "objectID": "02-effect-sizes/02-effect-sizes.html#correcting-effect-sizes",
    "href": "02-effect-sizes/02-effect-sizes.html#correcting-effect-sizes",
    "title": "4  Effect Sizes and Artifacts",
    "section": "4.5 Correcting Effect Sizes",
    "text": "4.5 Correcting Effect Sizes\nEffect sizes can only be corrected for predictable, systematic errors. Therefore the only way to reduce random sampling error would be to increase the sample size. In principle, if we know the value of the artifact attenuation/inflation factor \\(\\alpha\\) then we could correct the observed effect size for systematic errors quite easily. Continuing with our example (correlation between proxies \\(\\widetilde{X}\\) and \\(\\widetilde{Y}\\)), the artifact attenuation/inflation factor can be divided on both sides of Equation 4.13:\n\\[\n\\frac{r_{\\widetilde{X}\\widetilde{Y}}}{\\alpha} = \\rho_{XY} + \\frac{\\varepsilon_r}{\\alpha}\n\\tag{4.14}\\]\nThe corrected correlation \\(r_{\\widetilde{X}\\widetilde{Y}}/\\alpha\\) is an unbiased estimate of the target population correlation \\(\\rho_{XY}\\). We can thus rewrite \\(r_{\\widetilde{X}\\widetilde{Y}}/\\alpha\\) as \\(r_{XY}\\),\n\\[\nr_{XY} = \\rho_{XY} + \\frac{\\varepsilon_r}{\\alpha}\n\\tag{4.15}\\]\nImportantly, the error term is also divided by \\(\\alpha\\) which will change sampling variance. The sampling error variance of the corrected correlation is\n\\[\n\\mathrm{var}(r_{XY})=\\mathrm{var}\\left(\\frac{\\varepsilon_r}{\\alpha}\\right)=\\frac{\\mathrm{var}(\\varepsilon_r)}{\\alpha^2}.\n\\tag{4.16}\\]\nLet’s consider the example of how artificial dichotomization affects correlation coefficients in Example 4.3.\n\nExample 4.3 (Social Butterflies and Wallflowers) Let’s see what happens when we dichotomize a naturally continuous variable. Using a data set of 3032 individuals from William Revelle (2023) we can look at the correlation between Sociability and Impulsivity. The scores are summation of 4-point scale responses to various emotional statements. We can denote social butterflies as individuals who have a total score that is above the median, whereas Wallflowers are individuals who are below the median. This median split turns a continuous variable into a binary one. The figure below shows the distribution of sociability with the cut-point (i.e., the median).\n\n\n\n\n\n\n\n\nFigure 4.7\n\n\n\n\n\nThe joint distribution between sociability and impulsivity is plotted twice in Figure 4.8. The plot to the left shows the total scores for sociability and impulsivity whereas the plot on the right shows the the total scores for impulsivity and dichotomized scores for sociability.\n\n\n\n\n\n\n\n\nFigure 4.8\n\n\n\n\n\nThe observed correlations between sociability and impulsivity differs when we leave sociability as it’s original score vs when we dichotomize it (see Table 4.3). However if we assume that sociability \\(X\\) and impulsivity \\(Y\\) are distributed normally, the correlation \\(r_{XY}\\) will be attenuated under dichotomization of either (or both) variables. In our case, dichotomization shrunk the correlation from \\(r_{XY}=.39\\) to \\(r_{\\widetilde{X}Y}=.31\\) (\\(\\widetilde{X}\\) is denoting dichotomized \\(X\\)). A paper by J. Hunter and Schmidt (1990) derives the attenuation factor \\(\\alpha\\) for a correlation under a median split as \\(\\alpha \\approx .80\\) (assuming the underlying continuous distribution is normal). Therefore we can take the dichotomized correlation of \\(.31\\) and divide it by \\(.80\\) to obtain a corrected correlation per Equation 4.14,\n\\[\nr_{XY} = \\frac{r_{\\widetilde{X}Y}}{\\alpha} = \\frac{.31}{.80} = .38\n\\]\n\n\n\n\nTable 4.3: Correlations between sociability and impulsivity\n\n\n\n \n\n  \n    \n    \n    tinytable_h5emtp8hto8cop1l5js7\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                Original\n                Dichotomized\n                Corrected\n              \n        \n        \n        \n                \n                  0.39\n                  0.31\n                  0.38\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\nAs we can see from the table, the corrected correlation closely aligns with the original correlation on continuous scores.\n\nThe artifact factor \\(\\alpha\\) is sometimes unknown and must be estimated. An estimate of \\(\\alpha\\) will be denoted by the English letter \\(a\\). We can relate the estimate and the true value with an error term \\(\\xi = a - \\alpha\\),\n\\[\na = \\alpha + \\xi,\n\\tag{4.17}\\]\nThe corrected effect size can then be approximated with the sample estimate and can thus be calculated by dividing the observed effect size by the estimated artifact factor. For example the corrected correlation under measurement error would be,\n\\[\nr_{XY} \\approx \\frac{r_{\\widetilde{X}\\widetilde{Y}}}{a},\n\\]\nSampling variance of the corrected effect size will lead to some analytical issues. Technically we are not able to use Equation 4.16 since \\(a\\) is not a fixed value and can vary from sample to sample. Instead, we will have to either 1) treat \\(a\\) as if it were fixed 2) use a bootstrapping procedure, or 3) use the Delta method (i.e., using a Taylor series expansion) to approximate to estimate the sampling variance. This will be discussed further in subsequent chapters.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Sizes and Artifacts</span>"
    ]
  },
  {
    "objectID": "02-effect-sizes/02-effect-sizes.html#calculating-effect-sizes-in-r",
    "href": "02-effect-sizes/02-effect-sizes.html#calculating-effect-sizes-in-r",
    "title": "4  Effect Sizes and Artifacts",
    "section": "4.6 Calculating effect sizes in R",
    "text": "4.6 Calculating effect sizes in R\nLet’s turn to R to calculate effect sizes such as correlations and standardized mean differences. We will work with the bfi data set from the psych package (William Revelle 2023) for both cases. The bfi data set consists of 5 items (6-point scales) from each of the big 5 personality traits (Agreeableness, Conscientiousness, Extraversion, Neuroticism, and Oppenness to Experience) along with some demographic variables. The total data set contains 2,800 individuals. We can start by computing a standardized mean difference (SMD) between men and women for each personality trait:\n\n\n\n\n\n\nComputing SMDs in R\n\n\n\nIn this example we will compute the standardized mean difference (SMD) between men and women in each of the big 5 personality traits. Let’s load in the packages we need (William Revelle 2023; Wickham et al. 2023; Mayer 2023; Dahlke and Wiernik 2019) and the big 5 personality data set:\n\n# load in packages\nlibrary(psych) # for data set and cohen.d function\nlibrary(dplyr) # for data cleaning\nlibrary(missRanger) # for imputation\nlibrary(psychmeta) # for calculating sampling variance\n\n# display the first 6 rows\nhead(bfi)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 N1 N2 N3 N4 N5 O1 O2 O3 O4\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4  3  4  2  2  3  3  6  3  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3  3  3  3  5  5  4  2  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5  4  5  4  2  3  4  2  5  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4  2  5  2  4  1  3  3  4  3\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5  2  3  4  4  3  3  3  4  3\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6  3  5  2  2  3  4  3  5  6\n      O5 gender education age\n61617  3      1        NA  16\n61618  3      2        NA  18\n61620  2      2        NA  17\n61621  5      2        NA  17\n61622  3      1        NA  17\n61623  1      2         3  21\n\n\nThe items are denoted with the letter pertaining to each trait it is associated with (A = Agreeableness, C = Conscientiousness, E = Extraversion, N = Neuroticism, O = Oppenness to Experience). We first can impute missing item responses with a univariate imputation procedure 4 with the missRanger::imputeUnivariate() function (Mayer 2023). Then we can calculate the total sum-scores for each of the five personality traits. Some items are reverse scored and must be flipped prior to summing.\n\ndf &lt;- bfi |&gt;\n  # Impute missing item response values with univariate imputation\n  imputeUnivariate() |&gt;\n  # Calculate sum scores\n  mutate(A = 7-A1 +   A2 + A3 +   A4   +   A5, # Agreeableness\n         C =   C1 +   C2 + C3 + 7-C4   + 7-C5, # Consientiousness\n         E = 7-E1 + 7-E2 + E3 +   E4   +   E5, # Extraversion\n         N =   N1 +   N2 + N3 +   N4   +   N5, # Neuroticism\n         O =   O1 + 7-O2 + O3 +   O4   + 7-O5) # Openness to Experience\n\nhead(df)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 N1 N2 N3 N4 N5 O1 O2 O3 O4\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4  3  4  2  2  3  3  6  3  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3  3  3  3  5  5  4  2  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5  4  5  4  2  3  4  2  5  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4  2  5  2  4  1  3  3  4  3\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5  2  3  4  4  3  3  3  4  3\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6  3  5  2  2  3  4  3  5  6\n      O5 gender education age  A  C  E  N  O\n61617  3      1         3  16 20 14 19 14 15\n61618  3      2         4  18 21 20 25 19 20\n61620  2      2         5  17 19 20 21 18 24\n61621  5      2         4  17 23 15 18 14 16\n61622  3      1         3  17 20 22 24 16 18\n61623  1      2         3  21 23 28 28 15 25\n\n\nWe can then calculate the SMD between men and women using the psych::cohen.d(). The output displays the lower bound (lower), the SMD (effect), and the upper bound (upper) in that order. It also displays the multivariate version of the SMD (i.e., Maholonobis’ D) and the SMDs converted to point-biserial correlations.\n\nresults &lt;- cohen.d(A + C + E + N + O ~ gender, data=df)\n\nresults\n\nCall: cohen.d(x = A + C + E + N + O ~ gender, data = df)\nCohen d statistic of difference between two means\n  lower effect upper\nA  0.37   0.45  0.53\nC  0.12   0.20  0.28\nE  0.15   0.23  0.31\nN  0.19   0.27  0.35\nO -0.20  -0.12 -0.04\n\nMultivariate (Mahalanobis) distance between groups\n[1] 0.66\nr equivalent of difference between two means\n    A     C     E     N     O \n 0.21  0.09  0.11  0.13 -0.06 \n\n\nWe can also extract the sampling variances for each SMD estimate by squaring the standard error calculated by the function:\n\ndata.frame(d = results$cohen.d[,\"effect\"], \n           var = results$se^2)\n\n           d         var\nA  0.4510107 0.006361921\nC  0.1980098 0.006249246\nE  0.2272884 0.006257676\nN  0.2695356 0.006272147\nO -0.1202016 0.006232197\n\n\nIf the raw data is not available, yet we want to calculate the SMD for each trait, the psych function allows us to input summary statistics. For example lets say we are given the following table:\n\n\n \n\n  \n    \n    \n    tinytable_vtf5dcakb8fvsocvz6ar\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n \nWomen (n = 919)\nMen (n = 1881)\n\n        \n              \n                traits\n                mean\n                sd\n                mean\n                sd\n              \n        \n        \n        \n                \n                  Agreeableness    \n                  23.9 \n                  4.25 \n                  21.92\n                  4.631\n                \n                \n                  Conscientiousness\n                  21.63\n                  4.675\n                  20.69\n                  4.81 \n                \n                \n                  Extraversion     \n                  21.11\n                  5.097\n                  19.92\n                  5.569\n                \n                \n                  Neuroticism      \n                  16.32\n                  5.999\n                  14.73\n                  5.676\n                \n                \n                  Openness         \n                  22.78\n                  4.013\n                  23.27\n                  4.059\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nWe can plug in the corresponding values into the m2d function to obtain the SMD d, however it does not return estimates of sampling variance, therefore we can use the var_error_d() function from the psychmeta package (Dahlke and Wiernik 2019):\n\nd &lt;- m2d(m1 = c(23.91,21.64,21.11,16.33,22.77), \n         m2 = c(21.93,20.69,19.93,14.74,23.28), \n         s1 = c(4.25,4.675,5.099,6.019,4.007),\n         s2 = c(4.635,4.824,5.574,5.702,4.052),\n         n1 = 919,\n         n2 = 1881,\n         pooled=TRUE)\n\n\n\nvar_d &lt;- var_error_d(d, n1=rep(919,5), n2 = rep(1881,5))\n\n# display results\ndata.frame(d, var = var_d, row.names = c(\"A\",\"C\",\"E\",\"N\",\"O\"))\n\n           d         var\nA  0.4387999 0.001655319\nC  0.1989268 0.001627997\nE  0.2176020 0.001629387\nN  0.2737645 0.001634315\nO -0.1263223 0.001623780\n\n\n\n\nNow we can compute the correlations between the personality traits in all participants.\n\n\n\n\n\n\nComputing Correlations in R\n\n\n\nIn this example we will compute the correlations between each of the five personality traits. Let’s load in the packages we need (William Revelle 2023; Wickham et al. 2023; Mayer 2023; Dahlke and Wiernik 2019) and the big 5 personality data set:\n\n# install.packages(\"psych\")\n# install.packages(\"dplyr\")\n# install.packages(\"missRanger\")\n# install.packages(\"psychmeta\")\n\n# load in packages\nlibrary(psych) # for data set and cohen.d function\nlibrary(dplyr) # for data cleaning\nlibrary(missRanger) # for imputation\nlibrary(psychmeta) # for calculating sampling variance\n\n# display the first 6 rows\nhead(bfi)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 N1 N2 N3 N4 N5 O1 O2 O3 O4\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4  3  4  2  2  3  3  6  3  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3  3  3  3  5  5  4  2  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5  4  5  4  2  3  4  2  5  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4  2  5  2  4  1  3  3  4  3\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5  2  3  4  4  3  3  3  4  3\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6  3  5  2  2  3  4  3  5  6\n      O5 gender education age\n61617  3      1        NA  16\n61618  3      2        NA  18\n61620  2      2        NA  17\n61621  5      2        NA  17\n61622  3      1        NA  17\n61623  1      2         3  21\n\n\nWe can calculate the scores for each of the five personality traits (i.e., Agreeableness, Conscientiousness, Extraversion, Neuroticism, and Openness to Experience) by first imputing missing values with the missRanger package (Mayer 2023)5 and then summing the scores row wise (i.e., a sum-score for each trait is calculated for each person). Some items are reverse scored and must be flipped prior.\n\ndf &lt;- bfi |&gt;\n  imputeUnivariate() |&gt;\n  mutate(A = 7-A1 +   A2 + A3 +   A4   +   A5,   # Agreeableness\n         C =   C1 +   C2 + C3 + 7-C4   + 7-C5, # Consientiousness\n         E = 7-E1 + 7-E2 + E3 +   E4   +   E5,   # Extraversion\n         N =   N1 +   N2 + N3 +   N4   +   N5,   # Neuroticism\n         O =   O1 + 7-O2 + O3 +   O4   + 7-O5) # Openness to Experience\n\nhead(df)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 N1 N2 N3 N4 N5 O1 O2 O3 O4\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4  3  4  2  2  3  3  6  3  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3  3  3  3  5  5  4  2  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5  4  5  4  2  3  4  2  5  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4  2  5  2  4  1  3  3  4  3\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5  2  3  4  4  3  3  3  4  3\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6  3  5  2  2  3  4  3  5  6\n      O5 gender education age  A  C  E  N  O\n61617  3      1         3  16 20 14 19 14 15\n61618  3      2         3  18 21 20 25 19 20\n61620  2      2         3  17 19 20 21 18 24\n61621  5      2         5  17 23 15 18 14 16\n61622  3      1         3  17 20 22 24 16 18\n61623  1      2         3  21 23 28 28 15 25\n\n\nWe can then compute the correlation matrix between all of the sum scores:\n\n# construct correlation matrix\nr_matrix &lt;- cor(df[,c(\"A\",\"C\",\"E\",\"N\",\"O\")])\nround(r_matrix,3)\n\n       A      C      E      N      O\nA  1.000  0.257  0.457 -0.184  0.148\nC  0.257  1.000  0.260 -0.233  0.193\nE  0.457  0.260  1.000 -0.222  0.213\nN -0.184 -0.233 -0.222  1.000 -0.087\nO  0.148  0.193  0.213 -0.087  1.000\n\n\nNote that the diagonals are 1 since anything correlated with itself is one. Then we can calculate the sampling variance for each element of the correlation matrix:\n\n# manually calculate sampling variance\nvar_matrix &lt;- ((1 - r_matrix^2)^2) / (nrow(df)-1)\nround(var_matrix,5)\n\n        A       C       E       N       O\nA 0.00000 0.00031 0.00022 0.00033 0.00034\nC 0.00031 0.00000 0.00031 0.00032 0.00033\nE 0.00022 0.00031 0.00000 0.00032 0.00033\nN 0.00033 0.00032 0.00032 0.00000 0.00035\nO 0.00034 0.00033 0.00033 0.00035 0.00000\n\n\nNote the diagonals will be zero since there is no uncertainty in a correlation of 1. We can also use the psychmeta::var_error_r() function (Dahlke and Wiernik 2019) to calculate the sampling variance for any given correlation (e.g., Agreeableness vs Conscientiousness)\n\n## [1] 0.0003116634\n\nAs we can see, the var_error_r function produces identical results as the manual variance calculation.\n\n\n\n\n\n\nBarraza, Felipe, Marcelo Arancibia, Eva Madrid, and Cristian Papuzinski. 2019. “General Concepts in Biostatistics and Clinical Epidemiology: Random Error and Systematic Error.” Medwave 19 (7): e7687. https://doi.org/10.5867/medwave.2019.07.7687.\n\n\nBonett, Douglas G. 2008. “Meta-Analytic Interval Estimation for Bivariate Correlations.” Psychological Methods 13 (3): 173–81. https://doi.org/10.1037/a0012868.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Academic Press.\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “Psychmeta: An R Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nEnders, Craig K. 2022. Applied Missing Data Analysis. Guilford Publications.\n\n\nGnambs, Timo. 2023. “A Brief Note on the Standard Error of the Pearson Correlation.” Collabra: Psychology 9 (1): 87615. https://doi.org/10.1525/collabra.87615.\n\n\nGoldberg, Lewis. 1999. “Public Domain, Personality Inventory Measuring the Lower-Level Facets of Several Five-Factor Models.” Personality Psychology in Europe 7: 7–28. https://cir.nii.ac.jp/crid/1571417125727416704.\n\n\nHunter, John E., and Frank L. Schmidt. 2015. Methods of meta-analysis: correcting error and bias in research findings (third). Third. Thousand Oaks, California: Sage Publications.\n\n\nHunter, John, and Frank Schmidt. 1990. “Dichotomization of Continuous Variables: The Implications for Meta-Analysis.” Journal of Applied Psychology 75 (June): 334–49. https://doi.org/10.1037/0021-9010.75.3.334.\n\n\nMayer, Michael. 2023. missRanger: Fast Imputation of Missing Values. https://CRAN.R-project.org/package=missRanger.\n\n\nPearson, Karl. 1895. “Notes on the History of Correlation.” Society of Biometricians and Mathematical Statisticians. https://doi.org/10.2307/2331722.\n\n\nRevelle, William, Joshua Wilt, and Allen Rosenthal. 2010. “Individual Differences in Cognition: New Methods for Examining the Personality-Cognition Link.” In, edited by Aleksandra Gruszka, Gerald Matthews, and Blazej Szymura, 27–49. New York, NY: Springer. https://doi.org/10.1007/978-1-4419-1210-7_2.\n\n\nVan Buuren, Stef. 2018. Flexible Imputation of Missing Data. CRC press.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWilliam Revelle. 2023. Psych: Procedures for Psychological, Psychometric, and Personality Research. Evanston, Illinois: Northwestern University. https://CRAN.R-project.org/package=psych.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Sizes and Artifacts</span>"
    ]
  },
  {
    "objectID": "02-effect-sizes/02-effect-sizes.html#footnotes",
    "href": "02-effect-sizes/02-effect-sizes.html#footnotes",
    "title": "4  Effect Sizes and Artifacts",
    "section": "",
    "text": "Effect sizes can be defined more broadly as the association between multiple variables, however this book will only focus on the more narrow case of just two variables.↩︎\n1: Individuals who did not complete any one of the tests or who scored well below the expected guessing score (ACT &lt; 10, SATQ &lt; 300, SATV &lt; 300). ↩︎\n2: sampling variances often change with the location of the effect size, for example, the correlation coefficient has a variance of 0 when the correlation is unity no matter the sample size.↩︎\nThis may or may not be the optimal approach to imputing missing values, but imputation best practice is beyond the scope of this book. For information on imputation methods and best practice see Enders (2022) and Van Buuren (2018)↩︎\nThis may or may not be the optimal approach to imputing missing values, but imputation best practice is beyond the scope of this book. For information on imputation methods and best practice see Enders (2022) and Van Buuren (2018)↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Sizes and Artifacts</span>"
    ]
  },
  {
    "objectID": "03-small-samples/03-small-samples.html",
    "href": "03-small-samples/03-small-samples.html",
    "title": "5  Small Samples",
    "section": "",
    "text": "5.1 Introduction\nThe purpose of sample estimates is to draw inferences about the population effect sizes. However, effect size estimators such as Pearson’s correlation coefficient and Cohen’s \\(d\\) are biased in small sample sizes. This small sample bias can be construed as an artifact and can be adjusted with the appropriate correction factor.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Small Samples</span>"
    ]
  },
  {
    "objectID": "03-small-samples/03-small-samples.html#correcting-smds",
    "href": "03-small-samples/03-small-samples.html#correcting-smds",
    "title": "5  Small Samples",
    "section": "5.2 Correcting SMDs",
    "text": "5.2 Correcting SMDs\n\n5.2.1 Defining the Target SMD\nOur quantity of interest is the population SMD, \\(\\delta_{GY}\\). For now, let the asterisk \\(*\\) denote the Cohen’s sample estimator defined in the previous chapter, \\(d^*_{GY}\\). We can model the relationship between the population standardized mean difference and the estimate as,\n\\[\nd^*_{GY} = \\alpha\\delta_{GY}+\\varepsilon_d.\n\\]\nWhere \\(\\alpha\\) is an attenuation/inflation factor and \\(\\varepsilon\\) is our sampling error term.\n\n\n5.2.2 Artifact Correction for SMDs\nAs the sample size approaches infinity, Cohen’s estimator of the standardized mean difference is unbiased (Hedges 1981; Cohen 2013). However, in small sample sizes Cohen’s estimator is inflated, that is, on average, it overestimates the population standardized mean difference. To see why this is the case, we can first define the population standardized mean difference between group \\(A\\) and group \\(B\\) such that,\n\\[\n\\delta = \\frac{\\mu_{Y|G=0}-\\mu_{Y|G=0}}{\\sigma_{Y|G}}.\n\\]\nCohen’s sample estimator (Cohen 1988) of the SMD is,\n\\[\nd^*_{GY} = \\frac{m_{Y|G=0}-m_{Y|G=0}}{s_{Y|G}},\n\\tag{5.1}\\]\nwhere \\(s_{Y|G}\\) is calculated from pooling the within-group standard deviations. The estimator, \\(d^*_{GY}\\), is an asymptotically unbiased estimate of \\(\\delta_{GY}\\) as \\(n\\rightarrow \\infty\\). However, \\(d^*_{GY}\\) is a biased estimator of \\(\\delta_{GY}\\) when the sample size is finite (\\(n&lt;\\infty\\)). Particularly, the smaller the sample size, the larger the bias. We can see that in Figure 5.1, \\(d^*_{GY}\\) tends to over-estimates \\(\\delta_{GY}\\), therefore \\(d^*_{GY}\\) is an inflated estimator of \\(\\delta_{GY}\\). To obtain an unbiased estimate of the population standardized mean difference, we need to first calculate the artifact inflation factor, \\(\\alpha\\). Before we can calculate \\(\\alpha\\) we have to assume that the distribution of \\(Y\\) conditioned on \\(G\\) is normal such that,\n\\[\nY|G^{-1}(0)  \\sim \\mathcal{N}_1(\\mu_{Y|G=0},\\sigma^2_{Y|G})\n\\]\n\\[\nY|G^{-1}(1) \\sim \\mathcal{N}_1(\\mu_{Y|G=1},\\sigma^2_{Y|G})\n\\]\nRecall that the inverse of a random variable will return the subset of the sample space assigned that value (e.g., \\(G^{-1}(0)\\subset \\Omega\\)). In this case, the artifact inflation factor has been derived previously by Hedges (1989). For other types of artifacts, \\(\\alpha\\) is unknown in practice and must be estimated, however, for small sample bias the exact value of \\(\\alpha\\) is known (provided the distributional assumptions are true). The precise value of \\(\\alpha\\) is a function of sample size (equation 6e, Hedges 1989),\n\\[\n\\alpha = \\frac{\\Gamma\\left(\\frac{n-3}{2}\\right)\\sqrt{\\frac{n-2}{2}}}{\\Gamma\\left(\\frac{n-2}{2}\\right)}.\n\\]\nWhere \\(\\Gamma(\\cdot)\\) denotes the gamma function. The gamma function is factorial function generalized to non-integers (note that a factorial function on integers would look something like: \\(4! = 4 \\cdot 3 \\cdot 2 \\cdot 1\\), Taboga 2021). There is also an approximation of \\(\\alpha\\) that is more computationally trivial (re-arrangement of the first formula on pp. 114, Hedges 1989):\n\\[\n\\alpha \\approx \\frac{4n-9}{4n-12}\n\\]\nHowever, with the advent of computers, this approximation formula is unnecessary. We can see in Figure 5.1 that there is notable bias when sample size is below 20. Furthermore, the bias is most pronounced when the sample SMD value is larger (there is no bias at \\(d*_{GY}=0\\)).\n\n\n\n\n\n\n\n\nFigure 5.1: Plot showing the bias in the standardized mean difference computed in small samples. The X-axis is the sample size (\\(n\\), the vertical bars are indicative of each integer). The Y-axis is the the estimated standardized mean difference (\\(d\\)). The dark pink coloring indicates more bias where \\(\\mathsf{bias} = \\mathbb{E}[d]-\\delta\\).\n\n\n\n\n\nUsing value of \\(\\alpha\\), we can correct the \\(d\\) value such that,\n\\[\nd_{GY} = \\frac{d^*_{GY}}{\\alpha} = \\frac{d^*_{GY}}{ \\left[\\frac{\\Gamma\\left(\\frac{n-3}{2}\\right)\\sqrt{\\frac{n-2}{2}}}{\\Gamma\\left(\\frac{n-2}{2}\\right)}\\right]}.\n\\tag{5.2}\\]\nTo obtain the sampling variance of \\(d_{GY}\\), since we the value of \\(alpha\\) is fixed for a given sample size we can simply divide the sampling variance of \\(d^*_{GY}\\) by \\(\\alpha^2\\),\n\\[\n\\mathrm{var}(d_{GY}) = \\frac{\\mathrm{var}(d^*_{GY})}{\\alpha^2} = \\frac{\\mathrm{var}(d^*_{GY})}{ \\left[\\frac{\\Gamma\\left(\\frac{n-3}{2}\\right)\\sqrt{\\frac{n-2}{2}}}{\\Gamma\\left(\\frac{n-2}{2}\\right)}\\right]^2}.\n\\tag{5.3}\\]\n\nExample 5.1 (English Vocabulary Performance) The General Social Survey (GSS) is a large national survey conducted by the University of Chicago. The survey includes data on English vocabulary knowledge from 28,867 individuals. Vocabulary scores are calculated by asking respondents about their knowledge of 10 words and the number of words they know out of 10 is their vocabulary score. For many immigrants coming to the the United States, English is not their first language so there is reason to believe that individuals born in the United states will see higher vocabulary scores than those who were not. Let’s say we were to conduct a study on a small 20 person sample of the GSS sample,\n\n\n\n\n\n\n\n\nFigure 5.2\n\n\n\n\n\nThe sample SMD between native born individuals and immigrants using Cohen’s estimator of the standardized mean difference is \\(d^*_{GY}=.78\\). The correction factor can be applied to obtain an unbiased estimate of the population SMD,\n\\[\nd_{GY} = \\frac{d^*_{GY}}{\\alpha} = \\frac{d^*_{GY}}{ \\left[\\frac{\\Gamma\\left(\\frac{n-3}{2}\\right)\\sqrt{\\frac{n-2}{2}}}{\\Gamma\\left(\\frac{n-2}{2}\\right)}\\right]} = \\frac{.78}{ \\left[\\frac{42103.23}{40320}\\right]} = .75.\n\\]\nNote that \\(\\Gamma(\\cdot)\\) can be solved in R with the gamma() function. Notice that the correction is small, since the bias observed with moderate to large sample sizes becomes quite small.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Small Samples</span>"
    ]
  },
  {
    "objectID": "03-small-samples/03-small-samples.html#correcting-correlations",
    "href": "03-small-samples/03-small-samples.html#correcting-correlations",
    "title": "5  Small Samples",
    "section": "5.3 Correcting Correlations",
    "text": "5.3 Correcting Correlations\n\n5.3.1 Defining the Target Correlation\nOur target quantity is the population correlation, \\(\\rho_{XY}\\). We can model the relationship between the population correlation and Pearson’s sample estimator (\\(r^*_{XY}\\)) with,\n\\[\nr^*_{XY} = \\alpha\\rho_{XY}+\\varepsilon_r\n\\]\nWhere \\(a\\) is our small sample biasing factor and \\(e\\) is our sampling error term.\n\n\n5.3.2 Artifact Correction for Correlations\nLet’s first define the correlation in the population as the covariance between \\(X\\) and \\(Y\\) (\\(\\sigma_{XY}\\)) standardized by the product of the standard deviation of \\(X\\) (\\(\\sigma_X\\)) and \\(Y\\) (\\(\\sigma_Y\\)):\n\\[\n\\rho = \\frac{\\sigma_{XY}}{\\sigma_{X}\\sigma_Y}.\n\\]\nPearson’s sample estimator can be defined as,\n\\[\nr_{XY} = \\frac{s_{XY}}{s_{X}s_Y}\n\\]\nAssuming the joint distribution of \\(X\\) and \\(Y\\) is normal such that,\n\\[\nX,Y\\sim\\mathcal{N}_2\\left(\\begin{bmatrix} \\mu_{X} \\\\ \\mu_Y\\end{bmatrix},\\begin{bmatrix} \\sigma^2_{X} & \\sigma_{XY} \\\\ \\sigma_{XY}&\\sigma^2_{Y} \\end{bmatrix}\\right),\n\\]\nthen Pearson’s sample estimator will be attenuated in small samples (Olkin and Pratt 1958). Then attenuation factor \\(\\alpha\\) was derived by Olkin and Pratt (1958, eq. 2.3),\n\\[\n\\alpha = \\frac{1}{F\\left(\\frac{1}{2},\\frac{1}{2};\\frac{n-1}{2};1-\\left(r^*_{XY}\\right)^2\\right)}.\n\\tag{5.4}\\]\nWhere \\(F(\\cdot)\\) is the hypergeometric function. The hypergeometric function is a complicated and iterative function which which can be defined in terms of \\(\\Gamma(\\cdot)\\) functions (plugging in values into equation 2.2, Olkin and Pratt 1958)\n\\[\nF\\left(\\frac{1}{2},\\frac{1}{2};\\frac{n-1}{2};1-\\left(r^*_{XY}\\right)^2\\right) = \\sum^{\\infty}_{z=0} \\frac{\\Gamma\\left(\\frac{1}{2} + z\\right)\\Gamma\\left(\\frac{n-1}{2}\\right)\\left(1-\\left(r^*_{XY}\\right)^2\\right)^z}{\\Gamma\\left(\\frac{1}{2}\\right)\\Gamma\\left(\\frac{n-1}{2}+z\\right)z!}\n\\]\nAlthough this formula is complex, it can be easily done in R so do not worry! There is also an approximation of \\(\\alpha\\) that is much simpler than Equation 5.4,\n\\[\na \\approx \\frac{2(n-3)}{2n-\\left(r^*_{XY}\\right)^2-5}\n\\]\nThen we can correct the point-estimate the sampling variance for small sample bias. I will emphasize again that approximations are not necessary if a computer is available. We can see in Figure 5.3 that there is notable bias when sample size is below 15. Furthermore, the bias is most pronounced when the sample correlation around .60 (there is no bias at \\(r=0\\) and \\(r=\\pm 1\\)).\n\n\n\n\n\n\n\n\nFigure 5.3: Plot showing the bias in the correlations computed in small samples. The X-axis is the sample size (\\(n\\), the vertical bars are indicative of each integer). The Y-axis is the the estimated Pearson correlation (\\(r_{XY}\\)). The dark pink coloring indicates more bias.\n\n\n\n\n\nTo correct for small sample bias, we can divide the sample correlation \\(r\\) by the attenuation factor \\(\\alpha\\),\n\\[\nr_{XY} = \\frac{r^*_{XY}}{\\alpha} = \\frac{r^*_{XY}}{1/F\\left(\\frac{1}{2},\\frac{1}{2};\\frac{n-1}{2};1-(r^*_{XY})^2\\right)}\n\\tag{5.5}\\]\nWhere the sampling variance of \\(r_{XY}\\) can be obtained by correcting the observed sampling variance (\\(\\mathrm{var}\\left(r^*_{XY}\\right)\\)),\n\\[\n\\mathrm{var}\\left(r_{XY}\\right) = \\frac{\\mathrm{var}\\left(r^*_{XY}\\right)}{\\alpha^2} = \\frac{\\mathrm{var}\\left(r^*_{XY}\\right)}{\\left[1/F\\left(\\frac{1}{2},\\frac{1}{2};\\frac{n-1}{2};1-r^2\\right)\\right]^2}\n\\tag{5.6}\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Small Samples</span>"
    ]
  },
  {
    "objectID": "03-small-samples/03-small-samples.html#small-sample-correction-in-r",
    "href": "03-small-samples/03-small-samples.html#small-sample-correction-in-r",
    "title": "5  Small Samples",
    "section": "5.4 Small Sample Correction in R",
    "text": "5.4 Small Sample Correction in R\n\n\n\n\n\n\nHeight and Weight (Fake Data)\n\n\n\nLet’s say we compute a correlation of \\(r_{XY}=.63\\) between height and weight in a sample of 20 individuals and an SMD of \\(d_{XY}=.80\\) between the height of males (\\(n_0=10\\)) and females (\\(n_1=10\\)) in the same sample. In R, we can use the escalc function in the metafor package (Viechtbauer 2010) to calculate the sample estimates corrected for bias in small samples. For the correlation, we can set the measure argument to be measure = \"UCOR\" which will produce an Unbiased CORrelation equivalent to the correction we see in Equation 5.5,\n\n# install.packages('metafor')\n# install.packages('gsl')\nlibrary(metafor)\n\nrXY_obs &lt;- .63  # Pearson's sample estimator\nn &lt;- 20 # sample size\n\n# correct the correlation\nescalc(measure = 'UCOR',\n       ri = rXY_obs,\n       ni = n,\n       var.names = c(\"rXY\", \"var\"), # label output\n       digits = 3) # round digits to third decimal\n\n\n    rXY   var \n1 0.641 0.018 \n\n\nAs we can see the output shows a corrected correlation that is a bit larger than the observed Pearson correlation. To correct the SMD for small sample bias we can use the same function (escalc()) but with this time we can set the measure argument to be measure = \"SMD\" which corrects the Cohen’s sample estimator.\n\ndGY_obs &lt;- .80  # Pearson's sample estimator\nn0 &lt;- n1 &lt;- 10 # within-group sample sizes\n\n# correct the correlation\nescalc(measure = 'SMD',\n       di = dGY_obs,\n       n1i = n0,\n       n2i = n1,\n       var.names = c(\"dGY\", \"var\"), # label output\n       digits = 3) # round digits to third decimal\n\n\n    dGY   var \n1 0.766 0.215 \n\n\nAs expected, the corrected SMD is slightly adjusted to be smaller than the observed correlation.\n\n\n\n\n\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Academic Press.\n\n\n———. 2013. Statistical Power Analysis for the Behavioral Sciences. Academic Press.\n\n\nHedges, Larry V. 1981. “Distribution Theory for Glass’s Estimator of Effect Size and Related Estimators.” Journal of Educational Statistics 6 (2): 107–28. https://doi.org/10.3102/10769986006002107.\n\n\n———. 1989. “An Unbiased Correction for Sampling Error in Validity Generalization Studies.” Journal of Applied Psychology 74 (3): 469–77. https://doi.org/10.1037/0021-9010.74.3.469.\n\n\nOlkin, Ingram, and John W. Pratt. 1958. “Unbiased Estimation of Certain Correlation Coefficients.” The Annals of Mathematical Statistics 29 (1): 201–11. https://www.jstor.org/stable/2237306.\n\n\nTaboga, Marco. 2021. “Gamma Function.” https://www.statlect.com/mathematical-tools/gamma-function.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting meta-analyses in R with the metafor package.” Journal of Statistical Software 36 (3): 1–48. https://doi.org/10.18637/jss.v036.i03.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Small Samples</span>"
    ]
  },
  {
    "objectID": "04-introduction-to-measurement-error/04-introduction-to-measurement-error.html",
    "href": "04-introduction-to-measurement-error/04-introduction-to-measurement-error.html",
    "title": "Measurement Error",
    "section": "",
    "text": "Introduction\nIn general terms, measurement is the process of quantifying an attribute or characteristic of something. In scientific measurement, the measurand is the quantity or the attribute we intend to measure modeled as a random variable of interest. In the psychological sciences for example, measurands usually take the form of constructs such as intelligence or anxiety and it is the goal of measurement to produce quantities (i.e., scores) that accurately reflect individual differences in these constructs. However, in this book we interpret measurement more broadly such that meausurands do not have to reflect a real attribute of interest, instead they can be useful indices that have useful predictive value (e.g., socio-economic status, body mass index). This section of the book will cover various types of errors: classical errors, group misclassification, artificial dichotomization, and scale coarseness.",
    "crumbs": [
      "Measurement Error"
    ]
  },
  {
    "objectID": "05-error-in-continuous-variables/05-error-in-continuous-variables.html",
    "href": "05-error-in-continuous-variables/05-error-in-continuous-variables.html",
    "title": "6  Classical Measurement Errors",
    "section": "",
    "text": "6.1 Introduction\nMeasurements are often calibrated to their true value such that errors over repeated measurements tend to cancel out. In cases like this, averaging across the outcomes of multiple measurements may provide a more precise value. However, not all measures are created equal, some perform better than others. Ideally, measurement procedures should produce consistent scores upon repeated measurements. This repeatability is referred to as the reliability of a measure. A high quality measure should produce highly reliable scores. This section will review what reliability is in theory, how to estimate reliability, and how to correct effect sizes for measurement error.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classical Measurement Errors</span>"
    ]
  },
  {
    "objectID": "05-error-in-continuous-variables/05-error-in-continuous-variables.html#classical-measurement-error-calibration",
    "href": "05-error-in-continuous-variables/05-error-in-continuous-variables.html#classical-measurement-error-calibration",
    "title": "6  Classical Measurement Errors",
    "section": "6.2 Classical Measurement Error Calibration",
    "text": "6.2 Classical Measurement Error Calibration\nThe values of a target random variable are often referred to as true score and can be defined by some real characteristic or quality of an individual that is independent of the measurement procedure (e.g., height of a person), we can consider this a realist approach. However, if the underlying data generating process is unknown, one could opt to define the true score as the expected value of measurement outcomes (e.g., average reaction time over repeated trials), which can be thought of as an operationalist approach. Therefore if we take the operationalist approach, a convenient way to define the true scores for each individual is as follows:\n\\[\nX := \\mathbb{E}\\left[\\widetilde{X}\\;\\middle|\\; \\mathcal{M}_\\ell \\right],\n\\tag{6.1}\\]\nWhere \\(\\mathcal{M}\\) is defined as the \\(\\sigma\\)–field generated by the assignment-to-individual function \\(\\ell\\),\n\\[\n\\mathcal{M}_\\ell = \\left\\lbrace\\ell^{-1}(\\psi) \\;\\middle|\\; \\psi\\in\\Psi \\right\\rbrace \\subset \\mathcal{F}_{\\Omega}\n\\]\nwhere \\(\\psi\\in\\Psi\\) is an individual \\(\\psi\\) in the population of interest \\(\\Psi\\) and \\(\\mathcal{F}_{\\Omega}\\) is the \\(\\sigma\\)–field over the outcome space \\(\\Omega\\). Put in simpler words, the true score for an individual \\(\\psi\\in\\Psi\\) is defined as the expected value over all possible measurement outcomes for that individual. This is definition of true scores that is typically attributed to Classical Test Theory (Donald W. Zimmerman 1975). As a consequence, this definition of true scores produces the following properties (Kroc and Zumbo 2020),\n\\[\\begin{align}\n&\\mathrm{I.}\\;\\;\\;\\sigma_{XE_X}=0 \\\\[.3em]\n&\\mathrm{II.}\\;\\;\\;\\mathbb{E}\\!\\left[E_X\\right]\\!=0\n\\end{align} \\tag{6.2}\\]\nwhere \\(\\sigma_{XE_X}\\) is the covariance between the true value \\(X\\) and the associated error \\(E_X\\). Property \\(\\mathrm{I}\\) ensures that there is no correlation between true scores and errors whereas property \\(\\mathrm{II}\\) ensures that errors have a mean of zero in the population. A realist approach to measurement posits that \\(X\\) is not defined by the expectation of measurement outcomes, rather it is defined by a measurement independent attribute/characteristic. With this definition of true scores, properties \\(\\mathrm{I}\\) and \\(\\mathrm{II}\\) are not automatically true. If reasonable, the realist can assume that properties \\(\\mathrm{I}\\) and \\(\\mathrm{II}\\) are met. If the realist assumes these properties are met, then Equation 6.1 is a necessary consequence of those assumptions. In sum, the important difference between the realist and operationalist is that the properties described in Equation 6.2 must be assumed by the realist whereas it is a consequence of the definition of true scores for the operationalist.\nLet’s denote a single instance of a measurement outcome with \\(\\widetilde{X}_{\\mathsf{m}}:=\\widetilde{X}(\\omega)\\) and a single instance of the true score \\(X:=X(\\omega)\\) for some outcome \\(\\omega\\in\\ell^{-1}(\\psi)\\) for each individual \\(\\psi\\in\\Psi\\). The subscript \\(\\mathsf{m}\\) indexes the outcomes of a single measurement instance. Since the true score is fixed over all possible measurement outcomes within an individual this index is not needed for \\(X\\). For a measurement \\(\\mathsf{m}\\), we can relate the true score \\(X\\) and the observed score \\(\\widetilde{X}_\\mathsf{m}\\) with the following algebraic structure,\n\\[\n\\widetilde{X}_{\\mathsf{m}} = X + E_{X\\mathsf{m}}\n\\tag{6.3}\\]\nwhere the error is defined as \\(E_{X\\mathsf{m}} = \\widetilde{X}_{\\mathsf{m}} - X\\). Since we have established that the covariance between \\(X\\) and \\(E_X\\) is zero, we can easily parse out the variance of the three components in Equation 6.3,\n\\[\n\\sigma^2_\\widetilde{X} = \\sigma^2_X + \\sigma^2_{E_X}.\n\\]\nWe can see that the variance of observed scores is a simple summation of the variance of true scores and error which tells us that if the measure was perfect (i.e., no measurement error) than the error variance would be zero and \\(\\sigma^2_\\widetilde{X} = \\sigma^2_X\\).",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classical Measurement Errors</span>"
    ]
  },
  {
    "objectID": "05-error-in-continuous-variables/05-error-in-continuous-variables.html#sec-true-score-theory",
    "href": "05-error-in-continuous-variables/05-error-in-continuous-variables.html#sec-true-score-theory",
    "title": "6  Classical Measurement Errors",
    "section": "6.3 Reliability",
    "text": "6.3 Reliability\nThe reliability of \\(X\\) is defined as the variance of true scores over the variance in observed proxy scores \\(X\\) (i.e., an intra-class correlation),\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'} = \\frac{\\sigma^2_X}{\\sigma^2_\\widetilde{X}}= \\frac{\\sigma^2_X}{\\sigma^2_X + \\sigma^2_{E_X}}\n\\tag{6.4}\\]\nHowever we can also express it as the correlation between between two parallel measurements. Strictly parallel measurements have the following four properties (p. 69, Haertel 2006):\n\nMeasurements have identical specifications. That is, each measurement uses the same measurement procedure.\nThe distribution of observed scores for each measurement are identical: \\(f_{\\widetilde{X}_1} = f_{\\widetilde{X}_2} = \\dots\\)\nAny set of two measurements are assumed to covary the same as any other set of two measurements: \\(\\sigma_{\\widetilde{X}_1 \\widetilde{X}_2} = \\sigma_{\\widetilde{X}_2 \\widetilde{X}_3} = \\sigma_{\\widetilde{X}_1 \\widetilde{X}_3} = \\ldots\\)\nEach measurement equally covaries with any other variable: \\(\\sigma_{\\widetilde{X}_1 Y} = \\sigma_{\\widetilde{X}_2 Y} = \\ldots\\)\n\nThese properties will be useful especially when we discuss composite scores. The correlation between parallel measurements can also be expressed by the square of the correlation between observed proxy scores and true scores, \\(\\rho_{X\\widetilde{X}}^2\\) . To understand why this is the case, note that the covariance between parallel forms of a measure is equivalent to the covariance between observed scores and true scores, \\(\\sigma_{\\widetilde{X}X}=\\)\\(\\sigma_{(\\widetilde{X}+E_X)X}=\\)\\(\\sigma^2_X + \\sigma_{XE_X}=\\)\\(\\sigma^2_X = \\sigma_{\\widetilde{X}\\widetilde{X}'}\\) (Haertel 2006),\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'} = \\frac{\\sigma_X^2}{\\sigma_\\widetilde{X}^2} = \\frac{\\left(\\sigma_X^2\\right)^2}{\\sigma_\\widetilde{X}^2 \\sigma_X^2}= \\frac{\\sigma_{\\widetilde{X}X}^2}{\\sigma^2_\\widetilde{X}\\sigma^2_X} = \\rho^2_{X\\widetilde{X}}.\n\\tag{6.5}\\]\nEstimating reliability can easily be done if a researcher has access to parallel measurements as they would simply need to compute the correlation between the two sets of observed scores. This is not always the case however, therefore we will cover different ways of calculating the reliability of a measure depending on the available data\n\n6.3.1 Reliability of Composites\nComposite measurements try to average across multiple sub-measurements (i.e., items, trials, ratings) to obtain a more precise score. Let \\(\\mathsf{\\tilde{x}}_q\\) denote the outcome of sub-measurement \\(q\\) such that,\n\\[\n\\mathsf{\\tilde{x}}_q= \\mathsf{x}_q + \\mathsf{e}^\\mathsf{x}_q\n\\tag{6.6}\\]\nWhere \\(q=1{...}\\kappa\\) indexes the sub-measurement, \\(\\mathsf{x}_q\\) denotes the true score and \\(\\mathsf{e}^\\mathsf{x}_q\\) denotes the error of the \\(q\\)th sub-measurement. Each of the three components in Equation 6.6 are defined similarly to Equation 6.3 with the exception that the true score (the expected value) is allowed to vary between sub-measurements. A composite score reduces measurement error by combining multiple sub-measurements together. Therefore, measurement \\(\\mathsf{m}\\) of some individual \\(\\psi\\in\\Psi\\) is a weighted average of sub-measurement outcomes,\n\\[\n\\widetilde{X}_\\mathsf{m} = \\frac{\\sum^q_{1...\\kappa}\\mathsf{w}_q\\mathsf{\\tilde{x}}_q}{\\sum^q_{1...\\kappa}\\mathsf{w}_q}\n\\tag{6.7}\\]\nClearly, if the weights are uniform \\(\\mathsf{w}_1=\\mathsf{w}_2=...=\\mathsf{w}_\\kappa\\), then the composite becomes an unit-weighted average. Note that the weighted average of true sub-scores \\(\\mathsf{x}_q\\) is equal to the true score \\(X\\).\nThe estimating the reliability of the composite \\(\\widetilde{X}\\) is the primary purpose of this section. Before we can do that, we have to acknowledge that certain reliability coefficients, assumptions must be made that are analogous to the four assumptions about strictly parallel measurements. Depending on the reliability coefficient, not all of four of the assumptions of strictly parallel sub-measurements have to be met. Instead, we can talk about three conditions that hold different assumptions (Haertel 2006, 71):\n\nTau-equivalence: this is the strongest of the three conditions where true scores are fixed across sub-measurements \\(\\mathsf{x}_{1} = \\mathsf{x}_{2} = \\dots\\) as well as true variances are equivalent \\(\\sigma^2_\\mathsf{x_1} = \\sigma^2_\\mathsf{x_2} = \\dots\\). However, the variance of observed scores are allowed to vary between sub-measurements, in other words, the errors .\nEssential Tau-equivalence: this condition is looser than tau-equivalence as it allows the true score to vary between sub-measurements. Each sub-measurement is related to each other by an additive constant such that, \\(\\mathsf{x}_{1} = \\mathsf{x}_{2} + \\mathsf{c}_{12}\\) (note that this constant is the same for all individuals). The true variances still must be equivalent \\(\\sigma^2_\\mathsf{x_1} = \\sigma^2_\\mathsf{x_2}\\). However, the variance of observed scores are still allowed to vary between sub-measurements.\nCongeneric Measurements: this is the loosest of the three conditions. Congeneric measurements do not require that true variances are equal between sub-measurements are equal because now it relates the true scores between measurements as a linear function, \\(\\mathsf{x}_{1} = \\mathsf{b}_{12}\\mathsf{x}_{2} + \\mathsf{c}_{12}\\). This allows the mean and variance of the true scores to differ across sub-measurements.\n\n\n\n\n\n\n\n\n\nFigure 6.1: Figures showing the observed scores upon 10 sub-measurements and the composite observed score (dark point + error bars). The left panel shows a score with low reliability and the right shows an observed score with high reliability.\n\n\n\n\n\n\nCoefficient Alpha\nThe most common reliability coefficient in psychological and social sciences is Coefficient alpha (also referred to as Cronbach’s Alpha, Cronbach 1951). Coefficient alpha assumes the sub-measurements meet the conditions described by essential tau-equivalence. If the sub-measurements are not essentially tau-equivalent than Coefficient alpha is a lower bound (something to keep in mind when we are correcting effect sizes). The equation for the unstandardized version of Coefficient alpha is,\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'} = \\frac{\\kappa \\,\\bar{\\sigma}_{\\mathsf{\\tilde{x}}_q\\mathsf{\\tilde{x}}_j}}\n{\\bar{\\sigma}^2_{\\mathsf{\\tilde{x}}_q}+\n(\\kappa-1)\\bar{\\sigma}_{\\mathsf{\\tilde{x}}_q\\mathsf{\\tilde{x}}_j}}\\, , \\;\\;\\;\\;q\\neq j.\n\\tag{6.8}\\]\nwhere \\(\\bar{\\sigma}_{\\mathsf{x}_q\\mathsf{x}_j}\\) is the average of the off-diagonal elements of the covariance matrix (i.e., \\(q\\neq j\\)) and \\(\\bar{\\sigma}^2_{\\mathsf{x}_q}\\) is the average variance in observed scores across \\(\\kappa\\) sub-measurements. Since covariance matrices are not always available to calculate may be unavailable, so instead we can compute a standardized alpha coefficient using the correlation matrix (Charles Spearman 1910; Brown 1910),\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'} = \\frac{\\kappa \\,\\bar{\\rho}_{\\mathsf{\\tilde{x}}_q\\mathsf{\\tilde{x}}_j}}\n{1+\n(\\kappa-1)\\bar{\\rho}_{\\mathsf{\\tilde{x}}_q\\mathsf{\\tilde{x}}_j}}\\, , \\;\\;\\;\\;q\\neq j.\n\\tag{6.9}\\]\nAnother situation where standardized alpha is preferrable is sub-measurements were on completely different scales and therefore scores had to be standardized before combining them together. The standardized coefficient alpha assumes The equation can simplify further if you have only two measurements. For the unstandardized variant of coefficient alpha, if there are only two sub-measurements than it reduces to a split-half reliability (Rulon 1939, eq. 53),\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'} = \\frac{4\\,\\bar{\\sigma}_{\\mathsf{\\tilde{x}}_1\\mathsf{\\tilde{x}}_2}}{\\sigma^2_{\\mathsf{\\tilde{x}}_1} + \\sigma^2_{\\mathsf{\\tilde{x}}_2} + 2\\bar{\\sigma}_{\\mathsf{\\tilde{x}}_1\\mathsf{\\tilde{x}}_2}}.\n\\tag{6.10}\\] Whereas the standardized split-hald formula is even simpler,\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'} = \\frac{2\\,\\bar{\\rho}_{\\mathsf{\\tilde{x}}_1\\mathsf{\\tilde{x}}_2}}{1 + \\bar{\\rho}_{\\mathsf{\\tilde{x}}_1\\mathsf{\\tilde{x}}_2}}.\n\\tag{6.11}\\]\nIt is worth noting that the Kuder-Richardson-20 reliability is identical to Equation 6.8 with the difference being that the observed sub-scores are Bernoulli random variables (i.e., 0/1, correct/incorrect, yes/no valued), which simplifies the formula (see Kuder and Richardson 1937)\n\n\n\n\n\n\nReliability of Agreeableness Mean-Score\n\n\n\nThe psych package (William Revelle 2023) contains data on the big 5 personality traits from a large sample of 2800 individuals. We can try to calculate the reliability coefficient for the Agreeableness scale from the five question items (each item is a 6-point scale). Let’s first load in the data set and then clean up the data:\n\nlibrary(psych)\nlibrary(psychmeta)\nlibrary(tidyverse)\nlibrary(missRanger)\n\n## Clean data\ndf &lt;- bfi |&gt;\n  # select only relevant columns\n  dplyr::select(A1,A2,A3,A4,A5) |&gt;\n  # reverse scored items\n  mutate(A1 = 6-A1) |&gt;\n  # impute\n  imputeUnivariate()\n\nUsing the alpha function from the psych package we can compute the standardized and unstandardized Coefficient Alpha. Note that the argument check.keys=TRUE allows the function to automatically flip reversed scored items, however it is best to first flip the items to the desired direction instead of allowing the alpha() function to try to detect reversed items.\n\n# compute reliability\nreliability &lt;- psych::alpha(df)\n\n# only display the total scale reliabilities\nreliability$total[1:2] \n\n raw_alpha std.alpha\n 0.6980189 0.7077484\n\n\nThe reliability for the sample is estimated to be \\(\\rho_{\\widetilde{X}\\widetilde{X'}}=.70\\) for the unstandardized (raw) alpha coefficient and \\(\\rho_{\\widetilde{X}\\widetilde{X'}}=.71\\) for the standardized alpha coefficient.\nIf the raw data is not available to us but the following correlation matrix table (Table 6.1) is we can use the standardized formula of alpha to calculate the reliability.\n\n\n\n\nTable 6.1: item correlation matrix\n\n\n\n \n\n  \n    \n    \n    tinytable_jbxxis6ajiho0wn241hy\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                Item\n                A1\n                A2\n                A3\n                A4\n                A5\n              \n        \n        \n        \n                \n                  A1\n                  1.00\n                  0.33\n                  0.26\n                  0.14\n                  0.18\n                \n                \n                  A2\n                  0.33\n                  1.00\n                  0.47\n                  0.33\n                  0.38\n                \n                \n                  A3\n                  0.26\n                  0.47\n                  1.00\n                  0.36\n                  0.50\n                \n                \n                  A4\n                  0.14\n                  0.33\n                  0.36\n                  1.00\n                  0.31\n                \n                \n                  A5\n                  0.18\n                  0.38\n                  0.50\n                  0.31\n                  1.00\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n\n\nFrom this correlation matrix we can use Equation 6.9 to calculate the standardized alpha coefficient. In R, the compute_alpha() function in the psychmeta package (Dahlke and Wiernik 2019) takes in a correlation matrix (or a covariance matrix) as an argument.\n\ncorr_matrix &lt;- cor(df)\n# correlation matrix from example table:\n# 1\n# .34 1\n# .26 .48 1\n# .14 .33 .36 1\n# .18 .39 .50 .31 1\n\ncompute_alpha(sigma = corr_matrix)\n\n[1] 0.7077484\n\n\nAs expected, the reliability is identical to the standardized coefficient alpha computed from the raw data.\n\n\n\n\nMosier’s Reliability\nMosier’s (1943) reliability takes into account the within-sub-measurement reliability and weights formulation allows us to take the sub-measurement-level reliability as well as non-unit weights into account. In matrix notation,\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'} = \\frac{\\mathbf{w}^\\intercal(\\mathbf{R}_\\mathsf{\\tilde{x}} - \\mathbf{I} + \\boldsymbol{\\rho}_{\\mathsf{\\tilde{x}}\\mathsf{\\tilde{x}}'}\\mathbf{I} )\\mathbf{w}}{\\boldsymbol{\\mathbf{w}^\\intercal\\Sigma}_\\mathsf{x}\\mathbf{w} }.\n\\]\nTo describe the numerator: the correlation matrix between observed sub-scores \\(\\mathbf{R}_\\mathsf{\\tilde{x}}\\) is subtracted by a square \\(\\kappa\\times\\kappa\\) identity matrix \\(\\mathbf{I}\\) (1s in the diagonal, 0s in the off-diagonals) in effect removing the diagonal 1s in the correlation matrix, then the diagonal is replaced with \\(\\boldsymbol{\\rho}_{\\mathsf{\\tilde{x}}\\mathsf{\\tilde{x}}'}\\mathbf{I}\\) which is a an identity matrix where the diagonals are now the within-sub-measurement reliability coefficients. The denominator just contains the observed sub-score correlation matrix \\(\\mathbf{R}_\\mathsf{\\tilde{x}}\\). The vector of weights \\(\\mathbf{w}\\) acts as a weighted summation for the numerator and denominator. If the weights are simply unit weights, then the formula simplifies to,\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'} = \\frac{\\bar{\\rho}_{\\mathsf{\\tilde{x}} \\mathsf{\\tilde{x}}'} + (\\kappa - 1)\\bar{\\rho}_{\\mathsf{\\tilde{x}}_q \\mathsf{\\tilde{x}}_j}}{1+(\\kappa-1)\\bar{\\rho}_{\\mathsf{\\tilde{x}}_q \\mathsf{\\tilde{x}}_j}}.\n\\]\nWhere \\(\\bar{\\rho}_{\\mathsf{\\tilde{x}} \\mathsf{\\tilde{x}}'}\\) is the average reliability across all \\(q\\) sub-measurements. Mosier’s reliability, as opposed to Coefficient alpha, is an upper bound. One of the potential issues with using coefficient alpha for effect size corrections is that it assumes that the correlations between the true sub-scores for each sub-measurement are perfect, \\(\\rho_{\\mathsf{\\tilde{x}}_q \\mathsf{\\tilde{x}}_j}=1\\). The problem is that if the true scores do not correlate perfectly, than there may be true sub-score variance that is not captured by alpha. Therefore Mosier’s reliability uses the true variance for each sub-measurement by including it’s reliability. An example of this dilemma: if we want to estimate the reliability of the full-scale IQ score from a battery of cognitive tests like working memory, visuo-spatial reasoning, vocabulary knowledge, etc. then estimating coefficient alpha from the inter-correlations between these sub-test scores will index the true variance that is shared between working memory, reasoning, and knowledge without considering the true variance that is unique to each sub-test. Luckily these subtests usually consist of sub-measurements themselves (i.e., test items) and therefore calculating reliability for each sub-test is not a problem. However, this can become problematic in the case of Likert items where it is quite reasonable to suspect that there is true sub-score variance that is independent, it is often impossible to estimate the reliability.\n\n\n\n\n\n\nMosier’s Reliability in R\n\n\n\nThe psychTools package (William Revelle 2024) contains data on the cognitive abilities from the (ICAR) data base. There are four sub-tests consisting of basic reasoning, letter series, matrix reasoning, and spatial rotation. Let’s first load in the data set and impute missing values using predictive mean matching (Mayer 2023):\n\nlibrary(psychTools)\nlibrary(psychmeta)\nlibrary(tidyverse)\nlibrary(missRanger)\n\n## Clean data\ndf &lt;- as.data.frame(ability) |&gt;\n  # impute missing values multivariately\n  missRanger(verbose=F,pmm.k = 2)\n\nUsing the compute_composite_matrix function from the psychmeta package (Dahlke and Wiernik 2019) we can compute Mosier’s reliability. First we need to compute the coefficient alpha for each subtest:\n\n# initialize empty vector\nreliability &lt;- c()\n\n# compute alpha for reasoning test\nreliability[\"reasoning\"] &lt;- compute_alpha(\n  sigma = cov(df[,ability.keys$reasoning]),\n  standardized = FALSE)\n\nreliability[\"letters\"] &lt;- compute_alpha(\n  sigma = cov(df[,ability.keys$letters]),\n  standardized = FALSE)\n\nreliability[\"matrix\"] &lt;- compute_alpha(\n  sigma = cov(df[,ability.keys$matrix]),\n  standardized = FALSE)\n\nreliability[\"rotate\"] &lt;- compute_alpha(\n  sigma = cov(df[,ability.keys$rotate]),\n  standardized = FALSE)\n\nreliability\n\nreasoning   letters    matrix    rotate \n0.6357177 0.6631134 0.5363879 0.7640922 \n\n\nThe reliabilities for each test are poor, but our goal is to create a composite full scale IQ score from this test which should be more reliable than each of the sub-tests by themselves. Let’s compute the composite scores:\n\ncomposite_scores &lt;-  df |&gt;\n  # compute subtest scores\n  mutate(reasoning = reason.4 + reason.16 + reason.17 + reason.19,\n         letters = letter.7 + letter.33 + letter.34 + letter.58,\n         matrix = matrix.45 + matrix.46 + matrix.47 + matrix.55,\n         rotate = rotate.3 + rotate.4 + rotate.6 + rotate.8) |&gt;\n  # keep only the composite scores\n  dplyr::select(reasoning, letters, matrix, rotate) |&gt;\n  # compute IQ scores\n  mutate(IQ = reasoning + letters + matrix + rotate)\n\nhead(composite_scores)\n\n   reasoning letters matrix rotate IQ\n5          0       1      1      0  2\n6          1       2      0      1  4\n7          2       1      2      0  5\n8          2       1      0      0  3\n9          3       1      2      0  6\n10         4       4      3      3 14\n\n\nThen we can compute mosier’s reliability for IQ scores using the composite_rel_matrix() function in the psychmeta package:\n\n# create subtest data frame with just subtests (w/ IQ)\nsubtests &lt;- composite_scores |&gt;\n  dplyr::select(reasoning,letters,matrix,rotate)\n\n# correlation matrix between subtest scores\ncorr_matrix &lt;- cor(subtests)\n\n# create a vector of 1s to get standardized reliability\nsds &lt;- rep(1,4)\n\n# compute Mosier's reliability\ncomposite_rel_matrix(rel_vec = reliability,\n                     r_mat = corr_matrix,\n                     sd_vec = sds)\n\n[1] 0.8451205\n\n\nAs expected, the reliability is much larger for the full scale IQ scores than the individual subtests. Let’s briefly compare this value with coefficient alpha which does not take into account the reliability of each subtest:\n\ncompute_alpha(cor(subtests))\n\n[1] 0.7436062\n\n\nThe reliability is much lower. This is because the total true score variance does not include the true score variance that is exclusive to each subtest.\n\n\n\n\n\n6.3.2 Coefficient of Stability\nTransient errors represent fluctuations in observed scores over time. These fluctuations, even if they are systematic (e.g., fatigue over the course of a single day), add extraneous variance that can mask individual differences. Considering transient fluctuations as error depends on the research goal, so it is important for researchers to take care in considering which types of sources of variance that should be considered error in their study. A coefficient of stability (also referred to as test-retest reliability) is simply the correlation between observed scores upon repeated measurements. Note that calculating the Pearson correlation coefficient between time-points ignores systematic changes (e.g., practice effects). We can visualize test-retest reliability in Figure 6.2.\n\n\n\n\n\n\n\n\nFigure 6.2: Illustrating test-retest reliability. Top-left and top-right panels show the correlation between observed scores at both time-points for a measure that has low and high reliability, respectively. Bottom-left and bottom-right panels show the within-person change from time-point 1 to time-point 2 for scores with low and high reliability, respectively.\n\n\n\n\n\n\n\n6.3.3 Alpha Coefficient of Stability\nIf we want to capture both transient error and sub-measurement error variance, then we can also calculate the alpha coefficient of stability (also known as the test-retest alpha). This reliability estimate is the average split half correlation across two time points. Specifically, the procedure is as follows,\n\nSplit the set of sub-measurements for each time point into a two halves where both time points have the same split.\nThen calculate the split half reliability using Equation 6.10 or Equation 6.11 between the composite of first half from time point 1 and second half from time point 2.\nRepeat step 1 and 2 for all possible halves and the average is the alpha coefficient of stability.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classical Measurement Errors</span>"
    ]
  },
  {
    "objectID": "05-error-in-continuous-variables/05-error-in-continuous-variables.html#sec-correcting-correlations-me",
    "href": "05-error-in-continuous-variables/05-error-in-continuous-variables.html#sec-correcting-correlations-me",
    "title": "6  Classical Measurement Errors",
    "section": "6.4 Correcting Correlations",
    "text": "6.4 Correcting Correlations\n\n6.4.1 Defining the Target Correlation\nThe target correlation for this section can be defined as the population correlation between between true scores, \\(\\rho_{XY}\\). This can be related to observed sample correlation between observed proxy scores via the relation,\n\\[\nr_{\\widetilde{X}\\widetilde{Y}} = \\alpha \\rho_{XY} + \\varepsilon_r,\n\\] where \\(\\alpha\\) is the artifact attenuation/inflation factor and \\(\\varepsilon_r\\) is the the sampling error term.\n\n\n6.4.2 Artifact Correction for Correlations\nClassical measurement error induces systematic bias in effect size estimates such as correlation coefficients C. Spearman (1904). In the population, let us assume there is some factor \\(\\alpha\\) that accounts for the systematic bias in observed score correlations (\\(\\rho_{\\widetilde{X}\\widetilde{Y}}\\)) relative to true score correlations (\\(\\rho_{XY}\\)), such that\n\\[\n\\rho_{\\widetilde{X}\\widetilde{Y}} = \\alpha \\rho_{XY}.\n\\tag{6.12}\\]\nSince the correlation is defined as the covariance standardized by the standard deviations, the population correlation between true scores, \\(T\\) and \\(U\\), is defined as,\n\\[\n\\rho_{XY}=\\frac{\\sigma_{XY}}{\\sigma_{X} \\sigma_{Y}}.\n\\tag{6.13}\\]\nLikewise the correlation between the observed scores, \\(X\\) and \\(Y\\), would be the observed covariance divided by the observed standard deviations,\n\\[\n\\rho_{\\widetilde{X}\\widetilde{Y}} =\\frac{\\sigma_{\\widetilde{X}\\widetilde{Y}}}{\\sigma_\\widetilde{X} \\sigma_\\widetilde{Y}}.\n\\]\nHowever, if we assume that there is no covariance between errors \\(\\sigma_{E_X E_Y} = 0\\), then the covariance between observed scores is only attributable to the covariance between true scores, therefore \\(\\sigma_{\\widetilde{X}\\widetilde{Y}} = \\sigma_{XY}\\). This means that the observed score correlation can be expressed with the true score covariance in the numerator,\n\\[\n\\rho_{\\widetilde{X}\\widetilde{Y}} =\\frac{\\sigma_{XY}}{\\sigma_\\widetilde{X} \\sigma_\\widetilde{Y}}.\n\\tag{6.14}\\]\nNow the only difference between the observed score correlation (Equation 6.14) and the true score correlation (Equation 6.13) is the standard deviations in the denominator. In the presence of measurement error, the observed score standard deviations (\\(\\sigma_\\widetilde{X}\\) and \\(\\sigma_\\widetilde{Y}\\)) will be larger than the true score standard deviations (\\(\\sigma_X\\) and \\(\\sigma_Y\\)). Using the definition of reliability, we can show how the observed standard deviation is inflated compared to the true variance as a function of reliability. Since the reliability is defined as the ratio of true variance to total observed variance (see Equation 6.5), we can see how reliability inflates the observed variance,\n\\[\\begin{aligned}\n\\sigma^2_\\widetilde{X} &=\\sigma^2_{X} \\left(\\frac{\\sigma^2_\\widetilde{X}}{\\sigma^2_X} \\right)\\\\[.3em]\n&= \\sigma^2_X\\left(\\frac{1}{\\rho_{\\widetilde{X}\\widetilde{X}'}} \\right)\\\\[.3em]\n&= \\frac{\\sigma^2_{T}}{\\rho_{\\widetilde{X}\\widetilde{X}'}}.\n\\end{aligned}\\]\nTherefore the observed standard deviation is,\n\\[\n\\sigma_\\widetilde{X} = \\frac{\\sigma_{X}}{\\sqrt{\\rho_{\\widetilde{X}\\widetilde{X}'}}}.\n\\tag{6.15}\\]\nSince the reliability, and its square root, will be less than 1, the observed score variance will be larger than the true score variance \\(\\sigma_X \\geq \\sigma_\\widetilde{X}\\). If we use the definition of an observed score correlation in Equation 6.14, then we can replace \\(\\sigma_\\widetilde{X}\\) and \\(\\sigma_\\widetilde{Y}\\) with \\(\\frac{\\sigma_X}{\\sqrt{\\rho_{\\widetilde{X}\\widetilde{X}'}}}\\) and \\(\\frac{\\sigma_Y}{\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'}}}\\), respectively. Now we can show mathematically, how the observed score correlation differs from the true score correlation:\n\\[\\begin{aligned}\n\\rho_{\\widetilde{X}\\widetilde{Y}} &= \\frac{\\sigma_{XY}}{\\left[\\frac{\\sigma_X}{\\sqrt{\\rho_{\\widetilde{X}\\widetilde{X}'}}} \\right] \\left[ \\frac{\\sigma_Y}{\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'}}} \\right] } \\\\[.3em]\n&=  \\sqrt{\\rho_{\\widetilde{X}\\widetilde{X}'}}\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'}}\\,\\times\\frac{\\sigma_{XY}}{\\sigma_X\\sigma_Y} \\\\[.3em]\n&= \\underset{\\alpha}{\\underbrace{\\sqrt{\\rho_{\\widetilde{X}\\widetilde{X}'}}\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'}}} } \\times \\rho_{XY}\n\\end{aligned}\\]\nTherefore the attenuation factor described in Equation 6.12 is,\n\\[\n\\alpha = \\sqrt{\\rho_{\\widetilde{X}\\widetilde{X}'}}\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'}}\n\\tag{6.16}\\]\nThis attenuation formula was first derived by Charles Spearman (1904). This derivation. See Figure 6.3 for a visualization of the attenuation.\n\n\n\n\n\n\n\n\nFigure 6.3: Visualizing the attenuation of an observed score correlation (\\(\\rho_{XY}\\)) due to measurement error. Top left panel shows a scatter plot of the correlation between the true scores of the independent and dependent variable. Top right panel shows a scatter plot of the correlation between the observed scores of the independent and dependent variable. The bottom left panel shows the reliability of a single variable and it’s relationship with the observed score correlation (\\(\\rho_{XY}\\)) while varying the true score correlation (true score correlations are represented as the red dots, i.e., when reliability is perfect). The bottom right panel shows attenuation of a a true score correlation, when both \\(X\\) and \\(Y\\) are affected by measurement error. The darker red indicates a larger observed correlation, where it peaks at an observed score correlation of .50 (when reliability of \\(X\\) and \\(Y\\) is 1) which is equivalent to the true score correlation.\n\n\n\n\n\nLet us recall that we can express the study sample correlation between observed scores as a function of the true score population correlation (i.e., the target correlation, \\(\\rho_{XY}\\)),\n\\[\nr_{\\widetilde{X}\\widetilde{Y}} = \\alpha\\rho_{XY} + \\varepsilon_r.\n\\]\nNow that we have derived the attenuation factor \\(\\alpha\\) we can plug in it’s actual form from Equation 6.16,\n\\[\nr_{\\widetilde{X}\\widetilde{Y}} = \\left(\\sqrt{\\rho_{\\widetilde{X}\\widetilde{X}'}}\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'}}\\right) \\rho_{XY} + \\varepsilon_r.\n\\]\nWe could use the \\(\\alpha\\) coefficient to correct the correlation by dividing both sides of the above equation, however the population reliabilities \\(\\rho_{\\widetilde{X}\\widetilde{X}'}\\) and \\(\\rho_{\\widetilde{Y}\\widetilde{Y}'\\) are unknown in practice and therefore we have to use sample estimates. Since we must use sample estimates of reliability, then that means we only have access to a sample estimate of \\(\\alpha\\) which we denote with the English letter \\(a\\). Therefore we can correct the observed score study correlation by dividing by an estimate the attenuation factor using,\n\\[\nr_{XY} = \\frac{r_{\\widetilde{X}\\widetilde{Y}}}{a} = \\frac{r_{XY}}{\\sqrt{r_{\\widetilde{X}\\widetilde{X}'}}\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}'}}}\n\\]\nThe corrected correlation coefficient is a consistent estimator of the target correlation, \\(\\rho_{XY}\\).\n\n\n\n\n\n\nCorrecting Correlations in R\n\n\n\nA study reports the correlation between mean reaction time and exam grades of \\(r_{\\widetilde{X},\\widetilde{Y}}=.40\\)\n\nlibrary(psychmeta)\n\nrXY &lt;- .40  # correlation between X and Y\nrXX &lt;- .80  # reliability of X\nrYY &lt;- .70  # reliability of Y\nn &lt;- 100    # sample size\n\n# correct correlation\ncorrect_r(correction = 'meas',\n          rxyi = rXY,\n          rxx = rXX,\n          ryy = rYY)\n\nCorrelations Corrected for Measurement Error:\n---------------------------------------------------------------------------------------\n  rxy   rxp   rty   rtp\n1 0.4 0.478 0.447 0.535\n\n\nIn the psychmeta package, they show the correction for each variable therefore rxy is the observed correlation, rxp is corrected for the measurement error in \\(Y\\), rty is corrected for measurement error in \\(X\\), and rtp is the correlation corrected for measurement error in both variables. Therefore sample estimate of the true score correlation is \\(r_{XY} = .535\\).\n\n\n\nSampling Variance of Corrected Correlation\nThe next step is to obtain the sampling variance of the corrected correlation coefficient. The sampling variance of the uncorrected correlation, \\(\\mathrm{var}(r_{\\widetilde{X}\\widetilde{Y}})\\), can be adjusted directly. If we treat the reliability coefficients as fixed as the correlation, then the standard error formula can be calculated simply as,\n\\[\n\\mathrm{var}(r_{XY}) =  \\frac{\\mathrm{var}(r_{\\widetilde{X}\\widetilde{Y}})}{r_{XX'}r_{YY'}}\n\\]\nThis formula generally performs pretty well, however there are two additional methods that are preferrable: Bootstrapping and Taylor series approximations. If the raw data is available, then a sampling with replacement procedure (i.e., bootstrapping) can provide a non-parametric estimate of the sampling variance.\n\n\n\n\n\n\nBootstrapping Corrected Correlations in R\n\n\n\nAs an example in R, we can calculate the sampling variance between Extraversion and Agreeableness sum scores from the bfi data set in the psych package (William Revelle 2023).\n\nlibrary(tidyverse)\nlibrary(psychmeta)\nlibrary(psych)\nlibrary(missRanger)\n\nset.seed(1)\n\n# clean data and compute composites\ndf &lt;- bfi |&gt;\n  dplyr::select(A1,A2,A3,A4,A5,\n                E1,E2,E3,E4,E5) |&gt;\n  mutate(A1 = 6-A1, E1 = 6-E1, E2 = 6-E2) |&gt;\n  mutate(A = A1 + A2 + A3 + A4 + A5,\n         E = E1 + E2 + E3 + E4 + E5) |&gt;\n  imputeUnivariate()\n\n# initialize corrected correlation vector\nrAE_corrected &lt;- c()\n\n# loop through 1500 bootstrap iterations\nfor(i in 1:1500){\n  \n  # sample the data with replacement\n  boot = sample(1:nrow(df),nrow(df),replace = TRUE)\n  boot_df &lt;- df[boot,]\n  \n  # compute bootstrap correlation matrix for each trait\n  corr_mat_A &lt;- cor(boot_df[,c(\"A1\",\"A2\",\"A3\",\"A4\",\"A5\")])\n  corr_mat_E &lt;- cor(boot_df[,c(\"E1\",\"E2\",\"E3\",\"E4\",\"E5\")])\n\n  # compute reliability\n  rAA &lt;- compute_alpha(corr_mat_A)\n  rEE &lt;- compute_alpha(corr_mat_E)\n  \n  # compute correlation between composites\n  rAE &lt;- cor(boot_df$A, boot_df$E)\n  \n  # correct correlation\n  rAE_corrected[i] &lt;- rAE / sqrt(rAA*rEE)\n}\n\n# bootstrapped variance estimate\nvar(rAE_corrected)\n\n[1] 0.0004839236\n\n## compare bootstrapped variance with closed form\nvar_observed &lt;- (1 - cor(df$A,df$E)^2)^2 / (nrow(df)-1)\n\nrAA &lt;- compute_alpha(cor(df[,c(\"A1\",\"A2\",\"A3\",\"A4\",\"A5\")]))\nrEE &lt;- compute_alpha(cor(df[,c(\"E1\",\"E2\",\"E3\",\"E4\",\"E5\")]))\n\nvar_corrected &lt;- var_observed / (rAA * rEE)\n\n# closed form variance estimate\nvar_corrected\n\n[1] 0.0004384132\n\n\nIn this example, the bootstrapped sampling variance and the closed form are nearly equal.\n\n\nBobko and Rieck (1980) derived sampling variance formulas from Taylor series approximations for three different situations. However Bobko and Rieck (1980) only derived them for correcting the correlation only for the dependent variable \\(Y\\). Using the same methodology as Bobko and Rieck (1980) I derive the variance of the corrected correlation in the case where reliability estimates and correlations come from an independent samples (e.g., reliability comes from a test manual and not from the study sample). The formula requires the sample size for the study sample \\(n\\) as well as for the samples where the reliability coefficients were estimated \\(n_{r_{\\widetilde{X}\\widetilde{X}'}}\\) and \\(n_{r_{\\widetilde{Y}\\widetilde{Y}'}}\\).\n\\[\\begin{align}\n\\mathrm{var}(r_{XY}) =& \\frac{se(r_{\\widetilde{X}\\widetilde{Y}})^2}{r_{\\widetilde{X}\\widetilde{X}'}r_{\\widetilde{Y}\\widetilde{Y}'}} \\\\\n+ &\\frac{r^2_{\\widetilde{X}\\widetilde{Y}}\\left(1-r^2_{\\widetilde{X}\\widetilde{X}'}\\right)^2}{4(n_{r_{\\widetilde{X}\\widetilde{X}'}}-1)r_{\\widetilde{X}\\widetilde{X}'}^3r_{\\widetilde{Y}\\widetilde{Y}'}} \\\\\n&+\\frac{r^2_{\\widetilde{X}\\widetilde{Y}}\\left(1-r^2_{\\widetilde{Y}\\widetilde{Y}'}\\right)^2}{4(n_{r_{\\widetilde{Y}\\widetilde{Y}'}}-1)r_{\\widetilde{X}\\widetilde{X}'}r_{\\widetilde{Y}\\widetilde{Y}'}^3}\n\\end{align} \\tag{6.17}\\]\nThe full derivation can be found seen in the Appendix of this chapter.\n\n\n\n6.4.3 Differential Measurement Error\nBefore we move on to correcting standardized mean differences, I have to confess, I snuck in a major assumption earlier in this section:\n\nHowever, if we assume that there is no covariance between errors \\(\\sigma_{E_X E_Y} = 0\\), then the covariance between observed scores is only attributable to the covariance between true scores, therefore \\(\\sigma_{\\widetilde{X}\\widetilde{Y}} = \\sigma_{XY}\\).\n\nThe problem with this assumption is that the corrected correlation can be under-estimated if \\(\\sigma_{E_XE_Y}&lt;0\\) or over-estimated if \\(\\sigma_{E_XE_Y}&gt;0\\). A conservative correction approach would be to use Mosier’s reliability in the correction procedure allowing there to be true variance which will reduce the likelihood that the correction is an over-estimation. A better correction procedure would be to use the one introduced by Donald W. Zimmerman and Williams (1977),\n\\[\nr_{XY} = \\frac{r_{\\widetilde{X}\\widetilde{Y}}}{\\sqrt{r_{\\widetilde{X}\\widetilde{X}}}\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}}}} -\\frac{r_{E_XE_Y} \\sqrt{1-r_{\\widetilde{Y}\\widetilde{Y}}}\\sqrt{1-r_{\\widetilde{Y}\\widetilde{Y}}}}{\\sqrt{r_{\\widetilde{X}\\widetilde{X}}}\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}}}}\n\\tag{6.18}\\] Notice that the first term is identical to the correction formula described earlier, in fact, if the \\(r_{E_XE_Y}\\) is set to zero, we would recover the original correction formula. The problem with Equation 6.18 is that it requires an estimate of \\(r_{E_XE_Y}\\) which is only attainable if the raw data is available, since this would rarely be reported directly.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classical Measurement Errors</span>"
    ]
  },
  {
    "objectID": "05-error-in-continuous-variables/05-error-in-continuous-variables.html#correcting-standardized-mean-differences-smd",
    "href": "05-error-in-continuous-variables/05-error-in-continuous-variables.html#correcting-standardized-mean-differences-smd",
    "title": "6  Classical Measurement Errors",
    "section": "6.5 Correcting Standardized Mean Differences (SMD)",
    "text": "6.5 Correcting Standardized Mean Differences (SMD)\n\n6.5.1 Defining the Target SMD\nPrior to correcting for measurement error let us define our target effect size. Our target effect size is the SMD between groups 0 and 1 with respect to the true scores, \\(Y\\), of our dependent variable,\n\\[\n\\delta_{GY} = \\frac{\\mu_{Y|G=1} - \\mu_{Y|G=0}}{\\sigma_{Y|G}}.\n\\]\nWhere \\(\\mu_{Y|G=1}\\) and \\(\\mu_{Y|G=0}\\) is the conditional population mean for each group (\\(G\\)). If we are given a sample observed score SMD, then we can express the relationship between the population true score SMD (\\(\\delta_{GY}\\)) and our observed SMD with our effect size model:\n\\[\nd_{GY} = \\alpha\\delta_{GY}+\\varepsilon_d.\n\\]\nWhere \\(\\alpha\\) is the attenuation factor induced by measurement error and \\(\\varepsilon_d\\) denotes sampling error.\n\n\n6.5.2 Artifact Correction for SMDs\nThe population mean of true scores and observed scores are identical since classical measurement error, as defined here, only affects the variance in scores. Therefore the population mean difference is equivalent for true scores and observed scores,\n\\[\n\\underset{\\textsf{observed score mean diff}}{\\underbrace{\\mu_{\\widetilde{Y}|G=1} - \\mu_{\\widetilde{Y}|G=0}}}= \\underset{\\textsf{true score mean diff}}{\\underbrace{\\mu_{Y|G=1} - \\mu_{Y|G=0}}}.\n\\]\nThis means that an unstandardized mean difference is not biased by classical measurement error. Taking advantage of this fact, we can express an observed score SMD with replacing the observed score mean difference in the numerator with the true score mean difference such that,\n\\[\n\\delta_{G\\widetilde{Y}} = \\overset{\\textsf{observed score mean diff}}{\\overbrace{\\frac{\\mu_{\\widetilde{Y}|G=1} - \\mu_{\\widetilde{Y}|G=0}}{\\sigma_{\\widetilde{Y}|G}}}}  = \\overset{\\textsf{true score mean diff}}{\\overbrace{\\frac{ \\mu_{Y|G=1} - \\mu_{Y|G=0}}{\\sigma_{\\widetilde{Y}|G}}}}\n\\tag{6.19}\\]\nSimilar to Equation 6.15, the observed score within-group standard deviation \\(\\sigma_{\\widetilde{Y}|G}\\) can be expressed in terms of the true score within-group standard deviation \\(\\sigma_{Y|G}\\) and the within-group reliability \\(\\rho_{\\widetilde{Y}\\widetilde{Y}'|G}\\),\n\\[\n\\sigma_{\\widetilde{Y}|G}=\\frac{\\sigma_{Y|G}}{\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'|G}}}\n\\]\nWe can then plug this in for \\(\\sigma_{\\widetilde{Y}|G}\\) in the observed score SMD formula (Equation 6.19) which will allow us to recover the true score SMD and parse out the artifact attenuation coefficient \\(\\alpha\\),\n\\[\\begin{aligned}\n\\delta_{G\\widetilde{Y}} &=\\frac{\\mu_{Y|G=1} - \\mu_{Y|G=0}}{\\sigma_{\\widetilde{Y}|G}}  \\\\[.3em]\n&=  \\frac{\\mu_{Y|G=1} - \\mu_{Y|G=0}}{\\left[\\frac{\\sigma_{Y|G}}{\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'|G}}}\\right]} \\\\[.3em]\n&= \\underset{\\alpha}{\\underbrace{\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'|G}}} } \\times \\delta_{GY}.\n\\end{aligned}\\]\nTherefore the artifact attenuation factor \\(\\alpha\\) is,\n\\[\n\\alpha = \\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'|G}}.\n\\tag{6.20}\\]\nFor a given sample, the within-group reliability and thus the artifact attenuation factor must be estimated. The sample estimate of the within-group reliability can be estimated from pooling the reliability in group 0 (\\(\\rho_{\\widetilde{Y}\\widetilde{Y}'|G=0}\\)) and group 1 (\\(\\rho_{\\widetilde{Y}\\widetilde{Y}'|G=1}\\)),\n\\[\nr_{\\widetilde{Y}\\widetilde{Y}'|G} = \\frac{(n_0-1)r_{\\widetilde{Y}\\widetilde{Y}'|G=0} + (n_1-1) r_{\\widetilde{Y}\\widetilde{Y}'|G=1}}{n -2},\n\\] where \\(n = n_0 + n_1\\). Using Equation 6.20 we can correct the SMD with the sample estimate \\(a=\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}'|G}}\\),\n\\[\nd_{GY} = \\frac{d_{G\\widetilde{Y}}}{a} = \\frac{d_{G\\widetilde{Y}}}{\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}'|G}}}.\n\\] See Figure 6.4 for an illustration of how SMDs are affected by classical measurement error.\n\n\n\n\n\n\n\n\nFigure 6.4: Visualizing the attenuation of the standardized mean differences. Even though the means (dashed lines) do not change in the true score (top plot, in blue) and observed score distributions (bottom plot, in red), the true score distributions have a narrower variance than the observed score distributions. Since the variance and thus standard deviations are larger in the observed scores, the SMD in the observed scores is smaller than the true scores.\n\n\n\n\n\n\nSampling Variance of Corrected SMD\nThe sampling variance can be calculated similarly to the corrected correlation. The best if the raw data is available is to compute the sampling variance from a bootstrapping procedure (see the R example on bootstrapping in the previous section on correlations). If we treat the within-group reliability as fixed (or assumed to be known a priori) then the corrected sampling variance is,\n\\[\n\\mathrm{var}(d_{GY}) = \\frac{\\mathrm{var}(d_{GY})}{r_{\\widetilde{Y}\\widetilde{Y}'|G}}\n\\]\nThe last option for situations where the reliability and SMD are estimated from different samples the Taylor series approximation could be applied,\n\\[\n\\mathrm{var}(d_{GY}) = \\frac{\\mathrm{var}(d_{G\\widetilde{Y}})}{r_{\\widetilde{Y}\\widetilde{Y}'|G}} +\\frac{d^2_{gY}\\left(1-r^2_{\\widetilde{Y}\\widetilde{Y}'|G}\\right)^2}{4\\left(1-n_{r_{\\widetilde{Y}\\widetilde{Y}'|G}}\\right)r^3_{\\widetilde{Y}\\widetilde{Y}'|G}}.\n\\tag{6.21}\\]\nIt is common that studies will only report the full sample reliability and not the reliability within each group. If the groups differ substantially on the dependent variable, \\(Y\\), then the total sample reliability will over-estimate the within-group reliability. When the total sample reliability is all that is available, we can correct the standardized mean difference by first converting the SMD to a point-biserial correlation. To do this we also need the observed proportion of subjects in group 0 or 1 (\\(p_G = n_0/n\\) or \\(p_g = n_1/n\\), it does not matter which one is chosen). This three-step process is as follows:\n\nConvert the SMD to a point-biserial correlation: \\[\nr_{G\\widetilde{Y}} = \\frac{d_{G\\widetilde{Y}}}{\\sqrt{\\frac{1}{p_G(1-p_G)} +d^2_{G\\widetilde{Y}}} }\n\\]\nCorrect the point-biserial correlation: \\[\nr_{GY} = \\frac{r_{G\\widetilde{Y}} }{\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}'}}}\n\\]\nConvert back to an SMD: \\[\nd_{GY} = \\frac{r_{GY}}{\\sqrt{p_G(1-p_G)(1-r^2_{GY})}}\n\\]\n\nWith this correction procedure, the sampling variance must also go through the same three-step procedure. Treating \\(a\\) as fixed and stuffing the three-step procedure into a single formula we get,\n\\[\n\\mathrm{var}(d_{GY}) = \\frac {\\mathrm{var}(d_{G\\widetilde{Y}}) \\times\\left(\\frac{r_{GY}}{r_{G\\widetilde{Y}}}\\right)^2} {\\left(1+d_{G\\widetilde{Y}}^2p_G[1-p_G]\\right)^3\\left(1-r_{GY}^2\\right)^3}.\n\\tag{6.22}\\]\n\n\n\n\n\n\nApplied Example in R\n\n\n\nImagine we want to test the effectiveness of a drug that is meant to alleviate stress. Therefore we conduct a study and randomize a sample of 150 people into a control group (\\(n=75\\)) and a treatment group (\\(n=75\\)). After the intervention, the subjects report their stress levels on a self-report scale. The scale was shown to have a full sample reliability of \\(r_{\\widetilde{Y}\\widetilde{Y}'}=.80\\). We can correct the standardized mean differences on observed scores with the correct_d function in the psychmeta package (Dahlke and Wiernik 2019).\n\nlibrary(psychmeta)\n\n# observed values\ndGY &lt;- .40\nrYY &lt;- .80\nn0 &lt;- n1 &lt;- 75\n\nd_correct &lt;- correct_d(correction = 'meas',\n                         d = dGY,\n                         ryy = rYY,\n                         n1 = n0,\n                         n2 = n1)\n\n# corrected SMD\nd_correct$d_values$dGp$value\n\n[1] 0.4494666\n\n\nThe output of psychmeta shows a slightly larger (\\(d_{GY} = 0.45\\)). To calculate the sampling variance, we can use the var_error_d() function in the psychmeta package. The correction function not only gave us the corrected \\(d\\) value but also provided the effective sample size which is adjusted for the correction procedure. The effective sample size can then be inputted as the sample size for var_error_d. This way the sampling variance calculation utilizes the effective sample size rather than the actual sample size which is functionally identical to Equation 6.22:\n\n# compute sampling variance of corrected SMD\nvar_error_d(d = d_correct$d_values$dGp$value, \n            n1 = d_correct$d_values$dGp$n_effective)\n\n[1] 0.0354002\n\n\n\n\n\n\n\n\nBobko, Philip, and Angela Rieck. 1980. “Large Sample Estimators for Standard Errors of Functions of Correlation Coefficients.” Applied Psychological Measurement 4 (3): 385–98. https://doi.org/10.1177/014662168000400309.\n\n\nBrown, William. 1910. “Some Experimental Results in the Correlation of Mental Abilities1.” British Journal of Psychology, 1904-1920 3 (3): 296–322. https://doi.org/10.1111/j.2044-8295.1910.tb00207.x.\n\n\nCronbach, Lee J. 1951. “Coefficient Alpha and the Internal Structure of Tests.” Psychometrika 16 (3): 297–334. https://doi.org/10.1007/BF02310555.\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “Psychmeta: An R Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nHaertel, Edward H. 2006. “3. Reliability.” In, 4th ed.\n\n\nHunter, John E., and Frank L. Schmidt. 2015. Methods of meta-analysis: correcting error and bias in research findings (third). Third. Thousand Oaks, California: Sage Publications.\n\n\nKroc, Edward, and Bruno D. Zumbo. 2020. “A Transdisciplinary View of Measurement Error Models and the Variations of x=t+e.” Journal of Mathematical Psychology 98 (September): 102372. https://doi.org/10.1016/j.jmp.2020.102372.\n\n\nKuder, G. F., and M. W. Richardson. 1937. “The Theory of the Estimation of Test Reliability.” Psychometrika 2 (3): 151–60. https://doi.org/10.1007/BF02288391.\n\n\nMayer, Michael. 2023. missRanger: Fast Imputation of Missing Values. https://CRAN.R-project.org/package=missRanger.\n\n\nMendoza, Jorge L., and Michael Mumford. 1987. “Corrections for Attenuation and Range Restriction on the Predictor.” Journal of Educational Statistics 12 (3): 282–93. https://doi.org/10.3102/10769986012003282.\n\n\nMosier, Charles I. 1943. “On the Reliability of a Weighted Composite.” Psychometrika 8 (3): 161–68.\n\n\nRulon, Phillip J. 1939. “A Simplified Procedure for Determining the Reliability of a Test by Split-Halves.” Harvard Educational Review 9 (1): 99–103.\n\n\nSpearman, C. 1904. “The Proof and Measurement of Association Between Two Things.” International Journal of Epidemiology 39 (5): 1137–50. https://doi.org/10.1093/ije/dyq191.\n\n\nSpearman, Charles. 1910. “Correlation Calculated from Faulty Data.” British Journal of Psychology 3 (3): 271295. https://www.proquest.com/docview/1293688112/citation/7E133DC1091D4E47PQ/1.\n\n\nViswesvaran, Chockalingam, Deniz S. Ones, Frank L. Schmidt, Huy Le, and In-Sue Oh. 2014. “Measurement Error Obfuscates Scientific Knowledge: Path to Cumulative Knowledge Requires Corrections for Unreliability and Psychometric Meta-Analyses.” Industrial and Organizational Psychology 7 (4): 507–18. https://doi.org/10.1017/S1754942600006799.\n\n\nWilliam Revelle. 2023. Psych: Procedures for Psychological, Psychometric, and Personality Research. Evanston, Illinois: Northwestern University. https://CRAN.R-project.org/package=psych.\n\n\n———. 2024. psychTools: Tools to Accompany the ’Psych’ Package for Psychological Research. Evanston, Illinois: Northwestern University. https://CRAN.R-project.org/package=psychTools.\n\n\nZimmerman, Donald W. 1975. “Probability Spaces, Hilbert Spaces, and the Axioms of Test Theory.” Psychometrika 40 (3): 395–412. https://doi.org/10.1007/BF02291765.\n\n\nZimmerman, Donald W, and Richard H Williams. 1977. “Validity Coefficients and Correlated Errors in Test Theory.” The Journal of Experimental Education 45 (3): 4–9.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classical Measurement Errors</span>"
    ]
  },
  {
    "objectID": "06-misclassification/06-misclassification.html",
    "href": "06-misclassification/06-misclassification.html",
    "title": "7  Group Misclassification",
    "section": "",
    "text": "7.1 Introduction\nGroup misclassification describes a situation where true group membership (e.g., people with a disorder) does not perfectly match the observed group membership (e.g., people diagnosed with a disorder). Group misclassification can be considered a type of measurement error where instead of accounting for errors in continuous variables (i.e., unreliability), group misclassification accounts for errors in categorical variables. This section will be focused on non-differential (random) misclassification.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Group Misclassification</span>"
    ]
  },
  {
    "objectID": "06-misclassification/06-misclassification.html#defining-group-misclassification",
    "href": "06-misclassification/06-misclassification.html#defining-group-misclassification",
    "title": "7  Group Misclassification",
    "section": "7.2 Defining Group Misclassification",
    "text": "7.2 Defining Group Misclassification\nMisclassification can be defined as any deviations between true group membership and observed group membership. Let us imagine two groups, group 0 and group 1. In order to identify members of group 0 and group 1, we have to rely on some measurement (classification) procedure. We can also suppose that this measurement procedure produces imperfect group assignments, that is, people who are actually in group 0 are sometimes assigned group 1 and vice versa. We can visualize the performance of the classification procedure with a contingency table (see Table 7.1) between actual group membership (\\(G\\)) and observed group membership (\\(\\widetilde{G}\\)) where each cell is the number of number of individuals in that cell:\n\n\n\n\n\n\n\nTable 7.1: Contingency table between observed and true group membership.\n\n\n\n\n\n\n\\(G=0\\)\n\\(G=1\\)\n\n\n\n\n\\(\\widetilde{G}=0\\)\n\\(n_{00}\\)\n\\(n_{01}\\)\n\n\n\\(\\widetilde{G}=1\\)\n\\(n_{10}\\)\n\\(n_{11}\\)\n\n\n\n\n\n\n\n\n\n\nWe can see from the contingency table that individuals who were correctly classified, would populate the cell blocks \\(n_{00}\\) or \\(n_{11}\\) and those who were misclassified would belong to cells \\(n_{01}\\) and \\(n_{10}\\). Therefore we can define the proportion of individuals that are accurately classified as \\(p_{\\text{acc}} = (n_{01} + n_{10})/n\\) (\\(n\\) is the total sample size) whereas the proportion of people misclassified can be defined as \\(p_{\\text{mis}} = 1-p_\\text{acc}=(n_{01} + n_{10})/n\\). A high-quality classifier would would minimize \\(p_{\\text{mis}}\\) and maximize \\(p_{\\text{acc}}\\).",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Group Misclassification</span>"
    ]
  },
  {
    "objectID": "06-misclassification/06-misclassification.html#classification-reliability",
    "href": "06-misclassification/06-misclassification.html#classification-reliability",
    "title": "7  Group Misclassification",
    "section": "7.3 Classification Reliability",
    "text": "7.3 Classification Reliability\nSimilar to quantifying reliability in continuous variables by calculating the correlation in parallel sets of observed scores, the same can be done in categorical variables. Instead of a contingency table between observed (\\(\\widetilde{G}\\)) and true (\\(G\\)) group membership, we will instead create a contingency table of two measurements producing two sets of observed group assignments (\\(\\widetilde{G}\\) and \\(\\widetilde{G}'\\), see Table 7.2). An example might be two clinician’s diagnoses of Major Depressive Disorder (MDD) in the same sample of patients.\n\n\n\n\n\n\n\nTable 7.2: Contingency table between two sets of observed group assignments\n\n\n\n\n\n\n\\(\\widetilde{G}'=0\\)\n\\(\\widetilde{G}'=1\\)\n\n\n\n\n\\(\\widetilde{G}=0\\)\n\\(n_{00}\\)\n\\(n_{01}\\)\n\n\n\\(\\widetilde{G}=1\\)\n\\(n_{10}\\)\n\\(n_{11}\\)\n\n\n\n\n\n\n\n\n\n\nTo obtain the reliability of the group assignments, we can calculate the correlation coefficient between the Bernoulli variables \\(\\widetilde{G}\\) and \\(\\widetilde{G}'\\). A Pearson correlation coefficient between two Bernoulli variables is also referred to as a phi coefficient or Matthews’ correlation coefficient. Let’s denote the reliability as \\(\\rho_{\\widetilde{G}\\widetilde{G}'}\\). Remember that reliability from the chapter on unreliability can be defined as the square of the correlation between true scores and observed scores. As is the case here, we can define classification reliability as the square of the correlation between assigned group membership and actual group membership,\n\\[\n\\rho_{\\widetilde{G}\\widetilde{G}'} = \\rho^2_{\\widetilde{G}G}\n\\]\nThere are a few ways to obtain a sample estimate of \\(\\rho_{\\widetilde{G}\\widetilde{G}'}\\). The first way is to calculate the sample estimate directly from the contingency table (Table 7.2),\n\\[\nr_{\\widetilde{G}\\widetilde{G}'} = \\frac{n_{00}n_{11}-n_{01}n_{10}}{\\sqrt{(n_{00}+n_{10})(n_{01}+n_{11})(n_{00}+n_{01})(n_{10}+n_{11})}}.\n\\]\nWhere \\(n_{AA}\\), \\(n_{BB}\\), \\(n_{AB}\\), and \\(n_{BA}\\) are the number of subjects within their respective cells of the contingency table. If the values of the contingency table are not available, we can calculate the reliability from the \\(\\chi^2\\)-statistic,\n\\[\nr_{\\widetilde{G}\\widetilde{G}'} = \\sqrt{\\frac{\\chi^2}{n}}.\n\\]\nWhere \\(n\\) is the total sample size (sum of all cells). If the \\(\\chi^2\\)-statistic is unavailable, we can approximate the reliability from the accuracy (\\(p_{\\text{acc}}\\)) or the proportion of people misclassified (\\(p_{\\text{mis}}\\)),\n\\[\nr_{\\widetilde{G}\\widetilde{G}'} = (2p_{\\text{acc}}-1)^2 = (1-2p_{\\text{mis}})^2.\n\\]\nThis approximation assumes that the group sizes are approximately equal and the misclassification rates are approximately equal between groups. Otherwise, \\(r_{\\widetilde{G}\\widetilde{G}'}\\) will be overestimated (Wiernik and Dahlke 2020).\n\n\n\n\n\n\nClassification Reliability in R\n\n\n\nThe irr package (Gamer et al. 2019) has a data set called diagnoses that consists of 6 raters diagnosing the same thirty patients with various disorders. We will just look at depression for now. First we can construct the contingency table between the first two raters diagnoses of depression (1) vs not depression (0).\n\nlibrary(irr)\nlibrary(tidyverse)\nlibrary(psych)\n\ndata(diagnoses)\n\n# get depression diagnoses from first 2 raters\ndf &lt;- diagnoses |&gt;\n  mutate(depress1 = as.numeric(rater1 == \"1. Depression\"),\n         depress2 = as.numeric(rater2 == \"1. Depression\")) |&gt;\n  dplyr::select(depress1,depress2)\n  \n# create contingency table\ncontingency_table &lt;- table(df)\n\ncontingency_table\n\n        depress2\ndepress1  0  1\n       0 17  0\n       1  6  7\n\n\nThe psych package (William Revelle 2023) has a function phi() for calculating the phi coefficient from a contingency table:\n\n# calculate reliability from phi coefficient\nphi(contingency_table)\n\n[1] 0.63\n\n\nTherefore our estimate of the classification reliability is \\(r_{\\widetilde{G}\\widetilde{G}'}=.63\\).",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Group Misclassification</span>"
    ]
  },
  {
    "objectID": "06-misclassification/06-misclassification.html#correcting-standardized-mean-differences-smd",
    "href": "06-misclassification/06-misclassification.html#correcting-standardized-mean-differences-smd",
    "title": "7  Group Misclassification",
    "section": "7.4 Correcting Standardized Mean Differences (SMD)",
    "text": "7.4 Correcting Standardized Mean Differences (SMD)\n\n7.4.1 Defining our Target Quantity\nOur quantity of interest is the true score population standardized mean difference, \\(\\delta_{GY}\\), between actual members of group 0 and group 1 on the true scores of the dependent variable, \\(Y\\). Non-differential error in the assignment of groups (i.e., group misclassification) will bias the observed correlation. We can model the observed standardized mean difference as a function of the target quantity, \\(\\delta_{GU}\\),\n\\[\nd_{\\widetilde{G}\\widetilde{Y}} = \\alpha\\delta_{GU} + \\varepsilon_d.\n\\]\nWhere \\(\\alpha\\) is the artifact attenuation factor and \\(\\varepsilon_d\\) denotes the sampling error.\n\n\n7.4.2 Artifact Correction for SMDs\nSMDs are attenuated when non-differential misclassification is present. This is partially due to the fact that the means of each group are driven closer to one another. Let us suppose that, on average, group 0 and group 1 score differently on some outcome, \\(Y\\). When some subjects are erroneously assigned to the incorrect group, the observed mean will be a weighted average of the correct group mean and the incorrect group mean. To calculate the mean of the observed groups we must incorporate the true mean of the correctly classified subjects and the misclassified subjects,\n\\[\n\\mu_{Y|\\widetilde{G}=0} = \\left(\\frac{n_{00}}{n_{00}+n_{01}}\\right)\\mu_{Y|G=0} + \\left(\\frac{n_{01}}{n_{00}+n_{01}}\\right)\\mu_{Y|G=1},\n\\]\n\\[\n\\mu_{Y|\\widetilde{G}=1} = \\left(\\frac{n_{10}}{n_{11}+n_{10}}\\right)\\mu_{Y|G=0} + \\left(\\frac{n_{11}}{n_{11}+n_{10}}\\right)\\mu_{Y|G=1}.\n\\]\nFrom the above equations, it becomes evident that as the number of misclassified individuals increases (\\(n_{01}\\) and \\(n_{10}\\)), the observed means of each group gradually converge towards each other. As the means converge, the standardized mean difference will correspondingly shift toward zero. To illustrate this phenomenon, Figure 7.1 shows the distributions for groups \\(A\\) and \\(B\\) without any misclassification. In this case, there is no attenuation of the standardized mean difference.\n\n\n\n\n\n\n\n\nFigure 7.1: Distributions of scores without misclassification. Red squares denote actual group 0 members, blue circles denote actual group 1 members.\n\n\n\n\n\nIf some individuals are assigned to the incorrect group, then we will see attenuation in the standardized mean difference as the means converge. Figure 7.2 is showing what happens when the group misclassification rate is 10%. A group misclassification rate of 10% is equivalent to a classification reliability of \\(r_{\\widetilde{G}\\widetilde{G}'}=.64\\).\n\n\n\n\n\n\n\n\nFigure 7.2: Distributions of scores with a 10% misclassification rate. Observed standardized mean differences are biased toward the null (i.e., \\(\\delta\\) = 0). Note that a few members of group 0 (red squares) are within assigned group 1 and vice versa (indicative of misclassification).\n\n\n\n\n\nAs described in the chapter on classicla measurement error, some SMD corrections require a three-step procedure: 1) converting to a point-biserial correlation, 2) correcting the correlation, 3) converting back to an SMD. To correct for attenuation induced by non-differential misclassification we first need to convert the observed standardized mean difference to a point-biserial correlation coefficient by using the observed proportion of the sample that has been assigned to either group 0 or group 1 (\\(p_\\widetilde{G}\\)). Let there be misclassification as well as measurement error in the outcome \\(\\widetilde{Y}\\). Let’s converting \\(d_{\\widetilde{G}\\widetilde{Y}}\\) to \\(r_{\\widetilde{G}\\widetilde{Y}}\\):\n\\[\nr_{\\widetilde{G}\\widetilde{Y}} = \\frac{d_{\\widetilde{G}\\widetilde{Y}}}{\\sqrt{\\frac{1}{p_{\\widetilde{G}}(1-p_\\widetilde{G})}-d_{\\widetilde{G}\\widetilde{Y}}^2}}.\n\\]\nWe can then correct the point-biserial correlation for group misclassification by dividing by the square root of the classification reliability. Since we also want to correct for measurement error in the continuous dependent variable, we can simultaneously apply an additional correction:\n\\[\nr_{GY} = \\frac{r_{\\widetilde{G}\\widetilde{Y}}}{\\sqrt{r_{\\widetilde{G}\\widetilde{G}'}}\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}'}}}.\n\\]\nNow we can convert the corrected point-biserial correlation into a corrected standardized mean difference (\\(d_{GY}\\)). When converting back to a standardized mean difference, we need to use the true group proportions, \\(p_G\\). Although if we are to assume equal misclassification rates between groups, then the observed proportion can be used \\(p_\\widetilde{G}\\):\n\\[\nd_{GU} = \\frac{r_{GY}}{\\sqrt{p_G\\left(1-p_G\\right)\\left(1-r_{GY}^2\\right)}}.\n\\]\nThis process of converting, correcting, and then back-converting must also be done for the standard error. To avoid redundancy, we can incorporate each step into a single equation:\n\\[\n\\mathrm{var}(d_{GY}) = \\frac {\\mathrm{var}(d_{\\widetilde{G}\\widetilde{Y}})\\times \\left(\\frac{r_{GU}}{r_{\\widetilde{G}\\widetilde{Y}}}\\right)} {\\left(1+d_{\\widetilde{G}\\widetilde{Y}}^2p_\\widetilde{G}(1-p_\\widetilde{G})\\right)^2\\left(d_{\\widetilde{G}\\widetilde{Y}}^2+\\frac{1}{p_\\widetilde{G}(1-p_\\widetilde{G})}\\right)p_G(1-p_G)(1-r_{GY}^2)^3}.\n\\] This variance formula assumes that the reliability coefficients are known. If raw data is available, it is recommended that a bootstrap (resampling) procedure is used to estimate the sampling variance.\n\n\n\n\n\n\nApplied Example in R\n\n\n\nA researcher wants to compare the academic performance (measured by a standardized test) of people with and without Major Depressive Disorder (MDD). The researcher reports a classification reliability of \\(r_{\\widetilde{G}\\widetilde{G}'}=.80\\) and a reliability of the standardized test as \\(r_{\\widetilde{Y}\\widetilde{Y}'}=.85\\). The researcher than finds a standardized mean difference of \\(d_{\\widetilde{G}\\widetilde{Y}}=.30\\) favoring controls (i.e., controls had a higher average on the test). Using the correct_d() function in the psychmeta package (Dahlke and Wiernik 2019), we can obtain an unbiased estimate of the target standardized mean difference.\n\nlibrary(psychmeta)\n\ndGY &lt;- .30\nrYY &lt;- .85\nrGG &lt;- .80\nn0 &lt;- n1 &lt;- 100\n\n\nd_corrected &lt;- correct_d(correction = \"meas\",\n                         d = dGY,\n                         ryy = rYY, \n                         rGg = sqrt(rGG), \n                         n1 = n0,\n                         n2 = n1)\n\n# display corrected correlation\nd_corrected$d_values$dGp$value\n\n[1] 0.3657449\n\n\nThe corrected SMD is \\(d_{GY}=0.37\\). Using the effective sample size from the output we can compute the sampling variance\n\n# compute sampling variance\nvar_error_d(d = d_corrected$d_values$dGp$value,\n            n1 = d_corrected$d_values$dGp$n_effective)\n\n[1] 0.03093188\n\n\n\n\n\n\n\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “Psychmeta: An R Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nGamer, Matthias, Jim Lemon, Ian Fellows, and Puspendra Singh. 2019. Irr: Various Coefficients of Interrater Reliability and Agreement. https://CRAN.R-project.org/package=irr.\n\n\nWiernik, Brenton M., and Jeffrey A. Dahlke. 2020. “Obtaining Unbiased Results in Meta-Analysis: The Importance of Correcting for Statistical Artifacts.” Advances in Methods and Practices in Psychological Science 3 (1): 94–123. https://doi.org/10.1177/2515245919885611.\n\n\nWilliam Revelle. 2023. Psych: Procedures for Psychological, Psychometric, and Personality Research. Evanston, Illinois: Northwestern University. https://CRAN.R-project.org/package=psych.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Group Misclassification</span>"
    ]
  },
  {
    "objectID": "07-artificial-dichotomization/07-artificial-dichotomization.html",
    "href": "07-artificial-dichotomization/07-artificial-dichotomization.html",
    "title": "8  Artificial Dichotomization",
    "section": "",
    "text": "8.1 Introduction\nResearchers occasionally split naturally continuous variables into two discrete groups to increase interpretability or conduct specific analyses (e.g., t-tests). However, artificially dichotomizing variables introduces measurement error and thus attenuating effect size estimates Maxwell and Delaney (1993). The obvious solution to this problem is to simply not dichotomize variables, however if only summary data is available to us, then we may not have this luxury.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Artificial Dichotomization</span>"
    ]
  },
  {
    "objectID": "07-artificial-dichotomization/07-artificial-dichotomization.html#artificial-dichotomization-induced-measurement-error",
    "href": "07-artificial-dichotomization/07-artificial-dichotomization.html#artificial-dichotomization-induced-measurement-error",
    "title": "8  Artificial Dichotomization",
    "section": "8.2 Artificial Dichotomization Induced Measurement Error",
    "text": "8.2 Artificial Dichotomization Induced Measurement Error\nVariables that are dichotomized contain measurement error. This can be demonstrated by the simple fact that dichotomized scores are not perfectly correlated with their underlying continuous scores. To demonstrate this, we can draw a sample of scores and then split the data into high and low scorers and then calculate the correlation coefficient between the two (see Figure 8.1). We see that the dichotomized score does not perfectly correlate with it’s underlying continuous score.\n\n\n\n\n\n\n\n\nFigure 8.1: Visualizing the loss of precision when artificially dichotomizing. Left panel shows a normally distributed variable split (at the median/mean) into a high scoring group and a low scoring group.\n\n\n\n\n\nEven with a perfectly reliable measure, dichotomization will introduce measurement error. Dichotomization occurs when data is split into two groups (low and high groups will be denoted as \\(\\mathsf{low}\\) and \\(\\mathsf{high}\\), respectively) depending on whether they are above or below some cut-point \\(c\\). We can define artificially dichotomized scores as,\n\\[\n\\widetilde{X}=\n\\begin{cases}\n    \\mathsf{high},& \\text{if } \\widetilde{X}\\geq c\\\\\n    \\mathsf{low},& \\text{if } \\widetilde{X}&lt;c\n\\end{cases}\n\\]",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Artificial Dichotomization</span>"
    ]
  },
  {
    "objectID": "07-artificial-dichotomization/07-artificial-dichotomization.html#correcting-correlations-for-artificial-dichotomization",
    "href": "07-artificial-dichotomization/07-artificial-dichotomization.html#correcting-correlations-for-artificial-dichotomization",
    "title": "8  Artificial Dichotomization",
    "section": "8.3 Correcting Correlations for Artificial Dichotomization",
    "text": "8.3 Correcting Correlations for Artificial Dichotomization\n\n8.3.1 Defining the Target Quantity\nWe want to obtain the population correlation between continuous scores of the independent (\\(X\\)) and dependent variable (\\(Y\\)), \\(\\rho_{XY}\\).\nThere are two cases of dichotomization that may occur in a given study: the univariate case where only one variable (either \\(X\\) or \\(Y\\)) is dichotomized and the bivariate case where both variables are dichotomized. In either case, dichotomization will have a biasing effect on the study correlation coefficient. The study correlation on dichotomized data (using the bivariate case, \\(r_{\\widetilde{X}\\widetilde{Y}}\\)) can be modeled as a function of the population correlation on continuous scores (\\(\\rho_{XY}\\); i.e., the target), an artifact attenuation factor \\(\\alpha\\), and sampling error, \\(\\varepsilon_r\\),\n\\[\nr_{\\widetilde{X}\\widetilde{Y}} = \\alpha\\rho_{XY}+\\varepsilon_r.\n\\]\n\n\n8.3.2 Artifact Correction for Correlations\nCorrelations can suffer from dichotomization in one variable (univariate case) or both variables (bivariate case). This section will discuss the procedure for obtaining an unbiased estimate of the correlation coefficient for both cases. For a comparative visualization of a correlation with no dichotomization, univariate dichotomization, and bivariate dichotomization, see Figure 8.2.\n\n\n\n\n\n\n\n\nFigure 8.2: Scatter plots showing the correlation under dichotomization. The first panel (left to right) shows the correlation with no dichotomization (color and shapes of points denote where the split in the dichotomized cases will occur). The middle panel shows the univariate case where only the independent variable is dichotomized. The last panel shows the bivariate case where both independent and dependent variables are dichotomized.\n\n\n\n\n\n\nThe Univariate Case\nIn the simplest case of dichotomization, only one variable is dichotomized and the other is left continuous. As mentioned in previous chapters, a Pearson correlation between a dichotomous variable and a continuous variable is a point-biserial correlation. However, if the variable is naturally continuous, we can estimate the correlation of the underlying continuous scores by computing a biserial correlation. If all we have access to is the dichotomized data, then we need to assume the shape of the underlying distribution, the biserial correlation assumes bivariate normality.\nIn the population, the study correlation \\(\\rho_{\\widetilde{X} Y}\\) is biased by some artifact biasing factor, \\(\\alpha\\),\n\\[\n\\rho_{\\widetilde{X} Y} = \\alpha\\rho_{XY}.\n\\]\nTo estimate the attenuation factor \\(\\alpha\\), we must first figure out where the split of the data occured. To do this, we must first calculate the proportion of the sample in the assigned to the low or high scoring group [^1: It will not matter whether you calculate the proportion of the sample in the high scoring group or the low scoring group for \\(p_X\\). Once you decide on one, do not change it.] :\n\\[\np_\\widetilde{X}  =  \\frac{ n_{\\mathsf{high}} }{n_{\\mathsf{high}} + n_{\\mathsf{low}}},\n\\]\nWhere \\(n\\) indicates the sample size within the \\(\\mathsf{high}\\) and \\(\\mathsf{low}\\), scoring groups.\nWe can use the quantile function (\\(\\phi^{-1}[\\cdot]\\), i.e., the inverse of the cumulative density of the standard normal distribution) to find where the split would have occured on a standard normal distribution (i.e., z-score), \\(\\mathrm{z}_X=\\phi^{-1}[p_X]\\). Using the location of the split on the standard normal, we can compute the artifact attenuation factor (an adaptation of equation 2, Hunter and Schmidt 1990),\n\\[\n\\hat{a} =\\frac{f_X\\left(\\mathrm{z}_X\\right)}{\\sqrt{p_\\widetilde{X}(1-p_\\widetilde{X})}}.\n\\tag{8.1}\\]\nWhere \\(f_X(\\cdot)\\) is the normal ordinate function (i.e., probability density function of a standard normal distribution). Figure 8.3 visually demonstrates how each of these relate to a standard normal distribution.\n\n\n\n\n\n\n\n\nFigure 8.3: This figure shows a normal distribution of scores split into a high scoring and low scoring group. The cut-point of the standard normal distribution is computed with the quantile function, \\(\\phi^{-1}[p_X]\\). The ordinate of the normal distribution at that cut-point is calculated with the normal ordinate function, \\(\\varphi\\left(\\phi^{-1}[p_X]\\right)\\).\n\n\n\n\n\nWe can correct the study correlation using the estimated artifact factor, \\(\\hat{a}\\), therefore the full correction equation is,\n\\[\nr_{XY} = \\frac{r_{\\widetilde{X}Y}}{\\alpha} = \\frac{r_{\\widetilde{X}Y}}{\\left[\\frac{f_X\\left(\\mathrm{z}_X\\right)}{\\sqrt{p_\\widetilde{X}(1-p_\\widetilde{X})}}\\right]}.\n\\tag{8.2}\\]\nIn the case of a median split, where the cut-point would be placed at zero of a standard normal (splitting the distribution in equal halves), the attenuation factor would simplify to \\(\\hat{\\alpha} =\\frac{\\varphi(0)}{\\sqrt{.5(.5)}}\\) \\(=\\frac{2}{\\sqrt{2\\pi}}\\approx .80\\).\n\n\n\n\n\n\nWhat to do when correlation is unavailable\n\n\n\nIt is common that studies do not report the correlation between dichotomized and continuous scores, \\(r_{\\widetilde{X}Y}\\) (i.e., the point-biserial correlation), instead they may report the means and standard deviations of the high and low group instead. To obtain the point-biserial correlation, \\(r_{\\widetilde{X} Y}\\), we need the the mean of the high scoring group (\\(m_{Y|\\mathsf{high}}\\)), mean of the low scoring groups (\\(m_{Y|\\mathsf{low}}\\)), the standard deviation of \\(Y\\) across all individuals (\\(s_Y\\); not to be confused with the pooled/average standard deviation within each group), and the sample sizes within each group (\\(n_{\\mathsf{high}}\\) and \\(n_\\mathsf{low}\\)) to calculate \\(r_{\\widetilde{X}Y}\\),\n\\[\nr_{\\widetilde{X} Y} =\\frac{m_{Y|\\mathsf{high}}-m_{Y|\\mathsf{low}}}{s_Y} \\sqrt{p_\\widetilde{X}(1-p_\\widetilde{X})}.\n\\]\n\n\nHunter and Schmidt (1990) suggested that one should correct the standard error by dividing the uncorrected standard error by the artifact attenuation factor (see equation 6, Hunter and Schmidt 1990). However simulations have found that this computation does not work as well as Soper’s exact method (Soper 1914; Jacobs and Viechtbauer 2017). Therefore the standard error of the corrected (biserial) correlation can be estimated with the following formula (equation 12, Jacobs and Viechtbauer 2017),\n\\[\n\\mathrm{var}(r_{XY}) = \\frac{1}{n-1} \\left(r_{\\widetilde{X}Y}^4+r_{\\widetilde{X}Y}^2\\left(\\frac{p_\\widetilde{X}(1-p_\\widetilde{X})\\mathrm{z}_\\widetilde{X}^2}{\\varphi\\left(s_X\\right)^2} + \\frac{2p_\\widetilde{X} - 1}{f_X\\left(\\mathrm{z}_\\widetilde{X}\\right)} -\\frac{5}{2}\\right)+\\frac{p_\\widetilde{X}(1-p_\\widetilde{X})}{f_X\\left(\\mathrm{z}_\\widetilde{X}\\right)^2}\\right).\n\\]\nSoper (1914) also developed an approximation of the above formula,\n\\[\nse(r_{XY}) \\approx \\sqrt{\\frac{1}{n-1}} \\left(\\frac{\\sqrt{p_\\widetilde{X}(1-p_\\widetilde{X})}}{\\varphi\\left(\\mathrm{z}_\\widetilde{X}\\right)}-r_{\\widetilde{X}Y}^2\\right).\n\\]\n\n\n\n\n\n\nApplied Example in R\n\n\n\nLet’s say we want to assess the relationship between a sales person’s score on a job knowledge test and their job performance estimated as the number of sales made per week. However the researchers of the study chose to dichotomize sales people into high sales performers and low sales performers by splitting the sample into two equally sized groups. They then reported the means and standard deviations of job knowledge test scores of both groups:\n\nLow sales performers: Mean = 22 (SD = 4, n = 50)\nHigh sales performers: Mean = 24 (SD = 4, n = 50)\n\nTo calculate the corrected correlation we can use escalc() function from the metafor package (metafor?). Using the argument measure='RBIS' will return the biserial correlation coefficient which is equivalent to the corrected correlation.\n\nlibrary(metafor)\n\nescalc(measure = 'RBIS',\n       m1i = 24, # High performer mean \n       m2i = 22, # Low performer mean\n       sd1i = 4, # High performer SD\n       sd2i = 4, # Low performer SD\n       n1i = 50, # High performer sample size\n       n2i = 50, # Low performer sample size\n       var.names = c('rXY','var'),\n       digits = 3)\n\n\n    rXY   var \n1 0.307 0.014 \n\n\nTherefore the estimated correlation on continuous scores is \\(r_{XY}=.31\\).\nIf the study reported a Pearson correlation (point-biserial) between the dichotomized variable and the continuous variable of \\(r_{\\widetilde{X} Y}=.245\\), then\n\nlibrary(psychmeta)\n\ncorrect_r_dich(r = .245, # study point-biserial correlation\n               px = .50, # proportion of sample in low or high group\n               n = 100) # total sample size\n\n  r_corrected var_e_corrected    n_adj\n1    0.307062      0.01401901 59.51455\n\n\nThe corrected correlation for continuous scores is equal to the calculation using the means and standard deviations.\n\n\n\n\nThe Bivariate Case\nIn some cases, both independent and dependent variables are dichotomized. A Pearson correlation calculated on these two dichotomized (binary) variables would be equal to the phi coefficient (or also known as Matthew’s correlation coefficient) and we can denote it with our notation for dichotomized variables, \\(\\rho_{\\widetilde{X}\\widetilde{Y}}\\). Dichotomized data can be structured in a contingency table (see Table 8.1).\n\n\n\n\n\n\n\nTable 8.1: Contingency table.\n\n\n\n\n\n\n\n\n\n\n\n\\(\\widetilde{X}=\\mathrm{low}\\)\n\\(\\widetilde{X}=\\mathrm{high}\\)\n\n\n\n\n\\(\\widetilde{Y}=\\mathrm{low}\\)\n\\(n_{LL}\\)\n\\(n_{HL}\\)\n\n\n\\(\\widetilde{Y}=\\mathrm{high}\\)\n\\(n_{LH}\\)\n\\(n_{HH}\\)\n\n\n\n\n\n\n\n\n\n\nFigure 8.4 illustrates how this contingency table relates to an underlying continuous bivariate normal distribution.\n\n\n\n\n\n\nFigure 8.4: The ellipse indicates the bivariate normal distribution of \\(X\\) and \\(Y\\) with a strong positive correlation. If \\(X\\) and \\(Y\\) are positively correlated then we should more individuals populating the high-high and low-low cells rather than the high-low and low-high cells which can be seen by the area of the ellipse located in each quadrant.\n\n\n\nThe corrected correlation coefficient for two dichotomized variables is commonly referred to as the tetrachoric correlation coefficient. The tetrachoric correlation estimates the correlation on continuous scores assuming a bivariate normal distribution.\nOne of the difficulties of computing a dichotomization corrected (tetrachoric) correlation (\\(r_{XY}\\)) is that the relationship between binary variables is reported very differently, we will describe how to obtain a dichtomization corrected correlation in four different cases:\n\nThe full contingency table is provided, including the sample sizes for each cell.\nThe odds ratio is reported as well as the marginal proportions (proportions in low and high groups for each variable).\nThe Phi coefficient is reported.\n\n\nCase 1: Full contingency table is reported\nIf the full contingency table is reported, then the tetrachoric correlation can be calculated directly. Due to the complexity of the calculation, we will use R.\nThe escalc() function in the metafor package (Viechtbauer 2010) can take on values from a contingency table and compute a tetrachoric correlation using the measure='RTET' argument. The function uses the method described by Kirk (1973).\n\n# Example Contingency Table\n#    XL   XH\n# YL 43   23\n# YH 27   38  \n\nlibrary(metafor)\n\nescalc(measure = 'RTET',\n       ai = 43,\n       bi = 23,\n       ci = 27,\n       di = 38,\n       var.names = c('rXY','se.2'))\n\n\n     rXY   se.2 \n1 0.3637 0.0155 \n\n\nThe results show a dichotomization corrected correlation of \\(r_{XY} = .36\\) and an estimated sampling variance of \\(se_c^2=.016\\).\n\n\nCase 2: odds ratio is reported\nIf the odds ratio is all that is available, then we can use the tetrachoric correlation approximation described by Bonett and Price (2005). Using the estimated odds ratio (\\(OR=(n_{HH}n_{LL})/(n_{HL}n_{LH})\\)) and the marginal proportions (\\(p_X\\) and \\(p_Y\\); for this case, both proportions should be with respect to the high scoring group) we can approximate the dichotomization corrected (tetrachoric) correlation (see equation 4, Bonett and Price 2005),\n\\[\nr_{XY} \\approx \\cos\\left( \\frac{\\pi}{1+OR^\\gamma}\\right)\n\\] Where \\(\\Omega\\) is\n\\[\n\\gamma = 1 - \\frac{\\left|p_\\widetilde{X} -p_\\widetilde{Y}\\right|}{5} - \\left[\\frac{1}{2}-\\min(p_\\widetilde{X},p_\\widetilde{Y})\\right]^2.\n\\]\nNote that \\(\\min(p_X,p_Y)\\) is the smallest marginal proportion. The standard error of the estimated correlation can be computed with the following formula [see equation 9, Bonett and Price (2005); note this equation is slightly changed in order to account for the fact that we only have access to the marginal sample sizes and proportions]\n\\[\nse(r_{XY}) =  \\left(\\frac{\\pi\\times \\gamma\\times OR^\\gamma\\times\\sin\\left(\\frac{\\pi}{1+OR^\\gamma}\\right)}{\\left(1+OR^\\gamma\\right)^2}\\right)^2\\times\\frac{4}{n}\n\\]\nWhere \\(n\\) is the total sample size. Using base R, we can convert the odds ratio to a tetrachoric correlation.\n\npX &lt;- .4 # proportion of individuals in high group in XD\npY &lt;- .5 # proportion of individuals in high group in YD\nn &lt;- 150 # total sample size\nOR &lt;- 1.43 # odds ratio\ngamma_factor &lt;- 1 - abs(pX-pY) / 5 - (1/2 - min(c(pX,pY)))^2\n\n# calculate corrected correlation\nrXY &lt;- cos(pi/(1+OR^gamma_factor))\n\n# calculate standard error\nvar_r &lt;- (pi*gamma_factor*OR^gamma_factor*sin(pi/(1+OR^gamma_factor)) /\n  ((1+OR^gamma_factor)^2))^2 * 4/n\n\ncbind(rXY, var_r)\n\n           rXY      var_r\n[1,] 0.2665276 0.01354199\n\n\n\n\nCase 3: Correlation between dichotomized variables\nA Pearson correlation coefficient calculated between two binary variables is most commonly referred to as a Phi coefficient or Matthew’s correlation coefficient. However, the Phi coefficient underestimates the correlation on the underlying continuous scores (assuming bivariate normality). Therefore we can approximate the correlation on continuous scores by using a similar correction to the univariate case. We can define an artifact attenuation factor that is similar to Equation 8.1, but with the added attenuation of \\(\\widetilde{Y}\\),\n\\[\n\\alpha =\\left[\\frac{f_X\\left(\\mathrm{z}_X\\right)}{\\sqrt{p_\\widetilde{X}(1-p_\\widetilde{X})}}\\right]\\times\\left[\\frac{f_Y\\left(\\mathrm{z}_Y\\right)}{\\sqrt{p_\\widetilde{Y}(1-p_\\widetilde{Y})}}\\right].\n\\]\nTherefore we can correct \\(r_{\\widetilde{X}\\widetilde{Y}}\\) for dichotomization in both variables by dividing by the attenuation factor,\n\\[\nr_{XY} = \\frac{r_{\\widetilde{X}\\widetilde{Y}}}{\\alpha}=\\frac{r_{\\widetilde{X}\\widetilde{Y}}}{\\left[\\frac{f_X\\left(\\mathrm{z}_X\\right)}{\\sqrt{p_\\widetilde{X}(1-p_\\widetilde{X})}}\\right]\\times\\left[\\frac{f_Y\\left(\\mathrm{z}_Y\\right)}{\\sqrt{p_\\widetilde{Y}(1-p_\\widetilde{Y})}}\\right]}\n\\]\nThis correction is only an approximation, however it performs fairly well when the correlation is below .8 (Hunter and Schmidt 1990). The standard error of the corrected correlation can be calculated similarly (adaptation of equation 9, Hunter and Schmidt 1990),\n\\[\n\\mathrm{var}(r_{XY})=\\frac{se(r_{\\widetilde{X}\\widetilde{Y}})}{\\left[\\frac{f_X\\left(\\mathrm{z}_X\\right)}{\\sqrt{p_\\widetilde{X}(1-p_\\widetilde{X})}}\\right]^2\\times\\left[\\frac{f_Y\\left(\\mathrm{z}_Y\\right)}{\\sqrt{p_\\widetilde{Y}(1-p_\\widetilde{Y})}}\\right]^2}\n\\]\nUsing the correct_r_dich() function in the psychmeta package (dahlke2019?), we can correct the observed study correlation for dichotomization.\n\nlibrary(psychmeta)\n\ncorrect_r_dich(r = .20,  # observed study correlation\n               px = .50, # proportion of sample in high group of XD\n               py = .50, # proportion of sample in high group of YD\n               n = 100)  # sample size\n\n  r_corrected var_e_corrected    n_adj\n1   0.3141593      0.02296926 36.36678\n\n\nThe output shows the corrected correlation to be \\(r_{XY}=.31\\) and it’s estimated sampling variance \\(\\mathrm{var}(r_{XY})=.023\\).",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Artificial Dichotomization</span>"
    ]
  },
  {
    "objectID": "07-artificial-dichotomization/07-artificial-dichotomization.html#correcting-standardized-mean-differences-smds",
    "href": "07-artificial-dichotomization/07-artificial-dichotomization.html#correcting-standardized-mean-differences-smds",
    "title": "8  Artificial Dichotomization",
    "section": "8.4 Correcting Standardized Mean Differences (SMDs)",
    "text": "8.4 Correcting Standardized Mean Differences (SMDs)\n\n8.4.1 Defining our Target SMD\nThe target quantity is the standardized mean difference between groups of a naturally continuous variable. Our target can thus be defined as the population standardized mean difference between groups \\(A\\) and \\(B\\) on continuous scores of the dependent variable, \\(\\delta_{gY}\\). For a given study the dichotomized standardized mean difference (\\(d_{gY_D}\\)) can be defined as,\n\\[\nd_{G\\widetilde{Y}} = \\alpha\\delta_{GY} + \\varepsilon_d\n\\] where \\(\\alpha\\) is the artifact attenuation factor and \\(\\varepsilon_d\\) is the sampling error.\n\n\n8.4.2 Artifact Correction for SMD\nThe simplest way to correct for dichotomization in a standardized mean difference is to first convert the observed \\(d_{G\\widetilde{Y}}\\) value of the dichotomized dependent variable to a correlation coefficient. When converting to a correlation coefficient, it’s important to note the binary nature of both variables. Now when we convert the SMD to a correlation it will be the phi coefficient rather than the point-biserial correlation that we would be estimating if the dependent variable was continuous. To calculate the phi coefficient from a \\(d_{GY}\\) value we can use the proportion of group membership in group 0 or 1 (\\(p_G\\); it does not matter which one is chosen, as long as it is consistent),\n\\[\nr_{G\\widetilde{Y}} = \\frac{d_{G\\widetilde{Y}}}{\\sqrt{d_{G\\widetilde{Y}}^2+\\frac{1}{p_G(1-p_G)}}}\n\\]\nWe can then correct the correlation similar to how we did in Section 8.3.2,\n\\[\nr_{GY} = \\frac{r_{G\\widetilde{Y}}}{\\left[\\frac{f_Y\\left(\\mathrm{z}_Y\\right)}{\\sqrt{p_\\widetilde{Y}(1-p_\\widetilde{Y})}}\\right]}.\n\\]\nThen we can convert the corrected correlation back into a standardized mean difference,\n\\[\nd_{GY} = \\frac{r_{GY}}{\\sqrt{p_G\\left(1-p_G\\right)\\left(1-r_{GY}^2\\right)}}.\n\\]\nWhere \\(d_{GY}\\) is our corrected SMD (i.e., the estimated SMD on continuous variables). The observed sampling variance must also be corrected using the same three step procedure. For simplicity, we will consolidate this into one formula,\n\\[\n\\mathrm{var}(d_{GY}) = \\frac{\\mathrm{var}(d_{G\\widetilde{Y}}) \\times  \\frac{r_{GY}}{r_{G\\widetilde{Y}}} } {\\left(1+d_{G\\widetilde{Y}}^2p_G[1-p_G]\\right)^3(1-r_{GY}^2)^3}.\n\\]\n\nObtaining Standardized Mean Difference from Odds Ratio\nIn most cases, difference in dichotomized outcomes between two groups is unlikely to be reported as a standardized mean difference, instead it will be more commonly reported as an odds ratio (\\(OR\\)). The odds ratio is asymmetric about 1 (i.e., the null), but we can make it symmetric by log transforming it (\\(\\log(OR)\\)). The standard error of the log odds ratio can be defined as,\n\\[\n\\mathrm{var}(\\log(OR)) = \\frac{1}{n_{1H}} + \\frac{1}{n_{1L}} + \\frac{1}{n_{0H}} + \\frac{1}{n_{0L}}\n\\]\nThe equation above requires the full contingency table to compute. From there we can use the cox-logit method to convert the odds ratio to a standardized mean difference (Cox 1989; Haddock, Rindskopf, and Shadish 1998). Them method is quite simple as it just divides the log odds ratio by 1.65,\n\\[\nd_{GY} = \\frac{\\log(OR)}{1.65}\n\\tag{8.3}\\]\nand the corresponding sampling variance of the \\(d\\) value is,\n\\[\n\\mathrm{var}(d_{GY}) = \\frac{\\mathrm{var}(\\log(OR))}{1.65}.\n\\]\n\n\n\n\n\n\nApplied Example in R\n\n\n\nLet’s consider a hypothetical scenario where we want to examine the relationship between caffeine consumption and the occurrence of heart palpitations in a population. Our target quantity in this case is the standardized mean difference of coffee consumption between people with and without heart palpitations. The variable of interest, caffeine consumption, is continuous (measured in milligrams per day). However, the researcher decides to dichotomize this variable into two groups: “High Caffeine Consumers” and “Low Caffeine Consumers.”\nSuppose we have a sample of 500 individuals, and we dichotomize their caffeine consumption into “High Caffeine Consumers” (more than 250mg per day) and “Low Caffeine Consumers” (less than or equal to 250mg per day). We also observe the occurrence of heart palpitations in these individuals.\n\n\n\n\nHeart Palpitations: Yes\nHeart Palpitations: No\n\n\n\n\nHigh Consumers\n60\n140\n\n\nLow Consumers\n20\n280\n\n\n\nWe can calculate the dichotomization corrected standardized mean difference by calculating the log odds ratio with escalc() function and then applying Equation 8.3 to estimate \\(d_{gY}\\).\n\n# calculate log-odds ratio\nOR &lt;- escalc(measure = 'OR',\n             ai = 60,\n             bi = 140,\n             ci = 20,\n             di = 280,\n             var.names = c('logOR','var'))  \n\n# convert to standardized mean difference\ndGY &lt;- OR$logOR / 1.65\nvar_d &lt;- OR$var / 1.65\n\n# print results\ncbind(dGY,var_d)\n\n          dGY      var_d\n[1,] 1.085915 0.04689755\n\n\nWe can see that the standardized mean difference is estimated to be \\(d_{GY}=1.09\\) and the corrected standard error is \\(\\mathrm{var}(d_{GY})=.047\\)\n\n\n\n\n\n\n\nBonett, Douglas G., and Robert M. Price. 2005. “Inferential Methods for the Tetrachoric Correlation Coefficient.” Journal of Educational and Behavioral Statistics 30 (2): 213–25. https://www.jstor.org/stable/3701350.\n\n\nCox, D. R. 1989. Analysis of Binary Data. 2nd ed. New York: Routledge. https://doi.org/10.1201/9781315137391.\n\n\nHaddock, C. Keith, David Rindskopf, and William R. Shadish. 1998. “Using Odds Ratios as Effect Sizes for Meta-Analysis of Dichotomous Data: A Primer on Methods and Issues.” Psychological Methods 3 (3): 339–53. https://doi.org/10.1037/1082-989X.3.3.339.\n\n\nHunter, John, and Frank Schmidt. 1990. “Dichotomization of Continuous Variables: The Implications for Meta-Analysis.” Journal of Applied Psychology 75 (June): 334–49. https://doi.org/10.1037/0021-9010.75.3.334.\n\n\nJacobs, Perke, and Wolfgang Viechtbauer. 2017. “Estimation of the Biserial Correlation and Its Sampling Variance for Use in Meta-Analysis.” Research Synthesis Methods 8 (2): 161–80. https://doi.org/10.1002/jrsm.1218.\n\n\nKirk, David B. 1973. “On the Numerical Approximation of the Bivariate Normal (Tetrachoric) Correlation Coefficient.” Psychometrika 38 (2): 259–68. https://doi.org/10.1007/BF02291118.\n\n\nMaxwell, Scott, and Harold Delaney. 1993. “Bivariate Median Splits and Spurious Statistical Significance.” Psychological Bulletin 113 (January): 181–90. https://doi.org/10.1037/0033-2909.113.1.181.\n\n\nSoper, H. E. 1914. “On the Probable Error of the Bi-Serial Expression for the Correlation Coefficient.” Biometrika 10 (2/3): 384–90. https://doi.org/10.2307/2331789.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting meta-analyses in R with the metafor package.” Journal of Statistical Software 36 (3): 1–48. https://doi.org/10.18637/jss.v036.i03.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Artificial Dichotomization</span>"
    ]
  },
  {
    "objectID": "08-scale-coarseness/08-scale-coarseness.html",
    "href": "08-scale-coarseness/08-scale-coarseness.html",
    "title": "9  Scale Coarseness",
    "section": "",
    "text": "9.1 Introduction\nScale coarseness describes a situation where a variable that is naturally continuous (e.g., happiness) is binned into discrete values (e.g., happiness measured on a scale of 1-10). This situation is quite common in the social and psychological sciences where Likert items or dichotomous yes/no responses are aggregated to form a coarse total score for a naturally continuous construct. When coarseness is present, measurement error is introduced into the observed scores and those scores lose information.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Scale Coarseness</span>"
    ]
  },
  {
    "objectID": "08-scale-coarseness/08-scale-coarseness.html#dichotomizing-continuous-random-variables",
    "href": "08-scale-coarseness/08-scale-coarseness.html#dichotomizing-continuous-random-variables",
    "title": "9  Scale Coarseness",
    "section": "9.2 Dichotomizing Continuous Random Variables",
    "text": "9.2 Dichotomizing Continuous Random Variables\nUnlike dichotomization, coarseness is an artifact that occurs due to the design of the study rather than during the analysis phase (Aguinis, Pierce, and Culpepper 2009). Particularly, dichotomization occurs after scores are obtained (e.g., splitting a group into high scorers and low scorers), whereas coarseness occurs as an artifact of the measurement procedure itself. This can be visualized by correlating coarse scores with their underlying continuous scores (see Figure 9.1). You will notice that the correlation between coarse and continuous scores is not perfect, indicating that the coarse scores do not perfectly capture the underlying continuous scores.\n\n\n\n\n\n\n\n\nFigure 9.1: Scatterplot showing the correlation between coarse scores (on a 5-point scale) and the underlying continuous scores.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Scale Coarseness</span>"
    ]
  },
  {
    "objectID": "08-scale-coarseness/08-scale-coarseness.html#correcting-correlations",
    "href": "08-scale-coarseness/08-scale-coarseness.html#correcting-correlations",
    "title": "9  Scale Coarseness",
    "section": "9.3 Correcting Correlations",
    "text": "9.3 Correcting Correlations\n\n9.3.1 Defining our Target Correlation\nOur quantity of interest is the population correlation, \\(\\rho\\), between continuous independent variable, \\(X\\), and continuous dependent variable, \\(Y\\). However, in a given study the measurement procedure may produce coarse scores for \\(X\\) and \\(Y\\). We will denote coarse scores with the subscript \\(C\\) We can model the relationship between the observed sample correlation on coarse scores and the true population correlation,\n\\[\nr_{\\widetilde{X}\\widetilde{Y}} = \\alpha\\rho_{XY}+\\varepsilon_r.\n\\]\nWhere \\(\\alpha\\) is our artifact attenuation factor and \\(\\varepsilon_r\\) is our sampling error term.\n\n\n9.3.2 Artifact Correction for Coarseness\nProvided that the cuts are equally spaced, course attenuation of the correlation (MacCallum et al. 2002). Furthermore if we correlate a coarse score with another coarse score than we will observe even more attenuation (see Figure 9.2). There are two cases that we can run into: 1) the univariate case where only one variable is coarse and 2) the bivariate case where both variables are coarse.\n\n\n\n\n\n\n\n\nFigure 9.2: First plot (left to right) shows both variables as continuous and normal. The second plot shows coarseness (5-point scale) only on X, leaving Y continuous (\\(r_{\\widetilde{X}Y}=.47\\)). Last plot shows coarseness on both variables (\\(r_{\\widetilde{X}\\widetilde{Y}}=.47\\)).\n\n\n\n\n\nTo correct the correlation between coarse scores, we need to know the correlation between coarse scores and their underlying continuous scores (\\(\\rho_{X\\widetilde{X}}\\) or \\(\\rho_{Y\\widetilde{Y}}\\)). The calculation of the correlation will require us two important assumptions:\n\nThe shape of the underlying distribution (i.e., normal or uniform).\nThe intervals between scale-points are equal.\n\nBased on these assumptions, Peters and Voorhis (1940) constructed a table of correlations between coarse and continuous scores that is also reported more recently by Aguinis, Pierce, and Culpepper (2009). Table 9.1 is adapted from Peters and Voorhis (1940) and displays the correlation values for uniform and normal distributions for a given number of scale points. For the normal distribution correction, its been shown that even in cases of extreme skew, these correction factors perform well (Wylie 1976).\n\n\n\nTable 9.1: Correlations between continuous and coarse scores (\\(\\rho_{X\\widetilde{X}}\\)) from Peters and Voorhis (1940)\n\n\n\n\n\n\n\n\n\n\nScale Points\nContinuous-Coarse score Correlation (normal)\nContinuous-Coarse score Correlation (uniform)\n\n\n\n\n2\n.816\n.866\n\n\n3\n.859\n.943\n\n\n4\n.916\n.968\n\n\n5\n.943\n.980\n\n\n6\n.960\n.986\n\n\n7\n.970\n.990\n\n\n8\n.977\n.992\n\n\n9\n.982\n.994\n\n\n10\n.985\n.995\n\n\n11\n.988\n.996\n\n\n12\n.990\n.997\n\n\n13\n.991\n.997\n\n\n14\n.992\n.997\n\n\n15\n.994\n.998\n\n\n\n\n\n\nThe correlations between coarse and continuous scores from Table 9.1 (\\(\\rho_{X\\widetilde{X}}\\) and \\(\\rho_{Y\\widetilde{Y}}\\)) can be used as the \\(\\alpha\\) to correct the correlation coefficient,\n\\[\nr_{XY} = \\frac{r_{\\widetilde{X}\\widetilde{Y}}}{\\alpha} =\\frac{r_{\\widetilde{X}\\widetilde{Y}}}{\\rho_{X\\widetilde{X}}\\rho_{Y\\widetilde{Y}}}.\n\\]\nNotice that provided that the assumptions are true, \\(\\alpha\\) is known (the simulations used to compute \\(\\alpha\\) can be arbitrarily precise with more iterations). Since \\(\\alpha\\) is known we can easily,\n\\[\n\\widehat{\\mathrm{var}}(r_{XY}) = \\frac{\\widehat{\\mathrm{var}}(r_{\\widetilde{X}\\widetilde{Y}})}{\\alpha^2} =\\frac{\\widehat{\\mathrm{var}}(r_{\\widetilde{X}\\widetilde{Y}})}{\\rho^2_{X\\widetilde{X}}\\rho^2_{Y\\widetilde{Y}}}  .\n\\]\n\n\n\n\n\n\nCorrecting Correlations in R\n\n\n\nImagine that a researcher wants to relate depression and age. They collect a sample of 100 people from the general population and administer a very quick survey. Depression is measured based on a single item from the patient health questionnaire (PHQ, Kroenke, Spitzer, and Williams 2003) and age is measured in 5 age ranges:\n\n\nOver the last 2 weeks, how often have you been bothered by feeling down, depressed, or hopeless?\n\n\n\nWhat is your age?\n\n\n\n\n\nNot at all\nSeveral days\nMore than half the days\nNearly every day\n\n\n\n\n\n1-20 years\n21-40 years\n41-60 years\n61-80 years\n81+ years\n\n\n\nLet’s say we obtain a correlation of \\(r_{\\widetilde{X}\\widetilde{Y}}=-.20\\). Since the correlation is computed on coarse scores, it is likely attenuated relative to the correlation on each variables continuous underlying scores. Therefore we can use the correct_r_coarseness() function in the psychmeta package (Dahlke and Wiernik 2019) to correct the correlation.\n\nlibrary(psychmeta)\n\ncorrect_r_coarseness(r = -.20, # observed correlation\n                     kx = 5, # 5 age range bins\n                     ky = 4,  # 4 PHQ item options\n                     n = 100, # sample size\n                     dist_x = \"unif\", # assumed age distribution\n                     dist_y = \"norm\") # assumed depression distribution\n\n  r_corrected var_e_corrected    n_adj\n1  -0.2230339      0.01157681 78.99958\n\n\nWe see a slight increase in the magnitude of the correlation with the estimated correlation on continuous scores being \\(r_{XY}=-.22\\) \\((\\widehat{\\mathrm{var}}(r_{XY})=.012)\\).",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Scale Coarseness</span>"
    ]
  },
  {
    "objectID": "08-scale-coarseness/08-scale-coarseness.html#correcting-standardized-mean-differences-smds",
    "href": "08-scale-coarseness/08-scale-coarseness.html#correcting-standardized-mean-differences-smds",
    "title": "9  Scale Coarseness",
    "section": "9.4 Correcting Standardized Mean Differences (SMDs)",
    "text": "9.4 Correcting Standardized Mean Differences (SMDs)\n\n9.4.1 Defining our Target SMD\nOur quantity of interest is the population SMD, \\(\\delta_{GY}\\), between groups 0 and 1 on continuous variable, \\(Y\\). We can define the SMD on coarse scores (\\(d_{G\\widetilde{Y}}\\)) as,\n\\[\nd_{G\\widetilde{Y}} = \\alpha\\delta_{GY}+\\varepsilon_d.\n\\]\nWhere \\(\\alpha\\) is our coarseness biasing factor and \\(\\varepsilon_d\\) is our sampling error term.\n\n\n9.4.2 Artifact Correction for Coarseness\nTo correct a SMD for coarseness in dependent variable, we can use the correlation between coarse scores and continuous scores from Table 9.1,\n\\[\nd_{GY} = \\frac{d_{G\\widetilde{Y}}}{\\alpha} = \\frac{d_{G\\widetilde{Y}}}{\\rho_{Y\\widetilde{Y}}}.\n\\]\nWe must also adjust sampling variance is,\n\\[\n\\widehat{\\mathrm{var}}(d_{GY}) = \\frac{\\widehat{\\mathrm{var}}(d_{G\\widetilde{Y}}) }{\\rho_{Y\\widetilde{Y}}}.\n\\]\n\n\n\n\n\n\nApplied Example in R\n\n\n\nLet’s say that a researcher wants to investigate gender differences in depressive symptoms. The researcher administers a survey to a sample of 50 men and 50 women from the general population. Depression is measured based on a single item from the patient health questionnaire (PHQ, Kroenke, Spitzer, and Williams 2003):\nOver the last 2 weeks, how often have you been bothered by feeling down, depressed, or hopeless?\n\nNot at all\nSeveral days\nMore than half the days\nNearly every day\n\nLet’s say we obtain a SMD of \\(d_{G\\widetilde{Y}}=.25\\), slightly favoring women. Since there is currently no correct_d_coarseness() function in psychmeta, we can simply correct the correlation with base R:\n\nlibrary(psychmeta)\n\ndGY &lt;- .25 # SMD on coarse scores\nvar_d &lt;- var_error_d(dGY,n1 = 50, n2 = 100) # SMD on coarse scores\nrhoYY &lt;- .916 # from table 10.1 (normal, 4-points)\n\ndGY_corrected &lt;- dGY / rhoYY # correct d\nvar_dGY_corrected &lt;- var_d / rhoYY^2 # correct sampling variance\n\n# print results\ncbind(dGY_corrected, var_dGY_corrected)\n\n     dGY_corrected var_dGY_corrected\n[1,]     0.2729258        0.03649008\n\n\nWe see a slight increase in the magnitude of the correlation with the estimated correlation on continuous scores being \\(d_{GY}=.27\\). The adjusted sampling variance is \\(\\widehat{\\mathrm{var}}(d_{GY})=.036\\).\n\n\n\n\n\n\n\nAguinis, Herman, Charles A Pierce, and Steven A Culpepper. 2009. “Scale Coarseness as a Methodological Artifact,” September.\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “Psychmeta: An R Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nKroenke, Kurt, Robert L. Spitzer, and Janet B. W. Williams. 2003. “The Patient Health Questionnaire-2: Validity of a Two-Item Depression Screener.” Medical Care 41 (11): 1284–92. https://www.jstor.org/stable/3768417.\n\n\nMacCallum, Robert C., Shaobo Zhang, Kristopher J. Preacher, and Derek D. Rucker. 2002. “On the Practice of Dichotomization of Quantitative Variables.” Psychological Methods 7: 19–40. https://doi.org/10.1037/1082-989X.7.1.19.\n\n\nPeters, Charles C., and Walter R. Van Voorhis. 1940. “Further Methods of Correlation.” In, 362–403. New York, NY, US: McGraw-Hill Book Company. https://doi.org/10.1037/13596-013.\n\n\nWylie, Peter B. 1976. “Effects of Coarse Grouping and Skewed Marginal Distributions on the Pearson Product Moment Correlation Coefficient.” Educational and Psychological Measurement 36 (1): 1–7. https://doi.org/10.1177/001316447603600101.",
    "crumbs": [
      "Measurement Error",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Scale Coarseness</span>"
    ]
  },
  {
    "objectID": "09-introduction-to-selection-effects/09-introduction-to-selection-effects.html",
    "href": "09-introduction-to-selection-effects/09-introduction-to-selection-effects.html",
    "title": "Selection Effects",
    "section": "",
    "text": "Introduction\nSelection effects arise when individuals within a studies only are include individuals that are based on some eligibility criterion impacts the distributions of random variables. Range restriction is a selection effect where eligible individuals show less variation in the study population than in the target population of interest. On the other hand, range enhancement describes a selection effect where eligible individuals show more variation in the study population than in the target population of interest. In this book we will cover two broad selection cases: direct selection and indirect selection. Direct selection occurs when individual eligibility is based on the random variables used in the analysis (e.g., eligible individuals are above the mean of \\(X\\)), whereas indirect selection occurs when eligibility is based on some other variables.",
    "crumbs": [
      "Selection Effects"
    ]
  },
  {
    "objectID": "10-direct-selection/10-direct-selection.html",
    "href": "10-direct-selection/10-direct-selection.html",
    "title": "10  Direct Selection",
    "section": "",
    "text": "10.1 Introduction\nDirect selection occurs when subjects are explicitly selected based on some eligibility criterion on the variables of interest (rather than a third variable). Range restriction is a form of selection bias that describes a situation where there is less variation in our sample then there is in the population. Whereas range enhancement indicates that there is more variation in a sample then there is in the population.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Direct Selection</span>"
    ]
  },
  {
    "objectID": "10-direct-selection/10-direct-selection.html#introduction",
    "href": "10-direct-selection/10-direct-selection.html#introduction",
    "title": "10  Direct Selection",
    "section": "",
    "text": "Example 10.1 (Correlation between Test Scores) The chapter on effect sizes introduced in example relating the SAT and ACT (two college admissions test in the United States). Recall that the data set consists of 668 individuals who took both the SAT and the ACT from Revelle, Wilt, and Rosenthal (2010) can be used to estimate the correlation. The data set splits the SAT test into Quantitative (SATQ) and Verbal (SATV) subtests which each range from 200-800, whereas the ACT is reported as a score from 1-36. We can plot out the relationship between the total SAT score (SATV + SATQ) and the ACT scores with a scatter plot (see Figure 4.3).\n\n\n\n\n\n\n\n\nFigure 10.1: Scatter plot showing the joint distribution of SAT and ACT scores.\n\n\n\n\n\nIn the Figure 11.1 we see a strong correlation of .66 between test scores. Now let’s say we only study individuals from an elite college that requires students to have a minimum SAT score of 1200. Therefore all the individuals below 1200 would not be included in this sample. Let’s see how that impacts the correlation:\n\n\n\n\n\n\n\n\nFigure 10.2: Scatter plot showing the joint distribution of SAT and ACT scores.\n\n\n\n\n\nAs we can see in Figure 11.2 the correlation is attenuated from \\(r=.66\\) to \\(r=.43\\) when the range of students is restricted to SAT scores above 1200.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Direct Selection</span>"
    ]
  },
  {
    "objectID": "10-direct-selection/10-direct-selection.html#study-population",
    "href": "10-direct-selection/10-direct-selection.html#study-population",
    "title": "10  Direct Selection",
    "section": "10.2 Study Population",
    "text": "10.2 Study Population\nRecall in the first content chapter on probability and random variables, we defined a study sample \\(\\mathcal{S}\\) as being all possible outcomes of a random draw of individuals from the study population \\(\\mathcal{E}\\subseteq \\Psi\\), where \\(\\Psi\\) is our population of interest. However we were vague about what \\(\\mathcal{E}\\) actually is. In situations of direct selection we can define \\(\\mathcal{E}\\) more concretely with some eligibility criterion. For univariate direct selection, the study population can be defined as a subset of one of the random variables of interest,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(X^{-1}(B)\\right)\\;\\middle\\vert\\; B \\in \\mathcal{B}_\\mathbb{R}  \\right\\rbrace \\subseteq \\Psi,\n\\]\nwhere \\(B\\) is some Borel set on the real line and \\(\\ell\\) is the assignment to individual function. Most often \\(B\\) will be some interval on the real-line, for instance, the SAT and ACT example restricted scores above SAT &gt; 1200 therefore the eligible population is any person scoring within the interval \\(B=[1200,1600]\\) (where 1600 is a perfect score). For bivariate direct selection, both variables of interest are used to define the population,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(X^{-1}(B_1)\\cap Y^{-1}(B_2)\\right)\\;\\middle\\vert\\; B_1,B_2 \\in \\mathcal{B}_\\mathbb{R}  \\right\\rbrace \\subseteq \\Psi,\n\\]\nIt is often the case that selection is made via observed proxies, \\(\\widetilde{X}\\) and \\(\\widetilde{Y}\\), since these are usually what we actually observe. The selection in the SAT and ACT example was based on the observed scores of the SAT.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Direct Selection</span>"
    ]
  },
  {
    "objectID": "10-direct-selection/10-direct-selection.html#quantifying-direct-selection-with-the-u-ratio",
    "href": "10-direct-selection/10-direct-selection.html#quantifying-direct-selection-with-the-u-ratio",
    "title": "10  Direct Selection",
    "section": "10.3 Quantifying Direct Selection with the u-ratio",
    "text": "10.3 Quantifying Direct Selection with the u-ratio\nThe distribution of scores in the population of interest \\(\\Psi\\) will exhibit a greater (or lesser) degree of variability compared to the study population \\(\\mathcal{E}\\). Therefore the standard deviation of scores in the target population (\\(\\sigma_{X}\\)) will differ from that of the study population (\\(\\sigma_{X|\\mathcal{E}}\\)). To index the difference between the two standard deviations, we can calculate the \\(u\\)-ratio Wiernik and Dahlke (2020). The \\(u\\)-ratio is defined as the ratio between the standard deviations of the population (\\(\\sigma_{X|\\mathcal{E}}\\)) under selection and the target population (\\(\\sigma_{X}\\)) such that,\n\\[\n\\upsilon_X = \\frac{\\sigma_{X|\\mathcal{E}}}{\\sigma_{X}}\n\\]\nWhere \\(\\upsilon_{X}\\) denotes the population \\(u\\)-ratio. The \\(u\\)-ratio in cases of range restriction will exist in the interval (0–1). Conversely, when the \\(u\\)-ratio is greater than 1 it is indicative of range enhancement. For a sample, the \\(u\\)-ratio is calculated from sample standard deviations,\n\\[\nu_X = \\frac{s_{X|\\mathcal{E}}}{s_X}\n\\tag{10.1}\\]\nWhere \\(u_{X}\\) denotes the sample \\(u\\)-ratio. The target population standard deviation is often quite difficult to estimate since we generally do not have access to an estimate of the population of interest. However, the unrestricted standard deviation can be estimated from some reference or norm study that is representative of the population of interest. For example, the distribution full-scale IQ scores derived from the Wechsler Adult Intelligence Test has a standard deviation of 15 in the US population (Wechsler 2008). We can use this estimate as the standard deviation for the target population. Lets say we select a sample from members of Mensa, a high IQ society, where members are specifically selected on the basis high IQ scores. If the standard deviation of Mensa members is 5, then the \\(u\\)-ratio would be,\n\\[\nu_\\widetilde{X} = \\frac{s_{\\widetilde{X}|\\mathcal{E}}}{s_\\widetilde{X}} = \\frac{5}{15}= .33,\n\\]\nwhere \\(u_\\widetilde{X}\\), \\(s_\\widetilde{X}\\), and \\(s_{\\widetilde{X}|\\mathcal{E}}\\) are the sample estimate counterparts of the components in Equation 11.1, but now they with respect to observed IQ scores. If an estimate of the population standard deviation is not readily available, then a reliability coefficient from the reference sample and the sample under selection can be used to estimate the \\(u\\)-ratio of observed scores,\n\\[\nu_\\widetilde{X} = \\sqrt{\\frac{1-r_{\\widetilde{X}\\widetilde{X}'}}{1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}}}.\n\\]\nWhere \\(r_{XX'|\\mathcal{E}}\\) and \\(r_{XX'}\\) are the reliability estimates within the study sample and reference sample respectively.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Direct Selection</span>"
    ]
  },
  {
    "objectID": "10-direct-selection/10-direct-selection.html#correcting-correlations",
    "href": "10-direct-selection/10-direct-selection.html#correcting-correlations",
    "title": "10  Direct Selection",
    "section": "10.4 Correcting Correlations",
    "text": "10.4 Correcting Correlations\n\n10.4.1 Defining our Target Correlation\nWe want to estimate the correlation in the target population between true scores of the independent (\\(X\\)) and dependent variable (\\(Y\\)). Within a study that suffers from direct selection and measurement error, the observed score correlation will be biased relative to our target true score population correlation, \\(\\rho_{XY}\\). We can model observed score correlation under direct selection as,\n\\[\nr_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}} = \\alpha \\rho_{XY} + \\varepsilon_r\n\\]\nWhere \\(\\alpha\\) is the artifact attenuation/inflation factor and \\(\\varepsilon_r\\) is the sampling error term.\n\n\n10.4.2 Artifact Correction for Correlations\n\nThe Univariate Case\nLet \\(X\\) and \\(Y\\) be linearly related and homoscedastic. Consider the eligibility of an individual study population is on \\(X\\) and not \\(Y\\). It is important to note, that if there is direct selection one of the two variables, then there will be indirect selection in the other variable as long as they are correlated. This would suggest that if \\(u_X\\neq 1\\) and \\(\\rho_{XY}\\neq 0\\) then \\(u_Y\\neq 1\\). Lets visualize the correlation between independent (\\(X\\)) and dependent (\\(Y\\)) with zero-means and unit variance under univariate direct range restriction (see Figure 10.3). Defining the study population as individuals with an \\(X\\) value greater than –.5,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(X^{-1}([-.5,\\infty])\\right) \\right\\rbrace \\subseteq \\Psi,\n\\]\nThe scores of individuals that have been selected will show less variance than the population pool. Specifically, the scenario below shows a \\(u\\)-ratio of \\(u_X=0.69\\) in the independent variable. We see in Figure 10.3 that the correlation in the restricted scores \\((r_{XY|\\mathcal{E}})\\) are attenuated relative to the unrestricted correlation (\\(r_{XY}\\), indicative of \\(\\alpha&lt;1\\)).\n\n\n\n\n\n\n\n\nFigure 10.3: Scatterplot showing a correlation between \\(X\\) and \\(Y\\) under univariate direct range restriction. Dark blue dots indicate the selected sample and the transparent dots indicate the rejected sample.\n\n\n\n\n\nWe can also visualize what happens to the correlation when the range is enhanced. Enhancement can be accomplished by selecting individuals at the ends of the distribution (Taylor and Griess 1976). Therefore we can define the study population as anyone below -.5 and above .5,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(X^{-1}([\\infty,-.5] \\cup [.5,\\infty])\\right) \\right\\rbrace \\subseteq \\Psi,\n\\]\nIn the visualization below (Figure 10.4), we see an opposite effect on the correlation, that is, an inflation of the unrestricted correlation rather than an attenuation (indicating \\(\\alpha&gt;1\\)) like we see under range restriction. The scenario below has a \\(u\\)-ratio \\(u_X=1.26\\) in the independent variable.\n\n\n\n\n\n\n\n\nFigure 10.4: Scatterplot showing a correlation between \\(X\\) and \\(Y\\) under univariate direct range enhancement. Dark blue dots indicate the selected sample and the transparent dots indicate the rejected sample.\n\n\n\n\n\nIt starts to become apparent that if \\(u_X&gt;1\\) (i.e., \\(s_X&lt;s_{X|\\mathcal{E}}\\)) the observed correlation is inflated and when \\(u_X&lt;1\\) (i.e., \\(s_X&gt;s_{X|\\mathcal{E}}\\)) it becomes attenuated (Sackett and Yang 2000).\nThe attenuation/inflation of the correlation is dependent on the magnitude of the correlation, this is due to the fact that selection occurs on \\(X\\) and \\(X\\) is correlated with \\(Y\\), there will also be indirect range restriction in \\(Y\\). Therefore unlike other artifacts that have been discussed so far, range restriction/enhancement depends not only on the artifact value (i.e., the \\(u\\)-ratio), but also on the restricted correlation (Hunter, Schmidt, and Le 2006). Assuming linearity and homoscedasticity between \\(X\\) and \\(Y\\), the attenuation/inflation factor \\(\\alpha\\) is defined as (adapted from equation 4, Hunter, Schmidt, and Le 2006),\n\\[\n\\alpha = \\upsilon_X \\sqrt{1+\\rho_{XY|\\mathcal{E}}^2\\left(\\frac{1}{\\upsilon_X}-1\\right)}\n\\tag{10.2}\\]\nHowever the population values of \\(\\upsilon_X\\) and \\(\\rho_{XY|\\mathcal{E}}\\) are unknown and must be estimated. Therefore a sample estimate of the artifact factor \\(a\\) can be computed as,\n\\[\na = u_X \\sqrt{1+\\rho_{XY|\\mathcal{E}}^2\\left(\\frac{1}{u_X}-1\\right)}\n\\tag{10.3}\\]\nThe correction formula for univariate direct selection was first developed by Pearson (1903) and also provided more recently by Hunter, Schmidt, and Le (2006) and Wiernik and Dahlke (2020). To correct for the systematic bias in correlations, we can divide the correlation under selection by the attenuation factor,\n\\[\nr_{XY} = \\frac{r_{XY|\\mathcal{E}}}{a} = \\frac{r_{XY|\\mathcal{E}}}{u_X \\sqrt{1+\\rho_{XY|\\mathcal{E}}^2\\left(\\frac{1}{u_X}-1\\right)}}.\n\\tag{10.4}\\]\nIf the raw data is available, a bootstrapping procedure is preferred to estimate the sampling variance of the corrected correlation. If it is unavailable then we can treat the factor \\(a\\) as known and obtain an estimate of the sampling variance,\n\\[\n\\widehat{\\mathrm{var}}(r_{XY}) = \\frac{\\widehat{\\mathrm{var}}\\left(r_{XY|\\mathcal{E}}\\right)}{a^2} = \\frac{\\widehat{\\mathrm{var}}\\left(r_{XY|\\mathcal{E}}\\right)}{u_X \\sqrt{1+\\rho_{XY|\\mathcal{E}}^2\\left(\\frac{1}{u_X}-1\\right)}^2}.\n\\tag{10.5}\\]\nIf we want to also correct for measurement error in both samples, then we can also incorporate the reliability into these equations. Note that the following equations will incorporate the reliability within the selected sample (\\(\\rho_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\)) rather than the reference sample (\\(\\rho_{\\widetilde{X}\\widetilde{X}'}\\)). If the reliability coefficient comes from the reference sample, then we can estimate the selected (restricted or enhanced) sample reliability with the corresponding \\(u\\)-ratio,\n\\[\n\\rho_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}} = 1-\\frac{1-\\rho_{\\widetilde{X}\\widetilde{X}'}}{\\upsilon^2_\\widetilde{X}}.\n\\tag{10.6}\\]\nThen we can use the reliability and \\(u\\)-ratios simultaneously to calculate a new attenuation/inflation factor that accounts for both bias in measurement error and direct selection,\n\\[\n\\alpha = \\upsilon_\\widetilde{X}\\sqrt{1-\\upsilon_\\widetilde{X}^2(1-\\rho_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}})}\\sqrt{\\rho_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}}+\\rho_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2\\left(\\frac{1}{\\upsilon^2_\\widetilde{X}}-1\\right)}.\n\\]\nWhere the sample estimate of \\(\\alpha\\) is\n\\[\na = u_\\widetilde{X}\\sqrt{1-u_\\widetilde{X}^2(1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}})}\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}}+r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2\\left(\\frac{1}{u^2_\\widetilde{X}}-1\\right)}.\n\\]\nThen we can use the sample estimate to correct the correlation and to obtain a consistent estimate of the true score correlation in the target population (adapted from table 3, Wiernik and Dahlke 2020),\n\\[\nr_{XY}=\\frac{r_{XY|\\mathcal{E}}}{a} =\\frac{r_{XY|\\mathcal{E}}}{u_\\widetilde{X}\\sqrt{1-u_\\widetilde{X}^2(1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}})}\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}}+r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2\\left(\\frac{1}{u^2_\\widetilde{X}}-1\\right)}}\n\\]\nAgain, a bootstrapping procedure is best for commputing the sampling variance if the raw data is available. Otherwise, if we treat \\(a\\) as known we can be adjust the sampling variance as,\n\\[\n\\widehat{\\mathrm{var}}(r_{XY}) = \\frac{\\widehat{\\mathrm{var}}(r_{XY|\\mathcal{E}})}{a^2}\n\\]\nThere are three important things to note about the equations in this section: 1) these corrections assume linearity and homoskedasticity in the target population population, 2) all these corrections show selection on the independent variable, \\(X\\), however it does not matter whether univariate selection is on \\(X\\) or \\(Y\\), the corrections can be applied in the same fashion (just remember to flip \\(X\\) and \\(Y\\) and vice versa in the equations), 3) The corrections assume that any range restriction/enhancement observed in the non-selection variable (in our example this would be \\(Y\\)) is mediated by the range restriction/enhancement in the variable under selection (i.e., \\(X\\)).\n\n\nThe Bivariate Case\nBivariate direct range restriction/enhancement occurs when selection occurs on both variables of interest, therefore the selection function will be a function of \\(X\\) and \\(Y\\). Let’s visualize the correlation between independent (\\(X\\)) and dependent (\\(Y\\)) variables under bivariate range restriction by only selecting individuals above some cut off point for both \\(X\\) and \\(Y\\) (see Figure 10.5). For this example the selection function is\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(X^{-1}([-.5,\\infty]) \\cap Y^{-1}([-.5,\\infty])\\right) \\right\\rbrace \\subseteq \\Psi,\n\\]\nThe scores of individuals that have been selected will show less variance than the entire pool of individuals. Specifically, the scenario below shows a \\(u\\)-ratio of about 0.70 in the independent variable and dependent variables. We see Figure 10.5 that the correlation in the restricted sample (\\(r_{XY|\\mathcal{E}}\\)) is attenuated relative to the unrestricted correlation (\\(r_{XY}\\)).\n\n\n\n\n\n\n\n\nFigure 10.5: Scatterplot showing a correlation between \\(X\\) and \\(Y\\) under bivariate direct range restriction. Dark blue dots indicate the selected sample and the transparent dots indicate the rejected sample.\n\n\n\n\n\nLikewise let’s visualize what happens to the correlation when the range is enhanced. Enhancement in both variables can be accomplished by selecting individuals at the ends of the distribution of \\(X\\) and \\(Y\\). Therefore we can define the selection function as,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(X^{-1}([-\\infty,-.5] \\cup [.5,\\infty]) \\cap Y^{-1}([-\\infty,-.5] \\cup [.5,\\infty])\\right)  \\right\\rbrace \\subseteq \\Psi,\n\\]\nNote that this type of selection would be exceedingly rare to see in practice. In Figure 10.6, we see inflation of the enhanced correlation relative to the target correlation. The scenario below has a \\(u\\)-ratio of about 1.32 in both the independent variable and dependent variable.\n\n\n\n\n\n\n\n\nFigure 10.6: Scatterplot showing a correlation between \\(X\\) and \\(Y\\) under bivariate direct range enhancement. Dark blue dots indicate the selected sample and the transparent dots indicate the rejected sample.\n\n\n\n\n\nA correction procedure for bivariate range restriction is much more complicated than the univariate formulation. To break down the correction formula into simpler parts, let us first define a factor we will denote with the Greek letter \\(J_{XY}\\),\n\\[\nJ_{XY} = \\frac{\\upsilon_X \\upsilon_Y\\left(\\rho_{XY|\\mathcal{E}}^2-1\\right)}{2\\rho_{XY|\\mathcal{E}}}.\n\\tag{10.7}\\]\nA sample estimate can be denoted as \\(\\hat{J}_{XY}\\) and computed as,\n\\[\n\\hat{J}_{XY} = \\frac{u_X u_Y\\left(r_{XY|\\mathcal{E}}^2-1\\right)}{2r_{XY|\\mathcal{E}}}.\n\\]\nThis factor contains all the parameters needed to correct the correlation coefficient under direct selection. An unbiased estimate of the target population correlation can obtained by the following correction formula (adapted from table 3 Wiernik and Dahlke 2020),\n\\[\nr_{XY} = \\hat{J}_{XY} + \\mathrm{sign}\\left[r_{XY|\\mathcal{E}}\\right]\\sqrt{\\hat{J}_{XY}^2+1},\n\\tag{10.8}\\]\nwhere \\(\\mathrm{sign}[\\cdot]\\) is the sign function denoting whether it is positive (\\(\\mathrm{sign}[\\cdot&gt;0]=1\\)), negative (\\(\\mathrm{sign}[\\cdot]=-1\\)) or zero (\\(\\mathrm{sign}[\\cdot]=0\\)). The sample estimate of the artifact attenuation/inflation factor can be expressed simply as the ratio of the observed correlation and the corrected correlation \\(a = r_{XY|\\mathcal{E}}/r_{XY}\\). If Where the standard error can be computed from calculating the artifact factor (\\(a\\)) from the corrected and restricted/enhanced correlation,\n\\[\n\\widehat{\\mathrm{var}}(r_{XY}) = \\frac{\\widehat{\\mathrm{var}}\\left(r_{XY|\\mathcal{E}}\\right)}{a}= \\frac{\\widehat{\\mathrm{var}}\\left(r_{XY|\\mathcal{E}}\\right)}{\\left[\\frac{r_{XY|\\mathcal{E}}}{r_{XY}}\\right]}.\n\\tag{10.9}\\]\nNow we can also incorporate measurement error into the correction formula. Note that the following equations will incorporate the reliability within the selected sample (\\(r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\)) rather than the unrestricted population (\\(r_{\\widetilde{X}\\widetilde{X}'}\\); see Equation 10.6 on converting to the selected sample). Then we can use the restricted/enhanced (selected) sample reliability and the \\(u\\)-ratios in the following equation to obtain an consistent estimate of the target true score population correlation,\n\\[\nr_{XY} = \\frac{\\hat{J}_{\\widetilde{X}\\widetilde{Y}} + \\text{sign}\\left[r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\right]\\sqrt{\\hat{J}_{\\widetilde{X}\\widetilde{Y}}^2+1}}{\\sqrt{1-u_\\widetilde{X}^2\\left(1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\right)}\\sqrt{1-u_\\widetilde{Y}^2\\left(1-r_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}}\\right)}}.\n\\]\nIf the reliability coefficient comes from the unrestricted population, the formula simplifies to,\n\\[\nr_{XY} = \\frac{\\hat{J}_{\\widetilde{X}\\widetilde{Y}} + \\text{sign}\\left[r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\right]\\sqrt{\\hat{J}_{\\widetilde{X}\\widetilde{Y}}^2+1}}{\\sqrt{r_{\\widetilde{X}\\widetilde{X}'}}\\sqrt{r_{\\widetilde{Y}\\widetilde{Y}'}}}.\n\\]\nWe can use the same equation as Equation 10.9 to calculate the corrected standard error. The standard error can then be calculated as,\n\\[\n\\widehat{\\mathrm{var}}(r_{\\widetilde{X}\\widetilde{Y}}) = \\frac{\\widehat{\\mathrm{var}}\\left(r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\right)}{a}= \\frac{\\widehat{\\mathrm{var}}\\left(r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\right)}{\\left[\\frac{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}}{r_{\\widetilde{X}\\widetilde{Y}}}\\right]}.\n\\]\n\n\n\n\n\n\nCorrecting Correlations in R\n\n\n\nTo continue with our example of SAT and ACT score correlations, let us use the correction formulae that we learned to correct the range restricted correlation when individuals are selected above a 1200 SAT score. Using the sat.act data set in the psychTools package (William Revelle 2024). Lets first clean the data, compute the composite SAT score and add two variables in the data set indicating eligibility of the participant for a univariate selection case (SAT &gt; 1200) and a bivariate selection case (SAT &gt; 1200 and ACT &gt; 28):\n\nlibrary(psychmeta)\nlibrary(psychTools)\nlibrary(tidyverse)\n\ndf &lt;- sat.act[complete.cases(sat.act[,c(\"SATQ\",\"SATV\",\"ACT\")]),] |&gt;\n  # remove scores that are well below guess rate\n  filter(ACT &gt; 7 & SATV &gt; 300 & SATQ &gt; 300) |&gt;\n  # compute composite\n  mutate(SAT = SATV + SATQ) |&gt;\n  # eligibility indicator\n  mutate(eligible_uni = SAT&gt;1200, # univariate selection\n         eligible_biv = SAT&gt;1200 & ACT&gt;29) # bivariate selection\n\nhead(df)\n\n  gender education age ACT SATV SATQ  SAT eligible_uni eligible_biv\n1      2         3  19  24  500  500 1000        FALSE        FALSE\n2      2         3  23  35  600  500 1100        FALSE        FALSE\n3      2         3  20  21  480  470  950        FALSE        FALSE\n4      1         4  27  26  550  520 1070        FALSE        FALSE\n5      1         2  33  31  600  550 1150        FALSE        FALSE\n6      1         5  26  28  640  640 1280         TRUE        FALSE\n\n\nLets compute the correlation observed in the sample of eligible individuals and compare it to that of the full sample,\n\n# full sample\nrXY &lt;- cor(df$ACT, df$SAT)\nrXY\n\n[1] 0.6616793\n\n# eligible sample (univariate case)\nrXYelig_uni &lt;- cor(df$ACT[df$eligible_uni], df$SAT[df$eligible_uni])\nrXYelig_uni\n\n[1] 0.4282125\n\n# eligible sample (bivariate case)\nrXYelig_biv &lt;- cor(df$ACT[df$eligible_biv], df$SAT[df$eligible_biv])\nrXYelig_biv\n\n[1] 0.252818\n\n\nAs expected, the correlation is much lower (i.e., attenuated) after selecting above an SAT score of 1200 and even lower when selecting above an SAT score of 1200 and an ACT score of 29. Let us now calculate the u-ratio for SAT scores (\\(X\\)),\n\n# u ratio of X in univariate case\nuX_uni &lt;- sd(df$SAT[df$eligible_uni]) / sd(df$SAT) \nuX_uni\n\n[1] 0.5115896\n\n# u ratio of X and Y in bivariate case\nuX_biv &lt;- sd(df$SAT[df$eligible_biv]) / sd(df$SAT) \nuY_biv &lt;- sd(df$ACT[df$eligible_biv]) / sd(df$ACT) \ncbind(uX_biv, uY_biv)\n\n       uX_biv    uY_biv\n[1,] 0.479102 0.3883424\n\n\nThe u-ratio for bothe cases is well below 1 indicating that there is substantial range restriction. Notice that the u-ratios for the bivariate case are even lower due to the fact that not only is there direct restriction on both variables, but there is also indirect restriction from the other variable. Let us now use the direct selection correction procedure we discussed in this section with the correct_r function in the psychmeta package (Dahlke and Wiernik 2019),\n\n# correct correlation for univariate direct restriction\nr_corrected_uni &lt;- correct_r(correction = 'uvdrr_x',\n                         rxyi = rXYelig_uni,  \n                         ux = uX_uni,   \n                         n = sum(df$eligible_uni) ) # sample size\n\n# sampling variance for corrected correlation\nvar_r_uni &lt;- var_error_r(r = r_corrected_uni$correlations$rtpa$value,\n                         n = r_corrected_uni$correlations$rtpa$n_effective)\n\n\n# correct correlation\nr_corrected_biv &lt;- correct_r(correction = 'bvdrr',\n                         rxyi = rXYelig_biv,  \n                         ux = uX_biv,   \n                         uy = uY_biv,\n                         n = sum(df$eligible_biv) ) # sample size\n\n# sampling variance for corrected correlation\nvar_r_biv &lt;- var_error_r(r = r_corrected_biv$correlations$rtpa$value,\n                         n = r_corrected_biv$correlations$rtpa$n_effective)\n\n# corrected correlation and sampling variance\n\ncbind(case = c(\"Univariate\",\"Bivariate\"),\n      rXY = c(r_corrected_uni$correlations$rtpa$value,\n              r_corrected_biv$correlations$rtpa$value),\n      var_r = c(var_r_uni,var_r_biv))\n\n     case         rXY                 var_r               \n[1,] \"Univariate\" \"0.679532413152317\" \"0.0019129561847871\"\n[2,] \"Bivariate\"  \"0.713214274752572\" \"0.0208542548632104\"\n\n\nThe univariate correction procedure increases the correlation from .428 to .680 which is a much better approximation to the full sample correlation of .662. Likewise, the bivariate correction went from an extremely attenuated observed correlation .25 to a better estimate of .71.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Direct Selection</span>"
    ]
  },
  {
    "objectID": "10-direct-selection/10-direct-selection.html#correcting-standardized-mean-differences-smds",
    "href": "10-direct-selection/10-direct-selection.html#correcting-standardized-mean-differences-smds",
    "title": "10  Direct Selection",
    "section": "10.5 Correcting Standardized Mean Differences (SMDs)",
    "text": "10.5 Correcting Standardized Mean Differences (SMDs)\n\n10.5.1 Defining our Target SMD\nThe quantity of interest is the target population SMD between actual members of groups 0 and 1. We can denote this SMD as \\(\\delta_{GY}\\). Within a study that suffers from direct selection, the observed SMD (\\(d_{GY|\\mathcal{E}}\\)) will be biased relative to the target, \\(\\delta_{GY}\\). We can model the observed standardized mean difference as,\n\\[\nd_{GY|\\mathcal{E}}= \\alpha\\delta_{GY} + \\varepsilon_d.\n\\]\nWhere \\(\\alpha\\) is the attenuation/inflation factor and \\(\\varepsilon_d\\) is the sampling error term.\n\n\n10.5.2 Artifact Correction for SMDs\n\n10.5.2.1 Selection on the Continuous Variable\nTo correct for direct selection on the continuous variable, we can first convert the observed SMD (\\(d_{GY|\\mathcal{E}}\\)) to a point-biserial correlation (\\(r_{GY|\\mathcal{E}}\\)). Converting \\(d_{GY|\\mathcal{E}}\\) to \\(r_{GY|\\mathcal{E}}\\) can be done by using the observed proportion of individuals in group 0 (or 1), \\(p_{G|\\mathcal{E}}\\),\n\\[\nr_{GY|\\mathcal{E}} = \\frac{d_{GY|\\mathcal{E}}}{\\sqrt{\\frac{1}{p_{G|\\mathcal{E}}(1-p_{G|\\mathcal{E}})}-d_{GY|\\mathcal{E}}^2}}.\n\\]\nWe can then correct the point-biserial correlation for univariate direct selection using the formulas in Section 10.4.2. Note that if you want to correct for measurement error as well, replace \\(r_{\\widetilde{X}\\widetilde{X}'}\\) with \\(r_{\\widetilde{G}\\widetilde{G}'}\\) (i.e., group classification reliability; see chapter on group misclassification) whenever you are working with SMDs. Once we obtained the corrected correlation, \\(r_{GY}\\), we can convert back to a standardized mean difference, we need to use an adjusted group proportions, \\(p_G\\):\n\\[\nd_{GY} = \\frac{r_{GY}}{\\sqrt{p_G\\left(1-p_G\\right)\\left(1-r_{GY}^2\\right)}}.\n\\]\nWhere the adjusted group \\(p_G\\) is estimated with the following formula\n\\[\np_G = \\frac{1}{2}-\\frac{1}{2}\\sqrt{1-4p_{G|\\mathcal{E}}(1-p_{G|\\mathcal{E}})\\left[1+r_{GY|\\mathcal{E}}^2\\left(\\frac{1}{u^2_X}-1\\right)\\right]}\n\\]\nThe adjusted proportion, \\(p_G\\), can also be estimated from the proportion of individuals in the target population (e.g., the proportion of men vs women in the general population). This adjustment is necessary in order to account for indirect selection in the grouping variable. This is similar to the situation described in Section 10.4.2, where one variable suffers from direct range restriction and any variable that is correlated with it, will suffer from indirect selection. The corresponding corrected sampling error can also be computed with the observed and adjusted proportions such that,\n\\[\n\\widehat{\\mathrm{var}}(d_{GY}) = \\frac {\\widehat{\\mathrm{var}}\\left(d_{GY|\\mathcal{E}}\\right)\\left(\\frac{r_{GY}}{r_{GY|\\mathcal{E}}}\\right)^2} {\\left(1+d_{GY|\\mathcal{E}}^2\\,p_{G|\\mathcal{E}}[1-p_{G|\\mathcal{E}}]\\right)^2\\left(d_{GY|\\mathcal{E}}^2+\\frac{1}{p_{G|\\mathcal{E}}(1-p_{G|\\mathcal{E}})}\\right)p_G(1-p_G)(1-r_{GY}^2)^3}.\n\\]\n\n\n\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “Psychmeta: An R Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nHunter, John E., and Frank L. Schmidt. 2015. Methods of meta-analysis: correcting error and bias in research findings (third). Third. Thousand Oaks, California: Sage Publications.\n\n\nHunter, John E., Frank L. Schmidt, and Huy Le. 2006. “Implications of Direct and Indirect Range Restriction for Meta-Analysis Methods and Findings.” Journal of Applied Psychology 91 (3): 594–612. https://doi.org/10.1037/0021-9010.91.3.594.\n\n\nPearson, Karl. 1903. “I. Mathematical Contributions to the Theory of Evolution. XI. On the Influence of Natural Selection on the Variability and Correlation of Organs.” Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character 200 (321-330): 1–66. https://doi.org/10.1098/rsta.1903.0001.\n\n\nRevelle, William, Joshua Wilt, and Allen Rosenthal. 2010. “Individual Differences in Cognition: New Methods for Examining the Personality-Cognition Link.” In, edited by Aleksandra Gruszka, Gerald Matthews, and Blazej Szymura, 27–49. New York, NY: Springer. https://doi.org/10.1007/978-1-4419-1210-7_2.\n\n\nSackett, Paul R., and Hyuckseung Yang. 2000. “Correction for Range Restriction: An Expanded Typology.” Journal of Applied Psychology 85 (1): 112–18. https://doi.org/10.1037/0021-9010.85.1.112.\n\n\nTaylor, Erwin K., and Thomas Griess. 1976. “The Missing Middle in Validation Research.” Personnel Psychology 29 (1): 5–11. https://doi.org/10.1111/j.1744-6570.1976.tb00397.x.\n\n\nWechsler, David. 2008. Wechsler Adult Intelligence Scale–Fourth Edition. 4th ed. https://doi.org/10.1037/t15169-000.\n\n\nWiernik, Brenton M., and Jeffrey A. Dahlke. 2020. “Obtaining Unbiased Results in Meta-Analysis: The Importance of Correcting for Statistical Artifacts.” Advances in Methods and Practices in Psychological Science 3 (1): 94–123. https://doi.org/10.1177/2515245919885611.\n\n\nWilliam Revelle. 2024. psychTools: Tools to Accompany the ’Psych’ Package for Psychological Research. Evanston, Illinois: Northwestern University. https://CRAN.R-project.org/package=psychTools.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Direct Selection</span>"
    ]
  },
  {
    "objectID": "11-indirect-selection/11-indirect-selection.html",
    "href": "11-indirect-selection/11-indirect-selection.html",
    "title": "11  Indirect Selection",
    "section": "",
    "text": "11.1 Introduction\nIndirect selection occurs when the selection process is not directly on the variable of interest, but rather on another related variable. Similar to direct range restriction, this will cause restriction (or enhancement) in the variable of interest.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Indirect Selection</span>"
    ]
  },
  {
    "objectID": "11-indirect-selection/11-indirect-selection.html#introduction",
    "href": "11-indirect-selection/11-indirect-selection.html#introduction",
    "title": "11  Indirect Selection",
    "section": "",
    "text": "Example 11.1 (Correlation between Test Scores) Continuing with the example of test score correlations we saw in the chapter on direct selection. Recall A data set of 668 individuals who took both the SAT and the ACT from Revelle, Wilt, and Rosenthal (2010) can be used to estimate the correlation. The data set splits the SAT test into Quantitative (SATQ) and Verbal (SATV) subtests which each range from 200-800, whereas the ACT is reported as a score from 1-36. We can plot out the relationship between the SAT quantitative score (SATQ) and the ACT scores with a scatter plot (see Figure 11.1).\n\n\n\n\n\n\n\n\nFigure 11.1: Scatter plot showing the joint distribution of SATQ and ACT scores.\n\n\n\n\n\nIn the Figure 11.1 we see a strong correlation of .61 between test scores. Now let’s say we are looking at a sample of English tutors who were selected upon their verbal SAT scores (SATV &gt; 600) as part of their job application. Therefore all the individuals who scored below 600 on the verbal section would not be included in this sample. Let’s see how that impacts the correlation:\n\n\n\n\n\n\n\n\nFigure 11.2: Scatter plot showing the joint distribution of SAT and ACT scores.\n\n\n\n\n\nAs we can see in Figure 11.2 the correlation is attenuated from \\(r=.66\\) to \\(r=.34\\) when the range of students is restricted to SATV scores above 600.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Indirect Selection</span>"
    ]
  },
  {
    "objectID": "11-indirect-selection/11-indirect-selection.html#study-population",
    "href": "11-indirect-selection/11-indirect-selection.html#study-population",
    "title": "11  Indirect Selection",
    "section": "11.2 Study Population",
    "text": "11.2 Study Population\nRecall in the direct range restriction chapter that we looked to define the study population \\(\\mathcal{E}\\subseteq\\Psi\\) with respect to one or both of the random variables of interest (i.e., \\(X\\) and \\(Y\\)). For this chapter, we will introduce a new random variable \\(Z\\) that is not a variable of scientific interest to us. Therefore the study population can thus be defined as,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(Z^{-1}(B)\\right)\\;\\middle\\vert\\; B \\in \\mathcal{B}_\\mathbb{R}  \\right\\rbrace \\subseteq \\Psi,\n\\]\nwhere \\(B\\) is some Borel set on the real line and \\(\\ell\\) is the assignment to individual function. Most often \\(B\\) will be some interval on the real-line, for instance, the SAT and ACT example restricted scores above SATV &gt; 600 therefore the eligible population is any person scoring within the interval \\(B=[600,800]\\) (where 800 is a perfect score).",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Indirect Selection</span>"
    ]
  },
  {
    "objectID": "11-indirect-selection/11-indirect-selection.html#quantifying-selection-induced-restrictionenhancement",
    "href": "11-indirect-selection/11-indirect-selection.html#quantifying-selection-induced-restrictionenhancement",
    "title": "11  Indirect Selection",
    "section": "11.3 Quantifying Selection-Induced Restriction/enhancement",
    "text": "11.3 Quantifying Selection-Induced Restriction/enhancement\nThe distribution of scores in the target population may exhibit a greater (or lesser) degree of variability compared to the sample that has been selected into the study. Therefore the standard deviation of scores in the target population (\\(\\sigma_{X}\\)) may differ from the study population (\\(\\sigma_{X|\\mathcal{E}}\\)). To index the difference between the two standard deviations, we can calculate the u-ratio as we did with direct selection. The u-ratio is the ratio between the standard deviations of the population under selection and the target population such that (\\(\\upsilon\\) denotes the population u-ratio),\n\\[\n\\upsilon_X = \\frac{\\sigma_{X|\\mathcal{E}}}{\\sigma_{X}}\n\\tag{11.1}\\]\nThe u-ratio in cases of range restriction will exist in the interval \\(\\upsilon_X\\in[0,1)\\) . Conversely, when the u-ratio is greater than 1, \\(\\upsilon_X\\in(1,\\infty]\\), it is indicative of range enhancement. The target population standard deviation is often quite difficult to acquire since we do not usually have access to a random sample from that population. However, the target population standard deviation can be estimated from a reference sample that is representative of the target population. This often comes in the form of standardization samples or norm samples (obtained from test manuals) if the unrestricted group is the general population. For example, the distribution full-scale IQ scores derived from the Wechsler Adult Intelligence Test has a standard deviation of 15 in the US population (Wechsler 2008). We can use this estimate as the standard deviation for the unrestricted population. Lets say we select a sample from members of Harvard students, who tend to have higher IQs than the general population (this is due to the fact that selection criterion, such as GPA and SAT scores are positively correlated with IQ). If the standard deviation of IQ in Harvard students is 10, then the \\(u\\)-ratio would be,\n\\[\nu_\\widetilde{X} =  \\frac{s_{\\widetilde{X}|\\mathcal{E}}}{s_\\widetilde{X}} = \\frac{10}{15}= .67\n\\]\nwhere \\(u_\\widetilde{X}\\), \\(s_\\widetilde{X}\\), and \\(s_{\\widetilde{X}|\\mathcal{E}}\\) are the sample estimate counterparts of the components in Equation 11.1. However it is not always the case that an estimate of the unrestricted standard deviation is readily available. Therefore if the reliability coefficient from the reference sample and the study can be used to estimate the \\(u\\)-ratio,\n\\[\nu_X = \\sqrt{\\frac{1-r_{\\widetilde{X}\\widetilde{X}'}}{1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}}}\n\\]\nWhere \\(r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\) and \\(r_{\\widetilde{X}\\widetilde{X}'}\\) are the reliability estimates from the sample under selection and the reference (target population) sample, respectively. In the context of indirect range restriction, the selection does not occur directly on \\(X\\) (or \\(Y\\)), instead it occurs on a third variable, \\(Z\\). Assuming linearity and homoscedasticity between variables, the affect that selection on \\(Z\\) has on \\(X\\) is dependent on the correlation between them, \\(\\rho_{XZ}\\). Therefore we can see how the u-ratio of \\(Z\\) (\\(\\upsilon_Z\\)) related to the u-ratio of \\(X\\) (Hunter, Schmidt, and Le 2006),\n\\[\nu_X = \\sqrt{\\rho_{XZ}^2\\upsilon_Z^2 -\\rho_{XZ}^2 + 1 }\n\\]\nIf \\(\\rho_{XZ}=0\\), then you will notice that \\(\\upsilon_X=1\\), effectively having no range restriction/enhancement on \\(X\\). Also, notice that a correlation of \\(\\rho_{XZ}=1\\) will return \\(\\upsilon_X=\\upsilon_Z\\), indicating that directly selecting on \\(Z\\) would effectively be direct selection on \\(X\\) as well. This relationship between \\(\\upsilon_X\\), \\(\\upsilon_Z\\), and \\(\\rho_{XZ}\\) can be visualized in Figure 11.3\n\n\n\n\n\n\n\n\nFigure 11.3: The impact of the association between \\(X\\) and \\(Z\\). The data consists of \\(N=1,000\\) simulated observations, where the red plots show a low correlation case (\\(\\rho_{XZ}=.20\\)) and the blue plots show a high correlation case (\\(\\rho_{XZ}=.80\\)). The top plots show the relationship between \\(X\\) and \\(Z\\) with the darker points indicating individuals that have been selected into the sample. The bottom plots shows the probability of selection into the sample as a function of X. The dark distribution on the top of the plot show the distribution of individuals in the selected sample. Notice that the distribution of the selected individual’s in the high correlation case is a narrower distribution than the low correlation case.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Indirect Selection</span>"
    ]
  },
  {
    "objectID": "11-indirect-selection/11-indirect-selection.html#correcting-correlations",
    "href": "11-indirect-selection/11-indirect-selection.html#correcting-correlations",
    "title": "11  Indirect Selection",
    "section": "11.4 Correcting Correlations",
    "text": "11.4 Correcting Correlations\n\n11.4.1 Defining our Target Correlation\nWe want to estimate the correlation in the target population between true scores of the independent (\\(X\\)) and dependent variable (\\(Y\\)). Within a study that suffers from indirect selection and measurement error, the observed score correlation will be biased relative to our target true score population correlation, \\(\\rho_{XY}\\). We can model observed score correlation under direct selection as,\n\\[\nr_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}} = \\alpha \\rho_{XY} + \\varepsilon_r\n\\]\nWhere \\(\\alpha\\) is the artifact attenuation/inflation factor and \\(\\varepsilon_r\\) is the sampling error term.\n\n\n11.4.2 Artifact Correction for Correlations\n\nThe Univariate Case\nRange restriction (or enhancement) in either the independent or dependent variable will induce bias into the correlation coefficient. Let us consider a case where we select individuals based on meeting some criterion of some third variable, \\(Z\\). In the univariate case, we assume that selection on \\(Z\\) only directly affects restriction/enhancement in \\(X\\) while any restriction/enhancement in \\(Y\\) is mediated by the effect on \\(X\\) (see ?fig-corr-model-uni).\nNow consider a study where we want to calculate correlation in the target population between an independent variable, \\(X\\), and a dependent variable, \\(Y\\). However, the individual’s are selected whether they are above the mean of \\(Z\\) (Mean = 0). We can thus define the selection function such that,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(Z^{-1}([-.5,\\infty])\\right) \\right\\rbrace \\subseteq \\Psi,\n\\]\nIn the following examples, we will simulate a correlation of \\(\\rho_{XZ}=.80\\). Figure 11.4 shows a u-ratio of about \\(u_X=0.75\\) in the independent variable. We see that the sample correlation in the restricted scores (\\(r_{XY|\\mathcal{E}}=.42\\)) is attenuated relative to the unrestricted correlation (\\(r_{XY}=.50\\)).\n\n\n\n\n\n\n\n\nFigure 11.4: Scatterplot showing a correlation between \\(X\\) and \\(Y\\) under univariate indirect range restriction. Dark red dots indicate the selected sample and the transparent dots indicate the rejected sample.\n\n\n\n\n\nWe can also visualize what happens to the correlation when the range is enhanced. Enhancement can be accomplished by selecting individuals at the ends of the distribution (Taylor and Griess 1976). For indirect selection, individuals are selected at the ends of the distribution of \\(Z\\) such that the selection function can be defined as,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(Z^{-1}([-\\infty,-1]\\cup [1,\\infty])\\right) \\right\\rbrace \\subseteq \\Psi.\n\\]\nIn Figure 11.5, we see an opposite effect on the correlation, that is, an inflation of the correlation rather than an attenuation like we see under range restriction. The scenario below has a \\(u\\)-ratio of about \\(u_X=1.32\\) in the independent variable.\n\n\n\n\n\n\n\n\nFigure 11.5: Scatterplot showing a correlation between \\(X\\) and \\(Y\\) under univariate indirect range enhancement. Dark red dots indicate the selected sample and the transparent dots indicate the rejected sample.\n\n\n\n\n\nIn summary, if \\(u_X&gt;1\\) the observed correlation is inflated relative to the correlation in the target population. Whereas the correlation is attenuated when \\(u_X&lt;1\\) (Sackett and Yang 2000). The artifact attenuation/inflation factor \\(\\alpha\\) for indirect selection is as follows (equation 5, Le and Schmidt 2006),\n\\[\n\\alpha = \\sqrt{\\rho_{XY|\\mathcal{E}}^2 + \\upsilon_{X}^2 (1- \\rho_{XY|\\mathcal{E}}^2)  }\n\\]\nA sample estimate of the attenuation/inflation factor, \\(a\\), can be computed as,\n\\[\na = \\sqrt{r_{XY|\\mathcal{E}}^2 + u_{X}^2 (1- r_{XY|\\mathcal{E}}^2)  }\n\\]\nUsing the estimated attenuation/inflation factor, we can correct the observed correlation for bias induced by indirect selection\n\\[\nr_{XY} = \\frac{r_{XY|\\mathcal{E}}}{a} = \\frac{r_{XY|\\mathcal{E}}}{\\sqrt{r_{XY|\\mathcal{E}}^2 + u_{X}^2 (1- r_{XY|\\mathcal{E}}^2)  }}\n\\tag{11.2}\\]\nIf we want to correct for range restriction/enhancement and measurement error, we can incorporate the reliability coefficients (under selection) of \\(X\\) (\\(r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\)) and \\(Y\\) (\\(r_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}}\\)) into the formula for \\(\\alpha\\),\n\\[\n\\alpha = \\sqrt{\\rho_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2 + \\frac{\\upsilon_{\\widetilde{X}}^2 \\rho_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\left(\\rho_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\rho_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}} - \\rho_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2\\right) }{1 - \\upsilon_{\\widetilde{X}}^2 \\left(1-\\rho_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\right)} }.\n\\tag{11.3}\\]\nThe sample estimate of \\(\\alpha\\) is,\n\\[\na = \\sqrt{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2 + \\frac{u_{\\widetilde{X}}^2 r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\left(r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}r_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}} - r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2\\right) }{1 - u_{\\widetilde{X}}^2 \\left(1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\right)} }\n\\tag{11.4}\\]\nNow correcting the observed correlation with this modified estimate of \\(a\\) to correct the observed correlation will yield the true score correlation in the target population,\n\\[\nr_{XY}=\\frac{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}}{a} = \\frac{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}}{\\sqrt{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2 + \\frac{u_{\\widetilde{X}}^2 r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\left(r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}r_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}} - r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}^2\\right) }{1 - u_{\\widetilde{X}}^2 \\left(1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\right)} }}\n\\]\nIf the reliability coefficients come from the target population and do not suffer selection effects, we can estimate the reliability under selection using the following formulas (equation 11 and 12 Le and Schmidt 2006):\n\\[\nr_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}} = 1-\\frac{1-r_{\\widetilde{X}\\widetilde{X}'}}{u_\\widetilde{X}^2}\n\\tag{11.5}\\]\n\\[\nr_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}} = 1-\\frac{1-r_{\\widetilde{Y}\\widetilde{Y}'}}{u_\\widetilde{Y}^2}\n\\tag{11.6}\\]\nWe now need to adjust the standard error for the corrected correlation coefficient. To do this, we can either divide the observed standard error by the attenuation/inflation factor (or equivalently, the observed correlation divided by the corrected correlation),\n\\[\n\\widehat{\\mathrm{var}}(r_{XY}) = \\frac{\\widehat{\\mathrm{var}}\\left(r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\right)}{a^2}= \\frac{\\widehat{\\mathrm{var}}\\left(r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\right)}{\\left[\\frac{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}}{r_{XY}}\\right]^2}.\n\\]\n\n\nThe Bivariate Case\nBivariate indirect range restriction/enhancement occurs when the selection variable has independent relationships with both the independent and dependent variable. Like we did for the univariate case, let’s visualize the correlation between independent (\\(X\\)) and dependent (\\(Y\\)) variables under range restriction by only selecting individuals above a score of -0.50 in our selector variable, \\(Z\\). Therefore the selection function can be defined as,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(Z^{-1}([-.5,\\infty])\\right) \\right\\rbrace \\subseteq \\Psi.\n\\]\nWe will also fix the correlations between \\(Z\\) and independent variable, as well as the selector and dependent variable to be \\(\\rho_{XZ} = \\rho_{YZ} = .80\\). Unlike the univariate case, in the bivariate case \\(X\\) and \\(Y\\) have direct relationships with \\(Z\\). The scenario displayed in Figure 11.6, shows a \\(u\\)-ratio of about \\(u_X=u_Y=0.81\\) in the independent variable and dependent variables. We see in the figure below that the correlation in the restricted sample (\\(r_{XY|\\mathcal{E}}=.25\\)) is attenuated relative to the target population correlation (\\(r_{XY}=.50\\)).\n\n\n\n\n\n\n\n\nFigure 11.6: Scatterplot showing a correlation between \\(X\\) and \\(Y\\) under bivariate indirect range restriction. Dark red dots indicate the selected sample and the transparent dots indicate the rejected sample.\n\n\n\n\n\nLikewise let’s visualize what happens to the correlation when the range is enhanced. Enhancement in both variables can be accomplished by selecting individuals at the ends of the distribution of \\(Z\\) (for this case we will select individuals below a score of -1 and above a score of 1). We can thus define the study population as,\n\\[\n\\mathcal{E} = \\left\\lbrace\\vphantom{\\int} \\psi\\in \\ell\\left(Z^{-1}([-\\infty,1]\\cup[1,\\infty])\\right) \\right\\rbrace \\subseteq \\Psi.\n\\]\nIn Figure 11.7, we observe an inflation of observed correlation (\\(r_{XY|\\mathcal{E}}=.74\\)) relative to the target correlation (\\(r_{XY}=.50\\)). Figure 11.7 has a \\(u\\)-ratio of about \\(u_X=u_Y=1.38\\) in both the independent variable and dependent variable.\n\n\n\n\n\n\n\n\nFigure 11.7: Scatterplot showing a correlation between \\(X\\) and \\(Y\\) under bivariate indirect range enhancement. Dark red dots indicate the selected sample and the transparent dots indicate the rejected sample.\n\n\n\n\n\nA correction formula for bivariate range restriction is much more complicated than the univariate formulation. In the univariate case, we did not need any more information about the selection process beyond what we could infer from \\(u_X\\). However in the bivariate case, we need to have a basic idea of the selection mechanism at play (Dahlke and Wiernik 2020). Particularly we at least know the direction of the correlation between the selector variable, \\(Z\\), and the independent (\\(\\rho_{XZ}\\)) and dependent variable (\\(\\rho_{YZ}\\)). This will require a little bit of knowledge about the selection process within a given study. Let us first define a factor we will denote with \\(\\Lambda\\) (Dahlke and Wiernik 2020). This factor takes into account the direction of the correlation of \\(\\rho_{XZ}\\) (if positive, we can set \\(\\rho_{XZ}=1\\), if negative, \\(\\rho_{XZ}=-1\\), if zero, \\(\\rho_{XZ}=0\\)) and \\(\\rho_{YZ}\\) (repeat the same procedure as \\(\\rho_{XZ}\\)). Therefore \\(\\lambda\\) can be defined as,\n\\[\\begin{aligned}\n\\Lambda =& \\text{ sign}\\left(\\rho_{XZ}\\rho_{YZ} [1-u_X][1-u_Y]\\right) \\\\[.3em] &\\times\\frac{\\text{sign}\n\\left(1-u_X\\right)\\min\\left(u_X,\\frac{1}{u_X}\\right) +\n\\text{ sign}\\left(1-u_Y\\right)\\min\\left(u_Y,\\frac{1}{u_Y}\\right)\n}{\\min\\left(u_X,\\frac{1}{u_X}\\right)+\\min\\left(u_Y,\\frac{1}{u_Y}\\right)}.\n\\end{aligned}\\]\nAlthough complex, the output of \\(\\Lambda\\) will be either -1, 0, or 1. We can then plug this factor into the full correction equation that provides us with an consistent estimate of the correlation in the unrestricted population,\n\\[\nr_{XY} = r_{XY|\\mathcal{E}}u_Xu_Y+\\Lambda\\sqrt{|1-u_X^2||1-u_Y^2|}\n\\]\nSimilar to the univariate formula, we can also incorporate measurement error into the correction. Measurement error will bias the correlation on top of the bias induced by range restriction/enhancement. Therefore we can incorporate the reliabilities estimated within the restricted sample (\\(r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\) and \\(r_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}}\\)), into our correction formula:\n\\[\nr_{XY} = \\frac{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\cdot u_\\widetilde{X} u_\\widetilde{Y}+\\Lambda\\sqrt{|1-u_\\widetilde{X}^2||1-u_\\widetilde{Y}^2|}}{\\sqrt{1-u_\\widetilde{X}^2\\left(1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}}\\right)}\\sqrt{1-u_\\widetilde{Y}^2\\left(1-r_{\\widetilde{Y}\\widetilde{Y}'|\\mathcal{E}}\\right)}}\n\\]\nIf the reliability estimates come from an target population reference sample, we can get estimates of the reliability coefficients in the selected sample using Equation 11.5 and Equation 11.6. We then can correct the observed sampling variance (\\(\\sigma^2_{\\varepsilon_o}\\)),\n\\[\n\\widehat{\\mathrm{var}}(r_{XY}) = \\frac{\\widehat{\\mathrm{var}}\\left(r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\right)}{a^2}= \\frac{\\widehat{\\mathrm{var}}\\left(r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}\\right)}{\\left[\\frac{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}}}{r_{XY}}\\right]^2}.\n\\]\n\n\n\n\n\n\nCorrecting Correlations\n\n\n\nTo continue with our example of SAT and ACT score correlations, let us use the correction formulae that we learned to correct the indirect range restricted correlation between the quantitative sub-test of the SAT and the ACT. We will look at the case where individuals are selected above 600 on the verbal section of the SAT. Using the sat.act data set in the psychTools package (William Revelle 2024). Lets first clean the data and add two variables in the data set indicating eligibility of the participant.\n\nlibrary(psychmeta)\nlibrary(psychTools)\nlibrary(tidyverse)\n\ndf &lt;- sat.act[complete.cases(sat.act[,c(\"SATQ\",\"SATV\",\"ACT\")]),] |&gt;\n  # remove scores that are well below guess rate\n  filter(ACT &gt; 7 & SATV &gt; 300 & SATQ &gt; 300) |&gt;\n  # eligibility indicator\n  mutate(eligible = SATV&gt;600) # selection\n\nhead(df)\n\n  gender education age ACT SATV SATQ eligible\n1      2         3  19  24  500  500    FALSE\n2      2         3  23  35  600  500    FALSE\n3      2         3  20  21  480  470    FALSE\n4      1         4  27  26  550  520    FALSE\n5      1         2  33  31  600  550    FALSE\n6      1         5  26  28  640  640     TRUE\n\n\nLets compute the correlation observed in the sample of eligible individuals and compare it to that of the full sample,\n\n# full sample\nrXY &lt;- cor(df$ACT, df$SATQ)\nrXY\n\n[1] 0.6083657\n\n# eligible sample\nrXYelig &lt;- cor(df$ACT[df$eligible], df$SATQ[df$eligible])\nrXYelig\n\n[1] 0.4932103\n\n\nAs expected, the correlation is much lower (i.e., attenuated) after selecting above an SAT score of 1200 and even lower when selecting above an SAT score of 1200 and an ACT score of 29. Let us now calculate the u-ratio for SAT scores (\\(X\\)),\n\n# u ratio of X and Y\nuX &lt;- sd(df$SATQ[df$eligible]) / sd(df$SATQ) \nuY &lt;- sd(df$ACT[df$eligible]) / sd(df$ACT) \ncbind(uX, uY)\n\n            uX        uY\n[1,] 0.8165014 0.7214743\n\n\nThe u-ratio for both cases is well below 1 indicating that there is substantial range restriction. Now let’s use the direct selection correction procedure we discussed in this section with the correct_r function in the psychmeta package (Dahlke and Wiernik 2019),\n\n# correct correlation for bivariate indirect restriction\nr_corrected &lt;- correct_r(correction = 'bvirr',\n                         rxyi = rXYelig,  \n                         ux = uX,   \n                         uy = uY,   \n                         n = sum(df$eligible), # sample size\n                         sign_rxz = 1,\n                         sign_ryz = 1)\n\n# sampling variance for corrected correlation\nvar_r &lt;- var_error_r(r = r_corrected$correlations$rtpa$value,\n                     n = r_corrected$correlations$rtpa$n_effective)\n\n\n\ncbind(rXY = r_corrected$correlations$rtpa$value,\n      var_r = var_r)\n\n           rXY        var_r\n[1,] 0.6903191 0.0009294836\n\n\nThe bivariate correction procedure increases the correlation from .493 to .690 which is a better approximation to the full sample correlation of .608. If we instead hypothesize that the restriction in ACT scores is fully mediated by SATQ, then we can use the univariate indirect selection correction:\n\n# correct correlation for bivariate indirect restriction\nr_corrected &lt;- correct_r(correction = 'uvirr_x',\n                         rxyi = rXYelig,  \n                         ux = uX,\n                         n = sum(df$eligible), # sample size\n                         sign_rxz = 1,\n                         sign_ryz = 1)\n\n# sampling variance for corrected correlation\nvar_r &lt;- var_error_r(r = r_corrected$correlations$rtpa$value,\n                     n = r_corrected$correlations$rtpa$n_effective)\n\n\n\ncbind(rXY = r_corrected$correlations$rtpa$value,\n      var_r = var_r)\n\n           rXY      var_r\n[1,] 0.5703633 0.00167565\n\n\nThis value is a bit closer to the actual full sample correlation (.608) than the bivariate correction.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Indirect Selection</span>"
    ]
  },
  {
    "objectID": "11-indirect-selection/11-indirect-selection.html#correcting-standardized-mean-differences-smds",
    "href": "11-indirect-selection/11-indirect-selection.html#correcting-standardized-mean-differences-smds",
    "title": "11  Indirect Selection",
    "section": "11.5 Correcting Standardized Mean Differences (SMDs)",
    "text": "11.5 Correcting Standardized Mean Differences (SMDs)\nThis section will look earily similar to the SMD section for direct selection, that is because the directions to correct the SMD as outlined here is virtually identical.\n\n11.5.1 Defining our Target SMD\nThe quantity of interest is the target population SMD between actual members of groups 0 and 1. We can denote this SMD as \\(\\delta_{GY}\\). Within a study that suffers from direct selection, the observed SMD (\\(d_{GY|\\mathcal{E}}\\)) will be biased relative to the target, \\(\\delta_{GY}\\). We can model the observed standardized mean difference as,\n\\[\nd_{GY|\\mathcal{E}}= \\alpha\\delta_{GY} + \\varepsilon_d.\n\\]\nWhere \\(\\alpha\\) is the attenuation/inflation factor and \\(\\varepsilon_d\\) is the sampling error term.\n\n\n11.5.2 Artifact Correction for SMDs\n\n11.5.2.1 Selection on the Continuous Variable\nTo correct for direct selection on the continuous variable, we can first convert the observed SMD (\\(d_{GY|\\mathcal{E}}\\)) to a point-biserial correlation (\\(r_{GY|\\mathcal{E}}\\)). Converting \\(d_{GY|\\mathcal{E}}\\) to \\(r_{GY|\\mathcal{E}}\\) can be done by using the observed proportion of individuals in group 0 (or 1), \\(p_{G|\\mathcal{E}}\\),\n\\[\nr_{GY|\\mathcal{E}} = \\frac{d_{GY|\\mathcal{E}}}{\\sqrt{\\frac{1}{p_{G|\\mathcal{E}}(1-p_{G|\\mathcal{E}})}-d_{GY|\\mathcal{E}}^2}}.\n\\]\nWe can then correct the point-biserial correlation for univariate direct selection using the formulas in Section 10.4.2. Note that if you want to correct for measurement error as well, replace \\(r_{\\widetilde{X}\\widetilde{X}'}\\) with \\(r_{\\widetilde{G}\\widetilde{G}'}\\) (i.e., group classification reliability; see chapter on group misclassification) whenever you are working with SMDs. Once we obtained the corrected correlation, \\(r_{GY}\\), we can convert back to a standardized mean difference, we need to use an adjusted group proportions, \\(p_G\\):\n\\[\nd_{GY} = \\frac{r_{GY}}{\\sqrt{p_G\\left(1-p_G\\right)\\left(1-r_{GY}^2\\right)}}.\n\\]\nWhere the adjusted group \\(p_G\\) is estimated with the following formula\n\\[\np_G = \\frac{1}{2}-\\frac{1}{2}\\sqrt{1-4p_{G|\\mathcal{E}}(1-p_{G|\\mathcal{E}})\\left[1+r_{GY|\\mathcal{E}}^2\\left(\\frac{1}{u^2_X}-1\\right)\\right]}\n\\]\nThe adjusted proportion, \\(p_G\\), can also be estimated from the proportion of individuals in the target population (e.g., the proportion of men vs women in the general population). This adjustment is necessary in order to account for indirect selection in the grouping variable. This is similar to the situation described in Section 10.4.2, where one variable suffers from direct range restriction and any variable that is correlated with it, will suffer from indirect selection. The corresponding corrected sampling error can also be computed with the observed and adjusted proportions such that,\n\\[\n\\widehat{\\mathrm{var}}(d_{GY}) = \\frac {\\widehat{\\mathrm{var}}\\left(d_{GY|\\mathcal{E}}\\right)\\left(\\frac{r_{GY}}{r_{GY|\\mathcal{E}}}\\right)^2} {\\left(1+d_{GY|\\mathcal{E}}^2\\,p_{G|\\mathcal{E}}[1-p_{G|\\mathcal{E}}]\\right)^2\\left(d_{GY|\\mathcal{E}}^2+\\frac{1}{p_{G|\\mathcal{E}}(1-p_{G|\\mathcal{E}})}\\right)p_G(1-p_G)(1-r_{GY}^2)^3}.\n\\]\n\n\n\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “Psychmeta: An R Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\n———. 2020. “Not Restricted to Selection Research: Accounting for Indirect Range Restriction in Organizational Research.” Organizational Research Methods 23 (4): 717–49. https://doi.org/10.1177/1094428119859398.\n\n\nHunter, John E., Frank L. Schmidt, and Huy Le. 2006. “Implications of Direct and Indirect Range Restriction for Meta-Analysis Methods and Findings.” Journal of Applied Psychology 91 (3): 594–612. https://doi.org/10.1037/0021-9010.91.3.594.\n\n\nLe, Huy, and Frank L. Schmidt. 2006. “Correcting for Indirect Range Restriction in Meta-Analysis: Testing a New Meta-Analytic Procedure.” Psychological Methods 11 (4): 416–38. https://doi.org/10.1037/1082-989X.11.4.416.\n\n\nRevelle, William, Joshua Wilt, and Allen Rosenthal. 2010. “Individual Differences in Cognition: New Methods for Examining the Personality-Cognition Link.” In, edited by Aleksandra Gruszka, Gerald Matthews, and Blazej Szymura, 27–49. New York, NY: Springer. https://doi.org/10.1007/978-1-4419-1210-7_2.\n\n\nSackett, Paul R., and Hyuckseung Yang. 2000. “Correction for Range Restriction: An Expanded Typology.” Journal of Applied Psychology 85 (1): 112–18. https://doi.org/10.1037/0021-9010.85.1.112.\n\n\nTaylor, Erwin K., and Thomas Griess. 1976. “The Missing Middle in Validation Research.” Personnel Psychology 29 (1): 5–11. https://doi.org/10.1111/j.1744-6570.1976.tb00397.x.\n\n\nWechsler, David. 2008. Wechsler Adult Intelligence Scale–Fourth Edition. 4th ed. https://doi.org/10.1037/t15169-000.\n\n\nWilliam Revelle. 2024. psychTools: Tools to Accompany the ’Psych’ Package for Psychological Research. Evanston, Illinois: Northwestern University. https://CRAN.R-project.org/package=psychTools.",
    "crumbs": [
      "Selection Effects",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Indirect Selection</span>"
    ]
  },
  {
    "objectID": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html",
    "href": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html",
    "title": "12  Artifact Correction Meta-Analysis",
    "section": "",
    "text": "12.1 Introduction\nMeta-analysis is an analytic tool to synthesize quantitative evidence from multiple studies. By systematically combining and analyzing the results of multiple studies, meta-analysis provides a comprehensive overview, unveiling patterns, trends, and insights that individual studies might not be able to capture. Combining research findings also has the added benefit of increasing the precision of our results (i.e., greater statistical power). In this section we will cover the method described by (Hunter and Schmidt 2015) since it is readily compatible with artifact corrections (see next chapter). For the random-effects model however, we use an integrated approach that incorporates methods from Hunter and Schmidt (2015) and Hedges and Vevea (1998) that was first introduced by Morris et al. (2014). However it is important to note that there are other common methods to conduct meta-analyses that have their strengths and weaknesses (hedges2014?; Callender and Osburn 1980; Johnson, Mullen, and Salas 1995).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Artifact Correction Meta-Analysis</span>"
    ]
  },
  {
    "objectID": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#common-effect-model",
    "href": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#common-effect-model",
    "title": "12  Artifact Correction Meta-Analysis",
    "section": "12.2 Common Effect Model",
    "text": "12.2 Common Effect Model\nA common effect model is the simplest form of meta-analysis. It assumes that all the variation in observed effect sizes is attributable to sampling error (see Figure 12.1). In other words, all the observed effect sizes are estimates of the same population effect size. Note that there is a distinction between fixed effects models and a common effect model (Viechtbauer, n.d.; Laird and Mosteller 1990). The common effect model assumes that the true effect size is identical for each study while the fixed effects model does not assume this. Instead, the fixed effects model can be interpreted as the weighted average of true effects. Computationally, they are the same and provide the same parameter estimates, yet the interpretation differs (Viechtbauer, n.d.).\n\n\n\n\n\n\nFigure 12.1: The diagram above depicts a common effect meta-analysis of five studies. The study effect sizes are homogenous and all estimate a single true population effect size.\n\n\n\nTake a correlation coefficient between \\(X\\) and \\(Y\\) as an example. The common effect model can be modeled such that population correlation \\(\\rho\\) is held constant each study correlation estimate \\((r_{XY\\jmath})\\), such that,\n\\[\nr_{XY\\jmath}  = \\rho_{XY} + \\varepsilon_{\\jmath}\n\\tag{12.1}\\]\nWhere \\(\\varepsilon_\\jmath\\) indicates sampling error1 and the subscript \\(\\jmath\\) denotes each study. Similar to the true score theory model that we discussed in chapter 4, the variance components of each term can similarly be written out as,\n\\[\n\\mathrm{var}(r_{XY}) = \\mathrm{var}(\\rho_{XY}) + \\mathrm{var}(\\varepsilon)\n\\]\nHowever in our common effect model, the population effect size is fixed across studies and will not vary, simplifying the formula to,\n\\[\n\\mathrm{var}(r_{XY}) = \\mathrm{var}(\\varepsilon)\n\\tag{12.2}\\]\nTherefore the only source of variation in the observed effect sizes is sampling error. Ultimately, our goal in a common effects model is to obtain a precise estimate of the population correlation. To obtain an estimate of the population correlation, \\(\\rho_{XY}\\), we can calculate the average observed effect size, \\(\\bar{r}_{XY}\\) from \\(k\\) studies. However, in practice, effect sizes from different studies have varying levels of precision (i.e., different sampling variances). A simple arithmetic average will not account for the differences between studies in their precision. Instead, we can calculate a weighted average where the weights each study can be calculated by the inverse variance of each study such that,\n\\[\nw_\\jmath = \\frac{1}{\\widehat{\\mathrm{var}}(r_{XY})_\\jmath}.\n\\]\nThe sampling variances are different for each study hence the subscript \\(\\jmath\\). Then we can calculate a weighted average to get an estimate \\(\\hat{\\rho}_{XY}\\) of the population correlation \\(\\rho_{XY}\\),\n\\[\n\\hat{\\rho}_{XY} =\\frac{\\sum^k_{\\jmath=1}w_\\jmath r_\\jmath}{\\sum^k_{\\jmath=1}w_\\jmath}.\n\\]\nWhere \\(\\sum^k_{i=1}\\) is the sum across all \\(k\\) studies. This weighted average will be an unbiased estimate of the population effect size. However, even though this mean effect size is more precise compared to single-study estimates, it is not exempt from error itself. We we can compute the sampling variance for \\(\\hat{\\rho}_{XY}\\) as,\n\\[\n\\widehat{\\mathrm{var}}(\\hat{\\rho}_{XY}) = \\frac{1}{\\sum^k_{\\jmath=1} w_\\jmath}\n\\]\nThe sampling variance can be used to compute the normal approximation of the 95% confidence intervals of the meta-analytic point estimate:\n\\[\nC_{95} = \\hat{\\rho}_{XY}\\pm 1.96 \\cdot \\sqrt{\\widehat{\\mathrm{var}}(\\hat{\\rho}_{XY}) }\n\\]\nAll of this can be done analogously with standardized mean differences as we will see in the example below:\n\n\n\n\n\n\nApplied Example in R\n\n\n\nLets use a meta-analytic data set investigating the the effectiveness of a writing-to-learn intervention on academic achievement from Bangert-Drowns, Hurley, and Wilkinson (2004). This data set has standardized mean differences between the treatment group and a control group from \\(k=48\\) studies (total sample size: \\(n=5,576\\)) and is available within the developmental version of the metadat package (White et al. 2022). Lets conduct a common effect meta-analysis using the equations from the previous section. We can use the rma function in the metafor package (Viechtbauer 2010) to conduct a common effect (method = 'EE') meta-analysis without having to write each equation by hand.\n\nlibrary(metadat)\nlibrary(metafor)\nlibrary(tidyverse)\n\n# display first 6 studies\ndf &lt;- dat.bangertdrowns2004 |&gt;\n  dplyr::select('author','year','ni','yi','vi')\n\nhead(df)\n\n\n    author year  ni     yi    vi \n1 Ashworth 1992  60  0.650 0.070 \n2    Ayers 1993  34 -0.750 0.126 \n3   Baisch 1990  95 -0.210 0.042 \n4    Baker 1994 209 -0.040 0.019 \n5   Bauman 1992 182  0.230 0.022 \n6   Becker 1996 462  0.030 0.009 \n\n# fixed effects model\nmdl &lt;- rma(data = df,\n           yi = yi, # SMDs\n           vi = vi, # sampling variance\n           method = 'EE') # Equal-effects = Common Effect\n\n# print results\ndata.frame(delta_hat = mdl$b[1],\n           var = mdl$se[1]^2,\n           CI_ll = mdl$ci.lb[1],\n           CI_ul = mdl$ci.ub[1])\n\n  delta_hat          var     CI_ll     CI_ul\n1 0.1656264 0.0007252983 0.1128419 0.2184109\n\n\nThe results show an estimated population SMD of \\(\\hat{\\delta}_{GY}=0.17\\, [0.11,\\, 0.22]\\).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Artifact Correction Meta-Analysis</span>"
    ]
  },
  {
    "objectID": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#sec-random",
    "href": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#sec-random",
    "title": "12  Artifact Correction Meta-Analysis",
    "section": "12.3 Random Effects Model",
    "text": "12.3 Random Effects Model\nThe random-effects model refers to a model that allows for the population effect size to vary from study to study (see Figure 12.2). Random-effects differs from the fixed effects model in an important way: it does not assume that all observed effect sizes come from a single (fixed) population effect size (Borenstein et al. 2010). This variation in population effect sizes is called heterogeneity. In the traditional Hunter and Schmidt (2015) the weights utilized in the random effects meta-analysis are identical to the common effect model. In other conventional meta-analysis methods (Hedges and Vevea 1998), random-effect weights usually include a random effect component containing the variation in population effect sizes (this has the effect of making study weights more similar to each other with more variation in population effects). A modern approach introduced by Morris et al. (2014) and later tested by Brannick et al. (2019), added this random effect component to the Hunter-Schmidt method. The simulation study by Brannick et al. (2019), concluded that weights incorporating random effect components improved the Hunter-Schmidt estimates. Here we will discuss Hedges-Vevea’s method with some elements taken from Hunter-Schmidt.\n\n\n\n\n\n\nFigure 12.2: The diagram above depicts a random-effects meta-analysis of five studies. Effect sizes are more variable than the common effect meta-analysis since effect sizes vary due to sampling error and population effect sizes.\n\n\n\nThe model from Equation 12.1 can be changed slightly to encompass variation of the population effect size from study to study:\n\\[\nr_{XY\\jmath} = \\rho_{XY\\jmath} + \\varepsilon_{\\jmath}.\n\\]\nIn the common effect model, we assumed that all the variation in study correlations is accounted for by variation in sampling error (see Equation 12.2). However in the random-effects model the variance in population correlations (\\(\\sigma^2_\\rho\\)) is allowed to be greater than zero. The variance components can be written out as,\n\\[\n\\mathrm{var}(r_{XY}) = \\mathrm{var}(\\rho_{XY}) + \\mathrm{var}(\\varepsilon)\n\\tag{12.3}\\]\nEstimating variance components can be done computationally through an iterative estimation procedure called REstricted Maximum Likelihood (REML) estimation. The meta-analyses we call in the R code will do this for us automatically. The estimated variance of population effect sizes, \\(\\widehat{\\mathrm{var}}(\\rho_{XY})\\), can now be incorporated into the inverse variance weights alongside\n\\[\nw_\\jmath = \\frac{1}{\\widehat{\\mathrm{var}}(r_{XY})_\\jmath +\\widehat{\\mathrm{var}}(\\rho_{XY})}\n\\]\nThe sampling variances are different for each study hence the subscript \\(\\jmath\\). Now we can estimate the mean of population effects by taking the weighted average effect size (equation 16.5, Cooper, Hedges, and Valentine 2009),\n\\[\n\\hat{\\bar{\\rho}}_{XY} = \\frac{\\sum^k_{\\jmath=1}w_\\jmath r_{XY\\jmath}}{\\sum^k_{\\jmath=1}w_\\jmath}.\n\\]\nWhere \\(\\jmath=1...k\\) studies. The standard error of the mean of population effects can calculated from the summation of inverse weights (equation 16.6, Cooper, Hedges, and Valentine 2009),\n\\[\n\\widehat{\\mathrm{var}}\\left(\\hat{\\bar{\\rho}}_{XY}\\right) = \\frac{1}{\\sum^k_{\\jmath=1}w_\\jmath}.\n\\]\nThe 95% confidence interval can then be calculated as,\n\\[\nC_{95} = \\hat{\\bar{\\rho}} \\pm 1.96\\cdot\\sqrt{ \\widehat{\\mathrm{var}}\\left(\\hat{\\bar{\\rho}}\\right)}\n\\]\nIn other conventions, the variance in population effects (\\(\\mathrm{var}(\\rho_{XY})\\)) is denoted as \\(\\tau^2\\) (Borenstein et al. 2010; DerSimonian and Kacker 2007; Hedges and Vevea 1998), but conceptually \\(\\mathrm{var}(\\rho_{XY})\\) and \\(\\tau^2\\) these are identical. Taking the square root of \\(\\mathrm{var}(\\rho_{XY})\\) is the standard deviation of population effect sizes which can be a useful measure of heterogeneity. Furthermore, we can use \\(\\mathrm{var}(\\rho_{XY})\\) to calculate credibility (prediction) intervals which allows us to draw inferences about the range of plausible population effect sizes. For example, the 90% credibility interval can be calculated with the following equations:\n\\[\nCR_{90} = \\hat{\\bar{\\rho}}_{XY} \\pm 1.645\\cdot \\sqrt{\\widehat{\\mathrm{var}}(\\rho_{XY})}\n\\]\nThe confidence interval and credibility interval have fundamentally different interpretations that are often misinterpreted in published work (Whitener 1990). When we are interpreting a single realized interval (i.e., our estimate-in-hand), the 90% credibility interval can be interpreted as the region in which 90% of population effect sizes exist, however, a 95% confidence interval describes the interval in which there is a 95% probability of containing the true mean of population effect sizes. It is important to note that the confidence interval interpretation here is only valid in the case of a single realized interval (Vos and Holbert 2022), if there is more than one interval obtained from the same population of studies, then the interpretation does not hold (this would be a rare in a meta-analysis).\n\n\n\n\n\n\nApplied Example in R\n\n\n\nLet’s continue looking at the meta-analysis from Bangert-Drowns, Hurley, and Wilkinson (2004). This data set has standardized mean differences between the treatment group and a control group from \\(k=48\\) studies (total sample size: \\(n=5,576\\)) and is available within the developmental version of the metadat package (White et al. 2022). Lets conduct a common effect meta-analysis using the equations from the previous section. We can use the rma function in the metafor package (Viechtbauer 2010) to conduct a random effect meta-analysis with REML estimation we can use the method = 'REML' argument.\n\nlibrary(metadat)\nlibrary(metafor)\nlibrary(tidyverse)\n\n# display first 6 studies\ndf &lt;- dat.bangertdrowns2004 |&gt;\n  dplyr::select('author','year','ni','yi','vi')\n\nhead(df)\n\n\n    author year  ni     yi    vi \n1 Ashworth 1992  60  0.650 0.070 \n2    Ayers 1993  34 -0.750 0.126 \n3   Baisch 1990  95 -0.210 0.042 \n4    Baker 1994 209 -0.040 0.019 \n5   Bauman 1992 182  0.230 0.022 \n6   Becker 1996 462  0.030 0.009 \n\n# fixed effects model\nmdl &lt;- rma(data = df,\n           yi = yi, # SMDs\n           vi = vi, # sampling variance\n           method = 'REML') # Equal-effects = Common Effect\n\n# print results\ndata.frame(delta_hat = mdl$b[1],\n           var = mdl$se[1]^2,\n           CI_ll = mdl$ci.lb[1],\n           CI_ul = mdl$ci.ub[1])\n\n  delta_hat         var     CI_ll     CI_ul\n1 0.2219296 0.002119178 0.1317036 0.3121556\n\n\nThe results show an estimated population effect of \\(\\hat{\\bar{\\rho}}=0.22\\, [0.13,\\, 0.31]\\).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Artifact Correction Meta-Analysis</span>"
    ]
  },
  {
    "objectID": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#artifact-corrections",
    "href": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#artifact-corrections",
    "title": "12  Artifact Correction Meta-Analysis",
    "section": "12.4 Artifact Corrections",
    "text": "12.4 Artifact Corrections\nArtifact correction meta-analysis, also referred to as psychometric meta-analysis, is a form of meta-analysis where effect sizes are systematically corrected for sources of bias. These sources of bias have been discussed in previous chapters 4-10. Methodology for conducting artifact correction style meta-analyses were originally pioneered by Frank Schmidt and John Hunter (2015; 1977) and then reviewed more recently by Brenton Wiernik and Jeffrey Dahlke (2020). There has also been powerful R packages developed to aide in the application of artifact correction meta-analyses that we have used in previous chapters (dahlke2019?). You will notice that in this section, we do not discuss standardized mean differences. This is due to the fact that the artifact correction model is designed for pearson correlations, in order to use this method for standardized mean differences, convert to pearson correlations using the methods described in chapter 11, and then use the correction methods used below. Once you apply the corrections to the converted correlations they can then be converted back to a standardized mean difference.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Artifact Correction Meta-Analysis</span>"
    ]
  },
  {
    "objectID": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#bare-bones-vs-artifact-correction-meta-analysis",
    "href": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#bare-bones-vs-artifact-correction-meta-analysis",
    "title": "12  Artifact Correction Meta-Analysis",
    "section": "12.5 Bare Bones vs Artifact Correction Meta-Analysis",
    "text": "12.5 Bare Bones vs Artifact Correction Meta-Analysis\nBare bones meta-analyses are what we just went over, that is, meta-analyses that do not correct for biases in effect size estimates. This section will be dedicated to the artifact correction approach to meta-analysis that aims to correct for statistical artifacts. The choice between these two types of meta-analyses depends on the research question, the available data, and the assumptions researchers are willing to make. If the goal is to investigate effect sizes as they are reported, then a bare-bones meta-analysis might be the way to go. On the other hand, if the goal is to obtain a more accurate estimate of the target effect size by accounting for biases induced by statistical artifacts, an artifact correction meta-analysis is preferrable.\n\nBare-Bones Meta-Analysis: In a bare-bones meta-analysis, the focus is on aggregating effect sizes from various studies without explicitly correcting for potential biases in these effect size estimates.\nArtifact Correction Meta-Analysis: In contrast, an artifact correction meta-analysis takes into account and attempts to correct for biases that may be present in the effect size estimates from individual studies. This involves addressing potential sources of bias, such as measurement error or selection effects, through statistical techniques or adjustments. By doing so, the meta-analysis aims to provide a more accurate and unbiased estimate of the true effect size. Although it is important to note that this method will require additional assumptions about the nature of the data.\n\nNote that the bare-bones model does not assume that there is no bias, rather, the bare-bones model is estimating something else entirely, that is, the population effect size.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Artifact Correction Meta-Analysis</span>"
    ]
  },
  {
    "objectID": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#individual-artifact-correction-model",
    "href": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#individual-artifact-correction-model",
    "title": "12  Artifact Correction Meta-Analysis",
    "section": "12.6 Individual Artifact Correction Model",
    "text": "12.6 Individual Artifact Correction Model\nThe individual artifact correction model corrects each effect size individually prior to conducting the meta-analysis. In practice, observed (study) effect sizes (\\(r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}\\jmath}\\)) can be severely biased relative to our target population correlation (\\(\\rho_{XY\\jmath}\\)) due to measurement and selection artifacts as described in previous chapters. The nature of the beast is that there will be some that we can account for and some we can not. If we decide that corrections to observed effect sizes are necessary to answer our research question, then we can construct an artifact correction model. In the artifact correction model, we can incorporate an artifact attenuation/inflation factor, \\(\\alpha_\\jmath\\), to the bare-bones formula such that,\n\\[\nr_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}\\jmath} = \\alpha_\\jmath\\rho_{XY\\jmath} + \\varepsilon_\\jmath\n\\tag{12.4}\\]\nThe attenuation/inflation factor, \\(\\alpha_i\\), must be estimated for each study, \\(i\\). Using estimates of \\(\\alpha\\) (estimate denoted with the English letter \\(a\\)), Equation 12.4 can be re-arranged to obtain unbiased estimates of the target population effect size:\n\\[\n\\frac{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}\\jmath}}{a_\\jmath} = \\rho_{XY_\\jmath} + \\frac{\\varepsilon_\\jmath}{a_\\jmath}\n\\tag{12.5}\\]\nThis division of \\(\\hat{a}_i\\) will provide us with our corrected effect size estimates that we can denote with the subscript,\n\\[\nr_{XY\\jmath} = \\frac{r_{\\widetilde{X}\\widetilde{Y}|\\mathcal{E}\\jmath}}{a_\\jmath}\n\\] Using a random effects meta-analysis described in Section 12.3, we can average the \\(r_{XY\\jmath}\\) to get an estimate of the mean of true population correlations \\(\\hat{\\bar{\\rho}}_{XY}\\).\nIf we were to conduct a bare-bones and an artifact correction meta-analysis and compute the variance in population correlations, we could see how the corrections reduce the heterogeneity in the effect size estimates by comparing variance in true effect sizes between both models. The percent reduction in heterogeneity can be computed by taking the ratio of the two. Hunter and Schmidt (2015) suggest that if 75% of the heterogeneity is accounted for by artifact corrections, then we can assume that the remaining heterogeneity is attributable to remaining artifacts that have not been addressed in the current meta-analysis. Although it is important to point out that this is simply a rule of thumb rather than a mathematical property (arguably not even a useful rule of thumb).\n\n\n\n\n\n\nApplied Example in R\n\n\n\nLets conduct an individual correction meta-analysis in r using the data set by Roth (2015). This data set consists of correlations between school grades and intelligence test scores. It also contains information on the reliability of the intelligence test scores and the extent of range restriction in test scores. We can conduct a meta-analysis correcting for univariate indirect range restriction and measurement error in test scores. The artifact attenuation/inflation factor for the correlation would be:\n\\[\na_\\jmath=\\sqrt{r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}\\jmath}^2 + \\frac{u_{\\widetilde{X}\\jmath}^2 r_{\\widetilde{X}\\widetilde{X}'_\\jmath}(r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}\\jmath} - r_{\\widetilde{X}Y'|\\mathcal{E}\\jmath}^2) }{1 - u_{\\widetilde{X}\\jmath}^2 (1-r_{\\widetilde{X}\\widetilde{X}'|\\mathcal{E}\\jmath})} }\n\\]\nLets conduct the meta-analysis using the the psychmeta package (Dahlke and Wiernik 2019). The function ma_r_ic is designed to conduct an individual correction meta-analysis on correlation coefficients.\n\n# install.packages('psychmeta')\nlibrary(psychmeta)\n\n\n\n# conduct individual correction meta-analysis\nmdl_ic &lt;- ma_r_ic(rxyi = rxyi, n = n,\n            correction_method = \"uvirr\",\n            rxx = rxxi,\n            ux = ux,\n            ux_observed = TRUE,\n            rxx_restricted = TRUE,\n            data = data_r_roth_2015)\n\nsummary_stats &lt;- data.frame(\n  k = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$k,\n  n = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$N,\n  mean_rho = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$mean_rho,\n  SE = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$se_r_c,\n  SD_rho = mdl_ic$meta_tables$`analysis_id: 1`$individual_correction$true_score$sd_rho)\n\nsummary_stats \n\n    k      n  mean_rho         SE    SD_rho\n1 240 105151 0.4899442 0.01482776 0.2261415\n\n\nWe can also obtain credibility intervals by using the credibility function in the psychmeta package. The interval defaults to 80% intervals, however we can change that to 90% by inputting .90 into the cred_level argument.\n\ncredibility(mean = summary_stats$mean_rho,\n            sd = summary_stats$SD_rho,\n            cred_method = \"norm\",\n            cred_level = .90)\n\n      CR_LL_90  CR_UL_90\n[1,] 0.1179745 0.8619139\n\n\nLets compare these results to the bare-bones model. In psychmeta the bare-bones model can be conduced using ma_r_bb. However, the ma_r_ic function also reports the bare-bones results as well. Therefore we can just extract the necessary statistics from the model.\n\ndata.frame(\n  k = mdl_ic$meta_tables$`analysis_id: 1`$barebones$k,\n  n = mdl_ic$meta_tables$`analysis_id: 1`$barebones$N,\n  mean_rho_obs = mdl_ic$meta_tables$`analysis_id: 1`$barebones$mean_r,\n  SE = mdl_ic$meta_tables$`analysis_id: 1`$barebones$se_r,\n  SD_rho_obs = mdl_ic$meta_tables$`analysis_id: 1`$barebones$sd_r)\n\n    k      n mean_rho_obs         SE SD_rho_obs\n1 240 105151    0.4418789 0.01191933  0.1846534\n\n\nWe can see that the estimate of the population correlation is largely attenuated in the observed values. This is due to the fact tests of intelligence are not perfectly reliable and the scores were restricted in their range.\n\n\n\n\n\n\n\nBangert-Drowns, Robert L, Marlene M Hurley, and Barbara Wilkinson. 2004. “The Effects of School-Based Writing-to-Learn Interventions on Academic Achievement: A Meta-Analysis.” Review of Educational Research 74 (1): 29–58. https://doi.org/10.3102/00346543074001029.\n\n\nBorenstein, Michael, Larry V. Hedges, Julian P. T. Higgins, and Hannah R. Rothstein. 2010. “A Basic Introduction to Fixed-Effect and Random-Effects Models for Meta-Analysis.” Research Synthesis Methods 1 (2): 97–111. https://doi.org/10.1002/jrsm.12.\n\n\nBrannick, Michael T., Sean M. Potter, Bryan Benitez, and Scott B. Morris. 2019. “Bias and Precision of Alternate Estimators in Meta-Analysis: Benefits of Blending Schmidt-Hunter and Hedges Approaches.” Organizational Research Methods 22 (2): 490–514. https://doi.org/10.1177/1094428117741966.\n\n\nCallender, John C., and H. G. Osburn. 1980. “Development and Test of a New Model for Validity Generalization.” Journal of Applied Psychology 65 (5): 543–58. https://doi.org/10.1037/0021-9010.65.5.543.\n\n\nCooper, Harris M., Larry V. Hedges, and Jeff C. Valentine, eds. 2009. The Handbook of Research Synthesis and Meta-Analysis. 2nd ed. New York: Russell Sage Foundation.\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “Psychmeta: An R Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nDerSimonian, Rebecca, and Raghu N. Kacker. 2007. “Random-Effects Model for Meta-Analysis of Clinical Trials: An Update.” NIST 28 (January): 105–14. https://www.nist.gov/publications/random-effects-model-meta-analysis-clinical-trials-update.\n\n\nHedges, Larry V., and Jack L. Vevea. 1998. “Fixed- and Random-Effects Models in Meta-Analysis.” Psychological Methods 3 (4): 486–504. https://doi.org/10.1037/1082-989X.3.4.486.\n\n\nHunter, John E., and Frank L. Schmidt. 2015. Methods of meta-analysis: correcting error and bias in research findings (third). Third. Thousand Oaks, California: Sage Publications.\n\n\nJohnson, Blair T., Brian Mullen, and Eduardo Salas. 1995. “Comparison of Three Major Meta-Analytic Approaches.” Journal of Applied Psychology 80 (1): 94–106. https://doi.org/10.1037/0021-9010.80.1.94.\n\n\nLaird, Nan M., and Frederick Mosteller. 1990. “Some Statistical Methods for Combining Experimental Results.” International Journal of Technology Assessment in Health Care 6 (1): 5–30. https://doi.org/10.1017/S0266462300008916.\n\n\nMorris, Scott, Rebecca Daisley, Megan Wheeler, and Peggy Boyer. 2014. “A Meta-Analysis of the Relationship Between Individual Assessments and Job Performance.” The Journal of Applied Psychology 100 (May). https://doi.org/10.1037/a0036938.\n\n\nRoth, Bettina. 2015. “Intelligence and School Grades: A Meta-Analysis.”\n\n\nSchmidt, Frank, and John Hunter. 1977. “Development of a General Solution to the Problem of Validity Generalization.” Journal of Applied Psychology 62 (October): 529–40. https://doi.org/10.1037/0021-9010.62.5.529.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting meta-analyses in R with the metafor package.” Journal of Statistical Software 36 (3): 1–48. https://doi.org/10.18637/jss.v036.i03.\n\n\n———. n.d. “Fixed-Effects and Random-Effects Models in Meta-Analysis.” https://wviechtb.github.io/metafor/index.html.\n\n\nVos, Paul, and Don Holbert. 2022. “Frequentist Statistical Inference Without Repeated Sampling.” Synthese 200 (2): 89. https://doi.org/10.1007/s11229-022-03560-x.\n\n\nWhite, Thomas, Daniel Noble, Alistair Senior, W. Kyle Hamilton, and Wolfgang Viechtbauer. 2022. Metadat: Meta-Analysis Datasets. https://CRAN.R-project.org/package=metadat.\n\n\nWhitener, Ellen M. 1990. “Confusion of Confidence Intervals and Credibility Intervals in Meta-Analysis.” Journal of Applied Psychology 75 (3): 315–21. https://doi.org/10.1037/0021-9010.75.3.315.\n\n\nWiernik, Brenton M., and Jeffrey A. Dahlke. 2020. “Obtaining Unbiased Results in Meta-Analysis: The Importance of Correcting for Statistical Artifacts.” Advances in Methods and Practices in Psychological Science 3 (1): 94–123. https://doi.org/10.1177/2515245919885611.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Artifact Correction Meta-Analysis</span>"
    ]
  },
  {
    "objectID": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#footnotes",
    "href": "13-artifact-correction-meta-analysis/13-artifact-correction-meta-analysis.html#footnotes",
    "title": "12  Artifact Correction Meta-Analysis",
    "section": "",
    "text": "1: the r subscript that usually follows \\(\\varepsilon_r\\) is removed for the sake of simplicity.↩︎",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Artifact Correction Meta-Analysis</span>"
    ]
  },
  {
    "objectID": "14-conclusion/14-conclusion.html",
    "href": "14-conclusion/14-conclusion.html",
    "title": "13  Conclusion",
    "section": "",
    "text": "Future Directions\nThis book is a living resource and it will add new content with each version. Versions will be released in the Github repository as on the Open Science Framework (DOI here when created). In future releases, there are a number of features that are planned to be added. Here is a list of those features:\n\nInteractive visualizations of artifacts and bias using RShinyLive\nMore effect size types with corrections: Repeated measures SMDs, Variability ratios, and unstandardized effect sizes (mean differences and regression coefficients).\nA chapter on the artifact of treatment non-compliance.\nZ-transformations for corrected correlations.\nPractice problems.\nSmall simulations for assessing robustness of corrections in non-normal distributions (e.g., heavy-tails, skew)\n\nSuggestions for added features are welcome. Suggestions can be made by submitting an issue to the Github repository.\n\n\nLimitations\nApplying artifact corrections has trade-offs that should be considered before putting them into use. Obtaining more accurate estimates of our target effect sizes is the obvious major benefit of applying corrections, however it is also true that these artifact corrections can impose assumptions that may not be met in practice. The assumptions were laid out in each of the chapters, but it is important for the researcher to consider how reasonable these assumptions are for their research context. If the assumption violations are extreme, than the correction can potentially over- or under-correct the effect size estimates.\nDefining the scientific estimand is the most important step before proceeding with artifact corrections. Each correction procedure is meant to estimate very specific quantity. If a researcher’s target quantity is different from the one that the correction procedure is trying to estimate, then the correction may further bias the effect size. A good example of this is in college admissions testing, where it can be quite tempting to correct the correlation between test scores and college grade-point average (GPA) for measurement error in the test scores. However, the practical utility of test scores is limited to the prediction capability of observed test scores since admission committees do not have access to true scores. Therefore if our quantity of interest is the on-the-ground predictive utility of test scores on GPA, then correcting the correlation for measurement errors in test scores will over-estimate the predictive utility. Researchers should ensure that the ultimate research goals align with the correction procedure.\n\n\nConcluding Remarks\nImperfections in studies can obscure our view of reality, inhibit us from making sense of our observations, and they can mislead us. Corrections to these imperfections can allow us to see what findings may look like in an ideal study with perfect conditions. Meta-analyses will inevitably incorporate imperfect studies that vary in design and methodology that may restrict our ability to estimate a specific estimand. However, this should not limit the goal of meta-analysis to be merely a description of the literature. Corrections can allow meta-analysts to estimate specific scientifically-relevant quantities. Donald Rubin (1992) discusses the importance of estimating effect sizes in theoretically perfect studies:\n\nLiterature synthesis is fine, but, before scientifically valid statistical inference can take place, scientifically relevant quantities (i.e., estimands) must be defined, and the population estimands in the traditional view may be of limited scientific interest. The scientifically most interesting estimands involve the hypothetical results of technically perfect studies, rather than the average of results from some population of fallible studies.\n\nMost artifact correction meta-analyses have been conducted almost exclusively in industrial and organizational psychology (e.g., personnel selection) and education assessment research (e.g., college admissions testing). However, the concepts in this book apply to many fields including biomedical, social science, clinical research, among others. No discipline is immune to measurement error and selection effects, therefore it is important to address these artifacts in every field of research.\nThis book could not have been accomplished without the pioneering work of John Hunter and Frank Schmidt. This book stands as a testament to their foundational contributions to artifact corrections and meta-analysis. The goal of this current book was to expand the methodologies and applications presented in their book (Hunter and Schmidt 2015). It also aims to provide a comprehensive guide, drawing upon previous scholarship while adapting to the evolving landscape of research methodologies.\nI hope reading this book will provide invaluable insights and tools that empower people to address the bias in our studies. May it encourage a deeper awareness of these issues when confronted with them.\nWe want our research findings to accurately describe reality. Artifact corrections help us get closer to that goal.\n\n\nAcknowledgements\nThank you to Dr. Blair T. Johnson, Dr. Christopher Rhoads, and Dr. Elizabeth Schifano for taking the time to review and provide extremely valuable feedback over the course of writing this book.\n\nMatthew B. Jané\n @MatthewBJane\n\n\n\n\n\nHunter, John E., and Frank L. Schmidt. 2015. Methods of meta-analysis: correcting error and bias in research findings (third). Third. Thousand Oaks, California: Sage Publications.\n\n\nRubin, Donald B. 1992. “Meta-Analysis: Literature Synthesis or Effect-Size Surface Estimation?” Journal of Educational Statistics 17 (4): 363–74. https://doi.org/10.3102/10769986017004363.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "references/references_page.html",
    "href": "references/references_page.html",
    "title": "References",
    "section": "",
    "text": "Aguinis, Herman, Charles A Pierce, and Steven A Culpepper. 2009.\n“Scale Coarseness as a Methodological Artifact,” September.\n\n\nBangert-Drowns, Robert L, Marlene M Hurley, and Barbara Wilkinson. 2004.\n“The Effects of School-Based Writing-to-Learn Interventions on\nAcademic Achievement: A Meta-Analysis.” Review of Educational\nResearch 74 (1): 29–58. https://doi.org/10.3102/00346543074001029.\n\n\nBarraza, Felipe, Marcelo Arancibia, Eva Madrid, and Cristian Papuzinski.\n2019. “General Concepts in Biostatistics and Clinical\nEpidemiology: Random Error and Systematic Error.”\nMedwave 19 (7): e7687. https://doi.org/10.5867/medwave.2019.07.7687.\n\n\nBobko, Philip, and Angela Rieck. 1980. “Large Sample Estimators\nfor Standard Errors of Functions of Correlation Coefficients.”\nApplied Psychological Measurement 4 (3): 385–98. https://doi.org/10.1177/014662168000400309.\n\n\nBonett, Douglas G. 2008. “Meta-Analytic Interval Estimation for\nBivariate Correlations.” Psychological Methods 13 (3):\n173–81. https://doi.org/10.1037/a0012868.\n\n\nBonett, Douglas G., and Robert M. Price. 2005. “Inferential\nMethods for the Tetrachoric Correlation Coefficient.” Journal\nof Educational and Behavioral Statistics 30 (2): 213–25. https://www.jstor.org/stable/3701350.\n\n\nBorenstein, Michael, Larry V. Hedges, Julian P. T. Higgins, and Hannah\nR. Rothstein. 2010. “A Basic Introduction to Fixed-Effect and\nRandom-Effects Models for Meta-Analysis.” Research Synthesis\nMethods 1 (2): 97–111. https://doi.org/10.1002/jrsm.12.\n\n\nBrannick, Michael T., Sean M. Potter, Bryan Benitez, and Scott B.\nMorris. 2019. “Bias and Precision of Alternate Estimators in\nMeta-Analysis: Benefits of Blending Schmidt-Hunter and Hedges\nApproaches.” Organizational Research Methods 22 (2):\n490–514. https://doi.org/10.1177/1094428117741966.\n\n\nBrown, William. 1910. “Some Experimental Results in the\nCorrelation of Mental Abilities1.” British Journal of\nPsychology, 1904-1920 3 (3): 296–322. https://doi.org/10.1111/j.2044-8295.1910.tb00207.x.\n\n\nCallender, John C., and H. G. Osburn. 1980. “Development and Test\nof a New Model for Validity Generalization.” Journal of\nApplied Psychology 65 (5): 543–58. https://doi.org/10.1037/0021-9010.65.5.543.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. Academic Press.\n\n\n———. 2013. Statistical Power Analysis for the Behavioral\nSciences. Academic Press.\n\n\nCooper, Harris M., Larry V. Hedges, and Jeff C. Valentine, eds. 2009.\nThe Handbook of Research Synthesis and Meta-Analysis. 2nd ed.\nNew York: Russell Sage Foundation.\n\n\nCox, D. R. 1989. Analysis of Binary Data. 2nd ed. New York:\nRoutledge. https://doi.org/10.1201/9781315137391.\n\n\nCronbach, Lee J. 1951. “Coefficient Alpha and the Internal\nStructure of Tests.” Psychometrika 16 (3): 297–334. https://doi.org/10.1007/BF02310555.\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “Psychmeta: An R\nPackage for Psychometric Meta-Analysis.” Applied\nPsychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\n———. 2020. “Not Restricted to Selection Research: Accounting for\nIndirect Range Restriction in Organizational Research.”\nOrganizational Research Methods 23 (4): 717–49. https://doi.org/10.1177/1094428119859398.\n\n\nDerSimonian, Rebecca, and Raghu N. Kacker. 2007. “Random-Effects\nModel for Meta-Analysis of Clinical Trials: An Update.”\nNIST 28 (January): 105–14. https://www.nist.gov/publications/random-effects-model-meta-analysis-clinical-trials-update.\n\n\nEnders, Craig K. 2022. Applied Missing Data Analysis. Guilford\nPublications.\n\n\nGamer, Matthias, Jim Lemon, Ian Fellows, and Puspendra Singh. 2019.\nIrr: Various Coefficients of Interrater Reliability and\nAgreement. https://CRAN.R-project.org/package=irr.\n\n\nGnambs, Timo. 2023. “A Brief Note on the Standard Error of the\nPearson Correlation.” Collabra: Psychology 9 (1): 87615.\nhttps://doi.org/10.1525/collabra.87615.\n\n\nGoldberg, Lewis. 1999. “Public Domain, Personality Inventory\nMeasuring the Lower-Level Facets of Several Five-Factor Models.”\nPersonality Psychology in Europe 7: 7–28. https://cir.nii.ac.jp/crid/1571417125727416704.\n\n\nHaddock, C. Keith, David Rindskopf, and William R. Shadish. 1998.\n“Using Odds Ratios as Effect Sizes for Meta-Analysis of\nDichotomous Data: A Primer on Methods and Issues.”\nPsychological Methods 3 (3): 339–53. https://doi.org/10.1037/1082-989X.3.3.339.\n\n\nHaertel, Edward H. 2006. “3. Reliability.” In, 4th ed.\n\n\nHedges, Larry V. 1981. “Distribution Theory for Glass’s Estimator\nof Effect Size and Related Estimators.” Journal of\nEducational Statistics 6 (2): 107–28. https://doi.org/10.3102/10769986006002107.\n\n\n———. 1989. “An Unbiased Correction for Sampling Error in Validity\nGeneralization Studies.” Journal of Applied Psychology\n74 (3): 469–77. https://doi.org/10.1037/0021-9010.74.3.469.\n\n\nHedges, Larry V., and Jack L. Vevea. 1998. “Fixed- and\nRandom-Effects Models in Meta-Analysis.” Psychological\nMethods 3 (4): 486–504. https://doi.org/10.1037/1082-989X.3.4.486.\n\n\nHunter, John E., and Frank L. Schmidt. 2015. Methods of\nmeta-analysis: correcting error and bias in research findings\n(third). Third. Thousand Oaks, California: Sage Publications.\n\n\nHunter, John E., Frank L. Schmidt, and Huy Le. 2006. “Implications\nof Direct and Indirect Range Restriction for Meta-Analysis Methods and\nFindings.” Journal of Applied Psychology 91 (3):\n594–612. https://doi.org/10.1037/0021-9010.91.3.594.\n\n\nHunter, John, and Frank Schmidt. 1990. “Dichotomization of\nContinuous Variables: The Implications for Meta-Analysis.”\nJournal of Applied Psychology 75 (June): 334–49. https://doi.org/10.1037/0021-9010.75.3.334.\n\n\nJacobs, Perke, and Wolfgang Viechtbauer. 2017. “Estimation of the\nBiserial Correlation and Its Sampling Variance for Use in\nMeta-Analysis.” Research Synthesis Methods 8 (2):\n161–80. https://doi.org/10.1002/jrsm.1218.\n\n\nJohnson, Blair T., Brian Mullen, and Eduardo Salas. 1995.\n“Comparison of Three Major Meta-Analytic Approaches.”\nJournal of Applied Psychology 80 (1): 94–106. https://doi.org/10.1037/0021-9010.80.1.94.\n\n\nKirk, David B. 1973. “On the Numerical Approximation of the\nBivariate Normal (Tetrachoric) Correlation Coefficient.”\nPsychometrika 38 (2): 259–68. https://doi.org/10.1007/BF02291118.\n\n\nKroc, Edward, and Bruno D. Zumbo. 2020. “A Transdisciplinary View\nof Measurement Error Models and the Variations of x=t+e.”\nJournal of Mathematical Psychology 98 (September): 102372. https://doi.org/10.1016/j.jmp.2020.102372.\n\n\nKroenke, Kurt, Robert L. Spitzer, and Janet B. W. Williams. 2003.\n“The Patient Health Questionnaire-2: Validity of a Two-Item\nDepression Screener.” Medical Care 41 (11): 1284–92. https://www.jstor.org/stable/3768417.\n\n\nKuder, G. F., and M. W. Richardson. 1937. “The Theory of the\nEstimation of Test Reliability.” Psychometrika 2 (3):\n151–60. https://doi.org/10.1007/BF02288391.\n\n\nLaird, Nan M., and Frederick Mosteller. 1990. “Some Statistical\nMethods for Combining Experimental Results.” International\nJournal of Technology Assessment in Health Care 6 (1): 5–30. https://doi.org/10.1017/S0266462300008916.\n\n\nLe, Huy, and Frank L. Schmidt. 2006. “Correcting for Indirect\nRange Restriction in Meta-Analysis: Testing a New Meta-Analytic\nProcedure.” Psychological Methods 11 (4): 416–38. https://doi.org/10.1037/1082-989X.11.4.416.\n\n\nMacCallum, Robert C., Shaobo Zhang, Kristopher J. Preacher, and Derek D.\nRucker. 2002. “On the Practice of Dichotomization of Quantitative\nVariables.” Psychological Methods 7: 19–40. https://doi.org/10.1037/1082-989X.7.1.19.\n\n\nMayer, Michael. 2023. missRanger: Fast Imputation of Missing\nValues. https://CRAN.R-project.org/package=missRanger.\n\n\nMorris, Scott, Rebecca Daisley, Megan Wheeler, and Peggy Boyer. 2014.\n“A Meta-Analysis of the Relationship Between Individual\nAssessments and Job Performance.” The Journal of Applied\nPsychology 100 (May). https://doi.org/10.1037/a0036938.\n\n\nMosier, Charles I. 1943. “On the Reliability of a Weighted\nComposite.” Psychometrika 8 (3): 161–68.\n\n\nOlkin, Ingram, and John W. Pratt. 1958. “Unbiased Estimation of\nCertain Correlation Coefficients.” The Annals of Mathematical\nStatistics 29 (1): 201–11. https://www.jstor.org/stable/2237306.\n\n\nPearson, Karl. 1895. “Notes on the History of Correlation.”\nSociety of Biometricians and Mathematical Statisticians. https://doi.org/10.2307/2331722.\n\n\n———. 1903. “I. Mathematical Contributions to the Theory of\nEvolution. XI. On the Influence of Natural Selection on the\nVariability and Correlation of Organs.” Philosophical\nTransactions of the Royal Society of London. Series A, Containing Papers\nof a Mathematical or Physical Character 200 (321-330): 1–66. https://doi.org/10.1098/rsta.1903.0001.\n\n\nPeters, Charles C., and Walter R. Van Voorhis. 1940. “Further\nMethods of Correlation.” In, 362–403. New York, NY, US:\nMcGraw-Hill Book Company. https://doi.org/10.1037/13596-013.\n\n\nRevelle, William, Joshua Wilt, and Allen Rosenthal. 2010.\n“Individual Differences in Cognition: New Methods for Examining\nthe Personality-Cognition Link.” In, edited by Aleksandra\nGruszka, Gerald Matthews, and Blazej Szymura, 27–49. New York, NY:\nSpringer. https://doi.org/10.1007/978-1-4419-1210-7_2.\n\n\nRoth, Bettina. 2015. “Intelligence and School Grades: A\nMeta-Analysis.”\n\n\nRubin, Donald B. 1992. “Meta-Analysis: Literature Synthesis or\nEffect-Size Surface Estimation?” Journal of Educational\nStatistics 17 (4): 363–74. https://doi.org/10.3102/10769986017004363.\n\n\nRulon, Phillip J. 1939. “A Simplified Procedure for Determining\nthe Reliability of a Test by Split-Halves.” Harvard\nEducational Review 9 (1): 99–103.\n\n\nSackett, Paul R., and Hyuckseung Yang. 2000. “Correction for Range\nRestriction: An Expanded Typology.” Journal of Applied\nPsychology 85 (1): 112–18. https://doi.org/10.1037/0021-9010.85.1.112.\n\n\nSchmidt, Frank, and John Hunter. 1977. “Development of a General\nSolution to the Problem of Validity Generalization.” Journal\nof Applied Psychology 62 (October): 529–40. https://doi.org/10.1037/0021-9010.62.5.529.\n\n\nSoper, H. E. 1914. “On the Probable Error of the Bi-Serial\nExpression for the Correlation Coefficient.” Biometrika\n10 (2/3): 384–90. https://doi.org/10.2307/2331789.\n\n\nSpearman, C. 1904. “The Proof and Measurement of Association\nBetween Two Things.” International Journal of\nEpidemiology 39 (5): 1137–50. https://doi.org/10.1093/ije/dyq191.\n\n\nSpearman, Charles. 1910. “Correlation Calculated from Faulty\nData.” British Journal of Psychology 3 (3): 271295. https://www.proquest.com/docview/1293688112/citation/7E133DC1091D4E47PQ/1.\n\n\nTaboga, Marco. 2021. “Gamma Function.” https://www.statlect.com/mathematical-tools/gamma-function.\n\n\nTaylor, Erwin K., and Thomas Griess. 1976. “The Missing Middle in\nValidation Research.” Personnel Psychology 29 (1): 5–11.\nhttps://doi.org/10.1111/j.1744-6570.1976.tb00397.x.\n\n\nVan Buuren, Stef. 2018. Flexible Imputation of Missing Data.\nCRC press.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting meta-analyses in R with\nthe metafor package.” Journal of Statistical Software 36\n(3): 1–48. https://doi.org/10.18637/jss.v036.i03.\n\n\n———. n.d. “Fixed-Effects and Random-Effects Models in\nMeta-Analysis.” https://wviechtb.github.io/metafor/index.html.\n\n\nVos, Paul, and Don Holbert. 2022. “Frequentist Statistical\nInference Without Repeated Sampling.” Synthese 200 (2):\n89. https://doi.org/10.1007/s11229-022-03560-x.\n\n\nWechsler, David. 2008. Wechsler Adult Intelligence Scale–Fourth\nEdition. 4th ed. https://doi.org/10.1037/t15169-000.\n\n\nWhite, Thomas, Daniel Noble, Alistair Senior, W. Kyle Hamilton, and\nWolfgang Viechtbauer. 2022. Metadat: Meta-Analysis Datasets. https://CRAN.R-project.org/package=metadat.\n\n\nWhitener, Ellen M. 1990. “Confusion of Confidence Intervals and\nCredibility Intervals in Meta-Analysis.” Journal of Applied\nPsychology 75 (3): 315–21. https://doi.org/10.1037/0021-9010.75.3.315.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWiernik, Brenton M., and Jeffrey A. Dahlke. 2020. “Obtaining\nUnbiased Results in Meta-Analysis: The Importance of Correcting for\nStatistical Artifacts.” Advances in Methods and Practices in\nPsychological Science 3 (1): 94–123. https://doi.org/10.1177/2515245919885611.\n\n\nWilliam Revelle. 2023. Psych: Procedures for Psychological,\nPsychometric, and Personality Research. Evanston, Illinois:\nNorthwestern University. https://CRAN.R-project.org/package=psych.\n\n\n———. 2024. psychTools: Tools to Accompany the ’Psych’ Package for\nPsychological Research. Evanston, Illinois: Northwestern\nUniversity. https://CRAN.R-project.org/package=psychTools.\n\n\nWylie, Peter B. 1976. “Effects of Coarse Grouping and Skewed\nMarginal Distributions on the Pearson Product Moment Correlation\nCoefficient.” Educational and Psychological Measurement\n36 (1): 1–7. https://doi.org/10.1177/001316447603600101.\n\n\nZimmerman, Donald W. 1975. “Probability Spaces, Hilbert Spaces,\nand the Axioms of Test Theory.” Psychometrika 40 (3):\n395–412. https://doi.org/10.1007/BF02291765.\n\n\nZimmerman, Donald W, and Richard H Williams. 1977. “Validity\nCoefficients and Correlated Errors in Test Theory.” The\nJournal of Experimental Education 45 (3): 4–9.",
    "crumbs": [
      "References"
    ]
  }
]