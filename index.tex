% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Artifact Corrections for Effect Sizes},
  pdfauthor={Matthew B. Jané},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Artifact Corrections for Effect Sizes}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Implementation in R and Application to Meta-Analysis}
\author{Matthew B. Jané}
\date{2022-12-31}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, interior hidden, frame hidden, breakable, enhanced, sharp corners, borderline west={3pt}{0pt}{shadecolor}]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{greetings}{%
\chapter{Greetings}\label{greetings}}

Welcome to the living open source textbook \textbf{\emph{Correcting
Effect Sizes for Statistical Artifacts}}. This textbook covers all the
essential equations and code needed to correct for biases in our effect
size estimates. It will also hopefully provide readers with a deeper
understanding, appreciation, and intuition for these seemingly complex
formulas. It also covers how to apply these corrections to
meta-analysis.

\hypertarget{what-are-statistical-artifacts}{%
\subsubsection*{What are Statistical
Artifacts?}\label{what-are-statistical-artifacts}}
\addcontentsline{toc}{subsubsection}{What are Statistical Artifacts?}

In this book statistical artifacts will be defined broadly as
\textbf{any source of contamination that induces bias in research
findings}. Artifacts are present in virtually every research study, so
it is crucial that we address them.

\hypertarget{living-and-open-source}{%
\subsubsection*{Living and Open Source}\label{living-and-open-source}}
\addcontentsline{toc}{subsubsection}{Living and Open Source}

A living textbook is one that constantly updates with new features and
is open to changes from others. The goal is to have the most modern
cutting-edge methods for artifact correction in this book, so in order
to do that, this book needs to grow as the research grows. This book is
also open source (\href{LICENSE}{CC-BY license}). All the figures, code,
and documents are available open source in my
\href{https://github.com/MatthewBJane/artifact-corrections-for-effect-sizes/tree/gh-pages}{github
repository}.

\hypertarget{contributions}{%
\subsubsection*{Contributions}\label{contributions}}
\addcontentsline{toc}{subsubsection}{Contributions}

Please feel free to contribute to this textbook, if your contribution
makes it to the published version of this book, your name will be
included in the contributor list below with a description of your work.

\bookmarksetup{startatroot}

\hypertarget{dedication}{%
\chapter{Dedication}\label{dedication}}

In Loving Memory of Haley Jané

My companion, whose love and presence have filled my life with joy and
comfort.

\begin{figure}

{\centering \includegraphics[width=4.16667in,height=\textheight]{figure/dedication_2.png}

}

\end{figure}

\bookmarksetup{startatroot}

\hypertarget{effect-sizes-and-notation}{%
\chapter{Effect Sizes and Notation}\label{effect-sizes-and-notation}}

\hypertarget{what-are-effect-sizes}{%
\section{What are Effect Sizes?}\label{what-are-effect-sizes}}

Effect sizes are statistics that measure the magnitude of a relationship
between two variables. It's important to remember that effect sizes are
a valuable tool, enabling researchers to extract meaningful insights
from data, rather than being the ultimate objective themselves. Effect
sizes aide in researcher's ability to draw meaningful inferences from
data and therefore it is crucial that they are accurate. Biased effect
sizes can be likened to a foggy windshield. Just as condensation on
glass obstructs a clear view of the road, biased effect sizes can
obscure the true association between variables. Similar to how one must
clean the windshield to drive safely, researchers must correct for
biases in effect sizes to attain a clear and accurate perspective on
their data. Correlation coefficients and standardized mean differences
are two of the most common effect sizes and so they will be the primary
focus of this book. To see how an effect size may look in practice, the
example below will illustrate how calculating one may look in a clinical
setting.

\hypertarget{applied-example}{%
\subsection{Applied Example}\label{applied-example}}

Lets say we want to test whether a new drug can alleviate anxiety,
therefore we decide to conduct an experiment to see how well this drug
performs. We first randomly assign each participant in the study to
either a treatment group (\(T\)) or a control group (\(C\)). In our
experiment we want test how well the experimental drug reduces anxiety,
therefore we measure the subjects' self reported anxiety after
under-going the treatment. To see if the drug actually worked in
alleviating anxiety, we want to compare the scores from the treatment
group and the control group. To do this we can estimate the average
treatment effect (\(ATE\)), which is the difference in the mean value of
self-reported anxiety scores between the treatment group and the control
group such that, \(ATE = \text{Mean}(X_T) - \text{Mean}(X_C)\). However,
anxiety scores have no meaningful units, so if we obtain an \(ATE\)
value of \(-3\) there is no way to tell if this value is large or small,
since it is entirely dependent on how the anxiety scores are scaled.
Standardization can allow us to draw meaningful inferences about the
size of the effect that can be comparable across scales. We can
standardize the \(ATE\) by dividing by the standard deviation of scores
in the control group, (\(\text{SD}\)):
\(\text{Effect Size} = \frac{ATE}{\text{SD}_C}\). The effect size is now
on an interpretable scale (standard deviations). If we achieve an
standardized effect size value of \(-0.50\), we can interpret this as
the treatment group exhibiting a reduction in anxiety equivalent to half
a standard deviation compared to the control group.

\begin{figure}

{\centering \includegraphics{intro_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\caption{Simulated experimental data}

\end{figure}

\hypertarget{defining-effect-sizes}{%
\subsection{Defining effect sizes}\label{defining-effect-sizes}}

Lets say we have an effect size of interest that quantifies the
relationship between an independent and dependent variable. The
population effect size can be denoted as \(\vartheta\), however this
population value is unknown. We can obtain an estimate the population
effect size by conducting a study on a sample drawn from the population
and then calculating a study effect size, \(\theta\). The study effect
size is a function of the population effect size and sampling error
(\(\varepsilon\)) such that,

\begin{equation}\protect\hypertarget{eq-B}{}{
\theta = \vartheta + \varepsilon
}\label{eq-B}\end{equation}

Effect sizes will differ from study to study, this can be due to two
reasons: variance in population effect sizes (\(\sigma^2_\vartheta\)) or
variance in sampling error (\(\sigma_\varepsilon\)). Accordingly, we can
express the variance in study effect sizes (\(\sigma_\theta\)) as,

\[
\sigma^2_\theta = \sigma^2_\vartheta + \sigma^2_\varepsilon
\]

If studies were drawing samples from the same population, the variance
in the population effect size would be zero (\(\sigma^2_\vartheta = 0\))
and the expected value (i.e., the mean) of study effect sizes would be
equal to the population effect size, \(\mathbb{E}[\theta]=\vartheta\).

\hypertarget{effect-sizes-and-artifacts}{%
\section{Effect Sizes and Artifacts}\label{effect-sizes-and-artifacts}}

In practice, \emph{observed} effect size estimates are often biased
relative to the \emph{true} effect size of interest, that is, the
observed population effect size (\(\vartheta_o\)) is a product of the
true population effect size (\(\vartheta\)) and artifactual bias
(\(a\)):

\begin{equation}\protect\hypertarget{eq-A}{}{
\vartheta_o = a\vartheta
}\label{eq-A}\end{equation}

Note that if \(a=1\) this would indicate that there is no artifactual
bias (\(\vartheta_o=\vartheta\)), if \(a>1\) then it would indicate
effect size inflation (i.e., biased away from zero), and if \(a<1\) that
would indicate effect size attenuation (i.e., biased toward zero). It
can be seen in Equation~\ref{eq-A} that we can re-arrange the formula to
obtain the true population effect size by dividing the observed
population effect size by \(a\),

\[
\vartheta = \frac{\vartheta_o}{a}.
\]

For a single study that computes an effect size from a sample drawn from
the population, the observed study effect size (\(\theta_o\)) would be
expressed by

\[
\theta_o = \vartheta_o + \varepsilon_o
\] Using Equation~\ref{eq-A} we can express the observed effect size in
terms of the true population effect size rather than the observed
population effect size,

\[
\theta_o = a\vartheta + \varepsilon_o
\] Then we can correct the observed effect size by dividing by the
biasing factor, \(a\), to obtain an unbiased estimate of the true effect
size:

\[
\theta_c = \frac{\theta_o}{a}
\] The sampling error and it's variance must also be corrected,

\[
\varepsilon_c = \frac{\varepsilon_o}{a}
\] \[
\sigma_{\varepsilon_c}^2 = \frac{\sigma^2_{\varepsilon_o}}{a^2}.
\] The corrected effect size should be an unbiased estimate of the true
population effect size as long as the systematic bias multiplier is
accurately measured (which is not a trivial task). It is important to
note that the corrected effect size will not yield additional
statistical power, that is, test-statistics and p-values will remain
unchanged. We can demonstrate this mathematically that the z-statistic
of the observed effect size (\(z_{\theta_o}\)) is identical to the
z-statistic of the corrected effecct size (\(z_{\theta_c}\)),

\[
z_{\theta_o} = \frac{\theta_o}{\sigma_{\varepsilon_o}} = \frac{\frac{\theta_o}{a}}{\frac{\sigma_{\theta_o}}{a}} = \frac{\theta_c}{\sigma_{\varepsilon_c}} = z_{\theta_c}
\]

\hypertarget{defining-an-effect-size-estimand}{%
\section{Defining an Effect Size
Estimand}\label{defining-an-effect-size-estimand}}

An effect size \emph{estimand} is the theoretical quantity that we are
trying to estimate. Before delving into the application of correction
factors, it is important to clearly define the effect size estimand you
aim to capture, including the summary statistic, relevant variables, and
the target population. This preliminary step might appear trivial, but
it is crucial, as it determines the accuracy and relevance of any
subsequent artifact corrections. For instance, consider a scenario where
we conduct a study involving a sample of college students with the aim
of generalizing our findings to the broader general population. In this
context, it is important to correct for range restriction, given the
evident selection effects that exist in the college student populations.
However, if our sole objective is to draw conclusions pertaining
exclusively to the college student demographic, correcting for range
restriction would be inappropriate. Furthermore, let's examine the
variable of interest, such as grade-point average (GPA), within this
population. Do we intend to focus solely on the raw GPA score, or is our
goal to capture what GPA represents, namely, academic achievement? If
our aim is to investigate the raw GPA score, then correcting for
measurement error would be inappropriate. However, if our primary focus
lies in assessing the student's academic achievement, then it may be
relevant to correct GPA scores for measurement error. Defining our
estimand guides our approach to artifact correction and ensures that
these correction procedures align with the underlying research goals.

\hypertarget{effect-size-notation}{%
\section{Effect Size Notation}\label{effect-size-notation}}

Because of the nature of the topic, this book will cover a large amount
of equations and computer code. Therefore to make it as straight-forward
as possible the notation will follow a systematic framework to
distinguish between types of effect sizes. This book will only be
covering two main types of effect sizes: correlations (\(r\)) and
standardized mean differences (\(d\)). Throughout the book variations of
\(r\) and \(d\) will show up frequently, these variations will be
differentiated with subscripts that are consistent with that section.
Also, to distinguish between population-level values (i.e., the effect
size across all potential observations) and effect sizes specific to a
study or sample (i.e., the effect size observed within a single sample
drawn from the population), we will use the following notation:

\begin{itemize}
\tightlist
\item
  Arbitrary Effect Size

  \begin{itemize}
  \tightlist
  \item
    Population value: \(\vartheta\)
  \item
    Study/sample value: \(\theta\)
  \end{itemize}
\item
  Correlations

  \begin{itemize}
  \tightlist
  \item
    Population value: \(\rho\)
  \item
    Study/sample value: \(r\)
  \end{itemize}
\item
  Standardized Mean Differences

  \begin{itemize}
  \tightlist
  \item
    Population value: \(\delta\)
  \item
    Study/sample value: \(d\)
  \end{itemize}
\end{itemize}

In most cases, continuous independent variables will be denoted with
\(x\) and dependent variables with \(y\) (note that this notation may
differ when referring to observed and true scores). Categorical (i.e.,
groupings) variables will be denoted with \(g\) (this notation will be
used primarily for standardized mean differences).

\hypertarget{correlations}{%
\section{Correlations}\label{correlations}}

A correlation describes the relationship between two continuous
variables. The Pearson correlation coefficient was first introduced by
Auguste Bravais (1844). Later developed by Karl Pearson, lending itself
to the name.

\hypertarget{technical-overview-correlations-r}{%
\subsection{\texorpdfstring{Technical Overview Correlations
(\emph{r})}{Technical Overview Correlations (r)}}\label{technical-overview-correlations-r}}

If we draw a sample of \(n\) observations from a population, we can
calculate the study correlation (\(r\)) between variables \(x\) and
\(y\) using the following Pearson's product-moment estimator,

\begin{equation}\protect\hypertarget{eq-pearson-raw}{}{
r = \frac{
\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})
}{
\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}
\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}
}.
}\label{eq-pearson-raw}\end{equation}

For digestibility, we can break down the formula into parts. The
correlation coefficient can be defined as the covariance between \(x\)
and \(y\) standardized by the product of their standard deviations
(i.e., square root variance),

\begin{equation}\protect\hypertarget{eq-pearson}{}{
r = \frac{\sigma_{xy}}
{\sigma_x\sigma_y}.
}\label{eq-pearson}\end{equation}

we can first define the covariance (\(\sigma_{xy}\)) as the average
product of errors for \(x\) and \(y\),

\begin{equation}\protect\hypertarget{eq-cov}{}{
\sigma_{xy} =\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y}).
}\label{eq-cov}\end{equation}

Then we can find the variance for \(x\) and \(y\) by taking the average
squared error from the mean for \(x\) and \(y\),

\begin{equation}\protect\hypertarget{eq-varx}{}{
\sigma^2_x = \frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2
}\label{eq-varx}\end{equation}

\begin{equation}\protect\hypertarget{eq-vary}{}{
\sigma^2_y = \frac{1}{n-1}\sum_{i=1}^n (y_i - \bar{y})^2.
}\label{eq-vary}\end{equation}

Plugging in Equation~\ref{eq-cov}, Equation~\ref{eq-varx}, and
Equation~\ref{eq-vary} into Equation~\ref{eq-pearson} we can see that
the term, \(\frac{1}{n-1}\), will cancel out and we will be left with
the original pearson correlation coefficient formula from
Equation~\ref{eq-pearson-raw},

\begin{equation}\protect\hypertarget{eq-1}{}{
r = \frac{\sigma_{xy}}{\sigma_x\sigma_y} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}}.
}\label{eq-1}\end{equation}

In the absence of artifacts, the Pearson correlation \(r\) is an
asymptotically (i.e., as \(n\) approaches infinity) unbiased estimator
(in small sample sizes, it is biased see chapter 4). We can express
\(r\) similarly to Equation~\ref{eq-B},

\begin{equation}\protect\hypertarget{eq-2}{}{
r = \rho + \varepsilon,\;\; \sigma_\varepsilon^2 = \text{Var}(\varepsilon).
}\label{eq-2}\end{equation}

Where \(\sigma^2_\varepsilon\) is the sampling variance of the observed
correlation. The sampling variance can be calculated from the sample
size (\(n\)) and the population correlation,

\begin{equation}\protect\hypertarget{eq-3}{}{
\sigma_\varepsilon^2 =\frac{(1 - \rho^2)^2}{n}.
}\label{eq-3}\end{equation}

In practice, the population correlation is unknown so the study
correlation can be used instead (\(r\)) in the above formula as an
estimate of the population correlation. Note that the sampling variance
is the square of the standard error.

In the context of artifacts, if the observed correlation is biased
relative to the true correlation, we can see model the observed
population (\(\rho_o\)) correlation as a function of the true population
correlation (\(\rho\)) and a artifact biasing factor, \(a\),

\[
\rho_o = a\rho.
\]

The observed study (sample) correlation would then be defined as,

\[
r_o = \rho_o + \varepsilon_o = a\rho + \varepsilon_o.
\]

To obtain an unbiased estimate of the true population correlation, we
can correct the correlation coefficient (\(r_c\)) by dividing by the
biasing factor, \(a\),

\[
r_{c} = \frac{r_o}{a}.
\]

Note that the sampling error would also need to be adjusted and
therefore it's sampling variance (\(\sigma_{\varepsilon_c}\)) would be
corrected to be,

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o} }{a^2}.
\]

\hypertarget{standardized-mean-differences}{%
\section{Standardized Mean
Differences}\label{standardized-mean-differences}}

Standardized mean differences are used to quantify the average
difference in some variable between groups. The most commonly used
formulation is Cohen's \(d\) (Cohen 1988) which quantifies the average
difference between groups (e.g., men vs.~women) and standardizes by the
pooled standard deviation. Note that the other most commonly used
estimator is Hedges' \(g\), but the difference between the two is a
small sample correction factor that can be found in the chapter on small
samples.

\hypertarget{technical-overview-of-standardized-mean-difference-d}{%
\subsection{\texorpdfstring{Technical Overview of Standardized Mean
Difference
(\emph{d})}{Technical Overview of Standardized Mean Difference (d)}}\label{technical-overview-of-standardized-mean-difference-d}}

If we draw a sample of \(n_A\) subjects from group \(A\) and \(n_B\)
subjects from group \(B\), the mean difference between groups (\(d\)) on
variable \(y\) can be defined as,

\[
d=\frac{\bar{y}_A - \bar{y}_B}{\sigma_p}.
\]

Where the standardizer, \(\sigma_p\) is the pooled standard deviation
between the two groups. The pooled standard deviation is calculated by
taking the square root of the average variance between the two groups
weighted by the degrees of freedom (e.g., \(\text{df}_A=n_A-1\)),

\[
\sigma_p=\sqrt{\frac{(n_A-1)\sigma^2_{A} + (n_B-1)\sigma^2_{B}}{n_A + n_B - 2}}.
\]

Where \(\sigma_{A}\) and \(\sigma_{B}\) are the standard deviations of
\(y\) within groups \(A\) and \(B\) respectively. This SMD estimator is
commonly referred to as Cohen's \(d\). We can define the study/sample
\(d\) value as a function of the population \(d\) value (\(\delta\)): \[
d = \delta + \varepsilon.
\] Similar to the previous section on correlation coefficients, the
observed \(d\) value is a function of the true population value and an
artifactual biasing factor (\(a\)),

\[
\delta_o = a\delta.
\]

Therefore the observed study/sample \(d\) value can be defined as a
function of the observed population value \emph{or} the true population
value and bias:

\[
d = \delta_o + \varepsilon_o = a\delta + \varepsilon_o.
\]

Thus the corrected standardized mean difference (\(d_c\)) and it's
corresponding sampling variance (\(\sigma^2_{\varepsilon_c}\)) can both
be defined as:

\[
d_c = \frac{d_o}{a}
\]

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o}}{a^2}.
\]

\part{Artifact Corrections}

\hypertarget{small-samples}{%
\chapter{Small Samples}\label{small-samples}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

The purpose of sample statistics such as correlations and standardized
mean differences is to draw meaningful inferences about the population.
However, effect size estimators such as Pearson's correlation
coefficient and Cohen's \(d\) are biased in small sample sizes. This
small sample bias will impair our ability to draw accurate inferences
about the population.

\hypertarget{when-correcting-alongside-other-artifacts}{%
\section{When Correcting alongside other
Artifacts}\label{when-correcting-alongside-other-artifacts}}

The small sample bias should always be corrected for prior to applying
any other artifact correction. It is independent of all other artifact
corrections and therefore the corrected effect sizes in this section can
be treated as the observed effect sizes (and observed sampling variance)
in other sections.

\hypertarget{correcting-for-small-sample-bias-in-standardized-mean-differences}{%
\section{Correcting for Small Sample Bias in Standardized Mean
Differences}\label{correcting-for-small-sample-bias-in-standardized-mean-differences}}

\hypertarget{defining-our-estimand}{%
\subsection{Defining our Estimand}\label{defining-our-estimand}}

Our quantity of interest is the population standardized mean difference,
\(\delta\), between groups \(A\) and \(B\) on variable, \(y\). We can
model the relationship between the population standardized mean
difference and our observed standardized mean difference (\(d_o\)) with,

\[
d_o = a\delta+\varepsilon.
\]

Where \(a\) is our small sample biasing factor and \(\varepsilon\) is
our sampling error term. Ultimately, we can obtain an unbiased estimate
of the population standardized mean difference by correcting the
observed standardized mean difference as follows,

\[
d_c = \frac{d_o}{a}.
\]

\hypertarget{artifact-correction-for-small-sample-bias}{%
\subsection{Artifact Correction for Small Sample
Bias}\label{artifact-correction-for-small-sample-bias}}

As the sample size approaches infinity, Cohen's standardized mean
difference estimator is an unbiased estimator of the population
standardized mean difference (Hedges 1981; Cohen 2013). However, in
small sample sizes Cohen's estimator is biased upward, that is, on
average, it overestimates the population standardized mean difference.
To see why this is the case, we can first define the standardized mean
difference between group \(A\) and group \(B\) such that,

\[
d = \frac{\bar{y_A}-\bar{y}_B}{\sigma_p}.
\]

Where \(\bar{y}_A\) and \(\bar{y}_B\) are the observed arithmetic means
of group \(A\) and group \(B\), respectively. The raw difference between
these two means will be unbiased, since the arithmetic means themselves
are unbiased estimators at all sample sizes. However, the pooled
standard deviation, \(\sigma_p\), is biased when sample sizes are small.
Statisticians ultimately had to choose whether the estimator of the
standard deviation or the variance (the square of the standard
deviation) would be unbiased. Since the variance has more utility in
much of statistics, it was more important for the estimator of variance
to be unbiased. Therefore the resulting bias in the standard deviation
will bleed over into the equation for standardized mean differences.
This bias can be visualized in the figure below. Notice that the sample
standard deviation is under-estimated in small sample sizes (left plot),
and the standardized mean difference is over-estimated in small sample
sizes (right plot).

\begin{figure}

{\centering \includegraphics{small_samples_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\caption{\emph{Note}. dotted lines in both plots indicate the population
value and the dots indicate the sample value at each sample size integer
(n=1,2,3,\ldots)}

\end{figure}

To obtain an unbiased estimate of the population standardized mean
difference, we need to estimate a correction factor that can account for
this bias. The small sample correction factor has been derived
previously by Hedges (1989). When applied to a \(d\) value, it is common
convention to refer to resulting corrected value as ``Hedges' \(g\)'',
giving credit to the originator and to keep it similar in style to the
conventionally termed ``Cohen's \(d\)''. However this convention will
not be used here, instead we will denote it in this section as the small
sample corrected \(d\) value (\(d_c\)). We can compute the artifact
biasing factor, \(a\), with the total sample size (\(n=n_A+n_B\)) and
Gamma functions (\(\Gamma(\cdot)\)),

\[
a = \frac{\Gamma\left(\frac{n-3}{2}\right)\sqrt{\frac{n-2}{2}}}{\Gamma\left(\frac{n-2}{2}\right)}.
\]

Then to correct the observed standardized mean difference for small
sample bias we can divide by \(a\),

\[
d_c = \frac{d_o}{a} = \frac{d_o}{ \left[\frac{\Gamma\left(\frac{n-3}{2}\right)\sqrt{\frac{n-2}{2}}}{\Gamma\left(\frac{n-2}{2}\right)}\right]}.
\]

It is important to point out that there is not a sample size threshold
in which this correction does not apply, therefore common suggestions
such as ``small sample correction should be applied when n\textless30''
is misguided since this correction can (and should) be applied at any
sample size. Since the formula is quite complicated, there is also a
simpler approximation of the this formula also given by Hedges (1989),
\(a\approx 1/\left(1-\frac{3}{4n-3}\right)\). When this correction is
made, we must also adjust the sampling variance
(\(\sigma_{\varepsilon_o}\)),

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o}}{a^2} =\frac{\sigma^2_{\varepsilon_o}}{\left[\frac{\Gamma\left(\frac{n-3}{2}\right)\sqrt{\frac{n-2}{2}}}{\Gamma\left(\frac{n-2}{2}\right)}\right]^2}.
\]

\hypertarget{correcting-standardized-mean-differences-in-r}{%
\subsection{Correcting Standardized Mean Differences in
R}\label{correcting-standardized-mean-differences-in-r}}

To compute the correction in R, we can first simulate 20 data points, 10
in group \(A\) and 10 in group \(B\). Then we can calculate the observed
\(d\) value.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{120}\NormalTok{)}

\CommentTok{\# define parameters}
\NormalTok{nA }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{nB }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ nA }\SpecialCharTok{+}\NormalTok{ nB}
\NormalTok{delta }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}

\CommentTok{\# simulate data}
\NormalTok{yA }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(nA,delta,}\DecValTok{1}\NormalTok{)}
\NormalTok{yB }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(nB,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)}

\CommentTok{\# calculate observed d value}
\NormalTok{SD\_pooled }\OtherTok{=}\NormalTok{ ((nA}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{var}\NormalTok{(yA) }\SpecialCharTok{+}\NormalTok{ (nB}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{var}\NormalTok{(yB)) }\SpecialCharTok{/}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB}\DecValTok{{-}2}\NormalTok{)}
\NormalTok{do }\OtherTok{=}\NormalTok{ (}\FunctionTok{mean}\NormalTok{(yA) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(yB)) }\SpecialCharTok{/}\NormalTok{ SD\_pooled}
\end{Highlighting}
\end{Shaded}

Once we have obtained \(d_o\), we can then correct it with the equations
in the previous section.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate bias factor}
\NormalTok{a }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{gamma}\NormalTok{((n}\DecValTok{{-}3}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{((n}\DecValTok{{-}2}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{/} \FunctionTok{gamma}\NormalTok{((n}\DecValTok{{-}2}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{) }

\CommentTok{\# correct d value}
\NormalTok{dc }\OtherTok{=}\NormalTok{ do }\SpecialCharTok{/}\NormalTok{ a}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Observed: do = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(do,}\DecValTok{3}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Corrected: dc = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dc,}\DecValTok{3}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                   
[1,] "Observed: do = 0.889" 
[2,] "Corrected: dc = 0.851"
\end{verbatim}

You will notice that the small sample correction reduced the observed
\(d\) value however it is still far away from the true value. This is
simply due to the fact that there is a large amount of sampling error on
top of the bias.

\hypertarget{correcting-for-small-sample-bias-in-correlations}{%
\section{Correcting for Small Sample Bias in
Correlations}\label{correcting-for-small-sample-bias-in-correlations}}

\hypertarget{defining-our-estimand-1}{%
\subsection{Defining our Estimand}\label{defining-our-estimand-1}}

Our quantity of interest is the population correlation, \(\rho\),
between independent variable, \(x\) and dependent variable, \(y\). We
can model the relationship between the population correlation and our
observed correlation (\(r_o\)) with,

\[
r_o = a\rho+\varepsilon
\]

Where \(a\) is our small sample biasing factor and \(\varepsilon\) is
our sampling error term. Ultimately, we can obtain an unbiased estimate
of the population correlation by correcting the observed correlation as
follows,

\[
r_c = \frac{r_o}{a}
\]

\hypertarget{artifact-corrections-1}{%
\subsection{Artifact Corrections}\label{artifact-corrections-1}}

Correlation coefficients also are biased in small sample sizes (Olkin
and Pratt 1958). As opposed to standardized mean differences,
correlations are under-estimated, rather than over-estimated, in small
samples. The bias is quite small, however we can apply a correction
factor to obtain unbiased estimates of the population correlation.
Because the bias is so small and the exact formula is a hypergometric
function using infinite power series, we will instead focus on the
extremely close approximation provided in Olkin and Pratt (1958).
Therefore, the biasing factor can be calculated such that,

\[
a \approx \frac{1}{1+\frac{1-r_o^2}{2(n-3)}}.
\]

Then we can correct the point-estimate the sampling variance for small
sample bias

\[
r_c = \frac{r_o}{\left[ 1+\frac{1-r_o^2}{2(n-3)}\right]}
\]

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o}}{\left[ 1+\frac{1-r_o^2}{2(n-3)}\right]^2}.
\]

\hypertarget{correcting-correlations-in-r}{%
\subsection{Correcting Correlations in
R}\label{correcting-correlations-in-r}}

To compute the correction in R, we can first simulate 10 correlated data
points. Then we can calculate the observed correlation.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}MASS\textquotesingle{})}
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{\# define parameters}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{rho }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}

\CommentTok{\# simulate data}
\NormalTok{data }\OtherTok{=} \FunctionTok{mvrnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{,}
               \AttributeTok{mu=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
               \AttributeTok{Sigma =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,rho),}\AttributeTok{x=}\FunctionTok{c}\NormalTok{(rho,}\DecValTok{1}\NormalTok{)))}

\CommentTok{\# calculate observed d value}
\NormalTok{ro }\OtherTok{=} \FunctionTok{cor}\NormalTok{(data[,}\DecValTok{1}\NormalTok{],data[,}\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

Once we have obtained \(r_o\), we can then correct it with the equations
in the previous section.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate bias factor}
\NormalTok{a }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{ro}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(}\DecValTok{2}\SpecialCharTok{*}\NormalTok{(n}\DecValTok{{-}3}\NormalTok{)))}

\CommentTok{\# correct d value}
\NormalTok{rc }\OtherTok{=}\NormalTok{ ro }\SpecialCharTok{/}\NormalTok{ a}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Observed: ro = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(ro,}\DecValTok{3}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Corrected: rc = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{3}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                   
[1,] "Observed: ro = 0.247" 
[2,] "Corrected: rc = 0.264"
\end{verbatim}

You will notice that the small sample correction increases the observed
correlation however it is still far away from the true value. This is
simply due to the fact that there is a large amount of sampling error on
top of the bias.

\hypertarget{unreliability}{%
\chapter{Unreliability}\label{unreliability}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

In general terms, measurement is the process of quantifying an attribute
or characteristic of something. In scientific measurement, the measurand
is the quantity or the attribute we intend to measure. In the
psychological sciences, measurands usually take the form of constructs
such as intelligence or anxiety. Often the goal of measurement is to
produce quantities (i.e., scores) that accurately reflect the measurand.
However, quantities that do not reflect a \emph{real} attribute can
still have useful predictive value (e.g., socio-economic status). It is
important to note that measures are not all created equal, some perform
better than others. Ideally, measures should produce scores that are
consistent and repeatable, this is referred to as the \emph{reliability}
of a measure. A high quality measure should produce highly reliable
scores. This section will review what reliability is in theory, how to
estimate reliability, and how to correct effect sizes for measurement
error.

\hypertarget{sec-true-score-theory}{%
\section{Reliability in True Score Theory}\label{sec-true-score-theory}}

True score theory (or classical test theory) is a mathematical
formalization of observed scores obtained from a measurement procedure.
Observed scores, \(x_{im}\), is defined as a score obtained from
individual \(i\) upon measurement \(m\). The true score model assumes
that each individual, has a true score, \(T_i\), that stays constant
over repeated measurements. Variation in observed scores over repeated
measurements is due to measurement-specific error, \(e_{im}\),

\[
x_{im} = T_i+e_{im}.
\]

Here, measurements are \emph{strictly parallel}. Strictly parallel
measurements have the following four properties (p.~69, Haertel 2006):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Measurements have identical specifications. That is, each measurement
  is obtained with an identical format and procedure.
\item
  The distribution of observed scores for each measurement are
  identical: \(f(x_1) = f(x_2) = \ldots\).
\item
  Any set of two measurements are assumed to covary the same as any
  other set of two measurements:
  \(\sigma_{x_1 x_2} = \sigma_{x_2 x_3} = \sigma_{x_1 x_3} = \ldots\).
\item
  Each measurement equally covaries with any other variable:
  \(\sigma_{x_1 y} = \sigma_{x_2 y} = \ldots\).
\end{enumerate}

True scores can be defined as the expected value (i.e., the mean) of
observed scores over repeated measurements such that,
\(\mathbb{E}_m[x_{im}]=T_{i}\). Given this assumption, it can be
inferred that the average of the resultant errors is zero across
repeated measurements, \(\mathbb{E}_m[e_{im}]=0\) and therefore the
covariance between errors on repeated measurements is zero and the
covariance between errors in parallel measurements is zero
(\(\sigma_{e e'}=0\)). It follows that the covariance between errors and
true scores is also zero (\(\sigma_{eT}=0\)). The independence between
true scores and errors provide convenient parsing of the variance in
observed scores (\(\sigma^2_{x}\)) into components of variance in true
scores (\(\sigma_T^2\)) and measurement errors (\(\sigma_{e}^2\)),

\begin{equation}\protect\hypertarget{eq-variance}{}{
\sigma_{x}^2 = \sigma_T^2 + \sigma_{e}^2.
}\label{eq-variance}\end{equation}

Ultimately we desire to have observed scores that closely resemble true
scores, therefore it is important to minimize measurement error variance
(\(\sigma^2_e\)). If \(\sigma_{e}^2 = 0\) then the scores can be said to
have perfect reliability, that is, observed scores do not vary upon
repeated measurements and thus are identical to true scores. In
practice, this is virtually never the case. Since we assume that the
covariance between errors in parallel measurements is zero, it becomes
apparent that the covariance between observed scores in parallel
measurements must solely be attributable to variance in true scores,
\(\sigma_{xx'}=\,\)\(\sigma_{TT'} + \sigma_{ee'}=\,\)\(\sigma_{TT'}=\,\)\(\sigma_T^2\,\).
In true score theory, reliability can be defined as the proportion of
true variance in the total observed variance
(\(\frac{\sigma_T^2}{\sigma_x^2}\)) or the correlation between observed
scores in parallel measurements (\(r_{xx'}\)).

\[
r_{xx'}=\frac{\sigma_{xx'}}{\sigma_x\sigma_{x'}}  = \frac{\sigma_T^2}{\sigma^2_{x}}.
\] The reliability is also equivalent to the square of the correlation
between observed scores and true scores. To understand why this is the
case, note that the covariance between parallel forms of a measure is
equivalent to the covariance between observed scores and true scores,
\(\sigma_{xT}=\)\(\sigma_{(T+e)T}=\)\(\sigma^2_T + \sigma_{Te}=\)\(\sigma^2_T = \sigma_{xx'}\).

\begin{equation}\protect\hypertarget{eq-reliability}{}{
r_{xx'} = \frac{\sigma_T^2}{\sigma_{x}^2} = \frac{(\sigma_T^2)^2}{\sigma_x^2 \sigma_T^2}= \frac{\sigma_{xT}^2}{\sigma^2_x\sigma^2_T} = r^2_{xT}.
}\label{eq-reliability}\end{equation}

It is important to emphasize that true scores are expected values over
repeated observations and they do not necessarily correspond to an
actual, tangible quantity of interest (Borsboom and Mellenbergh 2002).
As a result, every measurement has a true score, regardless of whether
it gauges a concrete attribute or not. For example, if we construct a
test by summing the responses to the items: ``how many languages can you
confidently hold a conversation in?'' and ``Estimate the number of
photos you've taken in the last year across all devices''. Even in such
nonsensical cases, the test's composite score retains a true score, but
this true score does not mirror a tangible reality.

\begin{figure}

{\centering \includegraphics[width=4.16667in,height=\textheight]{figure/unreliability_diagram_1.png}

}

\caption{Structural diagram illustrating the relationship between true
scores, observed scores, and error scores. The pink circle labeled \(t\)
indicates the true scores, the blue squares labeled with \(x\) and
\(x'\) represent observed scores on parallel measurements, and the red
\(e\) denotes error. Correlations between \(T\), \(x\), and \(x'\) are
in terms of reliability (\(r_{xx'}\)). Note that
\(\sqrt{r_{xx'}}=r_{xT}\).}

\end{figure}

\hypertarget{reliability-vs-validity}{%
\section{Reliability vs Validity}\label{reliability-vs-validity}}

Reliability and validity are distinct properties in measurement theory.
Validity pertains to whether the scores produced by a measure reflects
the quantities it is intended to measure (p.~14 Kelley 1927). According
to Borsboom, Mellenbergh, and Van Heerden (2004), a measure is
\emph{valid} if both of the following statements are true:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The attribute exists.
\item
  Variations in the attribute causally produce variations in the
  outcomes of the measurement procedure.
\end{enumerate}

Borsboom's formulation of validity is simpler and more practical than
other formulations such as Cronbach and Meehl's (1955) nomological
network approach to validity. It is important to note that even if an
attribute does not exist (statement 1), scores may still provide
predictive utility. For example, socio-economic status (SES) is a
formative quantity that is constructed from a composite of education,
income, occupation status, etc. Although SES is not causal to these
indicators, SES can still be used as a predictor of important life
outcomes.

\hypertarget{estimating-reliability}{%
\section{Estimating Reliability}\label{estimating-reliability}}

In practice, reliability must be estimated through indirect methods,
this is due to the fact that true scores and errors are unknown. There
are many reliability estimators that can be used, however we will go
over a selection of internal consistency estimators as well as
test-retest stability estimators.

\hypertarget{internal-consistency-estimators}{%
\subsection{Internal Consistency
Estimators}\label{internal-consistency-estimators}}

Taking multiple measurements and then averaging tends to provide a more
stable estimate of true values. For instance, let's consider the case of
Francis Galton (1907), who conducted a study involving 787 individuals
estimating the weight of an ox. On average, each person's estimate
deviated by approximately 37 pounds from the actual weight of the ox,
which was recorded as 1198 pounds. However, when all the guesses were
averaged together, the combined estimate was 1207 pounds, just a 9 pound
difference from the true value. This principle can be extended to
broader applications, such as measuring psychological constructs. If we
were to assess someone's level of extraversion using ratings from their
mother, father, friend, and sibling, the average of their combined
assessments would yield a more reliable score compared to relying solely
on a single evaluator. So to create a more stable composite score
(\(x\)), we can take the score from \(\kappa\) items (\(\mathbb{x}\))
and sum them such that,

\[
x = \mathbb{x}_1 + \mathbb{x}_2 +...+\mathbb{x}_\kappa
\]

The most commonly reported reliability estimator in the psychological
sciences is coefficient alpha, also referred to as Cronbach's alpha.
Coefficient alpha, along with other internal consistency estimators,
serves the purpose of assessing the reliability of composite scores
comprising multiple item scores. Coefficient alpha only requires three
parameters to calculate, the number of measurements (\(\kappa\)), the
variances of each item (\(\sigma^2_{\text{i}_m}\)), and the variance of
the composite score (\(\sigma^2_{x}\)). Coefficient alpha will estimate
the reliability of the composite observed score, \(x\) (\(r_{xx'}\)),

\begin{equation}\protect\hypertarget{eq-alpha}{}{
_\alpha r_{xx'} = \frac{\kappa}{\kappa-1}\left( 1 - \frac{\sum_{m=1}^\kappa \sigma^2_{\mathbb{x}_m}}{\sigma^2_{x}} \right).
}\label{eq-alpha}\end{equation}

\begin{figure}

{\centering \includegraphics{unreliability_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\caption{Figures showing the observed scores upon 10 repeated
measurements and the composite observed score for a single person (the
true score is denoted with the dashed line). The left panel shows 10
observed scores with a lot of variation (i.e., low reliability). The
composite score (dark red dot with error bars), shows wide error bars
illustrating the low precision of the observed score score. The right
panel also shows 10 observed scores with little variation (i.e., high
reliability). The composite score (dark blue dot with error bars), shows
narrow error bars illustrating the high precision of the observed
score.}

\end{figure}

With tighter assumptions (see Haertel 2006), the formula for coefficient
alpha can be simplified to just two parameters: the number of
measurements (\(\kappa\)) and the average correlation between measured
scores (\(\bar{r}_{\mathbb{x}_i \mathbb{x}_j}\), where \(i\neq j\)).
This formula is known as Spearman-Brown's prophecy,

\begin{equation}\protect\hypertarget{eq-sp-brown}{}{
_\text{sb} r_{xx'}= \frac{\kappa \bar{r}_{\mathbb{x}_i \mathbb{x}_j}}{1+(\kappa-1)\bar{r}_{\mathbb{x}_i \mathbb{x}_j}}
}\label{eq-sp-brown}\end{equation}

This can be simplified further if we have two observed item scores. This
formulation is a variation of split-half reliability:

\begin{equation}\protect\hypertarget{eq-split-half}{}{
_\text{sh}r_{xx'}= \frac{2r_{\mathbb{x}_1 \mathbb{x}_2}}{1+r_{\mathbb{x}_1 \mathbb{x}_2}}
}\label{eq-split-half}\end{equation}

All of these reliability estimators measure internal consistency,
therefore they do not account for error outside of the
measurement-specific error. There are other sources of error that
internal consistency reliability estimates do not account for, such as
transient error or rater-specific error.

\begin{figure}

{\centering \includegraphics[width=4.16667in,height=\textheight]{figure/unreliability_diagram_2.png}

}

\caption{Structural model illustrating internal consistency. The pink
circle labeled \(T\) indicates the true scores, the blue squares,
\(\mathbb{x}_{1...\kappa}\), represent the observed scores across
multiple measurements, and the red \(e\) denotes error. The dark blue
hexagon, \(x\), indicates a composite score as a sum of the observed
scores (\(\mathbb{x}_{1...\kappa}\)). Note that
\(\sqrt{r_{xx'}}=r_{xT}\).}

\end{figure}

\hypertarget{calculating-internal-consistency-in-r}{%
\subsection{Calculating Internal Consistency in
R}\label{calculating-internal-consistency-in-r}}

Let us simulate a data set of 50 individuals that were measured four
times resulting in four sets of scores (\texttt{x1,x2,x3,x4}) that have
the same true score and error variance. Then let us calculate a
composite score (\texttt{x}) from these sub-scores.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{343}\NormalTok{)}

\CommentTok{\# set sample size}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{50}

\CommentTok{\# simulate data}
\NormalTok{T\_score }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate true scores}
\NormalTok{x1 }\OtherTok{\textless{}{-}}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate observed scores for measurement 1}
\NormalTok{x2 }\OtherTok{\textless{}{-}}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate observed scores for measurement 2}
\NormalTok{x3 }\OtherTok{\textless{}{-}}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate observed scores for measurement 3}
\NormalTok{x4 }\OtherTok{\textless{}{-}}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate observed scores for measurement 4}

\CommentTok{\# calculate composite score}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3 }\SpecialCharTok{+}\NormalTok{ x4}
\end{Highlighting}
\end{Shaded}

Now let us calculate coefficient alpha from the formula provided in
Equation~\ref{eq-alpha}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1. calculate variance of observed (measured) scores}
\NormalTok{var\_xm }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{var}\NormalTok{(x1),}\FunctionTok{var}\NormalTok{(x2),}\FunctionTok{var}\NormalTok{(x3),}\FunctionTok{var}\NormalTok{(x4))}

\CommentTok{\# step 2. get number of items (k)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(var\_xm)}

\CommentTok{\# step 3. calculate variance of composite score}
\NormalTok{var\_x }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(x)}

\CommentTok{\# step 4. calculate coefficient alpha reliability}
\NormalTok{rxx\_alpha }\OtherTok{\textless{}{-}}\NormalTok{ k }\SpecialCharTok{/}\NormalTok{ (k}\DecValTok{{-}1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(var\_xm)}\SpecialCharTok{/}\NormalTok{(var\_x))}

\CommentTok{\# display reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx\_alpha,}\DecValTok{3}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.775
\end{verbatim}

With the simplification of Coefficient alpha's formula, let us calculate
the reliability via Spearman-Brown's prophecy formula provided in
Equation~\ref{eq-sp-brown}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1. get correlation matrix between all observed scores}
\NormalTok{corr\_mat }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(x1,x2,x3,x4))}

\CommentTok{\# step 2. average off{-}diagonal elements of matrix}
\FunctionTok{diag}\NormalTok{(corr\_mat) }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{rxixj }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(corr\_mat, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# step 3. get number of items (k)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{dim}\NormalTok{(corr\_mat)[}\DecValTok{1}\NormalTok{]}

\CommentTok{\# step 4. calculate Spearman{-}Brown reliability}
\NormalTok{rxx\_SB }\OtherTok{\textless{}{-}}\NormalTok{ k }\SpecialCharTok{*}\NormalTok{ rxixj }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ (k}\DecValTok{{-}1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ rxixj)}

\CommentTok{\# display reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx\_SB,}\DecValTok{3}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.775
\end{verbatim}

If we simplify even further, we can calculate the Split-Half reliability
formula provided in Equation~\ref{eq-split-half},

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1. make composite scores for each half of the observed scores}
\NormalTok{xh1 }\OtherTok{\textless{}{-}}\NormalTok{ (x1 }\SpecialCharTok{+}\NormalTok{ x2)}\SpecialCharTok{/}\DecValTok{2}
\NormalTok{xh2 }\OtherTok{\textless{}{-}}\NormalTok{ (x3 }\SpecialCharTok{+}\NormalTok{ x4)}\SpecialCharTok{/}\DecValTok{2}

\CommentTok{\# step 2. calculate the correlation between the scores of both halves}
\NormalTok{rx1x2 }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(xh1,xh2)}

\CommentTok{\# step 3. calculate the split{-}half reliability}
\NormalTok{rxx\_SH }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{rx1x2 }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ rx1x2)}

\CommentTok{\# display reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx\_SH,}\DecValTok{3}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.824
\end{verbatim}

Lets see how the results compare to the actual reliability,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate true reliability, true scores must be re{-}scaled by number of items}
\NormalTok{rxx }\OtherTok{=} \FunctionTok{var}\NormalTok{(k}\SpecialCharTok{*}\NormalTok{T\_score) }\SpecialCharTok{/}\NormalTok{ var\_x}

\CommentTok{\# display actual reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx,}\DecValTok{3}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.734
\end{verbatim}

In this case, the reliability estimates do a fairly good job of
estimating the true reliability of the observed scores. We can also use
the \texttt{alpha} function from the \texttt{psych} package ({``Psych:
Procedures for Personality and Psychological Research''} 2017) to
estimate coefficient alpha too. It also provides additional item level
information that is quite useful:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load in package}
\CommentTok{\# install.packages(\textquotesingle{}psych\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psych)}

\CommentTok{\# compute summary reliability (only need first table)}
\FunctionTok{alpha}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(x1,x2,x3,x4))[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 raw_alpha std.alpha   G6(smc) average_r      S/N        ase        mean
 0.7749847 0.7751377 0.7337024 0.4628829 3.447166 0.05141467 -0.04386823
        sd  median_r
 0.9567892 0.4571798
\end{verbatim}

\hypertarget{test-retest-stability-estimator}{%
\subsection{Test-Retest Stability
Estimator}\label{test-retest-stability-estimator}}

Transient errors represent fluctuations in observed scores over time.
These fluctuations, even if they are systematic (e.g., fatigue over the
course of a single day), add extraneous within-person variance that can
mask true scores. Considering transient fluctuations as error depends on
the research goal, so it is important for researchers to take care in
considering which variance components should be considered error in
their study (see Section~\ref{sec-sources}). To estimate test-retest
reliability, we can compute the correlation between the measurement at
time 1 (\(x_{t_1}\)) and the second measurement at time 2 (\(x_{t_2}\)),

\[
_\text{tr}r_{xx'}= r_{x_{t_1}x_{t_2}}.
\]

Note that calculating the pearson correlation coefficient between
time-points ignores systematic changes (e.g., practice effects).

\begin{figure}

{\centering \includegraphics{unreliability_files/figure-pdf/unnamed-chunk-8-1.pdf}

}

\caption{Illustrating test-retest reliability. Top-left and top-right
panels show the correlation between observed scores at both time-points
for a measure that has low and high reliability, respectively.
Bottom-left and bottom-right panels show the within-person change from
time-point 1 to time-point 2 for scores with low and high reliability,
respectively.}

\end{figure}

\hypertarget{calculating-test-retest-reliability-in-r}{%
\subsection{Calculating Test-Retest Reliability in
R}\label{calculating-test-retest-reliability-in-r}}

Lets calculate test-retest reliability in R. First, we can simulate
observed scores at two time points, \texttt{xTime1} and \texttt{xTime2}.
We can assume that the true scores remain constant between time points.
Second, we can calculate the correlation between the observed scores at
each time point (\texttt{rxx}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{\# set sample size}
\NormalTok{n }\OtherTok{=} \DecValTok{100}

\CommentTok{\# simulate true scores}
\NormalTok{T\_score }\OtherTok{=} \FunctionTok{rnorm}\NormalTok{(n,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)}

\CommentTok{\# simulate scores at time 1}
\NormalTok{xTime1 }\OtherTok{=}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n,}\DecValTok{0}\NormalTok{,.}\DecValTok{5}\NormalTok{)}

\CommentTok{\# simulate scores at time 2}
\NormalTok{xTime2 }\OtherTok{=}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n,}\DecValTok{0}\NormalTok{,.}\DecValTok{5}\NormalTok{)}

\CommentTok{\# calculate test{-}retest reliability}
\NormalTok{rxx }\OtherTok{=} \FunctionTok{cor}\NormalTok{(xTime1,xTime2)}

\CommentTok{\# display reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.755
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compare with true reliability}
\NormalTok{rxx\_true }\OtherTok{=} \FunctionTok{var}\NormalTok{(T\_score) }\SpecialCharTok{/} \FunctionTok{var}\NormalTok{(xTime1)}

\CommentTok{\# display actual reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx\_true,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.779
\end{verbatim}

\hypertarget{sec-sources}{%
\subsection{Sources of Measurement Error}\label{sec-sources}}

Measurement error variance can itself be broken down into multiple
sources of error (e.g., transient, ). Depending on the study, different
sources of error may be more relevant than others. It is important for a
researcher to choose the right reliability estimator for their study
since they account for different sources of measurement error. A
description of four of the most common sources of error is adapted from
table 1 of Wiernik and Dahlke (2020):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Random Response Error: Genuine randomness in responses. Examples
  include: motor errors and variation in response time.
\item
  Time/Environment-Specific (Transient) Error: Fluctuations in scores as
  a result of the specific time or environment of the measurement. For
  instance, if researchers administered an ability test to a sample of
  undergraduate students throughout the course of a day, the student's
  who complete the test at the end of the day will likely perform worse
  than participant's who completed due to fatigue rather than ability.
  Errors due to illness, mood, hunger, environmental distractors, etc.
  all fall under the umbrella of transient errors.
\item
  Instrument-Specific Error: Error due to the specific content or
  make-up of the measurement instrument. For example, a psychological
  scale using Likert items may show participant's idiosyncratic
  interpretations of questions and response options rather than their
  standing on the latent construct.
\item
  Rater/Observer-Specific Error: Errors induced by idiosyncratic biases
  of individual raters and rater by ratee interactions (e.g., Teacher A
  gives higher grades to students who stay after class).
\end{enumerate}

Different estimators of reliability account for different sources of
measurement error therefore depending on the research design, it is
important to carefully choose which reliability is most relevant for
your use case. Note that even if two estimators account for the same
types of measurement error, they likely hold different assumptions that
may be violated in a given research context.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}@{}}
\caption{List of reliability coefficients and the sources of error they
account for. The sources of error are denoted by the columns labeled
1-4, corresponding to each of the four sources of error.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Estimator
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
4
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Estimator
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
4
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Coefficient Alpha & Internal consistency coefficient for composite
measures. & X️ & & X️ & \\
Coefficient Omega & Internal consistency coefficient for composite
measures with specified factor structure. & X️ & & X️ & \\
Split-Half & Internal consistency coefficient for measurements that are
split into two halves. & X️ & & X️ & \\
Kuder-Richardson 20 & Internal consistency when observed scores are
binary (special case of coefficient alpha). & X️ & & X️ & \\
Item Response Theory Reliability & Reliability coefficient derived from
item response theory (as opposed to classical test theory) & X️ & & X️
& \\
Inter-Rater/Inter-Observer Reliability & Consistency in scoring between
raters/observers. & X️ & & & X️ \\
Test-Retest & Stability coefficient for repeated measurements across
time & X️ & X️ & & \\
Delayed Coefficient Alpha & Average of all possible split-half
reliabilities & X️ & X️ & X️ & \\
G-Coefficient & Reliability coefficient derived from generalizability
theory (G-theory). Can incorporate any source of error if enough data is
present. & X️ & X️ & X️ & X️ \\
\end{longtable}

\hypertarget{correction-for-bias-in-correlations}{%
\section{Correction for Bias in
Correlations}\label{correction-for-bias-in-correlations}}

\hypertarget{defining-the-estimand}{%
\subsection{Defining the Estimand}\label{defining-the-estimand}}

Continuing with our emphasis on clearly defining our quantity of
interest (i.e., the estimand) prior to applying any corrections, let us
define it. Our estimand here is the population correlation between true
scores of our independent and dependent variables. We can define the
observed scores of the independent and dependent variables \(x\) and
\(y\) as,

\[
x=T+e_x
\]

\[
y=U+e_y.
\]

Where \(T\) and \(U\) are the true scores for the independent and
dependent variables, respectively. The true score correlation can thus
be be denoted by, \(\rho_{TU}\), and can be defined as the standardized
covariance,

\[
\rho_{TU} = \frac{\sigma_{TU}}{\sigma_{T}\sigma_{U}}.
\]

In a given study, we will only have knowledge of the observed scores of
the independent and dependent variables, \(x\) and \(y\), therefore the
observed study correlation is \(r_{xy}\). The relationship between the
observed correlation and the true population correlation is,

\[
r_{xy} = a\rho_{TU} + \varepsilon.
\]

Where \(a\) is the biasing factor. An unbiased estimate of the true
score population correlation (\(\rho_{TU}\)) can then be calculated by
dividing the obsereved study correlation by the biasing factor,

\[
r_c = \frac{r_{xy}}{a}.
\]

\begin{figure}

{\centering \includegraphics{figure/diagram-estimand-reliability-r.png}

}

\caption{This figure shows the relationship between the true scores,
observed scores, and error scores. The true score correlation is denoted
by the curved arrow connecting the circles indicating true score
variables, \emph{T} and \emph{U}.}

\end{figure}

\hypertarget{sec-r-corr}{%
\subsection{Artifactual Bias and Correction}\label{sec-r-corr}}

Measurement error induces systematic bias in effect size estimates such
as correlation coefficients Spearman (1904). In the population, let us
assume there is some factor \(a\) that accounts for the systematic bias
in observed score correlations (\(\rho_{xy}\)) relative to true score
correlations (\(\rho_{TU}\)), such that

\[
\rho_{xy} = a \rho_{TU}.
\]

Since the correlation is defined as the covariance standardized by the
standard deviations, the population correlation between true scores,
\(T\) and \(U\), is defined as,

\[
\rho_{TU}=\frac{\sigma_{TU}}{\sigma_{T} \sigma_{U}}.
\]

Likewise the correlation between the observed scores, \(x\) and \(y\),
would be the observed covariance divided by the observed standard
deviations. \[
\rho_{xy} =\frac{\sigma_{xy}}{\sigma_{x} \sigma_{y}}.
\] However, if we assume that there is no covariance between errors in
\(x\) and \(y\) (\(\sigma_{e_x e_y} = 0\)), then the covariance between
observed scores is only attributable to the covariance between true
scores, therefore \(\sigma_{xy} = \sigma_{TU}\). This means that the
observed score correlation can be expressed as,

\begin{equation}\protect\hypertarget{eq-bias}{}{
\rho_{xy} =\frac{\sigma_{TU}}{\sigma_{x} \sigma_{y}}.
}\label{eq-bias}\end{equation}

Now the only difference between the observed score correlation and the
true score correlation is the standard deviations in the denominator. In
the presence of measurement error, the observed score standard
deviations (\(\sigma_x\) and \(\sigma_y\)) will be larger than the true
score standard deviations (\(\sigma_{T}\) and \(\sigma_{U}\)). Using the
definition of reliability, we can show how the observed variance is
inflated compared to the true variance as a function of reliability.
Since the reliability is defined as the ratio of true variance to total
observed variance (see Equation~\ref{eq-reliability}), we can see how
reliability inflates the observed variance

\begin{align}
\sigma^2_x &=\sigma^2_{T} \left(\frac{\sigma^2_{x}}{\sigma^2_{T}} \right)
\\ &= \sigma^2_{T}\left(\frac{1}{r_{xx'}} \right)
\\ &= \frac{\sigma^2_{T}}{r_{xx'}}.
\end{align}

Therefore the observed standard deviation is,

\begin{equation}\protect\hypertarget{eq-sd-me}{}{
\sigma_x = \frac{\sigma_{T}}{\sqrt{r_{xx'}}}.
}\label{eq-sd-me}\end{equation}

If we use the definition of an observed score correlation
(Equation~\ref{eq-bias}), then we can replace \(\sigma_x\) and
\(\sigma_y\) with \(\frac{\sigma_{T}}{\sqrt{r_{xx'}}}\) and
\(\frac{\sigma_{U}}{\sqrt{r_{yy'}}}\), respectively. Now we can see how
the observed score correlation differs from the true score correlation:

\begin{align}
\rho_{xy} &= \frac{\sigma_{T U}}{\left[\frac{\sigma_{T}}{\sqrt{r_{xx'}}} \right] \left[ \frac{\sigma_{U}}{\sqrt{r_{yy'}}} \right] } 
\\ &= \frac{\sigma_{T U}}{\sigma_{T}\sigma_{U}} \cdot \sqrt{r_{yy'}}\sqrt{r_{xx'}}
\\ &= \rho_{TU} \sqrt{r_{yy'}}\sqrt{r_{xx'}} 
\end{align}

This attenuation formula was first derived by Spearman (1904). Note that
this formulation requires that there is no correlation between \(e_x\)
and \(e_y\) (\(r_{e_xe_y}=0\)). The study observed correlation will also
contain sampling error and thus can be expressed by, \[
r_{xy} = \rho_{xy} + \varepsilon_o
\] We can also express it in terms of our estimand, the population true
score correlation (\(\rho_{TU}\)),

\[
r_{xy} = \rho_{TU}\sqrt{r_{xx'}r_{xx'}} + \varepsilon_o.
\]

\begin{figure}

{\centering \includegraphics{unreliability_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\caption{Visualizing the attenuation of observed correlation
(\(\rho_{xy}\)) due to measurement error. The left panel shows a
situation where only one variable (\(x\)) has measurement error. The
observed correlation increases as a function of the true correlation
\(\rho_{TU}\) (darker lines indicate a higher true score correlation)
and the reliability of \(x\) (x-axis). The right panel shows the
attenuation of the correlation when both \(x\) and \(y\) variables are
affected by measurement error. The darker end of the gradient shows a
higher correlation, while the lighter end represents a smaller
correlation (the true score correlation sits on the top where no
measurement error is present, \(r_{xx'}=r_{yy'}=1\)).}

\end{figure}

It becomes apparent that if we have the reliability of \(x\) and \(y\),
we can obtain an unbiased estimate of \(\rho_{TU}\) by dividing both
sides of the above equation by \(\sqrt{r_{xx'}r_{xx'}}\) such that,

\[
\frac{r_{xy}}{\sqrt{r_{xx'}r_{xx'}}} =\rho_{TU} + \frac{\varepsilon_o}{\sqrt{r_{xx'}r_{xx'}}}.
\]

Therefore the corrected study correlation, \(r_c\), is defined as,

\[
r_c = \frac{r_{xy}}{\sqrt{r_{xx'}r_{xx'}}}.
\]

The sampling error of the corrected study correlation is,

\[
\varepsilon_c = \frac{\varepsilon_{o}}{\sqrt{r_{xx'}r_{xx'}}}
\]

and thus the sampling variance would be,

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_{o}}}{r_{xx'}r_{xx'}}.
\]

\hypertarget{correcting-correlations-in-r-1}{%
\subsection{Correcting Correlations in
R}\label{correcting-correlations-in-r-1}}

We can simulate continuous data that contains measurement error by using
the \texttt{simulate\_r\_sample} function in the \texttt{psychmeta}
package. Below we will simulate observed scores (\texttt{x\_score} and
\texttt{y\_score}) and true scores (\texttt{T\_score} and
\texttt{U\_score}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{\# define parameters}
\NormalTok{rhoTU }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}
\NormalTok{rxx }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{8}
\NormalTok{ryy }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{7}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{500}

\CommentTok{\# simulate data}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{simulate\_r\_sample}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }
                          \AttributeTok{rho\_mat =} \FunctionTok{reshape\_vec2mat}\NormalTok{(rhoTU),}
                          \AttributeTok{rel\_vec =} \FunctionTok{c}\NormalTok{(rxx, ryy), }
                          \AttributeTok{sr\_vec =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                          \AttributeTok{var\_names =} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{))}

\CommentTok{\# obtain observed scrores}
\NormalTok{x\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{x}
\NormalTok{y\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{y}

\CommentTok{\# obtain true scores}
\NormalTok{T\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{true}\SpecialCharTok{$}\NormalTok{x}
\NormalTok{U\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{true}\SpecialCharTok{$}\NormalTok{y}
\end{Highlighting}
\end{Shaded}

Then we can compute observed score (\texttt{rxy}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute observed score correlation and standard error}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x\_score,y\_score)}

\CommentTok{\# compute sampling variance of observed score correlation}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxy}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}2}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e\_o = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_o,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "rxy = 0.351  var_e_o = 0.0018"
\end{verbatim}

Let us now compare the observed correlation with the true score
correlation (\texttt{rTU}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute observed score correlation and standard error}
\NormalTok{rTU }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(T\_score,U\_score)}

\CommentTok{\# compute sampling variance of observed score correlation}
\NormalTok{var\_e }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rTU}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}2}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rTU = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rTU,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "rTU = 0.463  var_e = 0.0016"
\end{verbatim}

The observed correlation is substantially lower than the true score
correlation. In order to correct the observed score correlation, we can
calculate it by hand or use the \texttt{correct\_r()} function. Lets
first correct by hand using the equations in Section~\ref{sec-r-corr}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# correct correlation coefficient}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ rxy }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(rxx}\SpecialCharTok{*}\NormalTok{ryy)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(rxx}\SpecialCharTok{*}\NormalTok{ryy)}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rc = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{3}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}var\_e\_c = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]              
[1,] "rc = 0.47"       
[2,] "var_e_c = 0.0024"
\end{verbatim}

Now lets correct the correlation with the \texttt{correct\_r()}
function,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# correct correlation}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxy,}
          \AttributeTok{rxx =}\NormalTok{ rxx,}
          \AttributeTok{ryy =}\NormalTok{ ryy,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95   n n_effective
1  0.47    0.364    0.569 500         222
\end{verbatim}

As we can see, the corrected correlation (\(r_c = .470\)) is a more
accurate estimate of the true score population correlation
\(\rho_{TU} = .500\), than the observed score correlation
(\(r_{xy}=.351\)).

\hypertarget{correction-for-bias-in-standardized-mean-differences-d}{%
\section{\texorpdfstring{Correction for Bias in Standardized Mean
Differences
(\emph{d})}{Correction for Bias in Standardized Mean Differences (d)}}\label{correction-for-bias-in-standardized-mean-differences-d}}

\hypertarget{defining-the-estimand-1}{%
\subsection{Defining the Estimand}\label{defining-the-estimand-1}}

Prior to correcting for measurement error let us define our estimand.
Our estimand here is the difference in the means of group \(A\) and
\(B\) with respect to the true scores of our dependent variable. We can
define the observed scores of the independent and dependent variables
\(x\) and \(y\) as,

\[
y_A = U_A + e_A
\]

\[
y_B = U_B + e_B.
\]

Where \(U_A\) and \(U_B\) are the true scores for group \(A\) and group
\(B\), respectively. The true score standardized mean difference can
thus be be denoted by, \(\delta_{U}\), and can be defined as,

\[
\delta_{U} = \frac{\overline{U}_A - \overline{U}_B}{\sigma_{U_P}}.
\]

Where \(\overline{U}\) is the mean of true scores for the respective
group. In a given study, we only have access to the observed scores of
the dependent variables, \(y\), therefore the observed score study
standardized mean difference is \(d_{y}\). The relationship between the
population true score standardized mean difference (\(\delta_U\)) can be
related to the observed study standardized mean difference with the
following formulation:

\[
d_y = a\delta_U+\varepsilon.
\]

Where \(a\) is the artifactual bias induced by measurement error and
\(\varepsilon\) denotes sampling error. To obtain an unbiased estimate
of \(\delta_{U}\), we can correct the observed standardized mean
difference by dividing by \(a\),

\[
d_c = \frac{d_y}{a}.
\]

\hypertarget{sec-d-SMD}{%
\subsection{Artifact Correction for Unreliability}\label{sec-d-SMD}}

We can calculate the standardized mean difference of the observed scores
by dividing the mean difference in observed scores
(\(\bar{y}_A-\bar{y}_B\)) by the pooled standard deviation
(\(\sigma_p\)). It is important to note that the mean of true scores and
the mean of observed scores will be identical due to the fact that
measurement error only affects variance in scores rather than the means.
Therefore, we can express the observed standardized mean difference as,

\[
d_y = \frac{\bar{y}_A-\bar{y}_B}{\sigma_{y_P}} = \frac{\overline{U}_A-\overline{U}_B}{\sigma_{y_P}}.
\]

The pooled standard deviation is a weighted average of the observed
score standard deviations,

\[
\sigma_{y_P}=\sqrt{\frac{(n_A+1)\sigma^2_{y_A}+(n_B+1)\sigma^2_{y_B}}{n_A+n_B-2}}.
\]

To express \(\sigma_{y_P}\) in terms of the true score standard
deviations, we can replace the observed score standard deviations with
the attenuated true score standard deviation in Equation~\ref{eq-sd-me},

\[
\sigma_{y_P} = \sqrt{\frac{(n_A+1)\left(\frac{\sigma^2_{U_A}}{r_{yy'_A}}\right)+(n_B+1)\left(\frac{\sigma^2_{U_B}}{r_{yy'_B}}\right)}{n_A + n_B - 2}}.
\]

Alternatively, we can pool the reliability and the true score standard
deviations separately so that we can obtain a simplified version of the
above equation,

\[
\sigma_{U_P} = \sqrt{\frac{(n_A+1)\sigma_{U_A}^2+(n_B+1)\sigma_{U_B}^2}{n_A + n_B - 2}}
\]

\[
r_{yy'_P} = \sqrt{\frac{(n_A+1) r_{yy'_A}^2+(n_B+1)r_{yy'_B}^2}{n_A + n_B - 2}}.
\]

Then we can express \(\sigma_{y_P}\) similarly to
Equation~\ref{eq-sd-me},

\[
\sigma_{y_P} = \frac{\sigma_{U_P}}{\sqrt{r_{yy'_P}}}
\]

Now we can put it all together and see how the observed score
standardized mean difference (\(\delta_y\)) is biased relative to the
true score standardized mean difference (\(\delta_U\)),

\begin{align}
\delta_y &= \frac{\bar{y}_A-\bar{y}_B}{\sigma_{y_P}}
\\[1em] &= \frac{\overline{U}_A-\overline{U}_B}{\sigma_{y_P}}
\\[1em] &= \frac{\overline{U}_A-\overline{U}_B}{\frac{\sigma_{U_P}}{\sqrt{r_{yy'_P}}}} 
\\[1em] &= \frac{\overline{U}_A-\overline{U}_B}{\sigma_{U_P}}\sqrt{r_{yy'_P}}
\\[1em] &= \delta_U\sqrt{r_{yy'_P}}.
\end{align}

This attenuation bias is very similar to the one we saw in the
correlation, with the only difference being that the pooled reliability
is used here instead of the total sample reliability. Within a study,
the observed study standardized mean difference (\(d_y\)) is a function
of the observed population standardized mean (\(\delta_y\)), artifact
bias (\(a\)), and sampling error (\(\varepsilon\)),

\[
d_y = \delta_y + \varepsilon_o.
\]

replacing the observed population standardized mean difference,
\(\delta_y\), with \(\delta_U\sqrt{r_{yy'_P}}\), gives us,

\[
d_y = \delta_U\sqrt{r_{yy'_P}} + \varepsilon.
\] Therefore to obtain the corrected study standardized mean difference
(\(d_c\)) we can divide \(d_y\) by the attenuation factor,

\[
d_c = \frac{d_y}{\sqrt{r_{yy'_P}}}.
\]

Where the sampling variance of the corrected SMD must also be similarly
adjusted,

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o}}{r_{yy'_P}}.
\]

Although the attenuation factor is quite simple, in more complex
formulations (e.g., bivariate direct range restriction), it will be
easier to apply a simplified correction for the sampling variance using
the corrected correlation coefficient:

\[
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{d_c}{d_y}\right)^2.
\] It is important to point out that this correction can only be done if
when estimates of the within-group reliability are available. It is
common that studies will only report the full sample reliability. If
there are differences between groups on the variable, the total sample
reliability will over-estimate the within-group reliability. When the
total sample reliability is all that is available, to correct \(d_y\),
we must first convert it to a point-biserial correlation coefficient
(\(r_o\)) using the observed proportion of subjects in either group
\(A\) or \(B\) (\(p\,\); it does not matter which one is chosen, as long
as it is consistent throughout).

\[
r_o = \frac{d_y}{\sqrt{\frac{1}{p(1-p)}+d_y^2}}.
\]

Then correct \(r_o\) for the total sample reliability,

\[
r_c = \frac{r_o}{\sqrt{r_{yy'}}}
\]

Then we can convert \(r_c\) back into \(d_c\),

\[
d_c = \frac{r_c}{\sqrt{p(1-p)(1-r_c^2)}}
\]

The same process can be done for the sampling variance as well, but
instead we can put it all into one equation,

\[
\sigma^2_{\varepsilon_c} = \frac {\sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_o}\right)^2} {\left(1+d_y^2p[1-p]\right)^3\left(1-r_c^2\right)^3}
\]

\hypertarget{correcting-standardized-mean-differences-in-r-1}{%
\subsection{Correcting Standardized Mean Differences in
R}\label{correcting-standardized-mean-differences-in-r-1}}

We can simulate data that contains measurement error by using the
\texttt{simulate\_d\_sample} function in the \texttt{psychmeta} package.
Below we will simulate observed scores (\texttt{y\_score}) and true
scores (\texttt{U\_score}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\CommentTok{\# define parameters}
\NormalTok{Means }\OtherTok{=} \FunctionTok{c}\NormalTok{()}
\NormalTok{ryyA }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{75}
\NormalTok{ryyB }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{70}
\NormalTok{nA }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{nB }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ nA }\SpecialCharTok{+}\NormalTok{ nB}

\CommentTok{\# simulate data}
\NormalTok{data}\OtherTok{\textless{}{-}} \FunctionTok{simulate\_d\_sample}\NormalTok{(}\AttributeTok{n\_vec =} \FunctionTok{c}\NormalTok{(nA, nB), }
                         \AttributeTok{rho\_mat\_list =} \FunctionTok{list}\NormalTok{(}\FunctionTok{reshape\_vec2mat}\NormalTok{(}\DecValTok{1}\NormalTok{),}\FunctionTok{reshape\_vec2mat}\NormalTok{(}\DecValTok{1}\NormalTok{)),}
                         \AttributeTok{mu\_mat =} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{c}\NormalTok{(.}\DecValTok{5}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                                        \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }
                         \AttributeTok{sigma\_mat =} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
                                           \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)),}
                         \AttributeTok{rel\_mat =} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{c}\NormalTok{(ryyA,}\DecValTok{1}\NormalTok{),}
                                         \FunctionTok{c}\NormalTok{(ryyB,}\DecValTok{1}\NormalTok{)), }
                         \AttributeTok{sr\_vec =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
                         \AttributeTok{group\_names =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{))}

\CommentTok{\# obtain observed scores}
\NormalTok{y\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{y1}
\NormalTok{group }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{group}

\CommentTok{\# obtain true scores}
\NormalTok{U\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{true}\SpecialCharTok{$}\NormalTok{y1}
\end{Highlighting}
\end{Shaded}

Then we can compute observed score standardized mean difference
(\texttt{dy}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute observed score means and standard deviations}
\NormalTok{Mean\_A }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(y\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{])}
\NormalTok{Mean\_B }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(y\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}
\NormalTok{SD\_A }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(y\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{])}
\NormalTok{SD\_B }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(y\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}

\CommentTok{\# compute pooled standard deviation}
\NormalTok{SD\_P }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{( ((nA}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SD\_A}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (nB}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SD\_B}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB}\DecValTok{{-}2}\NormalTok{) )}

\CommentTok{\# compute standardized mean difference}
\NormalTok{dy }\OtherTok{\textless{}{-}}\NormalTok{ (Mean\_A }\SpecialCharTok{{-}}\NormalTok{ Mean\_B) }\SpecialCharTok{/}\NormalTok{ SD\_P}

\CommentTok{\# compute sampling variance of observed score correlation}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ n}\SpecialCharTok{/}\NormalTok{(nA}\SpecialCharTok{*}\NormalTok{nB) }\SpecialCharTok{+}\NormalTok{ dy}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{n)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}dy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dy,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e\_o = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_o,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dy = 0.273  var_e_o = 0.0202"
\end{verbatim}

Let us now compare the observed score standardized mean difference with
the true score standardized mean difference (\texttt{dU}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute true score means and standard deviations}
\NormalTok{Mean\_A }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(U\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{])}
\NormalTok{Mean\_B }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(U\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}
\NormalTok{SD\_A }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(U\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{])}
\NormalTok{SD\_B }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(U\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}

\CommentTok{\# compute pooled standard deviation}
\NormalTok{SD\_P }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{( ((nA}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SD\_A}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (nB}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SD\_B}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB}\DecValTok{{-}2}\NormalTok{) )}

\CommentTok{\# compute standardized mean difference}
\NormalTok{dU }\OtherTok{\textless{}{-}}\NormalTok{ (Mean\_A }\SpecialCharTok{{-}}\NormalTok{ Mean\_B) }\SpecialCharTok{/}\NormalTok{ SD\_P}

\CommentTok{\# compute sampling variance of the true score SMD}
\NormalTok{var\_e }\OtherTok{\textless{}{-}}\NormalTok{ n}\SpecialCharTok{/}\NormalTok{(nA}\SpecialCharTok{*}\NormalTok{nB) }\SpecialCharTok{+}\NormalTok{ dy}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{n)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}dU = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dU,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dU = 0.509  var_e = 0.0202"
\end{verbatim}

The observed score standardized mean difference is substantially lower
than the true score SMD (.286 vs .509). In order to correct the observed
score correlation for attenuation, we can calculate it by hand. Lets
correct the observed standardized mean difference for measurement error
variance using the equations in Section~\ref{sec-d-SMD}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate the pooled reliability}
\NormalTok{ryy\_P }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(((nA}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{ryyA}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (nB}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{ryyB}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB}\DecValTok{{-}2}\NormalTok{))}

\CommentTok{\# correct correlation coefficient}
\NormalTok{dc }\OtherTok{\textless{}{-}}\NormalTok{ dy }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(ryy\_P)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(ryyA)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rc = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dc,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e\_c = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "rc = 0.32  var_e_c = 0.0233"
\end{verbatim}

Now lets correct the correlation with the \texttt{correct\_r()}
function. The \texttt{correct\_d()} function only takes in the total
sample reliability, therefore we can extract the total sample
reliability from the simulated dataset and then use the resulting
reliability coefficient in the \texttt{ryy} argument.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# total sample reliability}
\NormalTok{ryy }\OtherTok{=}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{overall\_results}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{parallel\_ryyi\_total[}\DecValTok{1}\NormalTok{]}

\CommentTok{\# correct correlation}
\FunctionTok{correct\_d}\NormalTok{(}\AttributeTok{d =}\NormalTok{ dy,}
          \AttributeTok{ryy =}\NormalTok{ ryy,}
          \AttributeTok{n1 =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
d Values Corrected for Measurement Error:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95   n n_effective
1 0.322 -0.00878    0.667 200         142
\end{verbatim}

As we can see, the corrected correlation (\(d_c = .32\)) is a more
accurate estimate of the true score population SMD \(\delta_U = .500\),
than the observed score correlation (\(r_{xy}=.273\)).

\hypertarget{sec-lim-information}{%
\section{Estimating Reliability with Limited
Information}\label{sec-lim-information}}

Reliability estimates should preferably be calculated from within the
study's sample, however there are a couple of ways to estimate
reliability when this information is not provided. A common way to
obtain an estimate of the reliability is to look in meta-analyses or a
test manuals. If the number of items in a study differs from the test
manual, you can approximate the reliability of the study's test, with a
re-arrangement of the Spearman-Brown prophecy formula,

\[
r_{xx'_{study}} \approx \frac{1}{\frac{\kappa_{\text{ref}}}{\kappa_{\text{study}}} \left(\frac{1}{r_{xx'_{study}}} - 1\right) + 1}.
\]

Where \(\kappa_{\text{ref}}\) and \(\kappa_{\text{study}}\) denote the
number of items in the reference test and the test used in the study,
respectively.

\hypertarget{group-misclassification}{%
\chapter{Group Misclassification}\label{group-misclassification}}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

Group misclassification describes a situation where true group
membership (e.g., people with a disorder) does not perfectly match the
observed group membership (e.g., people \emph{diagnosed} with a
disorder). Group misclassification can be considered a type of
measurement error where instead of accounting for errors in continuous
variables (i.e., unreliability), group misclassification accounts for
errors in categorical variables.

\hypertarget{defining-group-misclassification}{%
\section{Defining Group
Misclassification}\label{defining-group-misclassification}}

Misclassification can be defined as any deviations between true group
membership and observed group membership. Let us imagine two arbitrary
groups, group \(A\) and group \(B\). In order to identify members of
group \(A\) and group \(B\), we have to use some measurement instrument.
We can also assume this measurement instrument produces imperfect group
classifications, that is, people who are actually in group \(A\) are
sometimes assigned group \(B\) and vice versa. We can visualize the
performance of the classification procedure with a contingency table
between actual group membership (\(G\)) and observed group membership
(\(g\)):

\begin{longtable}[]{@{}lcc@{}}
\toprule\noalign{}
& \(G=A\) & \(G=B\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(g=A\) & \(AA\) & \(BA\) \\
\(g=B\) & \(AB\) & \(BB\) \\
\end{longtable}

We can see from the contingency table that subjects who were correctly
classified, would be labeled in the cell block \(AA\) or \(BB\) and
those who were misclassified would belong to cells \(BA\) and \(AB\).
Therefore we can define the proportion of individuals that are
accurately classified as \(p_{\text{acc}} = P(AA) + P(BB)\) whereas the
proportion of people misclassified can be defined as
\(p_{\text{mis}} = P(AB)+ P(BA)\). A high-quality classifier would would
minimize \(p_{\text{mis}}\) and maximize \(p_{\text{acc}}\). Note that
the proportion of people misclassified is inversely proportional to the
proportion of people accurately classified such that,
\(p_{\text{mis}} = 1-p_{\text{acc}}\).

\hypertarget{classification-reliability}{%
\section{Classification Reliability}\label{classification-reliability}}

Similar to quantifying reliability in continuous variables by
calculating the correlation in parallel sets of observed scores, the
same can be done in categorical variables. Instead of a contingency
table between observed (\(g\)) and true (\(G\)) group membership, we
will instead create a contingency table of two measurements producing
two sets of observed group assignments (\(g\) and \(g'\)). Measurements
often will take the form of inter-rater assessments, for example, two
clinician's diagnosis of Major Depressive Disorder (MDD) in the same
sample of patients.

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& \(g=A\) & \(g=B\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(g'=A\) & \(AA\) & \(BA\) \\
\(g'=B\) & \(AB\) & \(BB\) \\
\end{longtable}

To obtain the reliability of the group assignments, we can calculate the
correlation coefficient between \(g\) and \(g'\). Since both variables
are categorical, a Pearson correlation coefficient would not be an
appropriate correlation estimator, instead, we must compute the phi
coefficient. The phi coefficient is often referred to as Matthew's
correlation coefficient and is most frequently used as an index of
performance of a binary classifier in machine learning. For the sake of
consistency, the phi coefficient will be denoted with the letter \(r\),
and thus the reliability (i.e., the correlation between \(g\) and
\(g'\)) is denoted with \(r_{gg'}\).

There are a few ways we can calculate the phi coefficient. The first way
is to calculate phi directly from the contingency table,

\[
r_{gg'} = \frac{n_{AA}n_{BB}-n_{AB}n_{BA}}{\sqrt{(n_{AA}+n_{BA})(n_{AB}+n_{BB})(n_{AA}+n_{AB})(n_{BA}+n_{BB})}}.
\]

Where \(n_{AA}\), \(n_{BB}\), \(n_{AB}\), and \(n_{BA}\) are the number
of subjects within their respective cells of the contingency table. If
the values of the contingency table are not available, we can calculate
the phi coefficient from the \(\chi^2\)-statistic,

\[
r_{gg'} = \sqrt{\frac{\chi^2}{n}}.
\]

Where \(n\) is the total sample size. If the \(\chi^2\)-statistic is
unavailable, we can approximate the phi coefficient from the accuracy
(\(p_{\text{acc}}\)) or the proportion of people misclassified
(\(p_{\text{mis}}\)),

\[
r_{gg'} = (2p_{\text{acc}}-1)^2 = (1-2p_{\text{mis}})^2.
\]

This approximation assumes that the group sizes are approximately equal
\emph{and} the misclassification rates are approximately equal between
groups. Otherwise, \(r_{gg'}\) will be overestimated (Wiernik and Dahlke
2020).

In the chapter 5, we discussed the relationship between reliability and
the correlation between observed and true scores. The classification
reliability will also be related similarly to the correlation between
observed group membership and true group membership (\(r_{gG}\)) such
that,

\[
r_{gG}=\sqrt{r_{gg'}}.
\]

\hypertarget{calculating-classification-reliability-in-r}{%
\section{Calculating Classification Reliability in
R}\label{calculating-classification-reliability-in-r}}

To calculate classification reliability we will first need data. We can
simulate 100 subjects with a group value for three variables: a true
group membership and two sets of assigned (observed) group membership.
We will set the misclassification rate to 10\%.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{17}\NormalTok{)}

\CommentTok{\# 10\% misclassification rate}
\NormalTok{p\_mis }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{10}

\CommentTok{\# sample size of 100}
\NormalTok{nA }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{nB }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{n }\OtherTok{=}\NormalTok{ nA }\SpecialCharTok{+}\NormalTok{ nB}

\CommentTok{\# create a vector of true group values}
\NormalTok{true\_A }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,nA)}
\NormalTok{true\_B }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,nB)}
\NormalTok{true\_group }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(true\_A,true\_B)}

\CommentTok{\# initialize vectors of observed group membership from true group membership}
\NormalTok{obs\_1\_A }\OtherTok{\textless{}{-}}\NormalTok{ true\_A}
\NormalTok{obs\_1\_B }\OtherTok{\textless{}{-}}\NormalTok{ true\_B}
\NormalTok{obs\_2\_A }\OtherTok{\textless{}{-}}\NormalTok{ true\_A}
\NormalTok{obs\_2\_B }\OtherTok{\textless{}{-}}\NormalTok{ true\_B}

\CommentTok{\# add misclassified values to observed group membership}
\NormalTok{obs\_1\_A[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nA,nA}\SpecialCharTok{*}\NormalTok{p\_mis)] }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}B\textquotesingle{}}
\NormalTok{obs\_1\_B[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nB,nB}\SpecialCharTok{*}\NormalTok{p\_mis)] }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}A\textquotesingle{}}
\NormalTok{obs\_2\_A[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nA,nA}\SpecialCharTok{*}\NormalTok{p\_mis)] }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}B\textquotesingle{}}
\NormalTok{obs\_2\_B[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nB,nB}\SpecialCharTok{*}\NormalTok{p\_mis)] }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}A\textquotesingle{}}
\NormalTok{obs\_1\_group }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(obs\_1\_A,obs\_1\_B)}
\NormalTok{obs\_2\_group }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(obs\_2\_A,obs\_2\_B)}
\end{Highlighting}
\end{Shaded}

Then we can generate a contingency table of the two sets of observed
group assignments.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create contingency table of the two observed group memberships}
\NormalTok{con\_table }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs\_1=}\NormalTok{obs\_1\_group,}
                              \AttributeTok{obs\_2=}\NormalTok{obs\_2\_group))}
\FunctionTok{print}\NormalTok{(con\_table)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     obs_2
obs_1  A  B
    A 40 10
    B 10 40
\end{verbatim}

Now we can calculate the reliability of the group assignments by
extracting the phi coefficient from the contingency table. We can
compute it by hand or by using the \texttt{psych} package by William
Revelle (2017).

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Strategy 1: Using the \{psych\} package}
\CommentTok{\# load in psych package (make sure it is installed first: install.packages(\textquotesingle{}psych\textquotesingle{}))}
\FunctionTok{library}\NormalTok{(psych)}
\NormalTok{rgg }\OtherTok{=} \FunctionTok{phi}\NormalTok{(con\_table,}\AttributeTok{digits =} \DecValTok{3}\NormalTok{)}

\DocumentationTok{\#\# Strategy 2: calculate from contingency table values}
\NormalTok{numerator }\OtherTok{\textless{}{-}}\NormalTok{ con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}\SpecialCharTok{*}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]}\SpecialCharTok{*}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}
\NormalTok{denominator }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}\SpecialCharTok{+}\NormalTok{con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]) }\SpecialCharTok{*}
               \FunctionTok{sqrt}\NormalTok{(con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}\SpecialCharTok{+}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]) }\SpecialCharTok{*} 
               \FunctionTok{sqrt}\NormalTok{(con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}\SpecialCharTok{+}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]) }\SpecialCharTok{*} 
               \FunctionTok{sqrt}\NormalTok{(con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]}\SpecialCharTok{+}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}

\NormalTok{rgg }\OtherTok{\textless{}{-}}\NormalTok{ numerator }\SpecialCharTok{/}\NormalTok{ denominator}

\DocumentationTok{\#\# Strategy 3: calculate from chi{-}square test}
\NormalTok{chi2 }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{chisq.test}\NormalTok{(con\_table)}\SpecialCharTok{$}\NormalTok{statistic)}
\NormalTok{rgg }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(chi2}\SpecialCharTok{/}\NormalTok{n)}

\DocumentationTok{\#\# Strategy 4: calculate from proportion of people misclassified}
\NormalTok{rgg }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1{-}2}\SpecialCharTok{*}\NormalTok{p\_mis)}\SpecialCharTok{\^{}}\DecValTok{2}
\FunctionTok{print}\NormalTok{(rgg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.64
\end{verbatim}

\hypertarget{correcting-for-group-misclassification-in-standardized-mean-difference}{%
\section{Correcting for Group Misclassification in Standardized Mean
Difference}\label{correcting-for-group-misclassification-in-standardized-mean-difference}}

\hypertarget{defining-our-estimand-2}{%
\subsection{Defining our Estimand}\label{defining-our-estimand-2}}

Our quantity of interest is the true population standardized mean
difference, \(\delta\), between members of group \(A\) and group \(B\)
on the scores of the dependent variable, \(y\). However, the observed
sample standardized mean difference (\(d_o\)) is estimating the
difference between individuals who are assigned group to \(A\) and group
\(B\). Error in the assignment of groups (i.e., group misclassification)
will bias the observed correlation by a factor we will label as \(a\).
The relationship between the observed study standardized mean difference
and the true population standardized mean difference

\[
d_o = a\delta + \varepsilon.
\]

Where \(\varepsilon\) denotes the sampling error. Therefore an unbiased
(corrected) estimate of the true population correlation would be:

\[
r_c = \frac{r_o}{a}.
\]

\hypertarget{artifact-correction-for-standardized-mean-difference}{%
\subsection{Artifact Correction for Standardized Mean
Difference}\label{artifact-correction-for-standardized-mean-difference}}

The standardized mean differences will become biased when subject's
assigned groups differ from their actual group. This is largely due to
the fact that the means of each group are driven closer to one another.
Let us suppose that, on average, group \(A\) and group \(B\) score
differently on some outcome, \(y\). The true mean of \(y\) for groups
\(A\) and \(B\) can be denoted as \(\bar{y}^\text{true}_{A}\) and
\(\bar{y}^\text{true}_{B}\), respectively. Nonetheless, when some
subjects are erroneously assigned to the wrong group, the
\emph{observed} mean within each group will reflect a weighted average
of the respective means. This is due to the fact that the misclassified
individuals are being drawn from a population with a different mean. To
calculate the mean of the observed groups we must incorporate the true
mean of the correctly classified subjects and the misclassified
subjects,

\[
\bar{y}^\text{obs}_A = \left(\frac{n_{AA}}{n_{AA}+n_{BA}}\right)\bar{y}^\text{true}_A + \left(\frac{n_{BA}}{n_{AA}+n_{BA}}\right)\bar{y}^\text{true}_B
\]

\[
\bar{y}^\text{obs}_A = \left(\frac{n_{BB}}{n_{BB}+n_{AB}}\right)\bar{y}^\text{true}_B + \left(\frac{n_{AB}}{n_{BB}+n_{AB}}\right)\bar{y}^\text{true}_A.
\]

From the above equations, it becomes evident that as the number of
misclassified individuals increases (\(n_{AB}\) and \(n_{BA}\)), the
observed means of each group gradually converge towards each other. As
the means converge, the standardized mean difference will
correspondingly shift toward zero. To illustrate this phenomenon, the
figure below shows the distributions for groups \(A\) and \(B\) without
any misclassification. In this case, there is no attenuation of the
standardized mean difference.

\begin{figure}

{\centering \includegraphics{misclassification_files/figure-pdf/unnamed-chunk-4-1.pdf}

}

\caption{Distributions of scores without misclassification. True mean
difference and observed mean differ only due to sampling error.}

\end{figure}

If some individual's are assigned to the incorrect group, then we will
see attenuation in the standardized mean difference as the means
converge. Now lets display a figure showing what happens when the group
misclassification rate is 10\%. A group misclassification rate of 10\%
is equivalent to a classification reliability of \(r_{gg'}=.60\).

\begin{figure}

{\centering \includegraphics{misclassification_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\caption{Distributions of scores with a 10\% misclassification rate.
Observed standardized mean differences are biased toward the null (i.e.,
SMD = 0). Note that a few members of group \(A\) (red squares) are
within observed group \(B\) and vice versa (indicative of
misclassification).}

\end{figure}

The bias in the standardized mean difference can be expressed as a
function of the classification reliability (\(r_{gg'}\)). To illuminate
this bias, we must first convert the true SMD to a point-biserial
correlation coefficient (\(\rho\)) using the proportion of individuals
in group \(A\) (\(p_A\)) and group \(B\) (\(1-p\)),

\[
\rho = \frac{\delta}{\sqrt{\frac{1}{p(1-p)}-\delta^2}}.
\]

Then attenuation of the correlation is similar to the attenuation of
correlation coefficients in the section on unreliability
(\(r = \rho\sqrt{r_{xx'}}\)). However in this case, we also need to
convert the point-biserial correlation to the observed standardized mean
difference:

\[
\delta_o =\frac{ \rho \sqrt{r_{gg'}} }{\sqrt{p (p-1)\left(1- r_{gg'} \rho^2\right) }}.
\]

It is important to note that for many of the biasing effects and
corrections, converting the standardized mean difference to a
point-biserial correlation is often a necessary step. However once the
corrected point-biserial correlation is obtained, the correlation can
then be converted back into a standardized mean difference like we see
in the last equation. To correct for bias induced by misclassification
we first need to convert the observed standardized mean difference to a
point-biserial correlation coefficient by using the observed proportion
of the sample that has been assigned to either group \(A\) or group
\(B\) (\(p\)). The group proportion \(p\) in the following equations
will only show up in the term \(p(1-p)\) so it will not matter which
group is used. Converting \(d\) to \(r\):

\[
r_o = \frac{d_o}{\sqrt{\frac{1}{p(1-p)}-d_o^2}}.
\]

We can then correct the point-biserial correlation for group
misclassification with the square root of the classification
reliability:

\[
r_c = \frac{r_o}{\sqrt{r_{gg'}}}.
\]

If we also wanted to correct for measurement error in the dependent
variable \(y\), we can use the correction formula used in the chapter 4

\[
r_c = \frac{r_o}{\sqrt{r_{gg'}}\sqrt{r_{yy'}}}.
\]

Now we can convert the corrected point-biserial correlation into a
corrected standardized mean difference (\(d_c\)). When converting back
to a standardized mean difference, we need to use the true group
proportions, \(p^*\). Although if we are to assume equal
misclassification rates between groups, then the observed proportion can
be used \(p\):

\[
\hat{\delta} = \frac{r_c}{\sqrt{p^*\left(1-p^*\right)\left(1-r_c^2\right)}}
\]

The s converting to a point-biserial correlation, correcting, and
converting back to a standardized mean difference. This time we will do
this in a single step. Therefore the adjusted sampling variance (squared
standard error) can be calculated as,

\[
\sigma^2_{\varepsilon_c} = \frac {\sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_o}\right)^2} {\left(1+d_o^2p[1-p]\right)^2\left(d_o^2+\frac{1}{p(1-p)}\right)p^*(1-p^*)(1-r_c^2)^3}
\]

This can be simplified if we assume that misclassification rates are
equal between groups,

\[
\sigma^2_{\varepsilon_c} = \frac {\sigma^2_{\varepsilon_o}\left(\frac{\hat{\rho}}{r}\right)^2} {\left(1+d_o^2p[1-p]\right)^3(1-r_c^2)^3}
\]

\hypertarget{correcting-for-misclassification-in-r}{%
\section{Correcting for Misclassification in
R}\label{correcting-for-misclassification-in-r}}

We can correct for group misclassification in R by hand or by using the
\texttt{psychmeta} package (Dahlke and Wiernik 2019). For our
correction, say we got an observed standardized mean difference of
\(d = 0.50\) and we calculated the classification reliability to be
\(r_{gg'} = .80\). Let us also say that the observed \emph{and} the true
proportion of individuals in one of the groups is \(p=p^*=.40\),
therefore the other group would be \(1-p=1-p^*=.60\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{=}\NormalTok{ .}\DecValTok{50}
\NormalTok{rgg }\OtherTok{=}\NormalTok{ .}\DecValTok{70}
\NormalTok{nA }\OtherTok{=} \DecValTok{40}
\NormalTok{nB }\OtherTok{=} \DecValTok{60}
\end{Highlighting}
\end{Shaded}

\hypertarget{using-the-psychmeta-package}{%
\subsubsection*{\texorpdfstring{Using the \emph{psychmeta}
package}{Using the psychmeta package}}\label{using-the-psychmeta-package}}
\addcontentsline{toc}{subsubsection}{Using the \emph{psychmeta} package}

The \texttt{psychmeta} package has a function, \texttt{correct\_d}, that
is dedicated to correcting standardized mean differences multiple types
of artifacts including group misclassification.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1: install and load in psychmeta}
\CommentTok{\# install.packages\{\textquotesingle{}psychmeta\textquotesingle{}\}}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# step 2: calculate proportion of group membership}
\NormalTok{p }\OtherTok{=}\NormalTok{ nA }\SpecialCharTok{/}\NormalTok{ (nA }\SpecialCharTok{+}\NormalTok{ nB)}
\CommentTok{\# p = nB / (nA + nB) \# alternative calculation}

\CommentTok{\# step 3: correct d for group misclassification}
\FunctionTok{correct\_d}\NormalTok{(}\AttributeTok{d =}\NormalTok{ d,}
          \AttributeTok{rGg =} \FunctionTok{sqrt}\NormalTok{(rgg), }\CommentTok{\# square root of rgg = rGg}
          \AttributeTok{correction =} \StringTok{"meas"}\NormalTok{,}
          \AttributeTok{pi =}\NormalTok{ p,}
          \AttributeTok{pa =}\NormalTok{ p,}
          \AttributeTok{n1 =}\NormalTok{ nA}\SpecialCharTok{+}\NormalTok{nB,}
          \AttributeTok{correct\_bias =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
d Values Corrected for Measurement Error:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95   n n_effective
1 0.618    0.118     1.18 100        66.6
\end{verbatim}

The output provides the corrected standardized mean difference
(\texttt{value}), the upper and lower 95\% confidence intervals
(\texttt{CI\_LL\_95} and \texttt{CI\_UL\_95}), the sample size
(\texttt{n}), and the effective sample size (\texttt{n\_effective}).

\hypertarget{correcting-by-hand}{%
\subsubsection*{Correcting by hand}\label{correcting-by-hand}}
\addcontentsline{toc}{subsubsection}{Correcting by hand}

To calculate the corrected standardized mean difference, we can use the
equations in \textbf{?@sec-corrections}.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Calculate point estimate}
\CommentTok{\# step 1: convert d to r}
\NormalTok{r }\OtherTok{=}\NormalTok{ d }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{( }\DecValTok{1}\SpecialCharTok{/}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)) }\SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}

\CommentTok{\# step 2: correct r}
\NormalTok{rho }\OtherTok{=}\NormalTok{ r }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(rgg)}

\CommentTok{\# step 3: convert r to d}
\NormalTok{delta }\OtherTok{=}\NormalTok{ rho }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{( p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rho}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) )}

\DocumentationTok{\#\# Calculate sampling variance}
\CommentTok{\# step 1: compute sampling variance for r}
\NormalTok{v\_d }\OtherTok{=}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB)}\SpecialCharTok{/}\NormalTok{(nA}\SpecialCharTok{*}\NormalTok{nB) }\SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{(nA}\SpecialCharTok{+}\NormalTok{nB))}

\CommentTok{\# step 2: adjust sampling variance for correction}
\NormalTok{v\_delta }\OtherTok{=}\NormalTok{ (v\_d }\SpecialCharTok{*}\NormalTok{ (rho}\SpecialCharTok{/}\NormalTok{r)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{3} \SpecialCharTok{*}\NormalTok{ p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rho}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{)}

\CommentTok{\# print corrected values}
\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected: d = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(delta,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{},  var = \textquotesingle{}}\NormalTok{, }\FunctionTok{round}\NormalTok{(v\_delta,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "corrected: d = 0.605,  var = 0.168"
\end{verbatim}

\hypertarget{artificial-dichotomization}{%
\chapter{Artificial Dichotomization}\label{artificial-dichotomization}}

\hypertarget{introduction-3}{%
\section{Introduction}\label{introduction-3}}

Primary studies sometimes will splitting naturally continuous variables
into two discrete groups to increase interpretability or conduct
specific analyses (e.g., t-tests). However, artificially dichotomizing
variables introduces measurement error variance thus attenuating effect
size estimates Maxwell and Delaney (1993). Clinical disorder diagnoses,
such as generalized anxiety disorder, are examples of dichotomization
where individuals are separated into either having the disorder or not
even though individual differences in anxiety exist as a continuum.

\hypertarget{artificial-dichotomization-induced-measurement-error}{%
\section{Artificial Dichotomization Induced Measurement
Error}\label{artificial-dichotomization-induced-measurement-error}}

Variables that are dichotomized contain measurement error. This can be
demonstrated by the simple fact that dichotomized scores are not
perfectly correlated with continuous scores. To demonstrate this, we can
draw a sample of scores and then split the data into high and low
scorers and then find the correlation coefficient between the two (see
figure below). It becomes apparent that the dichotomized scores leave a
lot of the variation in scores unaccounted for.

\includegraphics{artificial_dichotomization_files/figure-pdf/unnamed-chunk-1-1.pdf}

Even with a perfectly reliable measure, dichotomization will introduce
measurement error variance. We can define naturally continuous scores
(\(\ddagger\)) that have been artificially dichotomized as, \[
 x_\ddagger= 
\begin{cases}
    1,& \text{if } x>C_x\\
    0,& \text{if } x<C_x
\end{cases}
\]

Where \(C_x\) is the cut-score on the standard normal distribution. The
reliability can be defined as the correlation between dichotomized
scores and the underlying continuous scores (\(r_{x_\ddagger x}\)).

\hypertarget{correcting-correlations-for-artificial-dichotomization}{%
\section{Correcting Correlations for Artificial
Dichotomization}\label{correcting-correlations-for-artificial-dichotomization}}

\hypertarget{defining-our-estimand-3}{%
\subsection{Defining our estimand}\label{defining-our-estimand-3}}

Ultimately, we would like to know the correlation coefficient between
two naturally continuous variables. Sticking with our notation for true
scores, our estimand can be defined as the population correlation
between continuous observed scores of the independent (\(x\)) and
dependent variable (\(y\)), \(\rho_{xy}\). Where dichotomized scores can
be defined as,

\[
 x_\ddagger= 
\begin{cases}
    1,& \text{if } x>C_x\\
    0,& \text{if } x<C_x
\end{cases}
\]

\[
 y_\ddagger= 
\begin{cases}
    1,& \text{if } y>C_y\\
    0,& \text{if } y<C_y
\end{cases}
\]

Where \(C_y\) is the cut-score where the split took place. There are two
cases of dichotomization that may occur in a given study: the univariate
case where only one variable (either dependent or independent) is
dichotomized and the bivariate case where both variables are
dichotomized. Both of these situations will be addressed in the next
section.

\hypertarget{sec-corr-artifacts}{%
\subsection{Artifact Correction for
Correlations}\label{sec-corr-artifacts}}

\hypertarget{the-univariate-case}{%
\subsubsection*{The Univariate Case}\label{the-univariate-case}}
\addcontentsline{toc}{subsubsection}{The Univariate Case}

In the simplest case of dichotomization, only one variable is
dichotomized and the other is left continuous. In this case, a Pearson
product-moment correlation is equivalent to the \emph{point-biserial}
correlation coefficient, however for dichotomized data, the
\emph{biserial} correlation is a relatively unbiased estimate of the
pearson correlation on the underlying continuous data (assuming
normality). Therefore in the population, the observed correlation
\(\rho_{x_\ddagger y}\) is biased by some attenuation factor \(a\),

\[
\rho_{x_\ddagger y} = a\rho_{xy}
\]

The first step in estimating the attenuation of the correlation is to
first identify the cut-point, \(C_x\), of standard normal distribution
where the split of the data occurred. This can be calculated by first
obtaining the percent of the of the individuals in the low or high
scoring group:

\[
p_x = \frac{ n_{\text{high}} }{n_{\text{high}} + n_{\text{low}}}
\] or

\[
p_x = \frac{ n_{\text{low}} }{n_{\text{high}} + n_{\text{low}}}.
\]

Then we can use the quantile function (\(\phi^{-1}\); i.e., the inverse
of the cumulative density of the standard normal distribution) to obtain
the cut-point on the standard normal distribution,

\[
C_x = \phi^{-1}(p_x)
\]

Using the cut-point and the proportion of group membership in either the
low or high scoring group (\(p_x\)), the attenuation factor can be
defined as (J. Hunter and Schmidt 1990),

\[
a =\frac{\varphi(C_x)}{\sqrt{p_x(1-p_x)}} 
\]

Where \(\varphi\) is the normal ordinate function (i.e., probability
density function of a standard normal distribution). Since a standard
normal distribution is symmetric, the sign of \(C_x\) does not matter.
In the case of a median split, where the cut-point would be placed at
zero of a standard normal (splitting the distribution in equal halves),
the attenuation factor would simplify to
\(a =\frac{\varphi(0)}{\sqrt{.5(.5)}}\) \(=\frac{2}{\sqrt{2\pi}}\). To
correct the pearson correlation when one of the variables is
dichotomized, we can divide the observed correlation by the attenuation
factor such that, \(r_c = \frac{r_{x_Dy}}{a}\). Therefore the full
correction equation is,

\begin{equation}\protect\hypertarget{eq-dich-r}{}{
r_c = \frac{r_{x_\ddagger y}}{\left[\frac{\varphi(C_x)}{\sqrt{p_x(1-p_x)}} \right]}
}\label{eq-dich-r}\end{equation}

Where the sampling variance of the corrected correlation must also be
adjusted using the compound attenuation factor,

\[
\sigma^2_{\varepsilon_c} =\frac{\sigma^2_{\varepsilon_o}} {a^2} =\frac{\sigma^2_{\varepsilon_o}} {\left[\frac{\varphi(C_x)^2}{p_x(1-p_x)} \right]}
\]

\includegraphics{artificial_dichotomization_files/figure-pdf/unnamed-chunk-2-1.pdf}

\hypertarget{the-bivariate-case}{%
\subsubsection*{The Bivariate Case}\label{the-bivariate-case}}
\addcontentsline{toc}{subsubsection}{The Bivariate Case}

In some cases, both independent and dependent variables are dichotomized
inducing measurement error in both variables. A pearson correlation
calculated on these two dichotomized variables would be equal to the phi
coefficient and we can denote it with our notation for dichotomized
variables, \(r_{x_\ddagger y_\ddagger}\) The data can be structured in a
contingency table:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(x_\ddagger=\text{Low}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(x_\ddagger=\text{High}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(y_\ddagger=\text{Low}\) & \(n_{LL}\) & \(n_{HL}\) \\
\(y_\ddagger=\text{High}\) & \(n_{LH}\) & \(n_{HH}\) \\
\end{longtable}

We can also show how this contingency table would relate to a bivariate
normal distribution

\includegraphics{figure/diagram-dich.pdf}

The proper correction is to calculate the tetrachoric correlation
coefficient. The tetrachoric correlation is specifically meant for
dichotomous scores that represent continuous underlying normal
distribution. To calculate the tetrachoric correlation coefficient, the
contingency table must be available. To estimate the correlation of
continuous variables (\(r_{xy}\)) we can approximate the tetrachoric
correlation with the following formulation,

\begin{equation}\protect\hypertarget{eq-tet}{}{
r_c = \text{cos}\left(\frac{\pi}{1+\sqrt{\frac{n_{HH}n_{LL}}{n_{HL}n_{LH}}}}\right)
}\label{eq-tet}\end{equation}

If the contingency table is not provided, but the odds ratio
(\(OR=\frac{n_{HH}n_{LL}}{n_{HL}n_{LH}}\)) is, then we can calculate
\(r_{xy}\) in terms of the odds ratio,

\[
r_c = \text{cos}\left(\frac{\pi}{1+\sqrt{OR}}\right)
\]

The sampling variance must be calculated from the contingency table as
well. A sampling variance approximation can be obtained from Pearson
(1913), however due to the complexity of the formulation and because it
is simply an approximation, instead I recommend that researchers use a
bootstrap procedure to obtain approximate confidence intervals. To do
this, we must resample the contingency table (\textgreater10,000
iterations), calculating the tetrachoric correlation using
Equation~\ref{eq-tet} upon each iteration. Once you obtain a tetrachoric
correlation from each iteration, the standard deviation of all
correlations can be used as an estimate of the standard error and the
square of the standard error is the sampling variance.

Unfortunately, studies may not report the full contingency table.
Instead they may report summary statistics like a chi-squared value or a
phi coefficient (i.e., the pearson correlation on binary variables). If
the \(\chi^2\)-statistic is reported, we can first convert that to a phi
coefficient by using,

\[
r_{x_\ddagger y_\ddagger} = \sqrt{\frac{\chi^2}{n}}
\]

Where \(n\) is the total sample size. From the phi coefficient, we can
estimate the correlation of the continuous variables with a formula
similar to Equation~\ref{eq-dich-r},

\begin{equation}\protect\hypertarget{eq-dich-r-biv}{}{
r_c = \frac{r_{x_\ddagger y_\ddagger}}{\left[\frac{\varphi(C_x)}{\sqrt{p_x(1-p_x)}} \right]\left[\frac{\varphi(C_y)}{\sqrt{p_y(1-p_y)}} \right]}
}\label{eq-dich-r-biv}\end{equation}

This formula was introduced by J. Hunter and Schmidt (1990) and is a
rough approximation of the correlation between the continuous
independent and dependent variables (\(r_{xy}\)). The corresponding
sampling variance of the corrected correlation coefficient is,

\[
\sigma^2_{\varepsilon_c} =\frac{\sigma^2_{\varepsilon_o}} {a^2} =\frac{\sigma^2_{\varepsilon_o}} {\left[\frac{\varphi(C_x)^2}{p_x(1-p_x)} \right]\left[\frac{\varphi(C_y)^2}{p_y(1-p_y)} \right]}.
\]

\hypertarget{correcting-correlations-for-dichotomization-in-r}{%
\subsection{Correcting Correlations for Dichotomization in
R}\label{correcting-correlations-for-dichotomization-in-r}}

To correct correlations for dichotomization in R, we can use the
\texttt{correct\_r\_dich} in the \texttt{psychmeta} package.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-----------------------------------------------------  psychmeta version 2.6.5  --
\end{verbatim}

\begin{verbatim}

Please report any bugs to github.com/psychmeta/psychmeta/issues
or issues@psychmeta.com
\end{verbatim}

\begin{verbatim}

We work hard to produce these open-source tools for the R community.
Please cite psychmeta when you use it in your research:
  Dahlke, J. A., & Wiernik, B. M. (2019). psychmeta: An R package for
    psychometric meta-analysis. Applied Psychological Measurement, 43(5), 415-416.
    https://doi.org/10.1177/0146621618795933
\end{verbatim}

\begin{verbatim}

---------------------------------------------------------------  Version check  --
\end{verbatim}

\begin{verbatim}
v Yay! Your copy of psychmeta is up to date!
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define parameters}
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5} \CommentTok{\# the observed correlation}
\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{4}  \CommentTok{\# proportion of people in group A or B}
\NormalTok{px }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{6} \CommentTok{\# probability of subjects above or below the split in x}
\NormalTok{py }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{7} \CommentTok{\# probability of subjects above or below the split in y}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ r}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# get cut{-}point}
\FunctionTok{correct\_r\_dich}\NormalTok{(r,}\AttributeTok{px=}\NormalTok{px,}\AttributeTok{py=}\NormalTok{py,}\AttributeTok{n=}\NormalTok{n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  r_corrected var_e_corrected    n_adj
1   0.8356363      0.01587018 6.735923
\end{verbatim}

\[
var_{e}=\frac{(1-r^{2})^{2}}{n-1}
\]

We can also correct the correlation using base R. In order to correct
for dichotomization, we can use the three step process equations from
Section~\ref{sec-corr-smd}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# get cut{-}point}
\NormalTok{Cy }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(py)}
\NormalTok{Cx }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(px)}

\CommentTok{\# calculate attenuation factors}
\NormalTok{a\_x }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(Cx)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(px}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{px)) }\CommentTok{\# attenuation factor for dichotomization in x}
\NormalTok{a\_y }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(Cy)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(py}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{py)) }\CommentTok{\# attenuation factor for dichotomization in y}

\CommentTok{\# correct r}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ r }\SpecialCharTok{/}\NormalTok{ (a\_x}\SpecialCharTok{*}\NormalTok{a\_y)}

\CommentTok{\# adjust standard error for rc}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{r)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}, var = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "r = 0.836, var = 0.016"
\end{verbatim}

\hypertarget{correcting-standardized-mean-differences-for-artificial-dichotomization}{%
\section{Correcting Standardized Mean Differences for Artificial
Dichotomization}\label{correcting-standardized-mean-differences-for-artificial-dichotomization}}

\hypertarget{defining-our-estimand-4}{%
\subsection{Defining our estimand}\label{defining-our-estimand-4}}

We would like to know the group difference between scores of a naturally
continuous variable. Our estimand can thus be defined as the population
standardized mean difference between groups \(A\) and \(B\) on
continuous scores of the dependent variable (\(y\)), \(\delta_{y}\).
Where dichotomized scores can be defined as

\[
 y_{A\ddagger}= 
\begin{cases}
    1,& \text{if } y_A>C_y\\
    0,& \text{if } y_A<C_y
\end{cases}
\]

\[
 y_{B\ddagger}= 
\begin{cases}
    1,& \text{if } y_B>C_y\\
    0,& \text{if } y_B<C_y
\end{cases}
\]

In studies of group differences, since the independent variable is
already dichotomous, the only dichotomization that can occur is on the
dependent variable.

\hypertarget{sec-corr-smd}{%
\subsection{Artifact Correction for Standardized Mean
Differences}\label{sec-corr-smd}}

The simplest way to correct for dichotomization in a standardized mean
difference is to first convert the observed \(d\) value of the
\emph{dichotomized} dependent variable and the \emph{dichotomous}
independent variable (i.e., the grouping variable). When converting to a
correlation coefficient, it's important to note the binary nature of
both variables, leading us to estimate the phi coefficient rather than
the point-biserial correlation that we would be estimating if the
dependent variable was continuous. To calculate the phi coefficient from
a \(d\) value we can use the proportion of group membership in group
\(A\) or group \(B\) (\(p\); it does not matter which one is chosen, as
long as it is consistent for every instance of \(p\)),

\[
r_{\text{phi}} = \frac{d_{y_\ddagger}}{\sqrt{d_{y_\ddagger}^2+\frac{1}{p(1-p)}}}
\] We can then correct the phi coefficient similar to how we correct the
point-biserial correlation in Section~\ref{sec-corr-artifacts},

\[
r_c = \frac{r_{\text{phi}}}{\left[\frac{\varphi(C_y)}{\sqrt{p_y (1-p_y)}}\right]}.
\] Then we can convert the corrected correlation back into a
standardized mean difference, \[
d_c = \frac{r_c}{\sqrt{p\left(1-p\right)\left(1-r_c^2\right)}}
\] Where \(d_c\) is our corrected correlation. The sampling variance
must also be corrected using the same three step procedure. For
simplicity, we will consolidate this into one formula,

\[
\sigma^2_{\varepsilon_c} = \frac {\sigma^2_{\varepsilon_o} \left(\frac{r_c}{r_\text{phi}}\right)^2} {\left(1+d_{y_\ddagger}^2p[1-p]\right)^3(1-r_c^2)^3}
\]

\hypertarget{correcting-d-values-for-dichotomization-in-r}{%
\subsection{\texorpdfstring{Correcting \emph{d} values for
Dichotomization in
R}{Correcting d values for Dichotomization in R}}\label{correcting-d-values-for-dichotomization-in-r}}

To correct standardized mean differences for dichotomization in R. At
the moment the \texttt{psychmeta} package does not have a
\texttt{correct\_d\_dich} function. In order to correct for
dichotomization, we can use the three step process equations from
Section~\ref{sec-corr-smd}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define parameters}
\NormalTok{d }\OtherTok{=}\NormalTok{ .}\DecValTok{5} \CommentTok{\# observed standardized mean difference}
\NormalTok{nA }\OtherTok{=} \DecValTok{40}  \CommentTok{\# sample size for group A}
\NormalTok{nB }\OtherTok{=} \DecValTok{60}  \CommentTok{\# sample size for group A}
\NormalTok{n }\OtherTok{=}\NormalTok{ nA}\SpecialCharTok{+}\NormalTok{nB }\CommentTok{\# calculate total sample size}
\NormalTok{p }\OtherTok{=}\NormalTok{ nA }\SpecialCharTok{/}\NormalTok{ n }\CommentTok{\# calculate proportion of individuals in group A}
\NormalTok{py }\OtherTok{=}\NormalTok{ .}\DecValTok{7} \CommentTok{\# probability of subjects above or below the split}
\NormalTok{var\_e\_o }\OtherTok{=}\NormalTok{ ((n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{{-}} \DecValTok{3}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ (n }\SpecialCharTok{/}\NormalTok{ (nA }\SpecialCharTok{*}\NormalTok{ nB) }\SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ n))}

\CommentTok{\# get cut{-}point}
\NormalTok{Cy }\OtherTok{=} \FunctionTok{qnorm}\NormalTok{(py)}

\CommentTok{\# calculate attenuation factor of y}
\NormalTok{a\_y }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(Cy)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(py}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{py)) }\CommentTok{\# attenuation factor for dichotomization in y}

\CommentTok{\# convert d to r}
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ d }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(d}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ (p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p))))}

\CommentTok{\# correct r}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ r }\SpecialCharTok{/}\NormalTok{ a\_y}

\CommentTok{\# convert r to d}
\NormalTok{dc }\OtherTok{\textless{}{-}}\NormalTok{ rc }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rc}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ (var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{r)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{1}\SpecialCharTok{+}\NormalTok{d}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{*}\NormalTok{p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p))}\SpecialCharTok{\^{}}\DecValTok{3} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rc}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dc,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}, var = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{) ))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "r = 0.674, var = 0.087"
\end{verbatim}

\hypertarget{scale-coarseness}{%
\chapter{Scale Coarseness}\label{scale-coarseness}}

\hypertarget{introduction-4}{%
\section{Introduction}\label{introduction-4}}

Scale coarseness describes a situation where a variable that is
naturally continuous (e.g., happiness) is binned into discrete values
(e.g., happiness measured on a scale of 1-10). This situation is quite
common in the social and psychological sciences where Likert items or
dichotomous yes/no responses are aggregated to form a coarse total score
for a naturally continuous construct. When coarseness is present,
measurement error is introduced into the observed scores and those
scores lose information. Unlike dichotomization, coarseness is an
artifact that occurs due to the design of the study rather than during
the analysis phase (Aguinis, Pierce, and Culpepper 2009). Particularly,
dichotomization occurs after scores are obtained (e.g., splitting a
group into high scorers and low scorers), whereas coarseness occurs as
an artifact of the measurement device itself. The primary issue with
coarseness is that it limits the set of possible values a score can be
which introduces error when the variable is naturally continuous. Lets
visualize how this occurs by sampling 500 data points from a normal
distribution, and binning the scores into 5 equal-interval scale points.
Now the figure below shows the relationship between the coarse scores
and the true underlying continuous scores.

\includegraphics{scale_coarseness_files/figure-pdf/unnamed-chunk-1-1.pdf}

Notice that the correlation between coarse and continuous scores is not
perfect, indicating that the coarse scores do not perfectly capture the
underlying continuous scores.

\hypertarget{correcting-for-coarseness-in-correlations}{%
\section{Correcting for Coarseness in
Correlations}\label{correcting-for-coarseness-in-correlations}}

\hypertarget{defining-our-estimand-5}{%
\subsection{Defining our Estimand}\label{defining-our-estimand-5}}

Our quantity of interest is the population correlation, \(\rho\),
between continuous independent variable, \(x\), and continuous dependent
variable, \(y\). We can model the relationship between the observed
sample correlation on coarse scores and the true population correlation,

\[
r_o = a\rho+\varepsilon
\]

Where \(a\) is our coarseness biasing factor and \(\varepsilon\) is our
sampling error term. Ultimately, we can obtain an unbiased estimate of
the true (continuous) population correlation by correcting the observed
standardized mean difference as follows,

\[
r_c = \frac{r_o}{a}
\]

\hypertarget{sec-coarse-cor}{%
\subsection{Artifact Correction for Coarseness}\label{sec-coarse-cor}}

To correct the correlation between coarse scores for \(x\) and \(y\), we
need to know the correlation between coarse scores and their underlying
continuous scores. These correlations between coarse scores and their
underlying continuous scores do not have a specific closed form equation
as of now (Aguinis, Pierce, and Culpepper 2009). To find this we need to
make a couple of assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  The shape of the underlying distribution (i.e., normal or uniform).
\item
  The intervals between scale-points are equal.
\end{enumerate}

Peters and Voorhis (1940) constructed a table based on these assumptions
that is also reported more recently by Aguinis, Pierce, and Culpepper
(2009). The table below shows the correction factor for a given number
of scale points and underlying distribution shape. The correction factor
is equal to the square of the correlation between coarse scores and the
underlying continuous normal (or uniform) distribution. For the normal
distribution correction, its been shown that even in cases of extreme
skew, these correction factors perform well Wylie (1976).

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1972}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3944}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4085}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Scale Points
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Correction Factor (normal)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Correction Factor (uniform)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2 & .816 & .866 \\
3 & .859 & .943 \\
4 & .916 & .968 \\
5 & .943 & .980 \\
6 & .960 & .986 \\
7 & .970 & .990 \\
8 & .977 & .992 \\
9 & .982 & .994 \\
10 & .985 & .995 \\
11 & .988 & .996 \\
12 & .990 & .997 \\
13 & .991 & .997 \\
14 & .992 & .997 \\
15 & .994 & .998 \\
\end{longtable}

These correction factors can be applied similarly to the correction
formula for reliability (see chapter 5),

\[
r_c = \frac{r_o}{a_x a_y}
\] Where \(a_x\) and \(a_y\) are the appropriate correction factors from
the table for \(x\) and \(y\). We must also adjust the sampling variance
as well,

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o}}{a_x a_y}
\]

\hypertarget{correcting-correlations-in-r-2}{%
\subsection{Correcting Correlations in
R}\label{correcting-correlations-in-r-2}}

To correct scale coarseness in R, we can use the table in
Section~\ref{sec-coarse-cor}. Lets start by simulating a coarse data (5
scale-points for x and 7 scale-points for y) set of 500 individuals with
a true population correlation of \(\rho = .50\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{343}\NormalTok{)}

\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}MASS\textquotesingle{})}
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# simulate data}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{500}
\NormalTok{rho }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{50}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n,}
                \AttributeTok{mu =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                \AttributeTok{Sigma =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,rho),}\AttributeTok{y=}\FunctionTok{c}\NormalTok{(rho,}\DecValTok{1}\NormalTok{)),}
                \AttributeTok{empirical =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# obtain simulated continuous data}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{1}\NormalTok{]}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{2}\NormalTok{]}

\CommentTok{\# get coarse data}
\NormalTok{x\_coarse }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{cut}\NormalTok{(x,}\AttributeTok{breaks=}\DecValTok{5}\NormalTok{)) }
\NormalTok{y\_coarse }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{cut}\NormalTok{(y,}\AttributeTok{breaks=}\DecValTok{7}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

Now we can calculate the observed standardized mean difference and apply
the correction factor.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate observed d value}
\NormalTok{ro }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x\_coarse,y\_coarse)}

\CommentTok{\# correct observed do using table}
\NormalTok{ax }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{943}
\NormalTok{ay }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{970}

\CommentTok{\# correct observed d value}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ ro}\SpecialCharTok{/}\NormalTok{(ax}\SpecialCharTok{*}\NormalTok{ay)}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Observed: ro = \textquotesingle{}}\NormalTok{, }\FunctionTok{round}\NormalTok{(ro,}\DecValTok{3}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Corrected: rc = \textquotesingle{}}\NormalTok{, }\FunctionTok{round}\NormalTok{(rc,}\DecValTok{3}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                  
[1,] "Observed: ro = 0.457"
[2,] "Corrected: rc = 0.5" 
\end{verbatim}

\hypertarget{correcting-for-coarseness-in-d-values}{%
\section{\texorpdfstring{Correcting for Coarseness in \emph{d}
values}{Correcting for Coarseness in d values}}\label{correcting-for-coarseness-in-d-values}}

\hypertarget{defining-our-estimand-6}{%
\subsection{Defining our Estimand}\label{defining-our-estimand-6}}

Our quantity of interest is the population standardized mean difference,
\(\delta\), between groups \(A\) and \(B\) on variable, \(y\). We can
model the relationship between the observed sample standardized mean
difference on coarse scores and the true population standardized mean
difference,

\[
d_o = a\delta+\varepsilon
\]

Where \(a\) is our coarseness biasing factor and \(\varepsilon\) is our
sampling error term. Ultimately, we can obtain an unbiased estimate of
the true (continuous) population standardized mean difference by
correcting the observed standardized mean difference as follows,

\[
d_c = \frac{d_o}{a}
\]

\hypertarget{artifact-correction-for-coarseness}{%
\subsection{Artifact Correction for
Coarseness}\label{artifact-correction-for-coarseness}}

To correct a standardized mean difference for coarseness in the outcome
variable, \(y\), we can use the correction factors from the table in
Section~\ref{sec-coarse-cor},

\[
d_c = \frac{d_o}{a_y}
\] Where \(a_x\) and \(a_y\) are the appropriate correction factors from
the table for \(x\) and \(y\). We must also adjust the sampling variance
as well,

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o}}{a_y}
\]

\hypertarget{correcting-d-values-in-r}{%
\subsection{\texorpdfstring{Correcting \emph{d} values in
R}{Correcting d values in R}}\label{correcting-d-values-in-r}}

To correct scale coarseness in R, we can use the table in
Section~\ref{sec-coarse-cor}. Lets start by simulating a coarse data (5
scale-points) set of 1000 individuals with a true population
standardized mean difference of \(\delta = .50\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{343}\NormalTok{)}

\CommentTok{\# simulate data}
\NormalTok{nA }\OtherTok{\textless{}{-}}\NormalTok{ nB }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{yA }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(nA,.}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{yB }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(nB,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)}

\CommentTok{\# concatenate data}
\NormalTok{group }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,nA),}\FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,nB))}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(yA,yB)}

\CommentTok{\# get coarse data}
\NormalTok{y\_coarse }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{cut}\NormalTok{(y,}\AttributeTok{breaks=}\DecValTok{5}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

Now we can calculate the observed standardized mean difference and apply
the correction factor.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate observed d value}
\NormalTok{do }\OtherTok{\textless{}{-}}\NormalTok{ ( }\FunctionTok{mean}\NormalTok{(y\_coarse[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(y\_coarse[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]) ) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{((}\FunctionTok{var}\NormalTok{(y\_coarse) }\SpecialCharTok{+} \FunctionTok{var}\NormalTok{(y\_coarse))}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}

\CommentTok{\# correct observed do using table}
\NormalTok{ay }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{943}

\CommentTok{\# correct observed d value}
\NormalTok{dc }\OtherTok{\textless{}{-}}\NormalTok{ do}\SpecialCharTok{/}\NormalTok{ay}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Observed: do = \textquotesingle{}}\NormalTok{, }\FunctionTok{round}\NormalTok{(do,}\DecValTok{3}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Corrected: dc = \textquotesingle{}}\NormalTok{, }\FunctionTok{round}\NormalTok{(dc,}\DecValTok{3}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                   
[1,] "Observed: do = 0.499" 
[2,] "Corrected: dc = 0.529"
\end{verbatim}

\hypertarget{sec-direct_range_restriction}{%
\chapter{Direct Selection}\label{sec-direct_range_restriction}}

\hypertarget{introduction-5}{%
\section{Introduction}\label{introduction-5}}

Direct selection occurs when subjects are explicitly selected based on
some eligibility criterion on the variables of interest (rather than a
third variable). Range restriction is a form of selection bias that
describes a situation where there is less variation in our sample then
there is in the population. Whereas range enhancement indicates that
there is \emph{more} variation in a sample then there is in the
population. Direct range restriction/enhancement (as opposed to indirect
range restriction) is when selection into the sample is based on the
variable(s) of interest (i.e., the independent and/or dependent
variable). This selection into the sample will either restrict or
enhance the variation in the variable, thus causing

\hypertarget{an-applied-example-of-direct-range-restriction}{%
\section{An Applied Example of Direct Range
Restriction}\label{an-applied-example-of-direct-range-restriction}}

Imagine a tech company that wants to assess the correlation between
years of experience and programming proficiency for their software
engineers. They have two primary divisions: Division A and Division B.
Division A primarily hires entry-level software engineers, with less
than 3 years of experience. Division B, on the other hand, hires
experienced software engineers with more than 3 years of experience. The
company decides to conduct a study to assess the correlation between
years of experience and programming proficiency. However, they only
collect data from Division A due to logistical reasons, assuming that
the relationship found there would be represent. the entire company. In
this scenario, direct range restriction occurs because the sample used
for the study (Division A) represents a narrow range of years of
experience (0-3 years) compared to the broader range present in the
entire company (0+ years). Consequently, the standard deviation will be
smaller in the sample then it would if we had sampled from the entire
company. As we will see in later sections of this chapter, the observed
correlation between years of experience and programming proficiency
would be attenuated, underestimating the true correlation.

\hypertarget{indexing-range-restriction-with-the-u-ratio}{%
\section{\texorpdfstring{Indexing Range Restriction with the
\emph{u}-ratio}{Indexing Range Restriction with the u-ratio}}\label{indexing-range-restriction-with-the-u-ratio}}

The distribution of scores in the unrestricted pool of individuals will
exhibit a greater (or lesser) degree of variability compared to the
sample that has been selected into the study. Therefore the standard
deviation of scores in the unrestricted population (\(\sigma_x\)) will
differ from that of the selected (restricted/enhanced) sample
(\(\sigma_{x_{S}}\)). To index the difference between the two standard
deviations, we can calculate the \(u\)-ratio Wiernik and Dahlke (2020).
The \(u\)-ratio is the ratio between the standard deviations of the
selected sample to the unrestricted sample such that,

\[
u_x = \frac{\sigma_{x_S}}{\sigma_x}
\]

The \(u\)-ratio in cases of range restriction will exist in the interval
(0--1). Conversely, when the \(u\)-ratio is greater than 1 it is
indicative of range enhancement. The unrestricted standard deviation is
often quite difficult to acquire since we do not usually have access to
the unrestricted group. However, the unrestricted standard deviation can
be estimated from some reference study that has been conducted on the
unrestricted group. This often comes in the form of standardization
samples or norm samples (obtained from test manuals) if the unrestricted
group is the general population. For example, the distribution
full-scale IQ scores derived from the Wechsler Adult Intelligence Test
has a standard deviation of 15 in the US population (Wechsler 2008). We
can use this estimate as the standard deviation for the unrestricted
population. Lets say we select a sample from members of Mensa, a high IQ
society, who are specifically selected on the basis high IQ scores. If
the standard deviation of Mensa members is 5, then the \(u\)-ratio would
be,

\[
u =  \frac{\sigma_{x_S}}{\sigma_x} = \frac{5}{15}= .33
\]

However it is not always the case that an estimate of the unrestricted
standard deviation is readily available. Therefore if the reliability
coefficient from the unrestricted and selected sample can be used to
estimate the \(u\)-ratio,

\[
u_x = \sqrt{\frac{1-r_{xx'}}{1-r_{xx'_S}}}
\]

Where \(r_{xx'_S}\) and \(r_{xx'}\) are the reliability estimates within
the selected and unrestricted groups respectively.

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-1-1.pdf}

\hypertarget{correcting-correlations-for-direct-range-restriction}{%
\section{Correcting Correlations for Direct Range
Restriction}\label{correcting-correlations-for-direct-range-restriction}}

\hypertarget{defining-our-estimand-7}{%
\subsection{Defining our Estimand}\label{defining-our-estimand-7}}

For our study we want to estimate the population correlation of the
unrestricted scores of the independent (\(x_\mathcal{U}\)) and dependent
variable (\(y_S\)). We can denote this correlation as \(\rho_{xy_S}\).
The restricted population correlation can be denoted as \(\rho_{xy_S}\).
Within a study that suffers from range restriction, the study
correlation (\(r_{xy_{\mathcal{R}}}\)) will be biased relative to our
estimand, \(\rho_{xy_{\mathcal{U}}}\). This bias can be denoted by \(a\)
such that,

\[
r_{xy} = a \rho_{xy_S} + \varepsilon  
\]

Therefore an unbiased estimate of the unrestricted population
correlation would be

\[
r_c = \frac{ r_{xy_S} }{ a}.
\]

\hypertarget{artifact-correction-for-correlations}{%
\subsection{Artifact Correction for
Correlations}\label{artifact-correction-for-correlations}}

\hypertarget{the-univariate-case-1}{%
\subsubsection*{The Univariate Case}\label{the-univariate-case-1}}
\addcontentsline{toc}{subsubsection}{The Univariate Case}

Range restriction (or enhancement) in either the independent or
dependent variable will induce bias into the correlation coefficient.
Let us consider a case where just the independent variable is restricted
(or enhanced) such that \(u_x\neq 1\), but the dependent variable is not
restricted (directly). It is important to note, that if there is direct
selection one of the two variables, then there will be indirect
selection in the other variable if the two are correlated. This would
suggest that if \(u_x\neq 1\) and \(\rho_{xy}\neq 0\) then
\(u_y\neq 1\). Lets visualize the correlation between independent
(\(x\)) and dependent (\(y\)) variables under this range restriction by
only selecting individuals above some cut off. The scores of individuals
that have been selected will show less variance than the entire pool of
individuals. Specifically, the scenario below shows a \(u\)-ratio of
about 0.69 in the independent variable. We see in the figure that the
correlation in the restricted scores (\(\rho_{xy_S}\)) is attenuated
relative to the unrestricted (true) correlation (\(\rho_{xy}\)).

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-2-1.pdf}

We can also visualize what happens to the correlation when the range is
enhanced. Enhancement can be accomplished by selecting individuals at
the ends of the distribution (Taylor and Griess 1976). In the
visualization below, we see an opposite effect on the correlation, that
is, an over-estimate of the unrestricted correlation rather than an
attenuation like we see under range restriction. The scenario below has
a \(u\)-ratio of about 1.39 in the independent variable.

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-3-1.pdf}

It starts to become apparent that if \(u_x>1\) (i.e.,
\(\sigma_x>\sigma_\mathcal{x_S}\)) the observed correlation
over-estimates the true, unrestricted correlation and under-estimates
the unrestricted correlation when \(u_x<1\) (i.e.,
\(\sigma_x<\sigma_\mathcal{x_S}\), Sackett and Yang 2000).

A bias correction formula for univariate direct range restriction was
first developed by Pearson (1903) and provided more recently by J. E.
Hunter and Schmidt (1990). To correct for the systematic bias in
correlations, we can use the \(u\)-ratio of the independent variable
such that,

\begin{equation}\protect\hypertarget{eq-univariate}{}{
r_c = \frac{r_{xy_S}}{u_x\left(1+r_{xy_S}^2\left[\frac{1}{u^2_x}-1\right]\right)}
}\label{eq-univariate}\end{equation}

Where the sampling variance of the corrected correlation is

\begin{equation}\protect\hypertarget{eq-univariate-se}{}{
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{xy_S}}\right)^2.
}\label{eq-univariate-se}\end{equation}

\hypertarget{the-bivariate-case-1}{%
\subsubsection{The Bivariate Case}\label{the-bivariate-case-1}}

Bivariate direct range restriction/enhancement occurs when the
variability in both independent and dependent variables within the
selected sample is less than or greater than the variability in the
unrestricted population. Let us consider a case where just the
independent variable is restricted (or enhanced) such that \(u_x\neq 1\)
and \(u_y \neq 1\). Like we showed for the univariate case, let's
visualize the correlation between independent (\(x\)) and dependent
(\(y\)) variables under range restriction by only selecting individuals
above some cut off point for both \(x\) and \(y\). The scores of
individuals that have been selected will show less variance than the
entire pool of individuals. Specifically, the scenario below shows a
\(u\)-ratio of about 0.69 in the independent variable and dependent
variables. We see in the figure that the correlation in the restricted
sample (\(\rho_{xy_S}\)) is attenuated relative to the unrestricted
(true) correlation (\(\rho_{xy}\)).

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-4-1.pdf}

Likewise let's visualize what happens to the correlation when the range
is enhanced. Enhancement in both variables can be accomplished by
selecting individuals at the ends of the distribution of \(x\) and
\(y\). In the visualization below, we observe an over-estimation of
observed correlation relative to the unrestricted correlation. The
scenario below has a \(u\)-ratio of about 1.32 in both the independent
variable and dependent variable.

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-5-1.pdf}

A bias correction formula for bivariate range restriction is much more
complicated than the univariate formulation. This is due to the fact
that there is inter-dependence between the correlation, the \(u\)-ratio
of \(x\), and the \(u\)-ratio of \(y\). For instance, if \(x\) and \(y\)
are positively correlated and if there is direct range restriction in
\(x\) this will also restrict the variability in y even if there is no
range restriction in \(y\). To break down the correction formula into
simpler parts, let us first define a factor we will denote with
\(\psi\),

\begin{equation}\protect\hypertarget{eq-biv-1}{}{
\psi = \frac{u_x u_y\left(r_{xy_S}^2-1\right)}{2r_{xy_S}}
}\label{eq-biv-1}\end{equation} This factor contains all the parameters
needed to correct the correlation coefficient under direct selection
(\(r_{xy_S}\)). Then we can plug it into the formula

\begin{equation}\protect\hypertarget{eq-biv-2}{}{
r_c = \psi + \text{sign}\left[r_{xy_S}\right]\sqrt{\psi^2+1}
}\label{eq-biv-2}\end{equation}

Where the sampling variance of the corrected correlation is,

\begin{equation}\protect\hypertarget{eq-biv-se}{}{
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{xy_S}}\right)^2.
}\label{eq-biv-se}\end{equation}

\hypertarget{correcting-correlations-in-r-3}{%
\subsection{Correcting Correlations in
R}\label{correcting-correlations-in-r-3}}

To correct correlations for range restriction we can start by simulating
data from the the \texttt{mvrnorm} function in the \texttt{MASS}
package. Lets first simulate 200 data points.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}MASS\textquotesingle{})}
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{343}\NormalTok{)}

\CommentTok{\# define parameters }
\NormalTok{rho }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{50}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{200}

\CommentTok{\# sample data from a bivariate normal distribution}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n,}
                \AttributeTok{mu =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                \AttributeTok{Sigma =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,rho),}
                                  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(rho,}\DecValTok{1}\NormalTok{)),}
                \AttributeTok{empirical =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# obtain unrestricted scores}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{1}\NormalTok{]}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{univariate-direct-range-restriction}{%
\subsubsection*{Univariate Direct Range
Restriction}\label{univariate-direct-range-restriction}}
\addcontentsline{toc}{subsubsection}{Univariate Direct Range
Restriction}

We can start with univariate direct range restriction by selecting only
on the independent variable. We will select only the values above the
mean.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# obtain scores when x \textgreater{} Mean(x)}
\NormalTok{selected }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(x)}
\NormalTok{xS }\OtherTok{\textless{}{-}}\NormalTok{ x[selected]}
\NormalTok{yS }\OtherTok{\textless{}{-}}\NormalTok{ y[selected]}

\CommentTok{\# calculate correlation between unrestricted and restricted scores}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x,y) }\CommentTok{\# unrestricted}
\NormalTok{rxyS }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(xS,yS) }\CommentTok{\# restricted}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}unrestricted: rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}restricted: rxyS = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxyS,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                     
[1,] "unrestricted: rxy = 0.5"
[2,] "restricted: rxyS = 0.32"
\end{verbatim}

As expected, we observe an attenuation of the correlation under range
restriction. Now lets calculate the \(u\)-ratios for both variables.
Remember that even though we only selected on \(x\), we should expect
the variability in \(y\) in the restricted sample to also be smaller
than the unrestricted sample when \(x\) and \(y\) are correlated.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate u{-}ratios}
\NormalTok{ux }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(xS)}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(x)}
\NormalTok{uy }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(yS)}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(y)}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}ux = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(ux,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}uy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(uy,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]       
[1,] "ux = 0.59"
[2,] "uy = 0.86"
\end{verbatim}

As anticipated, not only is \(u_x\) below 1 indicating range
restriction, but also \(u_y\) is slightly below 1 since \(x\) and \(y\)
covary. Now we can apply the correction for univariate direct range
restriction by hand from Equation~\ref{eq-univariate} and
Equation~\ref{eq-univariate}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# correct the restricted correlation}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ rxyS }\SpecialCharTok{/}\NormalTok{ (ux }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ rxyS}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{ux}\SpecialCharTok{\^{}}\DecValTok{2{-}1}\NormalTok{)) )}

\CommentTok{\# acquire sample size from }
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(xS)}

\CommentTok{\# calculate the observed correlation sampling variance}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{rxyS)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected cor: r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected var: var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                         
[1,] "corrected cor: r = 0.49"    
[2,] "corrected var: var_e = 0.02"
\end{verbatim}

The correction formula produced a very close estimate of the true
population correlation (\(r_c = .49\) vs \(\rho_{xy}=.50\)). Lets also
correct the correlation using the \texttt{correct\_r} function in the
psychmeta package, \texttt{psychmeta} (Dahlke and Wiernik 2019).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# correct the restricted correlation for univariate direct range restriction}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxyS,}
          \AttributeTok{correction =} \StringTok{\textquotesingle{}uvdrr\_x\textquotesingle{}}\NormalTok{,  }\CommentTok{\# uvdrr\_x = univariate direct range restriction in x}
          \AttributeTok{ux =}\NormalTok{ ux,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error and Univariate Direct Range Restriction:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95  n n_effective
1 0.492    0.209    0.685 97        40.8
\end{verbatim}

We can see that the correction made by the \texttt{correct\_r} function
provides identical results to the one done by hand.

\hypertarget{bivariate-direct-range-restriction}{%
\subsubsection{Bivariate Direct Range
Restriction}\label{bivariate-direct-range-restriction}}

For bivariate direct range restriction we can select values above the
mean in both independent and dependent variables.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# obtain scores when x \textgreater{} Mean(x) and y \textgreater{} Mean(y)}
\NormalTok{selected }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(x) }\SpecialCharTok{\&}\NormalTok{ y }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(y)}
\NormalTok{xS }\OtherTok{\textless{}{-}}\NormalTok{ x[selected]}
\NormalTok{yS }\OtherTok{\textless{}{-}}\NormalTok{ y[selected]}

\CommentTok{\# calculate correlation between unrestricted and restricted scores}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x,y) }\CommentTok{\# unrestricted}
\NormalTok{rxyS }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(xS,yS) }\CommentTok{\# restricted}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}unresticted: rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}restricted: rxyS = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxyS,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                     
[1,] "unresticted: rxy = 0.5" 
[2,] "restricted: rxyS = 0.29"
\end{verbatim}

Notice that there is even more attenuation in the selected correlation
coefficient than there was in the univariate case. Now we can correct
for bivariate range restriction by hand using Equation~\ref{eq-biv-1},
Equation~\ref{eq-biv-2}, Equation~\ref{eq-biv-se}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate the factor, psi}
\NormalTok{psi }\OtherTok{\textless{}{-}}\NormalTok{ ux}\SpecialCharTok{*}\NormalTok{uy}\SpecialCharTok{*}\NormalTok{(rxyS}\SpecialCharTok{\^{}}\DecValTok{2{-}1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{rxyS)}

\CommentTok{\# calculate the corrected correlation using psi}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ psi }\SpecialCharTok{+} \FunctionTok{sign}\NormalTok{(rxyS)}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(psi}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \DecValTok{1}\NormalTok{)}

\CommentTok{\# acquire sample size from }
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(xS)}

\CommentTok{\# calculate the observed correlation sampling variance}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{rxyS)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected cor: r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected var: var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                          
[1,] "corrected cor: r = 0.48"     
[2,] "corrected var: var_e = 0.036"
\end{verbatim}

Again, we see that the corrected correlation closely resembles the
unrestricted correlation (\(r_c=.48\) vs \(\rho_{xy}=.50\)). lets

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# correct the restricted correlation for univariate direct range restriction}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxyS,}
          \AttributeTok{correction =} \StringTok{\textquotesingle{}bvdrr\textquotesingle{}}\NormalTok{,  }\CommentTok{\# bvdrr = bivariate direct range restriction}
          \AttributeTok{ux =}\NormalTok{ ux,}
          \AttributeTok{uy =}\NormalTok{ uy,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error and Bivariate Direct Range Restriction:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95  n n_effective
1  0.48   0.0943    0.689 64        17.3
\end{verbatim}

We can see that the correction exactly reflects the correction done by
hand.

\hypertarget{references}{%
\section{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-aguinis2009}{}}%
Aguinis, Herman, Charles A Pierce, and Steven A Culpepper. 2009.
{``Scale Coarseness as a Methodological Artifact,''} September.

\leavevmode\vadjust pre{\hypertarget{ref-borenstein2010}{}}%
Borenstein, Michael, Larry V. Hedges, Julian P. T. Higgins, and Hannah
R. Rothstein. 2010. {``A Basic Introduction to Fixed-Effect and
Random-Effects Models for Meta-Analysis.''} \emph{Research Synthesis
Methods} 1 (2): 97--111. \url{https://doi.org/10.1002/jrsm.12}.

\leavevmode\vadjust pre{\hypertarget{ref-borsboom2002}{}}%
Borsboom, Denny, and Gideon J Mellenbergh. 2002. {``True Scores, Latent
Variables, and Constructs: A Comment on Schmidt and Hunter.''}

\leavevmode\vadjust pre{\hypertarget{ref-borsboom2004}{}}%
Borsboom, Denny, Gideon J. Mellenbergh, and Jaap Van Heerden. 2004.
{``The Concept of Validity.''} \emph{Psychological Review} 111 (4):
1061--71. \url{https://doi.org/10.1037/0033-295X.111.4.1061}.

\leavevmode\vadjust pre{\hypertarget{ref-brannick2019}{}}%
Brannick, Michael T., Sean M. Potter, Bryan Benitez, and Scott B.
Morris. 2019. {``Bias and Precision of Alternate Estimators in
Meta-Analysis: Benefits of Blending Schmidt-Hunter and Hedges
Approaches.''} \emph{Organizational Research Methods} 22 (2): 490--514.
\url{https://doi.org/10.1177/1094428117741966}.

\leavevmode\vadjust pre{\hypertarget{ref-bravais1844}{}}%
Bravais, A. 1844. \emph{Analyse mathématique sur les probabilités des
erreurs de situation d'un point}. Impr. Royale.

\leavevmode\vadjust pre{\hypertarget{ref-callender1980}{}}%
Callender, John C., and H. G. Osburn. 1980. {``Development and Test of a
New Model for Validity Generalization.''} \emph{Journal of Applied
Psychology} 65 (5): 543--58.
\url{https://doi.org/10.1037/0021-9010.65.5.543}.

\leavevmode\vadjust pre{\hypertarget{ref-cohen1988}{}}%
Cohen, Jacob. 1988. \emph{Statistical Power Analysis for the Behavioral
Sciences}. Academic Press.

\leavevmode\vadjust pre{\hypertarget{ref-cohen1977}{}}%
---------. 2013. \emph{Statistical Power Analysis for the Behavioral
Sciences}. Academic Press.

\leavevmode\vadjust pre{\hypertarget{ref-cronbach1955}{}}%
Cronbach, Lee J., and Paul E. Meehl. 1955. {``Construct Validity in
Psychological Tests.''} \emph{Psychological Bulletin} 52 (4): 281--302.
\url{https://doi.org/10.1037/h0040957}.

\leavevmode\vadjust pre{\hypertarget{ref-dahlke2019}{}}%
Dahlke, Jeffrey A., and Brenton M. Wiernik. 2019. {``Psychmeta: An R
Package for Psychometric Meta-Analysis.''} \emph{Applied Psychological
Measurement} 43 (5): 415--16.
\url{https://doi.org/10.1177/0146621618795933}.

\leavevmode\vadjust pre{\hypertarget{ref-dahlke2020}{}}%
---------. 2020. {``Not Restricted to Selection Research: Accounting for
Indirect Range Restriction in Organizational Research.''}
\emph{Organizational Research Methods} 23 (4): 717--49.
\url{https://doi.org/10.1177/1094428119859398}.

\leavevmode\vadjust pre{\hypertarget{ref-dersimonian2007}{}}%
DerSimonian, Rebecca, and Raghu N. Kacker. 2007. {``Random-Effects Model
for Meta-Analysis of Clinical Trials: An Update.''} \emph{NIST} 28
(January): 105--14.
\url{https://www.nist.gov/publications/random-effects-model-meta-analysis-clinical-trials-update}.

\leavevmode\vadjust pre{\hypertarget{ref-galton1907}{}}%
Galton, Francis. 1907. {``Vox Populi.''} \emph{Nature} 75 (1949):
450--51. \url{https://doi.org/10.1038/075450a0}.

\leavevmode\vadjust pre{\hypertarget{ref-haertel2006}{}}%
Haertel, Edward H. 2006. {``3. Reliability.''} In, 4th ed.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1981}{}}%
Hedges, Larry V. 1981. {``Distribution Theory for Glass's Estimator of
Effect Size and Related Estimators.''} \emph{Journal of Educational
Statistics} 6 (2): 107--28.
\url{https://doi.org/10.3102/10769986006002107}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1989}{}}%
---------. 1989. {``An Unbiased Correction for Sampling Error in
Validity Generalization Studies.''} \emph{Journal of Applied Psychology}
74 (3): 469--77. \url{https://doi.org/10.1037/0021-9010.74.3.469}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges2014}{}}%
Hedges, Larry V., and Ingram Olkin. 2014. \emph{Statistical Methods for
Meta-Analysis}. Academic press.
\url{https://books.google.com/books?hl=en\&lr=\&id=7GviBQAAQBAJ\&oi=fnd\&pg=PP1\&dq=info:e6P1zfh2T6QJ:scholar.google.com\&ots=Dx-YqN6_9B\&sig=-39HgbYdWPp_BwSTzA9cRODs2Q0}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1998}{}}%
Hedges, Larry V., and Jack L. Vevea. 1998. {``Fixed- and Random-Effects
Models in Meta-Analysis.''} \emph{Psychological Methods} 3 (4):
486--504. \url{https://doi.org/10.1037/1082-989X.3.4.486}.

\leavevmode\vadjust pre{\hypertarget{ref-hunter1990a}{}}%
Hunter, John E., and Frank L. Schmidt. 1990. \emph{Methods of
meta-analysis: correcting error and bias in research findings}. Newbury
Park: Sage Publications.

\leavevmode\vadjust pre{\hypertarget{ref-hunter1990}{}}%
Hunter, John, and Frank Schmidt. 1990. {``Dichotomization of Continuous
Variables: The Implications for Meta-Analysis.''} \emph{Journal of
Applied Psychology} 75 (June): 334--49.
\url{https://doi.org/10.1037/0021-9010.75.3.334}.

\leavevmode\vadjust pre{\hypertarget{ref-johnson1995}{}}%
Johnson, Blair T., Brian Mullen, and Eduardo Salas. 1995. {``Comparison
of Three Major Meta-Analytic Approaches.''} \emph{Journal of Applied
Psychology} 80 (1): 94--106.
\url{https://doi.org/10.1037/0021-9010.80.1.94}.

\leavevmode\vadjust pre{\hypertarget{ref-kelley1927}{}}%
Kelley, Truman Lee. 1927. \emph{Interpretation of Educational
Measurements}. World Book Company.

\leavevmode\vadjust pre{\hypertarget{ref-laird1990}{}}%
Laird, Nan M., and Frederick Mosteller. 1990. {``Some Statistical
Methods for Combining Experimental Results.''} \emph{International
Journal of Technology Assessment in Health Care} 6 (1): 5--30.
\url{https://doi.org/10.1017/S0266462300008916}.

\leavevmode\vadjust pre{\hypertarget{ref-maxwell1993}{}}%
Maxwell, Scott, and Harold Delaney. 1993. {``Bivariate Median Splits and
Spurious Statistical Significance.''} \emph{Psychological Bulletin} 113
(January): 181--90. \url{https://doi.org/10.1037/0033-2909.113.1.181}.

\leavevmode\vadjust pre{\hypertarget{ref-mcdaniel1994}{}}%
McDaniel, Michael A., Deborah L. Whetzel, Frank L. Schmidt, and Steven
D. Maurer. 1994. {``The Validity of Employment Interviews: A
Comprehensive Review and Meta-Analysis.''} \emph{Journal of Applied
Psychology} 79 (4): 599--616.
\url{https://doi.org/10.1037/0021-9010.79.4.599}.

\leavevmode\vadjust pre{\hypertarget{ref-mendoza1987}{}}%
Mendoza, Jorge L., and Michael Mumford. 1987. {``Corrections for
Attenuation and Range Restriction on the Predictor.''} \emph{Journal of
Educational Statistics} 12 (3): 282--93.
\url{https://doi.org/10.3102/10769986012003282}.

\leavevmode\vadjust pre{\hypertarget{ref-morris2014}{}}%
Morris, Scott, Rebecca Daisley, Megan Wheeler, and Peggy Boyer. 2014.
{``A Meta-Analysis of the Relationship Between Individual Assessments
and Job Performance.''} \emph{The Journal of Applied Psychology} 100
(May). \url{https://doi.org/10.1037/a0036938}.

\leavevmode\vadjust pre{\hypertarget{ref-murphy2003}{}}%
Murphy, Kevin R. 2003. \emph{Validity Generalization: A Critical
Review}. Psychology Press.

\leavevmode\vadjust pre{\hypertarget{ref-olkin1958}{}}%
Olkin, Ingram, and John W. Pratt. 1958. {``Unbiased Estimation of
Certain Correlation Coefficients.''} \emph{The Annals of Mathematical
Statistics} 29 (1): 201--11. \url{https://www.jstor.org/stable/2237306}.

\leavevmode\vadjust pre{\hypertarget{ref-pearson1903}{}}%
Pearson, Karl. 1903. {``I. Mathematical Contributions to the Theory of
Evolution. {\textemdash}XI. On the Influence of Natural Selection on the
Variability and Correlation of Organs.''} \emph{Philosophical
Transactions of the Royal Society of London. Series A, Containing Papers
of a Mathematical or Physical Character} 200 (321-330): 1--66.
\url{https://doi.org/10.1098/rsta.1903.0001}.

\leavevmode\vadjust pre{\hypertarget{ref-pearson1913}{}}%
---------. 1913. {``On the Probable Error of a Coefficient of
Correlation as Found from a Fourfold Table.''} \emph{Biometrika} 9
(1/2): 22--33. \url{https://doi.org/10.2307/2331798}.

\leavevmode\vadjust pre{\hypertarget{ref-peters1940}{}}%
Peters, Charles C., and Walter R. Van Voorhis. 1940. {``Further Methods
of Correlation.''} In, 362--403. New York, NY, US: McGraw-Hill Book
Company. \url{https://doi.org/10.1037/13596-013}.

\leavevmode\vadjust pre{\hypertarget{ref-psych:p2017}{}}%
{``Psych: Procedures for Personality and Psychological Research.''}
2017. \url{https://CRAN.R-project.org/package=psych}.

\leavevmode\vadjust pre{\hypertarget{ref-raju1983}{}}%
Raju, Nambury, and Michael Burke. 1983. {``Two Procedures for Studying
Validity Generalization.''} \emph{Journal of Applied Psychology} 68
(August): 382--95. \url{https://doi.org/10.1037/0021-9010.68.3.382}.

\leavevmode\vadjust pre{\hypertarget{ref-roth2015}{}}%
Roth, Bettina. 2015. {``Intelligence and School Grades: A
Meta-Analysis.''}

\leavevmode\vadjust pre{\hypertarget{ref-sackett2000}{}}%
Sackett, Paul R., and Hyuckseung Yang. 2000. {``Correction for Range
Restriction: An Expanded Typology.''} \emph{Journal of Applied
Psychology} 85 (1): 112--18.
\url{https://doi.org/10.1037/0021-9010.85.1.112}.

\leavevmode\vadjust pre{\hypertarget{ref-schmidt1977}{}}%
Schmidt, Frank, and John Hunter. 1977. {``Development of a General
Solution to the Problem of Validity Generalization.''} \emph{Journal of
Applied Psychology} 62 (October): 529--40.
\url{https://doi.org/10.1037/0021-9010.62.5.529}.

\leavevmode\vadjust pre{\hypertarget{ref-spearman1904}{}}%
Spearman, C. 1904. {``The Proof and Measurement of Association Between
Two Things.''} \emph{International Journal of Epidemiology} 39 (5):
1137--50. \url{https://doi.org/10.1093/ije/dyq191}.

\leavevmode\vadjust pre{\hypertarget{ref-taylor1976}{}}%
Taylor, Erwin K., and Thomas Griess. 1976. {``The Missing Middle in
Validation Research.''} \emph{Personnel Psychology} 29 (1): 5--11.
\url{https://doi.org/10.1111/j.1744-6570.1976.tb00397.x}.

\leavevmode\vadjust pre{\hypertarget{ref-viechtbauer2010}{}}%
Viechtbauer, Wolfgang. 2010. {``Conducting meta-analyses in R with the
metafor package.''} \emph{Journal of Statistical Software} 36 (3):
1--48. \url{https://doi.org/10.18637/jss.v036.i03}.

\leavevmode\vadjust pre{\hypertarget{ref-viechtbauer}{}}%
---------. n.d. {``Fixed-Effects and Random-Effects Models in
Meta-Analysis.''} \url{https://wviechtb.github.io/metafor/index.html}.

\leavevmode\vadjust pre{\hypertarget{ref-viswesvaran1995}{}}%
Viswesvaran, Chockalingam, and Deniz S. Ones. 1995. {``Theory Testing:
Combining Psychometric Meta-Analysis and Structural Equations
Modeling.''} \emph{Personnel Psychology} 48 (4): 865--85.
\url{https://doi.org/10.1111/j.1744-6570.1995.tb01784.x}.

\leavevmode\vadjust pre{\hypertarget{ref-viswesvaran2014}{}}%
Viswesvaran, Chockalingam, Deniz S. Ones, Frank L. Schmidt, Huy Le, and
In-Sue Oh. 2014. {``Measurement Error Obfuscates Scientific Knowledge:
Path to Cumulative Knowledge Requires Corrections for Unreliability and
Psychometric Meta-Analyses.''} \emph{Industrial and Organizational
Psychology} 7 (4): 507--18.
\url{https://doi.org/10.1017/S1754942600006799}.

\leavevmode\vadjust pre{\hypertarget{ref-vos2022}{}}%
Vos, Paul, and Don Holbert. 2022. {``Frequentist Statistical Inference
Without Repeated Sampling.''} \emph{Synthese} 200 (2): 89.
\url{https://doi.org/10.1007/s11229-022-03560-x}.

\leavevmode\vadjust pre{\hypertarget{ref-wechsler2008}{}}%
Wechsler, David. 2008. \emph{Wechsler Adult Intelligence Scale--Fourth
Edition}. 4th ed. \url{https://doi.org/10.1037/t15169-000}.

\leavevmode\vadjust pre{\hypertarget{ref-whitener1990}{}}%
Whitener, Ellen M. 1990. {``Confusion of Confidence Intervals and
Credibility Intervals in Meta-Analysis.''} \emph{Journal of Applied
Psychology} 75 (3): 315--21.
\url{https://doi.org/10.1037/0021-9010.75.3.315}.

\leavevmode\vadjust pre{\hypertarget{ref-wiernik2020}{}}%
Wiernik, Brenton M., and Jeffrey A. Dahlke. 2020. {``Obtaining Unbiased
Results in Meta-Analysis: The Importance of Correcting for Statistical
Artifacts.''} \emph{Advances in Methods and Practices in Psychological
Science} 3 (1): 94--123. \url{https://doi.org/10.1177/2515245919885611}.

\leavevmode\vadjust pre{\hypertarget{ref-wylie1976}{}}%
Wylie, Peter B. 1976. {``Effects of Coarse Grouping and Skewed Marginal
Distributions on the Pearson Product Moment Correlation Coefficient.''}
\emph{Educational and Psychological Measurement} 36 (1): 1--7.
\url{https://doi.org/10.1177/001316447603600101}.

\end{CSLReferences}

\hypertarget{indirect-selection}{%
\chapter{Indirect Selection}\label{indirect-selection}}

\hypertarget{introduction-6}{%
\section{Introduction}\label{introduction-6}}

Indirect range restriction/enhancement occurs when selection of sample
participants is based on a variable that is correlated with the
variables of interest. If the selector Whereas range enhancement
indicates that there is \emph{more} variation in a sample then there is
in the population. Direct range restriction/enhancement (as opposed to
indirect range restriction) is when selection into the sample is based
on the variable(s) of interest (i.e., the independent and/or dependent
variable). This selection into the sample will either restrict or
enhance the variation in the variable, thus causing

\hypertarget{an-applied-example-of-indirect-range-restriction}{%
\section{An Applied Example of Indirect Range
Restriction}\label{an-applied-example-of-indirect-range-restriction}}

Imagine a research team is conducting a study on academic motivation
among college students using a survey that includes various questions
related to academic engagement, goal orientation, and effort investment.
The researchers administer the survey to a large sample of students
across different universities. However, during the data cleaning
process, the researchers identify a subset of respondents who exhibited
signs of inattentiveness and carelessness in their responses. These
signs include straight-lining questions (e.g., consistently selecting
the same response option without reading the questions) or responding
randomly without considering the content of the questions. Recognizing
that inattentive or careless responding can distort the measurement of
academic motivation, the researchers decide to exclude these individuals
from the analysis. The rationale is to ensure that the data collected
represents genuine responses and validly measures academic motivation.
The unintended consequence of this decision is indirect range
restriction. By removing inattentive and careless responders, who likely
also have lower academic motivation and engagement, from the dataset,
the observed range of academic motivation scores is reduced. The
excluded individuals, who may have had lower academic motivation scores,
are not accounted for in the analysis, resulting in an underestimation
of the variability of academic motivation relative to the population.

\hypertarget{indexing-range-restriction-with-the-u-ratio-1}{%
\section{\texorpdfstring{Indexing Range Restriction with the
\emph{u}-ratio}{Indexing Range Restriction with the u-ratio}}\label{indexing-range-restriction-with-the-u-ratio-1}}

The distribution of scores in the unrestricted pool of individuals will
exhibit a greater (or lesser) degree of variability compared to the
sample that has been selected into the study. Therefore the standard
deviation of scores in the unrestricted population (\(\sigma_x\)) will
differ from that of the selected (restricted/enhanced) sample
(\(\sigma_{x_{S}}\)). To index the difference between the two standard
deviations, we can calculate the \(u\)-ratio Wiernik and Dahlke (2020).
The \(u\)-ratio is the ratio between the standard deviations of the
selected sample to the unrestricted sample such that,

\[
u_x = \frac{\sigma_{x_S}}{\sigma_x}
\]

The \(u\)-ratio in cases of range restriction will exist in the interval
(0--1). Conversely, when the \(u\)-ratio is greater than 1 it is
indicative of range enhancement. The unrestricted standard deviation is
often quite difficult to acquire since we do not usually have access to
the unrestricted group. However, the unrestricted standard deviation can
be estimated from some reference study that has been conducted on the
unrestricted group. This often comes in the form of standardization
samples or norm samples (obtained from test manuals) if the unrestricted
group is the general population. For example, the distribution
full-scale IQ scores derived from the Wechsler Adult Intelligence Test
has a standard deviation of 15 in the US population (Wechsler 2008). We
can use this estimate as the standard deviation for the unrestricted
population. Lets say we select a sample from members of Harvard
students, who tend to have higher IQs than the general population (this
is due to the fact that selection criterion, such as GPA and SAT scores
are positively correlated with IQ). If the standard deviation of IQ in
Harvard students is 10, then the \(u\)-ratio would be,

\[
u =  \frac{\sigma_{x_S}}{\sigma_x} = \frac{10}{15}= .67
\]

However it is not always the case that an estimate of the unrestricted
standard deviation is readily available. Therefore if the reliability
coefficient from the unrestricted and selected sample can be used to
estimate the \(u\)-ratio,

\[
u_x = \sqrt{\frac{1-r_{xx'}}{1-r_{xx'_S}}}
\]

Where \(r_{xx'_S}\) and \(r_{xx'}\) are the reliability estimates within
the selected and unrestricted groups respectively. In the context of
indirect range restriction, the selection does not occur directly on
\(x\) (or \(y\)), instead it occurs on a selector variable, \(z\).
Therefore we can see how the \(u\)-ratio of the selector variable
(\(u_z\)) relates to the \(u\)-ratio of \(x\),

\[
u_x = \sqrt{\rho_{xz}^2u_z^2 -\rho_{xz}^2 + 1 }
\]

The formulation above is also dependent on the correlation between the
selector, \(z\), and \(x\). If the correlation between \(z\) and \(x\)
is \(\rho_{xz}=0\), then you will notice that \(u_x=u_z\). Notice that a
correlation of \(\rho_{xz}=1\) would also simplify to a direct range
restriction problem. A correlation of \(\rho_{xz}=0\), would effectively
have no selection effect (i.e., restriction nor enhancement) since the
equation would simplify to \(u_x=1\).

\hypertarget{correcting-correlations-for-direct-range-restriction-1}{%
\section{Correcting Correlations for Direct Range
Restriction}\label{correcting-correlations-for-direct-range-restriction-1}}

\hypertarget{defining-our-estimand-8}{%
\subsection{Defining our Estimand}\label{defining-our-estimand-8}}

For our study we want to estimate the population correlation of the
unrestricted scores of the independent (\(x\)) and dependent variable
(\(y\)). We can denote this correlation as \(\rho_{xy}\). The population
correlation within the selected sample can be denoted as
\(\rho_{xy_S}\). Within a study sample that suffers from indirect
selection (and sampling error), the study correlation (\(r_{xy_S}\))
will be biased relative to our estimand, \(\rho_{xy}\). This bias can be
denoted by \(a\) such that,

\[
r_{xy} = a \rho_{xy_S} + \varepsilon  
\]

Therefore an unbiased estimate of the unrestricted population
correlation would be

\[
r_c = \frac{ r_{xy_S} }{ a}.
\] Note that we may also want to correct for measurement on top of range
restriction. In this case, using the true score model for x
(\(x=T+e_x\)) and y (\(y = U+e_y\)), we may want to estimate the
unrestricted correlation between true scores (\(\rho_{TU}\)). The figure
below shows the relationship between three variables: the selector
(\(z\)), the independent variable (\(x\)), and the dependent variable
(\(y\)). The correlation between \(x\) and \(y\) (\(\rho_{xy}\)) is our
estimand (i.e., the quantity we want to estimate), however as we will
show, under selection on \(z\), the correlations between the selector
and the independent/dependent variable can severely bias the observed
correlation.

\includegraphics{figure/ind_selection.png}

\hypertarget{artifact-correction-for-correlations-1}{%
\subsection{Artifact Correction for
Correlations}\label{artifact-correction-for-correlations-1}}

\hypertarget{the-univariate-case-2}{%
\subsubsection*{The Univariate Case}\label{the-univariate-case-2}}
\addcontentsline{toc}{subsubsection}{The Univariate Case}

Range restriction (or enhancement) in either the independent or
dependent variable will induce bias into the correlation coefficient.
Let us consider a case where we select individuals based on meeting some
criterion of some third variable, \(z\). The extent to which selection
on \(z\) induces restriction (or enhancement) on \(x\) (or \(y\))
depends on the correlation between \(z\) and \(x\). We can simulate an
example where individuals are selected into the sample if they are above
the mean of \(z\). Lets see how the selection process affects the
distribution of \(x\) when we vary the correlation between \(x\) and
\(z\) (\(\rho_{xz}\)).

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-1-1.pdf}

Notice that the distribution of rejected and accepted participants are
more similar within the plot on the left where there is a relatively low
correlation between the selector variable and the independent variable.
More importantly, when the correlation is lower we see wider
distributions (larger standard deviation, \(\sigma_{x_S}\)) than in the
selected sample (and rejected), however, when the correlation is higher
the standard deviation shrinks accordingly. Not only is the correlation
between \(x\) and \(z\) important in the resulting variance of \(x\),
but so is where the cut-point, that is the threshold where individuals
are selected above (or below). For example, the standard deviation of
\(x\) will be smaller when individuals are selected above the 90th
percentile of \(z\) than when individuals are selected above the median
of \(z\) (i.e., the 50th percentile). We can visualize this phenomenon
as well by setting a low cut-point for selection (\(z>-1.0\)) and a high
cut-point for selection (\(z>0.5\)). Notice in the figure below that the
standard deviation is lower when the cut-point is higher on \(z\).

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-2-1.pdf}

Now lets consider a study where we want to calculate the unrestricted
correlation between an independent variable, \(x\), and a dependent
variable, \(y\). However, the sample is selected based on meeting some
criterion on a selector, \(z\). Lets look at a diagram looking at the
relationship between variables. We can visualize the correlation between
independent (\(x\)) and dependent (\(y\)) variables under range
restriction by only selecting individuals above some cut off of our
selector variable, \(z\). The scores of individuals that have been
selected will show less variance than the entire pool of individuals.
Specifically, the scenario below shows a \(u\)-ratio of about 0.69 in
the independent variable. We see in the figure that the correlation in
the restricted scores (\(\rho_{xy_S}\)) is attenuated relative to the
unrestricted (true) correlation (\(\rho_{xy}\)).

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-3-1.pdf}

We can also visualize what happens to the correlation when the range is
enhanced. Enhancement can be accomplished by selecting individuals at
the ends of the distribution (Taylor and Griess 1976). In the
visualization below, we see an opposite effect on the correlation, that
is, an over-estimate of the unrestricted correlation rather than an
attenuation like we see under range restriction. The scenario below has
a \(u\)-ratio of about 1.44 in the independent variable.

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-4-1.pdf}

It starts to become apparent that if \(u_x>1\) (i.e.,
\(\sigma_x>\sigma_\mathcal{x_S}\)) the observed correlation
over-estimates the true, unrestricted correlation and under-estimates
the unrestricted correlation when \(u_x<1\) (i.e.,
\(\sigma_x<\sigma_\mathcal{x_S}\), Sackett and Yang 2000). A bias
correction formula for univariate direct range restriction was first
developed by Pearson (1903) and provided more recently by J. E. Hunter
and Schmidt (1990). To correct for the systematic bias in correlations,
we can use the \(u\)-ratio of the independent variable such that,

\begin{equation}\protect\hypertarget{eq-univariate}{}{
r_c = \frac{r_{xy_S}}{\sqrt{r_{xy_S}^2 + u_{x}^2 (1- r_{xy_S}^2)  }}
}\label{eq-univariate}\end{equation}

This correction formula is only meant for observed scores only. If one
wants to correct for range restriction and measurement error, we need to
adjust the \(u\)-ratio for measurement error, as well as adjust the
reliability coefficients for range restriction/enhancement. We can
incorporate these adjustments into a single correction formula using the
equation in table 3 of Wiernik and Dahlke (2020), \[
r_c=\frac{r_{xy_S}}{\sqrt{r_{xy_S}^2 + \frac{u_{x}^2 r_{xx'_S}\left(r_{xx'_S}r_{yy'_S} - r_{xy_S}^2\right) }{1 - u_{x}^2 \left(1-r_{xx'_S}\right)} }}
\] Where \(r_{xx'_S}\) and \(r_{yy'_S}\) are the reliabilities within
the selected sample. If the reliability coefficients come from the
unrestricted population (e.g., from a norm/standardization sample), we
can estimate the restricted reliability using the following formulas:

\begin{equation}\protect\hypertarget{eq-rel-x}{}{
r_{xx'_S} = 1-\frac{1-r_{xx'}}{u_x^2}
}\label{eq-rel-x}\end{equation}
\begin{equation}\protect\hypertarget{eq-rel-y}{}{
r_{yy'_S} = 1-\frac{1-r_{yy'}}{u_y^2}
}\label{eq-rel-y}\end{equation}

Now once the the correlation is corrected the observed sampling variance
(\(\sigma_{\varepsilon_o}\)) must also be adjusted as well. To do this,
we can simply use the corrected correlation and the observed correlation
to adjust the sampling variance:

\begin{equation}\protect\hypertarget{eq-univariate-se}{}{
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{xy_S}}\right)^2.
}\label{eq-univariate-se}\end{equation}

\hypertarget{the-bivariate-case-2}{%
\subsubsection*{The Bivariate Case}\label{the-bivariate-case-2}}
\addcontentsline{toc}{subsubsection}{The Bivariate Case}

Bivariate direct range restriction/enhancement occurs when the selection
variable has independent relationships with both the independent and
dependent variable. Like we did for the univariate case, let's visualize
the correlation between independent (\(x\)) and dependent (\(y\))
variables under range restriction by only selecting individuals above
some cut off point in our selector variable, \(z\). We will fix the
correlations between the selector and independent variable
(\(\rho_{xz}\)), as well as the selector and dependent variable
(\(\rho_{yz}\)) to be .80. The \(x\) and \(y\) scores of individuals
that have been selected above some threshold of \(z\) will show less
variance than the entire pool of individuals. Specifically, the scenario
below shows a \(u\)-ratio of about \textasciitilde0.82 in the
independent variable and dependent variables. We see in the figure below
that the correlation in the restricted sample (\(\rho_{xy_S}=.24\)) is
attenuated relative to the unrestricted (true) correlation
(\(\rho_{xy}=.50\)).

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-5-1.pdf}

Likewise let's visualize what happens to the correlation when the range
is enhanced. Enhancement in both variables can be accomplished by
selecting individuals at the ends of the distribution of \(z\). In the
visualization below, we observe an over-estimation of observed
correlation (\(\rho_{xy_S}=.75\)) relative to the unrestricted
correlation (\(\rho_{xy}=.50\)). The scenario below has a \(u\)-ratio of
about \textasciitilde1.38 in both the independent variable and dependent
variable.

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-6-1.pdf}

Note that bivariate restriction or bivariate enhancement will increase
the amount of bias in the correlation coefficients similar to that of
measurement error in both variables rather than just one (see chapter
5). A bias correction formula for bivariate range restriction is much
more complicated than the univariate formulation. Particularly we need
to have a basic idea of the selection mechanism at play (Dahlke and
Wiernik 2019). The correction formula requires the direction of the
correlation between the selector variable, \(z\), and the independent
(\(\rho_{xz}\)) and dependent variable (\(\rho_{yz}\)). For example, if
we run a study on a college admissions test and college academic
performance (indexed by grade-point average), we can be reasonably
certain that the selection (i.e., admissions decisions) are positively
correlated with both academic performance and SAT scores. Other
situations this may not be as straight-forward however laying out the
correlational structure of the selection mechanism is vital step of the
correction procedure. To break down the correction formula into simpler
parts, let us first define a factor we will denote with \(\lambda\).
This factor is what takes into account the direction of the correlation
of \(\rho_{xz}\) (if positive, we can set \(\rho_{yz}=1\), if negative,
\(\rho_{yz}=-1\), if zero, \(\rho_{yz}=0\)) and \(\rho_{yz}\) (repeat
the same procedure as \(\rho_{xz}\)).

\begin{align}
\lambda =& \text{ sign}\left(\rho_{xz}\rho_{yz} [1-u_x][1-u_y]\right)\times \\
&\frac{\text{sign}
\left(1-u_x\right)\min\left(u_x,\frac{1}{u_x}\right) + 
\left(1-u_x\right)\min\left(u_y,\frac{1}{u_y}\right)
}{
\min\left(u_x,\frac{1}{u_x}\right)+\min\left(u_y,\frac{1}{u_y}\right)
}
\end{align}

The output of \(\lambda\) will be either -1, 0, or 1. We can then plug
this factor into the full correction equation that provides us with an
unbiased estimate of the correlation in the unrestricted population,

\[
r_c = r_{xy_S}u_xu_y+\lambda\sqrt{|1-u_x^2||1-u_y^2|}
\] Similar to the univariate formula, we can also incorporate
measurement error into the correction. Measurement error will bias the
observed correlation on top of the bias induced by range
restriction/enhancement. Therefore we can incorporate the reliabilities
estimated within the restricted sample (\(_{xx'_S}\) and \(r_{yy'_S}\)),
into our correction formula:

\[
r_c = \frac{r_{xy_S}u_xu_y+\lambda\sqrt{|1-u_x^2||1-u_y^2|}}{\sqrt{1-u_x^2(1-r_{xx'_S})}\sqrt{1-u_y^2(1-r_{yy'_S})}}
\]

If the reliability estimates come from an unrestricted sample, we can
get estimates of the reliability coefficients in the selected sample
using Equation~\ref{eq-rel-x} and Equation~\ref{eq-rel-y}. We then can
correct the observed sampling variance (\(\sigma^2_{\varepsilon_o}\)),

\[
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{xy_S}}\right)^2.
\]

\hypertarget{correcting-correlations-in-r-4}{%
\subsection{Correcting Correlations in
R}\label{correcting-correlations-in-r-4}}

\hypertarget{univariate-indirect-range-restriction}{%
\subsubsection*{Univariate Indirect Range
Restriction}\label{univariate-indirect-range-restriction}}
\addcontentsline{toc}{subsubsection}{Univariate Indirect Range
Restriction}

To correct correlations for range restriction we can start by simulating
data from the the \texttt{mvrnorm} function in the \texttt{MASS}
package. Lets first simulate 1000 data points. Then we will select
values above the mean of the selector variable, \(z\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}MASS\textquotesingle{})}
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{\# define parameters}
\NormalTok{rho\_xy }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}

\CommentTok{\# simulate data}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(}\AttributeTok{n=}\NormalTok{n,}
                \AttributeTok{mu=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                \AttributeTok{Sigma =} \FunctionTok{reshape\_vec2mat}\NormalTok{(}\FunctionTok{c}\NormalTok{(rho\_xy)),}
                \AttributeTok{empirical=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{1}\NormalTok{]}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{2}\NormalTok{]}
\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n,}\DecValTok{0}\NormalTok{,.}\DecValTok{5}\NormalTok{)}
\NormalTok{selected }\OtherTok{\textless{}{-}}\NormalTok{ z }\SpecialCharTok{\textgreater{}} \DecValTok{0}
\end{Highlighting}
\end{Shaded}

We can start with univariate indirect range restriction by selecting
only on the independent variable. We will select only the values above
the mean.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate correlation between unrestricted and restricted scores}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x,y) }\CommentTok{\# unrestricted}
\NormalTok{rxyS }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x[selected],y[selected]) }\CommentTok{\# restricted}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}unrestricted: rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}restricted: rxyS = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxyS,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                     
[1,] "unrestricted: rxy = 0.5"
[2,] "restricted: rxyS = 0.39"
\end{verbatim}

As expected, we observe an attenuation of the correlation under range
restriction. Now lets calculate the \(u\)-ratios for both variables. We
should expect the variability not only in \(x\), but also \(y\) in the
restricted sample to be smaller than the unrestricted sample. Since
\(x\) and \(y\) are positively correlated, restriction \(x\) will
restrict

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate u{-}ratios}
\NormalTok{ux }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(x[selected])}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(x)}
\NormalTok{uy }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(y[selected])}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(y)}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}ux = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(ux,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}uy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(uy,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]       
[1,] "ux = 0.69"
[2,] "uy = 0.93"
\end{verbatim}

Now we can apply the correction for univariate direct range restriction
by hand from Equation~\ref{eq-univariate} and
Equation~\ref{eq-univariate}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# correct the restricted correlation}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ rxyS }\SpecialCharTok{/}\NormalTok{ ( ux}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{((}\DecValTok{1}\SpecialCharTok{/}\NormalTok{ux}\SpecialCharTok{\^{}}\DecValTok{2{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{+}\DecValTok{1}\NormalTok{ ))}

\CommentTok{\# acquire sample size from }
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(x[selected])}

\CommentTok{\# calculate the observed correlation sampling variance}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{rxyS)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected cor: r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{3}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected var: var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                          
[1,] "corrected cor: r = 0.52"     
[2,] "corrected var: var_e = 0.003"
\end{verbatim}

The correction formula produced a very close estimate of the true
population correlation (\(r_c = .50\) vs \(\rho_{xy}=.50\)). Lets also
correct the correlation using the \texttt{correct\_r} function in the
psychmeta package, \texttt{psychmeta} (Dahlke and Wiernik 2019).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# correct the restricted correlation for univariate direct range restriction}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxyS,}
          \AttributeTok{correction =} \StringTok{\textquotesingle{}bvirr\textquotesingle{}}\NormalTok{,  }\CommentTok{\# uvdrr\_x = univariate direct range restriction in x}
          \AttributeTok{ux =}\NormalTok{ ux,}
          \AttributeTok{uy =}\NormalTok{ uy,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error and Bivariate Indirect Range Restriction:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95   n n_effective
1 0.523    0.474    0.568 517         220
\end{verbatim}

We can see that the correction made by the \texttt{correct\_r} function
provides identical results to the one done by hand.

\hypertarget{bivariate-indirect-range-restriction}{%
\subsubsection*{Bivariate Indirect Range
Restriction}\label{bivariate-indirect-range-restriction}}
\addcontentsline{toc}{subsubsection}{Bivariate Indirect Range
Restriction}

To correct correlations for range restriction we can start by simulating
data from the the \texttt{mvrnorm} function in the \texttt{MASS}
package. Lets first simulate 1000 data points. Then we will select
values above the mean of the selector variable, \(z\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}MASS\textquotesingle{})}
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{\# define parameters}
\NormalTok{rho\_xz }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{8}
\NormalTok{rho\_yz }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{8}
\NormalTok{rho\_xy }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}

\CommentTok{\# simulate data}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(}\AttributeTok{n=}\NormalTok{n,}
                \AttributeTok{mu=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                \AttributeTok{Sigma =} \FunctionTok{reshape\_vec2mat}\NormalTok{(}\FunctionTok{c}\NormalTok{(.}\DecValTok{5}\NormalTok{,.}\DecValTok{8}\NormalTok{,.}\DecValTok{8}\NormalTok{)),}
                \AttributeTok{empirical=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{1}\NormalTok{]}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{2}\NormalTok{]}
\NormalTok{z }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{3}\NormalTok{]}
\NormalTok{selected }\OtherTok{\textless{}{-}}\NormalTok{ z }\SpecialCharTok{\textgreater{}} \DecValTok{0}
\end{Highlighting}
\end{Shaded}

We can see how the correlations are attenuated under bivariate indirect
range restriction. We will select only the values above the mean.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate correlation between unrestricted and restricted scores}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x,y) }\CommentTok{\# unrestricted}
\NormalTok{rxyS }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x[selected],y[selected]) }\CommentTok{\# restricted}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}unrestricted: rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}restricted: rxyS = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxyS,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                     
[1,] "unrestricted: rxy = 0.5"
[2,] "restricted: rxyS = 0.18"
\end{verbatim}

As expected, we observe an attenuation of the correlation under range
restriction. Now lets calculate the \(u\)-ratios for both variables. We
should expect the variability in \(x\) and \(y\) in the restricted
sample to be smaller than the unrestricted sample.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate u{-}ratios}
\NormalTok{ux }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(x[selected])}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(x)}
\NormalTok{uy }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(y[selected])}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(y)}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}ux = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(ux,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}uy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(uy,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]       
[1,] "ux = 0.8" 
[2,] "uy = 0.78"
\end{verbatim}

Now we can apply the correction for univariate direct range restriction
by hand from Equation~\ref{eq-univariate} and
Equation~\ref{eq-univariate}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate lambda}
\NormalTok{rho\_xz }\OtherTok{\textless{}{-}} \DecValTok{1} \CommentTok{\# assume a positive correlation for rho\_xz}
\NormalTok{rho\_yz }\OtherTok{\textless{}{-}} \DecValTok{1} \CommentTok{\# assume a positive correlation for rho\_yz}
\NormalTok{lambda }\OtherTok{\textless{}{-}} \FunctionTok{sign}\NormalTok{(rho\_xz}\SpecialCharTok{*}\NormalTok{rho\_yz}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{ux)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{uy)) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{sign}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{ux)}\SpecialCharTok{*}\FunctionTok{min}\NormalTok{(}\FunctionTok{c}\NormalTok{(ux,}\DecValTok{1}\SpecialCharTok{/}\NormalTok{ux))}\SpecialCharTok{+}\FunctionTok{sign}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{uy)}\SpecialCharTok{*}\FunctionTok{min}\NormalTok{(}\FunctionTok{c}\NormalTok{(uy,}\DecValTok{1}\SpecialCharTok{/}\NormalTok{uy)))}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{min}\NormalTok{(}\FunctionTok{c}\NormalTok{(ux,}\DecValTok{1}\SpecialCharTok{/}\NormalTok{ux))}\SpecialCharTok{+}\FunctionTok{min}\NormalTok{(}\FunctionTok{c}\NormalTok{(uy,}\DecValTok{1}\SpecialCharTok{/}\NormalTok{uy)))}

\CommentTok{\# correct the restricted correlation}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ rxyS}\SpecialCharTok{*}\NormalTok{ux}\SpecialCharTok{*}\NormalTok{uy }\SpecialCharTok{+}\NormalTok{ lambda}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{ux}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{abs}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{uy}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}

\CommentTok{\# acquire sample size from }
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(x[selected])}

\CommentTok{\# calculate the observed correlation sampling variance}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{rxyS)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected cor: r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{3}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected var: var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                          
[1,] "corrected cor: r = 0.493"    
[2,] "corrected var: var_e = 0.014"
\end{verbatim}

The correction formula produced a very close estimate of the true
population correlation (\(r_c = .50\) vs \(\rho_{xy}=.50\)). Lets also
correct the correlation using the \texttt{correct\_r} function in the
psychmeta package, \texttt{psychmeta} (Dahlke and Wiernik 2019).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# correct the restricted correlation for univariate direct range restriction}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxyS,}
          \AttributeTok{correction =} \StringTok{\textquotesingle{}bvirr\textquotesingle{}}\NormalTok{,  }\CommentTok{\# uvdrr\_x = univariate direct range restriction in x}
          \AttributeTok{ux =}\NormalTok{ ux,}
          \AttributeTok{uy =}\NormalTok{ uy,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error and Bivariate Indirect Range Restriction:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95   n n_effective
1 0.493     0.44    0.545 500         465
\end{verbatim}

We can see that the correction made by the \texttt{correct\_r} function
provides identical results to the one done by hand.

\part{Application to Meta-Analysis}

\hypertarget{sec-metaanalysis_intro}{%
\chapter{Introduction to Meta-Analysis
Methods}\label{sec-metaanalysis_intro}}

\hypertarget{introduction-7}{%
\section{Introduction}\label{introduction-7}}

Meta-analysis is an analytic tool to synthesize quantitative evidence
from multiple studies. By systematically combining and analyzing the
results of multiple studies, meta-analysis provides a comprehensive
overview, unveiling patterns, trends, and insights that individual
studies might not be able to capture. Combining research findings also
has the added benefit of increasing the precision of our results (i.e.,
greater statistical power). In this section we will cover the method
described by (J. E. Hunter and Schmidt 1990) since it is readily
compatible with artifact corrections (see next chapter). For the
random-effects model however, we use an integrated approach that
incorporates methods from J. E. Hunter and Schmidt (1990) and Hedges and
Vevea (1998) that was first introduced by Morris et al. (2014). However
it is important to note that there are other common methods to conduct
meta-analyses that have their strengths and weaknesses (Hedges and Olkin
2014; Callender and Osburn 1980; Johnson, Mullen, and Salas 1995).

\hypertarget{common-effect-model}{%
\section{Common-Effect Model}\label{common-effect-model}}

A common effect model is the simplest form of meta-analysis. It assumes
that all the variation in observed effect sizes is attributable to
sampling error. In other words, all the observed effect sizes are
estimates of the same population effect size. Note that there is a
distinction between \emph{fixed-effects} models and a \emph{common
effect} model (Viechtbauer, n.d.; Laird and Mosteller 1990). The common
effect model assumes that the true effect size is identical for each
study while the fixed effects model does not assume this. Instead, the
fixed effects model can be interpreted as the weighted average of true
effects. Computationally, they are the same and provide the same
parameter estimates, yet the interpretation differs.

\begin{figure}

{\centering \includegraphics{figure/fixed_effects_diagram.png}

}

\caption{The diagram above depicts a common effect meta-analysis of five
studies. The study effect sizes are homogenous and all estimate a single
true population effect size.}

\end{figure}

\hypertarget{the-general-case}{%
\subsection{The General Case}\label{the-general-case}}

The common effect model can be modeled such that population effect size
\(\vartheta\) is held constant each sample (study) effect sizes
(\(\theta_i\)), such that,

\begin{equation}\protect\hypertarget{eq-fixed-mdl}{}{
\theta_i  = \vartheta + \varepsilon_i
}\label{eq-fixed-mdl}\end{equation}

Where \(\varepsilon_i\) indicates sampling error and the subscript \(i\)
denotes each study. Similar to the true score theory model that we
discussed in chapter 4, the variance components of each term can
similarly be written out as,

\[
\sigma^2_\theta = \sigma^2_\vartheta + \sigma^2_\varepsilon
\]

However in our fixed effects model, the population effect size is
constant across studies and will not vary, simplifying the formula to,

\begin{equation}\protect\hypertarget{eq-var-fixed}{}{
\sigma^2_\theta = \sigma^2_\varepsilon
}\label{eq-var-fixed}\end{equation}

Therefore the only source of variation in the observed effect sizes, is
sampling error. Since sampling error varies from study to study, we can
take the average sampling variance across studies to estimate
\(\sigma^2_\varepsilon\):

\[
\sigma^2_\varepsilon=\frac{1}{k}\sum^k_{i=1}\sigma^2_{\varepsilon_i}
\]

Ultimately, our goal is to obtain a precise estimate of the population
effect size. To obtain an estimate of the population effect size,
\(\vartheta\), we can calculate the average observed effect size,
\(\bar{\theta}_i\) from \(k\) studies. However, in practice, effect
sizes from different studies have varying levels of precision (i.e.,
varying sample size). A simple average will not account for the
differences between studies in their precision. Instead, we can
calculate a weighted average where the weights each study can be
calculated by the inverse variance (i.e., precision) of each study such
that,

\[
w_i = \frac{1}{\sigma^2_{\varepsilon_i}}
\]

Then we can calculate a weighted average,

\[
\hat{\vartheta} =\frac{\sum^k_{i=1}w_i\theta_i}{\sum^k_{i=1}w_i}
\]

This weighted average will be an unbiased estimate of the population
effect size. However, even though this mean effect size is more precise
compared to single-study estimates, it is not exempt from error itself.
In the fixed-effects model, we can obtain the standard error of our
estimate of the population effect size using,

\[
SE_\hat{\vartheta} = \sqrt{\frac{\sigma^2_\varepsilon}{k}}
\] The standard error can be used to comput the 95\% confidence
intervals of the meta-analytic point estimate:

\[
\vartheta_{\text{Lower}} = \hat{\vartheta}- 1.96 \cdot SE_\hat{\vartheta}
\] \[
\vartheta_{\text{Upper}} = \hat{\vartheta}+ 1.96\cdot SE_\hat{\vartheta}
\]

\hypertarget{sec-fixed-corr}{%
\subsection{Fixed Effects Meta-Analysis of
Correlations}\label{sec-fixed-corr}}

To apply the general case in the previous section to correlation
coefficients, lets define our model similarly to
Equation~\ref{eq-fixed-mdl},

\[
r_i=\rho+\varepsilon_i.
\]

Where \(r_i\) is our sample (study) correlation and \(\rho\) is the
population correlation. We can breakdown the variance components the
same way as we did in the general case,

\[
\sigma^2_r = \sigma^2_\rho + \sigma^2_\varepsilon
\]

For each sample correlation, the large sample formulation for sampling
variance is,

\begin{equation}\protect\hypertarget{eq-fixed-cor-se}{}{
\sigma^2_{\varepsilon_i} = \frac{\left(1-\rho^2\right)^2}{n_i}
}\label{eq-fixed-cor-se}\end{equation}

Note that formulation includes the population correlation, which is
unknown. Also notice that, since the population correlation is fixed,
the inverse sampling variance would be proportional to the sample size
(\(1/\sigma_{\varepsilon_i} \propto n_i\)). For this reason, we can use
the sample size as our weights. We can estimate the population
correlation, \(\rho\), by taking the \(n\)-weighted average,

\[
\hat{\rho} = \frac{\sum^k_{i=1} n_i r_i}{\sum^k_{i=1}n_i}
\]

We can use this estimate of the population correlation in the equation
in Equation~\ref{eq-fixed-cor-se} to estimate the sampling variance for
each study.

\[
\sigma^2_{\varepsilon_i} = \frac{\left(1-\hat{\rho}^2\right)^2}{n_i}
\] We also can acquire the standard error of our population correlation
estimate (\(\hat{\rho}\)). To do so, we must first calculate the
weighted average of the sampling variance from each study,

\[
\sigma_\varepsilon^2 = \frac{\sum^k_{i=1} n_i \sigma^2_{\varepsilon_i}}{\sum^k_{i=1}n_i}
\]

then we can calculate the standard error of the population correlation
from this by dividing by the number of studies, \(k\),

\[
SE_\hat{\rho} = \sqrt{\frac{\sigma^2_{\varepsilon}}{k}}
\]

The standard error can be used to comput the 95\% confidence intervals
of the meta-analytic point estimate:

\[
\rho_{\text{Lower}} = \hat{\rho}- 1.96 \cdot SE_\hat{\rho}
\] \[
\rho_{\text{Upper}} = \hat{\rho}+ 1.96\cdot SE_\hat{\rho}
\]

\hypertarget{fixed-effects-meta-analysis-of-d-values}{%
\subsection{\texorpdfstring{Fixed Effects Meta-Analysis of \emph{d}
values}{Fixed Effects Meta-Analysis of d values}}\label{fixed-effects-meta-analysis-of-d-values}}

Similar to Equation~\ref{eq-fixed-mdl}, we can model sample standardized
mean differences similarly,

\[
d_i = \delta + \varepsilon_i
\]

The most staightforward method for meta-analyzing standardized mean
differences (i.e., \(d\) values) is to first convert all the sample
\(d\) values to point-biserial correlations by using,

\[
r_i = \frac{d_i}{\sqrt{\frac{1}{p_i(1-p_i)}+d_i^2}}
\]

Where \(p_i\) is the observed proportion of group membership in either
group \(A\) or group \(B\). The sampling variance of the study
standardized mean difference is defined as

\[
\sigma_{\varepsilon_di} = \frac{n_A+n_B}{n_A n_B} + \frac{d_i^2}{2(n_A+n_B)}
\]

Which can then be converted to the standard error of the point-biserial
correlation,

\[
\sigma^2_{\varepsilon_ri} =\frac{\sigma_{\varepsilon_di}^2}{\left(d_i^2p_i[1-p_i]+1\right)\left(\frac{1}{p_i(1-p_i)}+d_i^2\right)}
\]

Note that the subscripts, \(r\) and \(d\) denote the sampling variances
for correlations and \(d\) values respectively. Once the \(d\) values
and sampling variances are converted to point-biserial correlations, the
meta-analysis can then be conducted by using the methods from
Section~\ref{sec-fixed-corr}. Once the meta-analysis is completed, the
estimate of the population correlation and it's standard error can be
converted back to a \(d\) value using the weighted average proportion of
individuals in group \(A\) or \(B\) (\(\bar{p}\)),

\[
\hat{\delta} = \frac{\hat{\rho}}{\sqrt{\bar{p}(1-\bar{p})(1-\hat{\rho}^2)}}
\]

\[
SE_{\hat{\delta}} = \sqrt{\frac{\sigma_\varepsilon^2}{k\,\bar{p}(1-\bar{p})(1-\hat{\rho}^2)^3}}
\]

Where \(k\) is the number of studies. The standard error can be used to
comput the 95\% confidence intervals of the meta-analytic point
estimate:

\[
\delta_{\text{Lower}} = \hat{\delta}- 1.96 \cdot SE_\hat{\delta}
\] \[
\delta_{\text{Upper}} = \hat{\delta}+ 1.96\cdot SE_\hat{\delta}
\]

\hypertarget{example-from-roth-et-al.-2015}{%
\subsection{Example from Roth et
al.~(2015)}\label{example-from-roth-et-al.-2015}}

Lets use a meta-analytic data set investigating the correlation of
school grades and intelligence test scores from Roth (2015). This data
set has correlation coefficients from \(k=240\) studies (total sample
size: \(n=105,151\)) and is available within the developmental version
of the \texttt{psychmeta} package (Dahlke and Wiernik 2019). Note that
there is substantial heterogeneity in effect sizes here, far more than
what could be accounted for by sampling error alone, but for the sake of
this example we will assume that there is no heterogeneity. Lets conduct
a common effect meta-analysis using the equations from the previous
section:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load in packages (we need the development version of psychmeta)}
\CommentTok{\# install.packages("devtools")}
\CommentTok{\# devtools::install\_github("psychmeta/psychmeta")}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# obtain data for correlations (r) amd sample size (n)}
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{rxyi}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(r)}

\CommentTok{\# calculate the sample size weighted average of r}
\NormalTok{r\_bar }\OtherTok{=} \FunctionTok{sum}\NormalTok{(r}\SpecialCharTok{*}\NormalTok{n) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)}

\CommentTok{\# calculate the sampling variance for each study}
\NormalTok{var\_ei }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{r\_bar}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ n}

\CommentTok{\# estimate the mean population correlation}
\NormalTok{rho\_hat }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(r}\SpecialCharTok{*}\NormalTok{n) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)}

\CommentTok{\# calculate the variance in study correlations (r)}
\NormalTok{var\_r }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{(r}\SpecialCharTok{{-}}\NormalTok{rho\_hat)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)}

\CommentTok{\# calculate average sampling variance}
\NormalTok{var\_e }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{var\_ei) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)}

\CommentTok{\# calculate the variance in true population correlations}
\NormalTok{var\_rho }\OtherTok{\textless{}{-}}\NormalTok{ var\_r }\SpecialCharTok{{-}}\NormalTok{ var\_e}

\CommentTok{\# calculate standard error of rho estimate}
\NormalTok{SE\_rho }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(var\_r}\SpecialCharTok{/}\NormalTok{k)}

\CommentTok{\# compute confidence interval}
\NormalTok{CI\_lower }\OtherTok{=}\NormalTok{ rho\_hat }\SpecialCharTok{{-}} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{975}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SE\_rho}
\NormalTok{CI\_upper }\OtherTok{=}\NormalTok{ rho\_hat }\SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{975}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SE\_rho}

\CommentTok{\# print results}
\FunctionTok{data.frame}\NormalTok{(rho\_hat,}
           \AttributeTok{SE =}\NormalTok{ SE\_rho,}
\NormalTok{           CI\_lower,}
\NormalTok{           CI\_upper)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    rho_hat         SE  CI_lower  CI_upper
1 0.4413862 0.01188354 0.4180949 0.4646775
\end{verbatim}

Due to the massive sample size and the assumption that there is no
variation in population correlations (i.e., fixed effects), the standard
error is quite small. We can also use the \texttt{metafor} package
(Viechtbauer 2010) to conduct a fixed effects meta-analysis without
having to write each equation by hand.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages("metafor")}
\FunctionTok{library}\NormalTok{(metafor)}

\CommentTok{\# fixed effects model}
\NormalTok{mdl }\OtherTok{\textless{}{-}} \FunctionTok{rma}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data\_r\_roth\_2015,}
           \AttributeTok{yi =}\NormalTok{ rxyi,}
           \AttributeTok{vi =}\NormalTok{ var\_ei,}
           \AttributeTok{method =} \StringTok{\textquotesingle{}EE\textquotesingle{}}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{rho\_hat =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{b[}\DecValTok{1}\NormalTok{],}
           \AttributeTok{SE =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{se[}\DecValTok{1}\NormalTok{],}
           \AttributeTok{CI\_lower =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{ci.lb[}\DecValTok{1}\NormalTok{],}
           \AttributeTok{CI\_upper =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{ci.ub[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    rho_hat          SE  CI_lower  CI_upper
1 0.4413862 0.002483049 0.4365195 0.4462529
\end{verbatim}

\hypertarget{random-effects-model}{%
\section{Random Effects Model}\label{random-effects-model}}

The random-effects model refers to a model that allows for the
population effect size to vary from study to study. Random-effects
differs from the fixed effects model in an important way: it does not
assume that all observed effect sizes come from a single (fixed)
population effect size (Borenstein et al. 2010). This variation in
population effect sizes is called heterogeneity. In the traditional J.
E. Hunter and Schmidt (1990) the weights utilized in the random effects
meta-analysis are identical to the common effect version (sample size
weights). In other conventional meta-analysis methods (Hedges and Vevea
1998), random-effect weights include a random effect component
containing the variation in population effect sizes (this has the effect
of making study weights more similar to each other with more variation
in population effects). A modern approach introduced by Morris et al.
(2014) and later tested by Brannick et al. (2019), combined these two
approaches. The simulation study by Brannick et al. (2019), concluded
that weights incorporating random effect components improved the J. E.
Hunter and Schmidt (1990) estimates. This section will thus use Morris's
method.

\begin{figure}

{\centering \includegraphics{figure/random_effects_diagram.png}

}

\caption{The diagram above depicts a random-effects meta-analysis of
five studies. The study effect sizes are heterogeneous as population
effect sizes vary.}

\end{figure}

\hypertarget{the-general-case-1}{%
\subsection{The General Case}\label{the-general-case-1}}

The model from Equation~\ref{eq-fixed-mdl} can be changed slightly to
encompass variation of the population effect size from study to study:

\[
\theta_i = \vartheta_i + \varepsilon_i.
\]

In the common effect model, we assumed that all the variation in study
effect sizes is accounted for by variation in sampling error
(\(\sigma^2_\theta = \sigma^2_\varepsilon\); see
Equation~\ref{eq-var-fixed}). However in the random-effects model the
variance in population effect sizes (\(\sigma^2_\vartheta\)) is allowed
to be greater than zero. The variance components can be written out as

\begin{equation}\protect\hypertarget{eq-var-random}{}{
\sigma^2_\theta=\sigma^2_\vartheta + \sigma^2_\varepsilon.
}\label{eq-var-random}\end{equation}

The variance of population effects, \(\sigma^2_\vartheta\), can be
calculated by first calculating \(\sigma^2_\theta\) and
\(\sigma^2_\varepsilon\). Since the variation in study effect sizes is
no longer solely accounted for by sampling error, this would suggest
that \(\sigma^2_\theta \neq \sigma^2_\varepsilon\), therefore we must
calculate them separately. First we need to calculate study weights
using the inverse of the sampling variance and a the variance in
population effect sizes (i.e., the random effect component) from each
study,

\[
w_i = \frac{1}{\sigma^2_{\varepsilon_i}+\sigma_\vartheta^2}
\]

In order to estimate random effects component, \(\sigma_\vartheta^2\)
(i.e., the variance in population effect sizes), we can calculate it by
subtracting the average sampling variance (\(\sigma^2_\varepsilon\))
from the the observed variance in effect sizes (\(\sigma^2_\theta\)).
The problem however is that in order to calculate the variance
components, we need estimates of the population effect size and the
weights, and in order to calculate the population effect size and the
weights, we need the variance components. So instead, we will use sample
size weights and the sample size weighted mean effect size
(\(\bar{\theta}\)) as an estimate of the population correlation to
estimate the weights:

\[
w_i = \frac{1}{\sigma^2_{\varepsilon_i}+\sigma_\vartheta^2} = \frac{1}{\sigma^2_{\varepsilon_i}+(\sigma^2_{\theta}-\sigma^2_{\varepsilon})} \approx \frac{1}{\sigma^2_{\varepsilon_i}+\left(\frac{\sum^k_{i=1}n_i(\theta_i - \bar{\theta})^2}{\sum^k_{i=1}n_i}-\frac{\sum^k_{i=1}n_i\sigma^2_{\varepsilon_i}}{\sum^k_{i=1}n_i}\right)}
\]

Now with these weights, we can calculate a more precise estimate of the
mean population effect size,

\[
\hat{\bar{\vartheta}} = \frac{\sum^k_{i=1}w_i\theta_i}{\sum^k_{i=1}w_i}
\]

With these weights and the estimate of the population effect size, we
can now estimate each of the three variance components from
Equation~\ref{eq-var-random}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  variance in study effect sizes \[
  \sigma^2_{\theta}=\frac{\sum^k_{i=1}w_i(\theta_i - \hat{\bar{\vartheta}})}{\sum^k_{i=1}w_i}
  \]
\item
  sampling error variance (mean) \[
  \sigma^2_{\varepsilon} = \frac{\sum^k_{i=1}w_i\sigma^2_{\varepsilon_i}}{\sum^k_{i=1}w_i}
  \]
\item
  variance in true effect sizes \[
  \sigma^2_{\vartheta} = \sigma^2_{\theta} - \sigma^2_{\varepsilon}
  \]
\end{enumerate}

In other conventions, \(\sigma^2_\vartheta\) is denoted as \(\tau^2\)
(Borenstein et al. 2010; DerSimonian and Kacker 2007; Hedges and Vevea
1998), but conceptually these are identical. Taking the root of
\(\sigma^2_\vartheta\), \(\sigma_\vartheta\), is the standard deviation
of population effect sizes which can be a useful measure of
heterogeneity. Furthermore, we can use \(\sigma_\vartheta\) to calculate
credibility (prediction) intervals which allows us to draw inferences
about the range of plausible population effect sizes. For example, the
90\% credibility interval can be calculated with the following
equations:

\[
\vartheta_\text{Upper} = \hat{\bar{\vartheta}} + 1.645\sigma_\vartheta
\]

\[
\vartheta_\text{Lower} = \hat{\bar{\vartheta}} - 1.645\sigma_\vartheta
\]

We can also calculate the standard error of the mean of population
effect sizes (\(SE_{\hat{\bar{\vartheta}}}\)) by dividing the sampling
error variance component by the number of studies, \(k\),

\[
SE_\hat{\bar{\vartheta}} = \sqrt{\frac{\sigma^2_\theta}{k}}
\]

Which can then be used to calculate 95\% confidence intervals:

\[
\bar{\vartheta}_\text{Upper} = \hat{\bar{\vartheta}} + 1.96\cdot SE_\hat{\bar{\vartheta}}
\]

\[
\bar{\vartheta}_\text{Lower} = \hat{\bar{\vartheta}} - 1.96\cdot SE_\hat{\bar{\vartheta}}
\]

The confidence interval and credibility interval have fundamentally
different interpretations that are often misinterpreted in published
work (Whitener 1990). When we are interpreting a single realized
interval (i.e., our estimate-in-hand), the 90\% credibility interval can
be interpreted as the region in which 90\% of population effect sizes
exist, however, a 95\% confidence interval describes the interval in
which there is a 95\% probability of containing the true mean of
population effect sizes. It is important to note that the confidence
interval interpretation here is only valid in the case of a single
realized interval (Vos and Holbert 2022), if there is more than one
computed intervals the same population of studies, then the
interpretation does not hold (this would be an exceedingly rare scenario
in a meta-analysis).

\hypertarget{sec-random-corr}{%
\subsection{Random Effects Meta-Analysis of
Correlations}\label{sec-random-corr}}

Lets now specifically apply the random effects model to pearson
correlation coefficients. Let us again start by defining the
meta-analytic model allowing the population correlation to vary for each
study,

\[
r_i = \rho_i + \varepsilon_i
\]

Where it's corresponding variance components are defined similarly as,

\[
\sigma^2_r = \sigma^2_\rho + \sigma^2_\varepsilon
\]

Like in the general case, we must calculate the study weights using the
method by Morris et al. (2014) and further described in Brannick et al.
(2019). The weights are a function of the study-level sampling variance
(\(\sigma^2_{\varepsilon_i}\)) and the variance in population
correlations (\(\sigma^2_{\rho}\)).

\[
w_i = \frac{1}{\sigma^2_{\varepsilon_i}+\sigma^2_{\rho}}
\] However as described in the last section, to estimate the variance in
population effect sizes (\(\sigma^2_{\rho}\)), we need estimates of the
mean of true population effect sizes and the weights, but to get both
those parameters, we need the weights. In order to get around this
dilemma we can instead replace the weights with \(n_i\) and the mean of
population correlations with the \(n\)-weighted average correlation
(\(\bar{r}\)). Lets first define the sampling variance for a pearson
correlation:

\[
\sigma^2_{\varepsilon_i} = \frac{\left(1-\rho^2\right)^2}{n_i}
\] Therefore we can approximate the weights with,

\[
w_i = \frac{1}{\sigma^2_{\varepsilon_i}+\sigma_\vartheta^2} = \frac{1}{\sigma^2_{\varepsilon_i}+(\sigma^2_{\theta}-\sigma^2_{\varepsilon})} \approx \frac{1}{\sigma^2_{\varepsilon_i}+\left(\frac{\sum^k_{i=1}n_i(r_i - \bar{r})^2}{\sum^k_{i=1}n_i}-\frac{\sum^k_{i=1}n_i\sigma^2_{\varepsilon_i}}{\sum^k_{i=1}n_i}\right)}
\]

With the weights we can estimate a precise estimate of the mean of
population correlations (\(\bar{\rho}\))

\[
\hat{\bar{\rho}} = \frac{\sum^k_{i=1}w_ir_i}{\sum^k_{i=1}w_i}
\]

Where the variance components can be calculated as:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Variance in study correlations: \[
  \sigma^2_{r}=\frac{\sum^k_{i=1}w_i(r_i - \hat{\bar{\rho}})}{\sum^k_{i=1}w_i}.
  \]
\item
  Sampling error variance (mean): \[
  \sigma^2_{\varepsilon} = \frac{\sum^k_{i=1}w_i\sigma^2_{\varepsilon_i}}{\sum^k_{i=1}w_i}.
  \]
\item
  Variance in population correlations: \[
  \sigma^2_\rho = \sigma^2_r - \sigma^2_{\varepsilon}.
  \]
\end{enumerate}

Now lets use these variance components to calculate the 90\% credibility
(prediction) interval and the 95\% confidence interval. The 90\%
credibility interval can be calculated with the following equations:

\[
\rho_\text{Upper} = \hat{\bar{\rho}} + 1.645\sigma_\rho
\]

\[
\rho_\text{Lower} = \hat{\bar{\rho}} - 1.645\sigma_\rho
\]

We can also calculate the standard error of the mean of population
effect sizes (\(SE_{\hat{\bar{\rho}}}\)) by dividing the sampling error
variance component by the number of studies, \(k\),

\[
SE_\hat{\bar{\rho}} = \sqrt{\frac{\sigma^2_r}{k}}
\]

Which can then be used to calculate 95\% confidence intervals:

\[
\bar{\rho}_\text{Upper} = \hat{\bar{\rho}} + 1.96\cdot SE_\hat{\bar{\rho}}
\]

\[
\bar{\rho}_\text{Lower} = \hat{\bar{\rho}} - 1.96\cdot SE_\hat{\bar{\rho}}
\]

\hypertarget{sec-random-d}{%
\subsection{\texorpdfstring{Random Effects Meta-Analysis of \emph{d}
values}{Random Effects Meta-Analysis of d values}}\label{sec-random-d}}

We can model sample standardized mean differences similarly to that of
correlations,

\[
d_i = \delta_i + \varepsilon_i
\]

Like we did in the common effect model, instead of meta-analyzing the
\(d\) values, we can instead convert all the sample \(d\) values to
point-biserial correlations by using,

\[
r_i = \frac{d_i}{\sqrt{\frac{1}{p_i(1-p_i)}+d_i^2}}
\]

Where \(p_i\) is the observed proportion of group membership in either
group \(A\) or group \(B\). The sampling variance of the study
standardized mean difference can be defined as

\[
\sigma^2_{\varepsilon_id} = \frac{n_A+n_B}{n_A n_B} + \frac{\delta_i^2}{2(n_A+n_B)}
\] Where the population standardized mean difference, \(\delta_i\) can
be approximated with the sample size weighted mean \(d\) value
(\(\bar{d}\)).

\[
\sigma^2_{\varepsilon_id} = \frac{n_A+n_B}{n_A n_B} + \frac{\bar{d}^2}{2(n_A+n_B)}
\]

Which can then be converted to the standard error of the point-biserial
correlation,

\[
\sigma^2_{\varepsilon_ir} =\frac{\sigma_{\varepsilon_id}^2}{\left(d_i^2p_i[1-p_i]+1\right)\left(\frac{1}{p_i(1-p_i)}+d_i^2\right)}
\]

The subscripts, \(r\) and \(d\) denote the sampling variances for
correlations and \(d\) values respectively. Once the \(d\) values and
sampling variances are converted to point-biserial correlations, the
meta-analysis can then be conducted by using the methods from
Section~\ref{sec-fixed-corr}. Once the meta-analysis is completed, the
estimate of the population correlation and it's standard error can be
converted back to a \(d\) value,

\[
\hat{\bar{\delta}} = \frac{\hat{\bar{\rho}}}{\sqrt{\bar{p}(1-\bar{p})(1-\hat{\bar{\rho}}^2)}}
\]

\[
SE_{\hat{\bar{\delta}}}= \sqrt{\frac{\sigma_r^2}{k\, \bar{p}\left(1-\bar{p}\right)\left(1-\hat{\bar{\rho}}^2\right)^3}}
\]

Where \(k\) is the number of studies. Likewise we can also convert the
variance of the population correlations to the standard deviation of
population standardized mean differences.

\[
\sigma_\delta = \sqrt{\frac{\sigma_\rho^2}{\bar{p}(1-\bar{p})(1-\hat{\rho}^2)^3}}
\]

\hypertarget{random-effects-meta-analysis-in-r}{%
\subsection{Random Effects Meta-Analysis in
R}\label{random-effects-meta-analysis-in-r}}

Lets conduct a random effects meta-analysis using the equations from the
previous section and the data set we used earlier (Roth 2015). For this
dataset, it is more appropriate to use a random-effects model due to the
large amount of heterogeneity we observe in the correlations.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load in packages (we need the development version of psychmeta)}
\CommentTok{\# install.packages("devtools")}
\CommentTok{\# devtools::install\_github("psychmeta/psychmeta")}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# obtain data for correlations (r) amd sample size (n)}
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{rxyi}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(r)}

\CommentTok{\# calculate the sample size weighted average of r}
\NormalTok{r\_bar }\OtherTok{=} \FunctionTok{sum}\NormalTok{(r}\SpecialCharTok{*}\NormalTok{n) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)}

\CommentTok{\# calculate the sampling variance for each study}
\NormalTok{var\_ei }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{r\_bar}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ n}

\CommentTok{\# calculate weights}
\NormalTok{w }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ (var\_ei }\SpecialCharTok{+}\NormalTok{ ( (}\FunctionTok{sum}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{(r}\SpecialCharTok{{-}}\NormalTok{r\_bar)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(n)) }\SpecialCharTok{{-}}\NormalTok{ (}\FunctionTok{sum}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{var\_ei)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(n)) ) )}

\CommentTok{\# estimate the mean population correlation}
\NormalTok{mean\_rho\_hat }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(r}\SpecialCharTok{*}\NormalTok{w) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(w)}

\CommentTok{\# calculate the variance in study correlations (r)}
\NormalTok{var\_r }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w}\SpecialCharTok{*}\NormalTok{(r}\SpecialCharTok{{-}}\NormalTok{mean\_rho\_hat)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(w)}

\CommentTok{\# calculate average sampling variance}
\NormalTok{var\_e }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w}\SpecialCharTok{*}\NormalTok{var\_ei) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(w)}

\CommentTok{\# calculate the variance in population correlations}
\NormalTok{var\_rho }\OtherTok{\textless{}{-}}\NormalTok{ var\_r }\SpecialCharTok{{-}}\NormalTok{ var\_e}

\CommentTok{\# calculate standard error of rho estimate}
\NormalTok{SE\_rho }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(var\_r}\SpecialCharTok{/}\NormalTok{k)}

\CommentTok{\# compute 95\% confidence interval}
\NormalTok{CI\_lower }\OtherTok{=}\NormalTok{ mean\_rho\_hat }\SpecialCharTok{{-}} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{975}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SE\_rho}
\NormalTok{CI\_upper }\OtherTok{=}\NormalTok{ mean\_rho\_hat }\SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{975}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SE\_rho}

\CommentTok{\# compute 90\% credibility interval}
\NormalTok{CR\_lower }\OtherTok{=}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{b[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(var\_rho)}
\NormalTok{CR\_upper }\OtherTok{=}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{b[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(var\_rho)}

\CommentTok{\# print results}
\FunctionTok{data.frame}\NormalTok{(mean\_rho\_hat,}
           \AttributeTok{SE =}\NormalTok{ SE\_rho,}
\NormalTok{           CI\_lower,}
\NormalTok{           CI\_upper,}
           \AttributeTok{SD\_rho =} \FunctionTok{sqrt}\NormalTok{(var\_rho),}
\NormalTok{           CR\_lower,}
\NormalTok{           CR\_upper)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  mean_rho_hat         SE  CI_lower  CI_upper    SD_rho  CR_lower  CR_upper
1    0.4265249 0.01131785 0.4043424 0.4487075 0.1601417 0.1779766 0.7047958
\end{verbatim}

Notice that the standard error of the mean correlation is larger than
the common effects model. The reason for this disparity, is that the
random effects model has two sources of variance, sampling error and
variance in true correlations. We can also use the \texttt{metafor}
package (Viechtbauer 2010) to conduct a random effects meta-analysis.
The method used in the previous sections is not available in metafor so
slight deviations with the resulting statistics may occur.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages("metafor")}
\FunctionTok{library}\NormalTok{(metafor)}

\CommentTok{\# fixed effects model}
\NormalTok{mdl }\OtherTok{\textless{}{-}} \FunctionTok{rma}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data\_r\_roth\_2015,}
           \AttributeTok{yi =}\NormalTok{ rxyi,}
           \AttributeTok{vi =}\NormalTok{ var\_ei,}
           \AttributeTok{method =} \StringTok{\textquotesingle{}HS\textquotesingle{}}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{mean\_rho\_hat =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{b[}\DecValTok{1}\NormalTok{],}
           \AttributeTok{SE =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{se[}\DecValTok{1}\NormalTok{],}
           \AttributeTok{CI\_LO =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{ci.lb[}\DecValTok{1}\NormalTok{],}
           \AttributeTok{CI\_HI =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{ci.ub[}\DecValTok{1}\NormalTok{],}
           \AttributeTok{SD\_rho =} \FunctionTok{sqrt}\NormalTok{(mdl}\SpecialCharTok{$}\NormalTok{tau2),}
           \AttributeTok{CR\_LO =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{b[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(mdl}\SpecialCharTok{$}\NormalTok{tau2),}
           \AttributeTok{CR\_HI =}\NormalTok{ mdl}\SpecialCharTok{$}\NormalTok{b[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(mdl}\SpecialCharTok{$}\NormalTok{tau2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  mean_rho_hat         SE     CI_LO     CI_HI    SD_rho     CR_LO     CR_HI
1    0.4265249 0.01250165 0.4020222 0.4510277 0.1800354 0.1303931 0.7226568
\end{verbatim}

\hypertarget{sec-artifact}{%
\chapter{Artifact Correction Meta-Analysis}\label{sec-artifact}}

\hypertarget{introduction-8}{%
\section{Introduction}\label{introduction-8}}

Artifact correction meta-analysis, also referred to as psychometric
meta-analysis, is a form of meta-analysis where effect sizes are
systematically corrected for sources of bias. These sources of bias have
been discussed in previous chapters 4-10. Methodology for conducting
artifact correction style meta-analyses were originally pioneered by
Frank Schmidt and John Hunter (J. E. Hunter and Schmidt 1990; Schmidt
and Hunter 1977) and then reviewed more recently by Brenton Wiernik and
Jeffrey Dahlke (Wiernik and Dahlke 2020). There has also been powerful R
packages developed to aide in the application of artifact correction
meta-analyses that we have used in previous chapters (Dahlke and Wiernik
2019). You will notice that in this section, we do not discuss
standardized mean differences. This is due to the fact that the artifact
correction model is designed for pearson correlations, in order to use
this method for standardized mean differences, convert to pearson
correlations using the methods described in chapter 11, and then use the
correction methods used below. Once you apply the corrections to the
converted correlations they can then be converted back to a standardized
mean difference.

\hypertarget{bare-bones-vs-artifact-correction-meta-analysis}{%
\section{Bare Bones vs Artifact Correction
Meta-Analysis}\label{bare-bones-vs-artifact-correction-meta-analysis}}

This is because even if the estimates are biased relative to our
estimand (i.e., the thing we are trying to estimate), the observed value
still has its own population value. Chapter 11 focused on bare-bones
meta-analysis, that is, meta-analyses that do not correct for biases in
effect size estimates. This section will be dedicated to the artifact
correction style of meta-analysis that does aim to correct for such
artifactual biases. The choice between these two types of meta-analyses
depends on the research question, the available data, and the
assumptions researchers are willing to make. If the goal is to
investigate the state of the quantitative evidence while avoiding
additional assumptions about the data, then a bare-bones meta-analysis
might be the way to go. On the other hand, if the goal is to obtain a
more accurate estimate of the true effect size by accounting for biases
induced by statistical artifacts, an artifact correction meta-analysis
is preferable.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Bare-Bones Meta-Analysis: In a bare-bones meta-analysis, the focus is
  on aggregating effect sizes from various studies without explicitly
  correcting for potential biases in these effect size estimates.
\item
  Artifact Correction Meta-Analysis: In contrast, an artifact correction
  meta-analysis takes into account and attempts to correct for biases
  that may be present in the effect size estimates from individual
  studies. This involves addressing potential sources of bias, such as
  measurement error or selection effects, through statistical techniques
  or adjustments. By doing so, the meta-analysis aims to provide a more
  accurate and unbiased estimate of the true effect size. Although it is
  important to note that this method will require additional assumptions
  about the nature of the data.
\end{enumerate}

Note that the bare-bones model does not assume that there is no bias,
rather, the bare-bones model is estimating something else entirely, that
is, the observed population effect size.

\includegraphics{figure/correction_forest.png}

\hypertarget{individual-artifact-correction-model}{%
\section{Individual Artifact Correction
Model}\label{individual-artifact-correction-model}}

The individual artifact correction model corrects each effect size
individually prior to conducting the meta-analysis. This method is ideal
if we have high-quality artifact estimates for most/all studies in the
meta-analysis. If there is a substantial amount of missingness in the
artifact values, then the artifact distribution model may be a better
choice.

\hypertarget{the-general-case-2}{%
\subsection{The General Case}\label{the-general-case-2}}

Let us recall the random effects model in chapter 11, where
\(\theta_i=\vartheta_i+\varepsilon_i\). This model would be considered a
bare-bones meta-analytic model; we can re-write it slightly to denote
that these are observed values:
\(\theta_{o_i}=\vartheta_{o_i}+\varepsilon_{o_i}\). Ultimately, observed
values tend to be biased relative to true values due to many artifactual
factors, some that we can account for and some we can not. If we decide
that corrections to observed effect sizes are necessary to answer our
research question, then we can construct an artifact correction model.
In the artifact correction framework, we can incorporate a compound
artifact biasing factor, \(A\), to the bare-bones formula such that,

\begin{equation}\protect\hypertarget{eq-art-mdl}{}{
\theta_{o_i} = A_i\vartheta_i + \varepsilon_{o_i}
}\label{eq-art-mdl}\end{equation}

So now instead of the model being in terms of the observed population
value (\(\vartheta_{o_i}\)), it is now in terms of the \emph{true}
population value (\(\vartheta_{i}\)).The compound biasing factor,
\(A_i\) is a product of \(K\) independent artifact values (e.g.,
unreliability and range restriction),

\[
A_i = a_{1i} a_{2i} ... a_{Ki}
\]

This compound artifact formula assumes that the values are independent
of one another, which is not always the case, see chapter 11 on
independence of artifacts. Therefore adjustments must be made to ensure
independence. eq-art-mdl can be re-arranged to obtain unbiased estimates
of the true population effect size:

\begin{equation}\protect\hypertarget{eq-correction-mdl}{}{
\frac{\theta_{o_i}}{A_i} = \vartheta_i + \frac{\varepsilon_{o_i}}{A_i}
}\label{eq-correction-mdl}\end{equation}

This division of \(A_i\) will provide us with our corrected effect size
estimates that we can denote with the subscript, \(c\),

\[
\theta_{c_i} = \frac{\theta_{o_i}}{A_i}
\]

and the corresponding error term must also be corrected

\begin{equation}\protect\hypertarget{eq-error}{}{
\varepsilon_{c_i} = \frac{\varepsilon_{o_i}}{A_i}.
}\label{eq-error}\end{equation}

Therefore Equation~\ref{eq-correction-mdl} can be reformulated as,

\begin{equation}\protect\hypertarget{eq-correction-formula}{}{
\theta_{c_i} = \vartheta_i + \varepsilon_{c_i} 
}\label{eq-correction-formula}\end{equation}

These corrections cause changes in the point estimate and the error
variance of the study effect sizes. Like we saw in chapter 11, we can
breakdown the variance components of the model,

\begin{equation}\protect\hypertarget{eq-corrected-var}{}{
\sigma^2_{\theta_c} = \sigma^2_{\vartheta} + \sigma^2_{\varepsilon_c}
}\label{eq-corrected-var}\end{equation}

To obtain these variance components, we can start by correcting the
observed sampling variances from each study. We can calculate the
corrected sampling variance (\(\sigma^2_{\varepsilon_c}\)) by first
correcting each study-level sampling variance estimate,

\[
\sigma^2_{\varepsilon_ci} = \frac{\sigma^2_{\varepsilon_oi}}{A^2_i}
\] This may also be done by using the corrected effect size and the
observed effect size to correct the sampling variance:

\[
\sigma^2_{\varepsilon_ci} = \sigma^2_{\varepsilon_oi} \left(\frac{\theta_{c_i}}{\theta_{o_i}}\right)^2
\]

The next step is to obtain the random effects weights of the study, we
can do this with the inverse corrected variance for each study,
\(w_i=1/(\sigma^2_{\varepsilon_ci}+\sigma^2_\rho)\). From here we can
calculate our estimate of the mean of true population correlations,

\[
\hat{\bar{\vartheta}}=\frac{\sum^k_{i=1}n_i\theta_{c_i}}{\sum^k_{i=1}n_i}
\]

Remember that because this is a random effects model,
\(\hat{\bar{\vartheta}}\) is not an estimate of the true population
effect size, instead it is an estimate of the mean of a distribution of
true population effect sizes. Now that we have an estimate of the mean
and the corrected sampling variances, the variance components from
Equation~\ref{eq-corrected-var} can be easily calculated as follows:

\[
\sigma^2_{\theta_c} = \frac{\sum^k_{i=1}n_i(\theta_{c_i} - \hat{\bar{\vartheta}})^2}{\sum^k_{i=1}n_i}
\]

\[
\sigma^2_{\varepsilon_c} = \frac{\sum^k_{i=1}n_i\sigma^2_{\varepsilon_c i}}{\sum^k_{i=1}n_i}
\]

\[
\sigma^2_{\vartheta}  = \sigma^2_{\theta_c} - \sigma^2_{\varepsilon_c}
\]

The standard deviation of true effects is a useful measure of
heterogeneity and is simply the square root of the variance of true
population effect sizes (\(\sigma_{\vartheta}\)). From the standard
deviation in true effects, we can also calculate a credibility
(prediction) interval that shows the range of plausible values for which
a true effect size is likely to fall,

\[
\vartheta_{\text{Upper}} = \hat{\bar{\vartheta}} + 1.645\sigma_\vartheta
\]

\[
\vartheta_{\text{Lower}} = \hat{\bar{\vartheta}} - 1.645\sigma_\vartheta\, .
\]

Note that this is not to be confused with \emph{confidence} intervals
which denotes the range of plausible values that the \emph{mean} of true
effects can take on. This differentiation is akin to understanding the
disparity between the standard error of the mean and the standard
deviation in the context of a normal distribution. We can also see how
the corrections reduced the heterogeneity in the effect size estimates
by comparing variance in true effect sizes (\(\sigma^2_{\vartheta_o}\))
to the variance in observed effect sizes (\(\sigma^2_{\vartheta_o}\);
this can be calculated by conducting a bare-bones random effects
meta-analysis described in chapter 11). The percent reduction in
heterogeneity can be computed by taking the ratio of the two,
\(\sigma^2_{\vartheta}/\sigma^2_{\vartheta_o}\). J. E. Hunter and
Schmidt (1990) suggest that if 75\% of the heterogeneity is accounted
for by artifact corrections, then we can assume that the remaining
heterogeneity is attributable to remaining artifacts that have not been
addressed in the current meta-analysis. Although it is important to
point out that this is simply a rule of thumb rather than a mathematical
property.

\hypertarget{individual-corrections-in-correlations}{%
\subsection{Individual Corrections in
Correlations}\label{individual-corrections-in-correlations}}

For correlation coefficients we can define the model similarly to
Equation~\ref{eq-art-mdl}, with the only difference being that we will
use the notation for pearson correlations,

\[
r_{o_i} = A_i\rho_i + \varepsilon_{o_i}
\]

The artifact correction formulation of this, corresponding to
Equation~\ref{eq-correction-formula}, would be

\[
r_{c_i} = \rho_i + \varepsilon_{c_i}
\]

The corresponding variance components would then be,

\[
\sigma^2_{r_c} = \sigma^2_\rho + \sigma^2_{\varepsilon_c}
\]

In order to compute the variance components as well as the mean true
population correlation, we first need to calculate the study weights. We
will follow a similar procedure for calculating random effects weights
in chapter 11. Lets define the corrected random effects weights as,

\$\$

w\_i = \frac{1}{\sigma^2_{\varepsilon_ci}+\sigma_\rho^2}.

\[
However the variance components, $\sigma^2_{\varepsilon_ci}$ and $\sigma^2_\rho$, require the weights themselves to actually estimate them, so instead we can approximate the variance components using the sample size as the weights such that,
\] w\_i =\frac{1}{\sigma^2_{\varepsilon_ci}+\sigma_\rho^2}=
\frac{1}{\sigma^2_{\varepsilon_ci}+(\sigma^2_{r_c}-\sigma^2_{\varepsilon})}
\approx \frac{1}{\sigma^2_{\varepsilon_ci}+\left(\frac{\sum^k_{i=1}n_i(r_{c_i} - \bar{r}_c)^2}{\sum^k_{i=1}n_i}-\frac{\sum^k_{i=1}n_i\sigma^2_{\varepsilon_ci}}{\sum^k_{i=1}n_i}\right)}
\$\$

Where \(\bar{r}_c\) is the sample size weighted average corrected
correlation. These weights can then be used to obtain a more precise
estimate of the true population correlation,

\[
\hat{\bar{\rho}}=\frac{\sum_{i=1}^k w_i r_{c_i}}{\sum_{i=1}^k w_i}
\] Now we can compute each of the three variance components:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Variance in corrected correlations:
\end{enumerate}

\[
\sigma^2_{r_c}=\frac{\sum^k_{i=1}w_i(r_{c_i} - \hat{\bar{\rho}})}{\sum^k_{i=1}w_i}.
\] 2) Sampling error variance: \[
\sigma^2_{\varepsilon_c} = \frac{\sum^k_{i=1}w_i\sigma^2_{\varepsilon_ci}}{\sum^k_{i=1}w_i}.
\] 3) Variance in population correlations: \[
\sigma^2_\rho = \sigma^2_r - \sigma^2_{\varepsilon}.
\] Now lets use these variance components to calculate the 90\%
credibility (prediction) interval and the 95\% confidence interval. The
90\% credibility interval can be calculated with the following
equations:

\[
\rho_\text{Upper} = \hat{\bar{\rho}} + 1.645\sigma_\rho
\]

\[
\rho_\text{Lower} = \hat{\bar{\rho}} - 1.645\sigma_\rho
\]

We can also calculate the standard error of the mean of true population
effect sizes (\(SE_{\hat{\bar{\rho}}}\)) by dividing the sampling error
variance component by the number of studies, \(k\),

\[
SE_\hat{\bar{\rho}} = \sqrt{\frac{\sigma^2_{r_c}}{k}}
\]

Which can then be used to calculate 95\% confidence intervals:

\[
\bar{\rho}_\text{Upper} = \hat{\bar{\rho}} + 1.96\cdot SE_\hat{\bar{\rho}}
\]

\[
\bar{\rho}_\text{Lower} = \hat{\bar{\rho}} - 1.96\cdot SE_\hat{\bar{\rho}}
\]

\hypertarget{applied-example-in-r}{%
\subsection{Applied Example in R}\label{applied-example-in-r}}

Lets conduct an individual correction meta-analysis in r using the data
set by Roth (2015). This data set consists of correlations between
school grades and intelligence test scores. It also contains information
on the reliability of the intelligence test scores and the extent of
range restriction in test scores. We can conduct a meta-analysis
correcting for univariate indirect range restriction and measurement
error in test scores. The compound artifact biasing factor for the
correlation would be: \[
A_i=\sqrt{r_{o_i}^2 + \frac{u_{x_i}^2 r_{xx'_i}(r_{xx'_i} - r_{o_i}^2) }{1 - u_{x_i}^2 (1-r_{xx'_i})} }
\] Sticking with our theme of doing everything in base R first, lets use
the equations from the previous section to conduct the meta-analysis.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load in packages (we need the development version of psychmeta)}
\CommentTok{\# install.packages("devtools")}
\CommentTok{\# devtools::install\_github("psychmeta/psychmeta")}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# obtain artifact values}
\NormalTok{rxx }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{rxxi}
\NormalTok{ux }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{ux}
\NormalTok{ro }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{rxyi}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(ro)}

\CommentTok{\# fill in missing artifact values with mean}
\NormalTok{rxx[}\FunctionTok{is.na}\NormalTok{(rxx)] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(rxx,}\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{ux[}\FunctionTok{is.na}\NormalTok{(ux)] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(ux,}\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# calculate compound artifact biasing factor for univariate direct range restriction with measurement error}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(ro}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (ux}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{*}\NormalTok{rxx}\SpecialCharTok{*}\NormalTok{(rxx }\SpecialCharTok{{-}}\NormalTok{ ro}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ ux}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxx)))}

\CommentTok{\# calculate the sample size weighted average of r}
\NormalTok{ro\_bar }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(ro}\SpecialCharTok{*}\NormalTok{n) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)}

\CommentTok{\# calculate the observed sampling variance for each study}
\NormalTok{var\_eoi }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{ro\_bar}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_eci }\OtherTok{\textless{}{-}}\NormalTok{ var\_eoi }\SpecialCharTok{/}\NormalTok{ A}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# calculate corrected correlations}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ ro }\SpecialCharTok{/}\NormalTok{ A}

\CommentTok{\# calculate weights}
\NormalTok{w }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\NormalTok{var\_eci}

\CommentTok{\# calculate population effect size estimate}
\NormalTok{mean\_rho\_hat }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(rc}\SpecialCharTok{*}\NormalTok{w) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(w)}

\CommentTok{\# calculate the variance in corrected correlations (rc)}
\NormalTok{var\_rc }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(w}\SpecialCharTok{*}\NormalTok{(rc }\SpecialCharTok{{-}}\NormalTok{ mean\_rho\_hat)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(w)}

\CommentTok{\# calculate average corrected sampling variance}
\NormalTok{var\_ec }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(var\_eci}\SpecialCharTok{*}\NormalTok{w) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(w)}

\CommentTok{\# calculate the variance in true population correlations}
\NormalTok{var\_rho }\OtherTok{\textless{}{-}}\NormalTok{ var\_rc }\SpecialCharTok{{-}}\NormalTok{ var\_ec}

\CommentTok{\# calculate standard error of rho estimate}
\NormalTok{SE\_rho }\OtherTok{=} \FunctionTok{sqrt}\NormalTok{(var\_rc}\SpecialCharTok{/}\NormalTok{k)}

\CommentTok{\# print results}
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{k =}\NormalTok{ k,}
           \AttributeTok{n =} \FunctionTok{sum}\NormalTok{(n),}
\NormalTok{           mean\_rho\_hat,}
           \AttributeTok{SE =}\NormalTok{ SE\_rho,}
           \AttributeTok{SD\_rho =} \FunctionTok{sqrt}\NormalTok{(var\_rho))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    k      n mean_rho_hat         SE    SD_rho
1 240 105151    0.5398838 0.01339916 0.2022865
\end{verbatim}

The estimated mean correlation of .540 is precisely what is precisely
what the original paper reported (Roth 2015). Lets conduct the
meta-analysis using the the \texttt{psychmeta} package (Dahlke and
Wiernik 2019). The function \texttt{ma\_r\_ic} is designed to conduct an
individual correction meta-analysis on correlation coefficients.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# conduct individual correction meta{-}analysis}
\NormalTok{mdl\_ic }\OtherTok{\textless{}{-}} \FunctionTok{ma\_r\_ic}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ ro, }\AttributeTok{n =}\NormalTok{ n,}
            \AttributeTok{correction\_method =} \StringTok{"uvirr"}\NormalTok{,}
            \AttributeTok{rxx =}\NormalTok{ rxx,}
            \AttributeTok{ux =}\NormalTok{ ux,}
            \AttributeTok{ux\_observed =} \ConstantTok{TRUE}\NormalTok{,}
            \AttributeTok{rxx\_restricted =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{summary\_stats }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{k =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{individual\_correction}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{k,}
                            \AttributeTok{n =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{individual\_correction}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{N,}
                            \AttributeTok{mean\_rho =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{individual\_correction}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{mean\_rho,}
                            \AttributeTok{SE =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{individual\_correction}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{se\_r\_c,}
                            \AttributeTok{SD\_rho =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{individual\_correction}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{sd\_rho)}
\NormalTok{summary\_stats }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    k      n  mean_rho        SE    SD_rho
1 240 105151 0.5404134 0.0134356 0.2036946
\end{verbatim}

We can also obtain credibility intervals by using the
\texttt{credibility} function in the \texttt{psychmeta} package. The
interval defaults to 80\% intervals, however we can change that to 90\%
by inputting .90 into the \texttt{cred\_level} argument.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{credibility}\NormalTok{(}\AttributeTok{mean =}\NormalTok{ summary\_stats}\SpecialCharTok{$}\NormalTok{mean\_rho\_hat,}
            \AttributeTok{sd =}\NormalTok{ summary\_stats}\SpecialCharTok{$}\NormalTok{SD\_rho,}
            \AttributeTok{cred\_method =} \StringTok{"norm"}\NormalTok{,}
            \AttributeTok{cred\_level =}\NormalTok{ .}\DecValTok{90}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     CR_LL_90 CR_UL_90
\end{verbatim}

Lets compare these results to the bare-bones model. In
\texttt{psychmeta} the bare-bones model can be conduced using
\texttt{ma\_r\_bb}. However, the \texttt{ma\_r\_ic} function also
reports the bare-bones results as well. Therefore we can just extract
the necessary statistics from the model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{k =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{k,}
  \AttributeTok{n =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{N,}
  \AttributeTok{mean\_rho\_obs =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{mean\_r,}
  \AttributeTok{SE =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{se\_r,}
  \AttributeTok{SD\_rho\_obs =}\NormalTok{ mdl\_ic}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{sd\_r)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
    k      n mean_rho_obs         SE SD_rho_obs
1 240 105151    0.4418789 0.01191933  0.1846534
\end{verbatim}

We can see that the estimate of the population correlation is largely
attenuated in the observed values. This is due to the fact tests of
intelligence are not perfectly reliable and the scores were restricted
in their range.

\hypertarget{artifact-distribution-model}{%
\section{Artifact Distribution
Model}\label{artifact-distribution-model}}

When we observe a lot of missingness in artifact values (e.g., studies
not reporting reliability), we may choose to use an artifact
distribution model. The artifact distribution model conducts a
meta-analysis on the observed effect sizes and artifact values
separately, and then uses the aggregate artifact values to correct for
the observed mean effect size. Since the artifact distribution method
uses Taylor series approximations (Dahlke and Wiernik 2020) that are
custom-tailored to estimate the sampling variance of corrected
correlations, we will skip the general case to focus on its application
to correlations.

\hypertarget{the-correlational-case}{%
\subsection{The Correlational Case}\label{the-correlational-case}}

The model here can be broken down into two parts, the first part
aggregates the observed effect sizes and the second part aggregates the
artifact values. The artifact values we will focus on here are the
reliability coefficients (see chapter 5 and 6), however other artifact
values like \(u\)-ratios will follow similar procedures. We can start
with the bare-bones meta-analysis model:
\(r_{o_i} = \rho_{o_i} + \varepsilon_{o_i}\). We can estimate the
observed population correlation (\(\vartheta_{o_i}\)) by first
calculating the weights (using the \(n\)-weighted mean correlation in
the formula for sampling variance, \(\bar{r}\)):

\[
\sigma^2_{\varepsilon_oi} \approx \frac{(1-\bar{r}^2)^2}{n_i-1} 
\]

\[
w_i = \frac{1}{\sigma^2_{\varepsilon_i}+\sigma_\vartheta^2} = \frac{1}{\sigma^2_{\varepsilon_i}+(\sigma^2_{\theta}-\sigma^2_{\varepsilon})} \approx \frac{1}{\sigma^2_{\varepsilon_i}+\left(\frac{\sum^k_{i=1}n_i(\theta_i - \bar{\theta})^2}{\sum^k_{i=1}n_i}-\frac{\sum^k_{i=1}n_i\sigma^2_{\varepsilon_oi}}{\sum^k_{i=1}n_i}\right)}
\]

Taking the mean of the observed study correlations weighted by the
inverse sampling variance,

\[
\hat{\bar{\rho}}_o=\frac{\sum^k_{i=1}w_i r_{o_i}}{\sum^k_{i=1}w_i}
\]

Then lets get the variance in observed population correlations, in order
to do this we need the v

\[
\sigma^2_{\rho_o}=\sigma^2_{r_o} - \sigma^2_{\varepsilon_o} = \frac{\sum^k_{i=1}w_i (r_{o_i}-\hat{\bar{\rho}}_o)^2}{\sum^k_{i=1}w_i} - \frac{\sum^k_{i=1}w_i \sigma^2_{\varepsilon_oi}}{\sum^k_{i=1}w_i}
\]

With the weights we can also take the weighted average of the artifact
values (such as \(u\)-ratios or reliabilities) that are available. For
our example here, we will correct only for measurement error, therefore
the weighted means for reliability in \(x\) and \(y\) will be:

\[
\bar{r}_{xx'}=\frac{\sum^k_{i=1}w_i r_{xx'_i}}{\sum^k_{i=1}w_i}
\]

\[
\bar{r}_{yy'}=\frac{\sum^k_{i=1}w_i r_{yy'_i}}{\sum^k_{i=1}w_i}
\]

Now recall from chapter 5 that the square root of the reliability is
equal to the correlation between observed scores and true scores. We can
denote the mean correlation as follows:
\(\bar{r}_{xT}=\sqrt{\bar{r}_{xx'}}\) and
\(\bar{r}_{yU}=\sqrt{\bar{r}_{xx'}}\). We then must also compute the
average sampling variances of \(r_{xT_i}\) and \(r_{yU_i}\) between
studies. These sampling variance of these correlations can be computed
the same way as a pearson correlation:

\[
\sigma^2_{r_{xT}i} \approx \frac{(1-\bar{r}_{xT}^2)^2}{n_i-1} 
\]

\[
\sigma^2_{r_{yU}i} \approx \frac{(1-\bar{r}_{yU}^2)^2}{n_i-1} 
\]

Then weighted average of these sampling variances is

\[
\sigma^2_{r_{xT}} = \frac{\sum^k_{i=1}w_i r_{xT_i}}{\sum^k_{i=1}w_i}
\]

\[
\sigma^2_{r_{yU}} = \frac{\sum^k_{i=1}w_i r_{yU_i}}{\sum^k_{i=1}w_i}
\] Now that we have the point-estimate of the population observed
correlation, the variance of observed population correlations, the
sampling variance of observed correlations, and the sampling variance of
the square root of the reliability for \(x\) and \(y\), we can now
attempt to correct the point-estimate and the variance of population
correlations.

\hypertarget{correcting-using-summary-values}{%
\paragraph*{Correcting Using Summary
Values}\label{correcting-using-summary-values}}
\addcontentsline{toc}{paragraph}{Correcting Using Summary Values}

First, we can start by correcting the overall point-estimate for the
observed population correlation in order to remove bias due to
measurement error. Recall from chapter 5 the correction formula:

\[
\hat{\bar{\rho}} = \frac{\hat{\bar{\rho}}_o}{\bar{A}} = \frac{\hat{\bar{\rho}}_o}{\bar{r}_{xT} \bar{r}_{yU}} = \frac{\hat{\bar{\rho}}_o}{\sqrt{\bar{r}_{xx'}} \sqrt{\bar{r}_{yy'}}}
\]

Note that the artifact biasing factor, \(A\), is the product of the two
sources of attenuation. Correcting the variance in observed population
correlations (\(\sigma^2_{\rho_o}\)), so that it is accurately
estimating the variance of true population effect sizes
(\(\sigma^2_{\rho}\)), we must use a Taylor series approximation. This
formula can become fairly complex with more types of artifacts involved.
The taylor series approximation is for estimating specifically the
amount of sampling variance within the correction factor we apply to the
observed correlation. The first step is lay out our attenuation formula
(the equation where observed effect size is on the left side of the
equation and the artifact values and true effect size is on the right
hand side of the equation). In the case of correcting only for
measurement error, the attenuation formula is relatively simple

\[
\hat{\bar{\rho}}_o = \hat{\bar{\rho}}\cdot \bar{r}_{xT}\cdot \bar{r}_{yU}
\]

For the taylor series approximation, we want to first find the partial
derivitive with respect to each artifact component:

\[
B_{r_{xT}}=\frac{\partial}{\partial r_{xT}} (\hat{\bar{\rho}}\cdot \bar{r}_{xT}\cdot \bar{r}_{yU}) = \hat{\bar{\rho}}\cdot \bar{r}_{yU}
\] \[
B_{r_{yU}}=\frac{\partial}{\partial r_{yU}} (\hat{\bar{\rho}}\cdot \bar{r}_{xT}\cdot \bar{r}_{yU}) = \hat{\bar{\rho}}\cdot \bar{r}_{xT}
\]

The variance due to artifacts is then approximately,

\[
\sigma^2_A\approx B^2_{r_{xT}} \sigma^2_{r_{xT}} + B^2_{r_{yU}} \sigma^2_{r_{yU}}
\]

Now we can approximate the variance in true population correlations,

\[
\sigma_\rho^2= \frac{\sigma^2_{\rho_o} - \sigma^2_A}{\bar{A}^2}
\]

Where the artifact biasing factor is:
\(\bar{A}=\bar{r}_{xT}\cdot \bar{r}_{yU}\). See the supplementary
materials of Dahlke and Wiernik (2020) for detailed Taylor series
approximation derivations for the immensely more complicated bivariate
indirect range restriction plus measurement error correction.

\hypertarget{applied-example-in-r-1}{%
\subsection{Applied Example in R}\label{applied-example-in-r-1}}

Lets conduct an artifact distribution correction meta-analysis in R,
instead using data from the meta-analysis by McDaniel et al. (1994).
This dataset contains correlations between employment interviews and job
performance. This data set has a lot of missing values for reliability
coefficients and \(u\)-ratios which might suggest that the artifact
distribution approach is a better choice compared to the individual
correction approach. We can conduct a meta-analysis correcting for
univariate indirect range restriction and measurement error in both job
performance and employment interviews. The attenuation formula will be
important for calculating the Taylro series approximation can be defined
as

\[
\bar{\rho}_o=\bar{\rho}\sqrt{\bar{r}_{o_i}^2 + \frac{\bar{u}_{x_i}^2 \bar{r}_{xx'_i}(\bar{r}_{xx'_i}\bar{r}_{yy'_i} - \bar{r}_{o_i}^2) }{1 - \bar{u}_{x_i}^2 (1-\bar{r}_{xx'_i})} }
\] Instead of conducting a taylor series approximation by hand, we will
simply use the \texttt{psychmeta} package to perform the artifact
distribution meta-analysis. The function \texttt{ma\_r\_ad} is designed
to conduct an artifact distribution meta-analysis on correlation
coefficients. The function also reports the bare-bones model allowing us
to compare the corrected estimates to the uncorrected.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load in packages (we need the development version of psychmeta)}
\CommentTok{\# install.packages("devtools")}
\CommentTok{\# devtools::install\_github("psychmeta/psychmeta")}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# obtain artifact values}
\NormalTok{rxx }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{rxxi}
\NormalTok{ux }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{ux}
\NormalTok{ro }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{rxyi}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ data\_r\_roth\_2015}\SpecialCharTok{$}\NormalTok{n}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(ro)}

\CommentTok{\# compute barebones meta{-}analysis}
\NormalTok{ma\_obj }\OtherTok{\textless{}{-}} \FunctionTok{ma\_r\_bb}\NormalTok{(}\AttributeTok{r =}\NormalTok{ rxyi, }
                  \AttributeTok{n =}\NormalTok{ n, }
                  \AttributeTok{correct\_bias =} \ConstantTok{FALSE}\NormalTok{, }
                  \AttributeTok{wt\_type =} \StringTok{"REML"}\NormalTok{,}
                  \AttributeTok{data =}\NormalTok{ data\_r\_mcdaniel\_1994)}

\CommentTok{\# construct artifact distribution for x}
\NormalTok{ad\_obj\_x }\OtherTok{\textless{}{-}} \FunctionTok{create\_ad}\NormalTok{(}\AttributeTok{ad\_type =} \StringTok{"tsa"}\NormalTok{, }
                      \AttributeTok{mean\_rxxi =}\NormalTok{ data\_r\_mcdaniel\_1994}\SpecialCharTok{$}\NormalTok{Mrxxi[}\DecValTok{1}\NormalTok{],}
                      \AttributeTok{var\_rxxi =}\NormalTok{ data\_r\_mcdaniel\_1994}\SpecialCharTok{$}\NormalTok{SDrxxi[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}
                      \AttributeTok{ux =}\NormalTok{ data\_r\_mcdaniel\_1994}\SpecialCharTok{$}\NormalTok{ux,}
                      \AttributeTok{wt\_ux =}\NormalTok{ data\_r\_mcdaniel\_1994}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{ux frequency}\StringTok{\textasciigrave{}}\NormalTok{)}

\CommentTok{\# construct artifact distribution for y}
\NormalTok{ad\_obj\_y }\OtherTok{\textless{}{-}} \FunctionTok{create\_ad}\NormalTok{(}\AttributeTok{ad\_type =} \StringTok{"tsa"}\NormalTok{, }
                      \AttributeTok{rxxi =}\NormalTok{ data\_r\_mcdaniel\_1994}\SpecialCharTok{$}\NormalTok{ryyi,}
                      \AttributeTok{wt\_rxxi =}\NormalTok{ data\_r\_mcdaniel\_1994}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{ryyi frequency}\StringTok{\textasciigrave{}}\NormalTok{)}

\CommentTok{\# compute artifact{-}distribution meta{-}analysis, correcting for measurement error only}
\NormalTok{mdl\_ad }\OtherTok{\textless{}{-}} \FunctionTok{ma\_r\_ad}\NormalTok{(}\AttributeTok{ma\_obj =}\NormalTok{ ma\_obj, }
                  \AttributeTok{ad\_obj\_x =}\NormalTok{ ad\_obj\_x, }
                  \AttributeTok{ad\_obj\_y =}\NormalTok{ ad\_obj\_y, }
                  \AttributeTok{correction\_method =} \StringTok{"meas"}\NormalTok{)}


\CommentTok{\# summary table of meta{-}analysis}
\NormalTok{summary\_stats }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{type =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Artifact Distribution\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Bare{-}Bones\textquotesingle{}}\NormalTok{),}
  \AttributeTok{k =} \FunctionTok{c}\NormalTok{(mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{artifact\_distribution}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{k,mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{k),}
  \AttributeTok{n =} \FunctionTok{c}\NormalTok{(mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{artifact\_distribution}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{N,mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{N),}
  \AttributeTok{mean\_rho =} \FunctionTok{c}\NormalTok{(mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{artifact\_distribution}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{mean\_rho,mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{mean\_r),}
  \AttributeTok{SE =} \FunctionTok{c}\NormalTok{(mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{artifact\_distribution}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{se\_r\_c,mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{barebones}\SpecialCharTok{$}\NormalTok{se\_r),}
  \AttributeTok{SD\_rho =} \FunctionTok{c}\NormalTok{(mdl\_ad}\SpecialCharTok{$}\NormalTok{meta\_tables}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{analysis\_id: 1}\StringTok{\textasciigrave{}}\SpecialCharTok{$}\NormalTok{artifact\_distribution}\SpecialCharTok{$}\NormalTok{true\_score}\SpecialCharTok{$}\NormalTok{sd\_rho,}\DecValTok{0}\NormalTok{))}

\NormalTok{summary\_stats }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                   type   k     n  mean_rho         SE    SD_rho
1 Artifact Distribution 160 25244 0.3201828 0.02108407 0.1985571
2            Bare-Bones 160 25244 0.2205043 0.01452023 0.0000000
\end{verbatim}

We can also obtain credibility intervals by using the
\texttt{credibility} function in the \texttt{psychmeta} package. The
interval defaults to 80\% intervals, however we can change that to 90\%
by inputting .90 into the \texttt{cred\_level} argument.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{credibility}\NormalTok{(}\AttributeTok{mean =}\NormalTok{ summary\_stats}\SpecialCharTok{$}\NormalTok{mean\_rho[}\DecValTok{1}\NormalTok{],}
            \AttributeTok{sd =}\NormalTok{ summary\_stats}\SpecialCharTok{$}\NormalTok{SD\_rho[}\DecValTok{1}\NormalTok{],}
            \AttributeTok{cred\_method =} \StringTok{"norm"}\NormalTok{,}
            \AttributeTok{cred\_level =}\NormalTok{ .}\DecValTok{90}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         CR_LL_90  CR_UL_90
[1,] -0.006414571 0.6467802
\end{verbatim}

Lets compare these results to the bare-bones model. In
\texttt{psychmeta} the bare-bones model can be conduced using
\texttt{ma\_r\_bb}. However, the \texttt{ma\_r\_ic} function also
reports the bare-bones results as well. Therefore we can just extract
the necessary statistics from the model.

(J. E. Hunter and Schmidt 1990)

(Wiernik and Dahlke 2020)

(Schmidt and Hunter 1977)

(Murphy 2003)

(Viswesvaran and Ones 1995)

(Raju and Burke 1983)

(Callender and Osburn 1980)

\bookmarksetup{startatroot}

\hypertarget{references-1}{%
\chapter*{References}\label{references-1}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-aguinis2009}{}}%
Aguinis, Herman, Charles A Pierce, and Steven A Culpepper. 2009.
{``Scale Coarseness as a Methodological Artifact,''} September.

\leavevmode\vadjust pre{\hypertarget{ref-borenstein2010}{}}%
Borenstein, Michael, Larry V. Hedges, Julian P. T. Higgins, and Hannah
R. Rothstein. 2010. {``A Basic Introduction to Fixed-Effect and
Random-Effects Models for Meta-Analysis.''} \emph{Research Synthesis
Methods} 1 (2): 97--111. \url{https://doi.org/10.1002/jrsm.12}.

\leavevmode\vadjust pre{\hypertarget{ref-borsboom2002}{}}%
Borsboom, Denny, and Gideon J Mellenbergh. 2002. {``True Scores, Latent
Variables, and Constructs: A Comment on Schmidt and Hunter.''}

\leavevmode\vadjust pre{\hypertarget{ref-borsboom2004}{}}%
Borsboom, Denny, Gideon J. Mellenbergh, and Jaap Van Heerden. 2004.
{``The Concept of Validity.''} \emph{Psychological Review} 111 (4):
1061--71. \url{https://doi.org/10.1037/0033-295X.111.4.1061}.

\leavevmode\vadjust pre{\hypertarget{ref-brannick2019}{}}%
Brannick, Michael T., Sean M. Potter, Bryan Benitez, and Scott B.
Morris. 2019. {``Bias and Precision of Alternate Estimators in
Meta-Analysis: Benefits of Blending Schmidt-Hunter and Hedges
Approaches.''} \emph{Organizational Research Methods} 22 (2): 490--514.
\url{https://doi.org/10.1177/1094428117741966}.

\leavevmode\vadjust pre{\hypertarget{ref-bravais1844}{}}%
Bravais, A. 1844. \emph{Analyse mathématique sur les probabilités des
erreurs de situation d'un point}. Impr. Royale.

\leavevmode\vadjust pre{\hypertarget{ref-callender1980}{}}%
Callender, John C., and H. G. Osburn. 1980. {``Development and Test of a
New Model for Validity Generalization.''} \emph{Journal of Applied
Psychology} 65 (5): 543--58.
\url{https://doi.org/10.1037/0021-9010.65.5.543}.

\leavevmode\vadjust pre{\hypertarget{ref-cohen1988}{}}%
Cohen, Jacob. 1988. \emph{Statistical Power Analysis for the Behavioral
Sciences}. Academic Press.

\leavevmode\vadjust pre{\hypertarget{ref-cohen1977}{}}%
---------. 2013. \emph{Statistical Power Analysis for the Behavioral
Sciences}. Academic Press.

\leavevmode\vadjust pre{\hypertarget{ref-cronbach1955}{}}%
Cronbach, Lee J., and Paul E. Meehl. 1955. {``Construct Validity in
Psychological Tests.''} \emph{Psychological Bulletin} 52 (4): 281--302.
\url{https://doi.org/10.1037/h0040957}.

\leavevmode\vadjust pre{\hypertarget{ref-dahlke2019}{}}%
Dahlke, Jeffrey A., and Brenton M. Wiernik. 2019. {``Psychmeta: An R
Package for Psychometric Meta-Analysis.''} \emph{Applied Psychological
Measurement} 43 (5): 415--16.
\url{https://doi.org/10.1177/0146621618795933}.

\leavevmode\vadjust pre{\hypertarget{ref-dahlke2020}{}}%
---------. 2020. {``Not Restricted to Selection Research: Accounting for
Indirect Range Restriction in Organizational Research.''}
\emph{Organizational Research Methods} 23 (4): 717--49.
\url{https://doi.org/10.1177/1094428119859398}.

\leavevmode\vadjust pre{\hypertarget{ref-dersimonian2007}{}}%
DerSimonian, Rebecca, and Raghu N. Kacker. 2007. {``Random-Effects Model
for Meta-Analysis of Clinical Trials: An Update.''} \emph{NIST} 28
(January): 105--14.
\url{https://www.nist.gov/publications/random-effects-model-meta-analysis-clinical-trials-update}.

\leavevmode\vadjust pre{\hypertarget{ref-galton1907}{}}%
Galton, Francis. 1907. {``Vox Populi.''} \emph{Nature} 75 (1949):
450--51. \url{https://doi.org/10.1038/075450a0}.

\leavevmode\vadjust pre{\hypertarget{ref-haertel2006}{}}%
Haertel, Edward H. 2006. {``3. Reliability.''} In, 4th ed.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1981}{}}%
Hedges, Larry V. 1981. {``Distribution Theory for Glass's Estimator of
Effect Size and Related Estimators.''} \emph{Journal of Educational
Statistics} 6 (2): 107--28.
\url{https://doi.org/10.3102/10769986006002107}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1989}{}}%
---------. 1989. {``An Unbiased Correction for Sampling Error in
Validity Generalization Studies.''} \emph{Journal of Applied Psychology}
74 (3): 469--77. \url{https://doi.org/10.1037/0021-9010.74.3.469}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges2014}{}}%
Hedges, Larry V., and Ingram Olkin. 2014. \emph{Statistical Methods for
Meta-Analysis}. Academic press.
\url{https://books.google.com/books?hl=en\&lr=\&id=7GviBQAAQBAJ\&oi=fnd\&pg=PP1\&dq=info:e6P1zfh2T6QJ:scholar.google.com\&ots=Dx-YqN6_9B\&sig=-39HgbYdWPp_BwSTzA9cRODs2Q0}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1998}{}}%
Hedges, Larry V., and Jack L. Vevea. 1998. {``Fixed- and Random-Effects
Models in Meta-Analysis.''} \emph{Psychological Methods} 3 (4):
486--504. \url{https://doi.org/10.1037/1082-989X.3.4.486}.

\leavevmode\vadjust pre{\hypertarget{ref-hunter1990a}{}}%
Hunter, John E., and Frank L. Schmidt. 1990. \emph{Methods of
meta-analysis: correcting error and bias in research findings}. Newbury
Park: Sage Publications.

\leavevmode\vadjust pre{\hypertarget{ref-hunter1990}{}}%
Hunter, John, and Frank Schmidt. 1990. {``Dichotomization of Continuous
Variables: The Implications for Meta-Analysis.''} \emph{Journal of
Applied Psychology} 75 (June): 334--49.
\url{https://doi.org/10.1037/0021-9010.75.3.334}.

\leavevmode\vadjust pre{\hypertarget{ref-johnson1995}{}}%
Johnson, Blair T., Brian Mullen, and Eduardo Salas. 1995. {``Comparison
of Three Major Meta-Analytic Approaches.''} \emph{Journal of Applied
Psychology} 80 (1): 94--106.
\url{https://doi.org/10.1037/0021-9010.80.1.94}.

\leavevmode\vadjust pre{\hypertarget{ref-kelley1927}{}}%
Kelley, Truman Lee. 1927. \emph{Interpretation of Educational
Measurements}. World Book Company.

\leavevmode\vadjust pre{\hypertarget{ref-laird1990}{}}%
Laird, Nan M., and Frederick Mosteller. 1990. {``Some Statistical
Methods for Combining Experimental Results.''} \emph{International
Journal of Technology Assessment in Health Care} 6 (1): 5--30.
\url{https://doi.org/10.1017/S0266462300008916}.

\leavevmode\vadjust pre{\hypertarget{ref-maxwell1993}{}}%
Maxwell, Scott, and Harold Delaney. 1993. {``Bivariate Median Splits and
Spurious Statistical Significance.''} \emph{Psychological Bulletin} 113
(January): 181--90. \url{https://doi.org/10.1037/0033-2909.113.1.181}.

\leavevmode\vadjust pre{\hypertarget{ref-mcdaniel1994}{}}%
McDaniel, Michael A., Deborah L. Whetzel, Frank L. Schmidt, and Steven
D. Maurer. 1994. {``The Validity of Employment Interviews: A
Comprehensive Review and Meta-Analysis.''} \emph{Journal of Applied
Psychology} 79 (4): 599--616.
\url{https://doi.org/10.1037/0021-9010.79.4.599}.

\leavevmode\vadjust pre{\hypertarget{ref-mendoza1987}{}}%
Mendoza, Jorge L., and Michael Mumford. 1987. {``Corrections for
Attenuation and Range Restriction on the Predictor.''} \emph{Journal of
Educational Statistics} 12 (3): 282--93.
\url{https://doi.org/10.3102/10769986012003282}.

\leavevmode\vadjust pre{\hypertarget{ref-morris2014}{}}%
Morris, Scott, Rebecca Daisley, Megan Wheeler, and Peggy Boyer. 2014.
{``A Meta-Analysis of the Relationship Between Individual Assessments
and Job Performance.''} \emph{The Journal of Applied Psychology} 100
(May). \url{https://doi.org/10.1037/a0036938}.

\leavevmode\vadjust pre{\hypertarget{ref-murphy2003}{}}%
Murphy, Kevin R. 2003. \emph{Validity Generalization: A Critical
Review}. Psychology Press.

\leavevmode\vadjust pre{\hypertarget{ref-olkin1958}{}}%
Olkin, Ingram, and John W. Pratt. 1958. {``Unbiased Estimation of
Certain Correlation Coefficients.''} \emph{The Annals of Mathematical
Statistics} 29 (1): 201--11. \url{https://www.jstor.org/stable/2237306}.

\leavevmode\vadjust pre{\hypertarget{ref-pearson1903}{}}%
Pearson, Karl. 1903. {``I. Mathematical Contributions to the Theory of
Evolution. {\textemdash}XI. On the Influence of Natural Selection on the
Variability and Correlation of Organs.''} \emph{Philosophical
Transactions of the Royal Society of London. Series A, Containing Papers
of a Mathematical or Physical Character} 200 (321-330): 1--66.
\url{https://doi.org/10.1098/rsta.1903.0001}.

\leavevmode\vadjust pre{\hypertarget{ref-pearson1913}{}}%
---------. 1913. {``On the Probable Error of a Coefficient of
Correlation as Found from a Fourfold Table.''} \emph{Biometrika} 9
(1/2): 22--33. \url{https://doi.org/10.2307/2331798}.

\leavevmode\vadjust pre{\hypertarget{ref-peters1940}{}}%
Peters, Charles C., and Walter R. Van Voorhis. 1940. {``Further Methods
of Correlation.''} In, 362--403. New York, NY, US: McGraw-Hill Book
Company. \url{https://doi.org/10.1037/13596-013}.

\leavevmode\vadjust pre{\hypertarget{ref-psych:p2017}{}}%
{``Psych: Procedures for Personality and Psychological Research.''}
2017. \url{https://CRAN.R-project.org/package=psych}.

\leavevmode\vadjust pre{\hypertarget{ref-raju1983}{}}%
Raju, Nambury, and Michael Burke. 1983. {``Two Procedures for Studying
Validity Generalization.''} \emph{Journal of Applied Psychology} 68
(August): 382--95. \url{https://doi.org/10.1037/0021-9010.68.3.382}.

\leavevmode\vadjust pre{\hypertarget{ref-roth2015}{}}%
Roth, Bettina. 2015. {``Intelligence and School Grades: A
Meta-Analysis.''}

\leavevmode\vadjust pre{\hypertarget{ref-sackett2000}{}}%
Sackett, Paul R., and Hyuckseung Yang. 2000. {``Correction for Range
Restriction: An Expanded Typology.''} \emph{Journal of Applied
Psychology} 85 (1): 112--18.
\url{https://doi.org/10.1037/0021-9010.85.1.112}.

\leavevmode\vadjust pre{\hypertarget{ref-schmidt1977}{}}%
Schmidt, Frank, and John Hunter. 1977. {``Development of a General
Solution to the Problem of Validity Generalization.''} \emph{Journal of
Applied Psychology} 62 (October): 529--40.
\url{https://doi.org/10.1037/0021-9010.62.5.529}.

\leavevmode\vadjust pre{\hypertarget{ref-spearman1904}{}}%
Spearman, C. 1904. {``The Proof and Measurement of Association Between
Two Things.''} \emph{International Journal of Epidemiology} 39 (5):
1137--50. \url{https://doi.org/10.1093/ije/dyq191}.

\leavevmode\vadjust pre{\hypertarget{ref-taylor1976}{}}%
Taylor, Erwin K., and Thomas Griess. 1976. {``The Missing Middle in
Validation Research.''} \emph{Personnel Psychology} 29 (1): 5--11.
\url{https://doi.org/10.1111/j.1744-6570.1976.tb00397.x}.

\leavevmode\vadjust pre{\hypertarget{ref-viechtbauer2010}{}}%
Viechtbauer, Wolfgang. 2010. {``Conducting meta-analyses in R with the
metafor package.''} \emph{Journal of Statistical Software} 36 (3):
1--48. \url{https://doi.org/10.18637/jss.v036.i03}.

\leavevmode\vadjust pre{\hypertarget{ref-viechtbauer}{}}%
---------. n.d. {``Fixed-Effects and Random-Effects Models in
Meta-Analysis.''} \url{https://wviechtb.github.io/metafor/index.html}.

\leavevmode\vadjust pre{\hypertarget{ref-viswesvaran1995}{}}%
Viswesvaran, Chockalingam, and Deniz S. Ones. 1995. {``Theory Testing:
Combining Psychometric Meta-Analysis and Structural Equations
Modeling.''} \emph{Personnel Psychology} 48 (4): 865--85.
\url{https://doi.org/10.1111/j.1744-6570.1995.tb01784.x}.

\leavevmode\vadjust pre{\hypertarget{ref-viswesvaran2014}{}}%
Viswesvaran, Chockalingam, Deniz S. Ones, Frank L. Schmidt, Huy Le, and
In-Sue Oh. 2014. {``Measurement Error Obfuscates Scientific Knowledge:
Path to Cumulative Knowledge Requires Corrections for Unreliability and
Psychometric Meta-Analyses.''} \emph{Industrial and Organizational
Psychology} 7 (4): 507--18.
\url{https://doi.org/10.1017/S1754942600006799}.

\leavevmode\vadjust pre{\hypertarget{ref-vos2022}{}}%
Vos, Paul, and Don Holbert. 2022. {``Frequentist Statistical Inference
Without Repeated Sampling.''} \emph{Synthese} 200 (2): 89.
\url{https://doi.org/10.1007/s11229-022-03560-x}.

\leavevmode\vadjust pre{\hypertarget{ref-wechsler2008}{}}%
Wechsler, David. 2008. \emph{Wechsler Adult Intelligence Scale--Fourth
Edition}. 4th ed. \url{https://doi.org/10.1037/t15169-000}.

\leavevmode\vadjust pre{\hypertarget{ref-whitener1990}{}}%
Whitener, Ellen M. 1990. {``Confusion of Confidence Intervals and
Credibility Intervals in Meta-Analysis.''} \emph{Journal of Applied
Psychology} 75 (3): 315--21.
\url{https://doi.org/10.1037/0021-9010.75.3.315}.

\leavevmode\vadjust pre{\hypertarget{ref-wiernik2020}{}}%
Wiernik, Brenton M., and Jeffrey A. Dahlke. 2020. {``Obtaining Unbiased
Results in Meta-Analysis: The Importance of Correcting for Statistical
Artifacts.''} \emph{Advances in Methods and Practices in Psychological
Science} 3 (1): 94--123. \url{https://doi.org/10.1177/2515245919885611}.

\leavevmode\vadjust pre{\hypertarget{ref-wylie1976}{}}%
Wylie, Peter B. 1976. {``Effects of Coarse Grouping and Skewed Marginal
Distributions on the Pearson Product Moment Correlation Coefficient.''}
\emph{Educational and Psychological Measurement} 36 (1): 1--7.
\url{https://doi.org/10.1177/001316447603600101}.

\end{CSLReferences}



\end{document}
