% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Correcting Effect Sizes for Statistical Artifacts},
  pdfauthor={Matthew B. Jané},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Correcting Effect Sizes for Statistical Artifacts}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Application in Meta-Analysis and Implementation in R and
Python}
\author{Matthew B. Jané}
\date{2023-06-13}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[breakable, borderline west={3pt}{0pt}{shadecolor}, enhanced, sharp corners, boxrule=0pt, interior hidden, frame hidden]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

Preface page still in progress

\bookmarksetup{startatroot}

\hypertarget{dedication}{%
\chapter{Dedication}\label{dedication}}

In Loving Memory of Haley Jané

My companion whose unwavering presence and unconditional love provided
me with stability and solace in life's ever-changing journey

\begin{figure}

{\centering \includegraphics[width=4.16667in,height=\textheight]{figure/dedication_2.png}

}

\end{figure}

\bookmarksetup{startatroot}

\hypertarget{effect-sizes-and-notation}{%
\chapter{Effect Sizes and Notation}\label{effect-sizes-and-notation}}

\hypertarget{what-are-effect-sizes}{%
\section{What are Effect Sizes?}\label{what-are-effect-sizes}}

Effect sizes are statistics that measure the magnitude of a relationship
between two variables. It's important to remember that effect sizes are
a valuable tool, enabling researchers to extract meaningful insights,
rather than being the ultimate objective themselves. Effect sizes aide
in researcher's ability to draw meaningful inferences from data and
therefore it is important that they are accurate. Biased effect sizes
can be likened to a foggy windshield. Just as condensation on glass
obstructs a clear view of the road, biased effect sizes can obscure the
true association between variables. Similar to how one must clean the
windshield to drive safely, researchers must correct for biases in
effect sizes to attain a clear and accurate perspective on their data.
Correlation coefficients and standardized mean differences are two of
the most common effect sizes and so they will be the primary focus of
this book. To see how an effect size may look in practice, the example
below will illustrate how calculating one may look in a clinical
setting.

\hypertarget{applied-example}{%
\subsection{Applied Example}\label{applied-example}}

Lets say we want to test whether a new drug can alleviate anxiety,
therefore we decide to conduct an experiment to see how well this drug
performs. We first randomly assign each participant in the study to
either a treatment group (\(T\)) or a control group (\(C\)). In our
experiment we want test how well the experimental drug reduces anxiety,
therefore we measure the subjects' self reported anxiety after
under-going the treatment. To see if the drug actually worked in
alleviating anxiety, we want to compare the scores from the treatment
group and the control group. To do this we can estimate the average
treatment effect (\(ATE\)), which is the difference in the mean value of
self-reported anxiety scores between the treatment group and the control
group such that, \(ATE = \text{Mean}(X_T) - \text{Mean}(X_C)\). However,
anxiety scores have no meaningful units, so if we obtain an \(ATE\)
value of \(-3\) there is no way to tell if this value is large or small,
since it is entirely dependent on how the anxiety scores are scaled.
Standardization can allow us to draw meaningful inferences about the
size of the effect that can be comparable across scales. We can
standardize the \(ATE\) by dividing by the standard deviation of scores
in the control group, (\(\text{SD}\)):
\(\text{Effect Size} = \frac{ATE}{\text{SD}_C}\). The effect size is now
on an interpretable scale (standard deviations). If we achieve an
standardized effect size value of \(-0.50\), we can interpret this as
the treatment group exhibiting a reduction in anxiety equivalent to half
a standard deviation compared to the control group.

\begin{figure}

{\centering \includegraphics{intro_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\caption{Simulated experimental data}

\end{figure}

\hypertarget{defining-effect-sizes}{%
\subsection{Defining effect sizes}\label{defining-effect-sizes}}

Lets say we have an effect size of interest that quantifies the
relationship between an independent and dependent variable. The
population effect size can be denoted as \(\vartheta\), however this
population value is unknown. We can obtain an estimate the population
effect size by conducting a study on a sample drawn from the population
and then calculating a study effect size, \(\theta\). The study effect
size is a function of the population effect size and sampling error
(\(\varepsilon\)) such that,

\begin{equation}\protect\hypertarget{eq-B}{}{
\theta = \vartheta + \varepsilon
}\label{eq-B}\end{equation}

Effect sizes will differ from study to study, this can be due to two
reasons: variance in population effect sizes (\(\sigma^2_\vartheta\)) or
variance in sampling error (\(\sigma_\varepsilon\)). Accordingly, we can
express the variance in study effect sizes (\(\sigma_\theta\)) as,

\[
\sigma^2_\theta = \sigma^2_\vartheta + \sigma^2_\varepsilon
\]

If studies were drawing samples from the same population, the variance
in the population effect size would be zero (\(\sigma^2_\vartheta = 0\))
and the expected value (i.e., the mean) of study effect sizes would be
equal to the population effect size, \(\mathbb{E}[\theta]=\vartheta\).

\hypertarget{effect-sizes-and-artifacts}{%
\section{Effect Sizes and Artifacts}\label{effect-sizes-and-artifacts}}

In practice, \emph{observed} effect size estimates are often biased
relative to the \emph{true} effect size of interest, that is, the
observed population effect size (\(\vartheta_o\)) is a product of the
true population effect size (\(\vartheta\)) and artifactual bias
(\(a\)):

\begin{equation}\protect\hypertarget{eq-A}{}{
\vartheta_o = a\vartheta
}\label{eq-A}\end{equation}

Note that if \(a=1\) this would indicate that there is no artifactual
bias (\(\vartheta_o=\vartheta\)), if \(a>1\) then it would indicate
effect size inflation (i.e., biased away from zero), and if \(a<1\) that
would indicate effect size attenuation (i.e., biased toward zero). It
can be seen in Equation~\ref{eq-A} that we can re-arrange the formula to
obtain the true population effect size by dividing the observed
population effect size by \(a\),

\[
\vartheta = \frac{\vartheta_o}{a}.
\] For a single study that computes an effect size from a sample drawn
from the population, the observed study effect size (\(\theta_o\)) would
be expressed by

\[
\theta_o = \vartheta_o + \varepsilon_o
\] Using Equation~\ref{eq-A} we can express the observed effect size in
terms of the true population effect size rather than the observed
population effect size,

\[
\theta_o = a\vartheta + \varepsilon_o
\] Then we can correct the observed effect size by dividing by the
biasing factor, \(a\), to obtain an unbiased estimate of the true effect
size:

\[
\theta_c = \frac{\theta_o}{a}
\] The sampling error and it's variance must also be corrected,

\[
\varepsilon_c = \frac{\varepsilon_o}{a}
\] \[
\sigma_{\varepsilon_c}^2 = \frac{\sigma^2_{\varepsilon_o}}{a^2}.
\] The corrected effect size should be an unbiased estimate of the true
population effect size as long as the systematic bias multiplier is
accurately measured (which is not a trivial task). It is important to
note that the corrected effect size will not yield additional
statistical power, that is, test-statistics and p-values will remain
unchanged. We can demonstrate this mathematically that the z-statistic
of the observed effect size (\(z_{\theta_o}\)) is identical to the
z-statistic of the corrected effecct size (\(z_{\theta_c}\)),

\[
z_{\theta_o} = \frac{\theta_o}{\sigma_{\varepsilon_o}} = \frac{\frac{\theta_o}{a}}{\frac{\sigma_{\theta_o}}{a}} = \frac{\theta_c}{\sigma_{\varepsilon_c}} = z_{\theta_c}
\]

\hypertarget{defining-an-effect-size-estimand}{%
\section{Defining an Effect Size
Estimand}\label{defining-an-effect-size-estimand}}

An effect size \emph{estimand} is the theoretical quantity that we are
trying to estimate. Before delving into the application of correction
factors, it is important to clearly define the effect size estimand you
aim to capture, including the summary statistic, relevant variables, and
the target population. This preliminary step might appear trivial, but
it is crucial, as it determines the accuracy and relevance of any
subsequent artifact corrections. For instance, consider a scenario where
we conduct a study involving a sample of college students with the aim
of generalizing our findings to the broader general population. In this
context, it is important to correct for range restriction, given the
evident selection effects that exist in the college student populations.
However, if our sole objective is to draw conclusions pertaining
exclusively to the college student demographic, correcting for range
restriction would be inappropriate. Furthermore, let's examine the
variable of interest, such as grade-point average (GPA), within this
population. Do we intend to focus solely on the raw GPA score, or is our
goal to capture what GPA represents, namely, academic achievement? If
our aim is to investigate the raw GPA score, then correcting for
measurement error would be inappropriate. However, if our primary focus
lies in assessing the student's academic achievement, then it may be
relevant to correct GPA scores for measurement error. Defining our
estimand guides our approach to artifact correction and ensures that
these correction procedures align with the underlying research goals.

\hypertarget{effect-size-notation}{%
\section{Effect Size Notation}\label{effect-size-notation}}

Because of the nature of the topic, this book will cover a large amount
of equations and computer code. Therefore to make it as straight-forward
as possible the notation will follow a systematic framework to
distinguish between types of effect sizes. This book will only be
covering two main types of effect sizes: correlations (\(r\)) and
standardized mean differences (\(d\)). Throughout the book variations of
\(r\) and \(d\) will show up frequently, these variations will be
differentiated with subscripts that are consistent with that section.
Also, to distinguish between population-level values (i.e., the effect
size across all potential observations) and effect sizes specific to a
study or sample (i.e., the effect size observed within a single sample
drawn from the population), we will use the following notation:

\begin{itemize}
\tightlist
\item
  Arbitrary Effect Size

  \begin{itemize}
  \tightlist
  \item
    Population value: \(\vartheta\)
  \item
    Study/sample value: \(\theta\)
  \end{itemize}
\item
  Correlations

  \begin{itemize}
  \tightlist
  \item
    Population value: \(\rho\)
  \item
    Study/sample value: \(r\)
  \end{itemize}
\item
  Standardized Mean Differences

  \begin{itemize}
  \tightlist
  \item
    Population value: \(\delta\)
  \item
    Study/sample value: \(d\)
  \end{itemize}
\end{itemize}

In the most cases, continuous independent variables will be denoted with
\(x\) and dependent variables with \(y\) (note that this notation may
differ when referring to observed and true scores). Categorical (i.e.,
groupings) variables will be denoted with \(g\) (these will be used for
standardized mean differences).

\hypertarget{correlations}{%
\section{Correlations}\label{correlations}}

A correlation describes the relationship between two continuous
variables. The Pearson correlation coefficient was first introduced by
Auguste Bravais (1844). Later developed by Karl Pearson, lending itself
to the name.

\hypertarget{technical-overview-correlations-r}{%
\subsection{\texorpdfstring{Technical Overview Correlations
(\emph{r})}{Technical Overview Correlations (r)}}\label{technical-overview-correlations-r}}

If we draw a sample of \(n\) observations from a population, we can
calculate the study correlation (\(r\)) between variables \(x\) and
\(y\) using the following Pearson's product-moment estimator,

\begin{equation}\protect\hypertarget{eq-pearson-raw}{}{
r = \frac{
\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})
}{
\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}
\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}
}.
}\label{eq-pearson-raw}\end{equation}

For digestibility, we can break down the formula into parts. The
correlation coefficient can be defined as the covariance between \(x\)
and \(y\) standardized by the product of their variances,

\begin{equation}\protect\hypertarget{eq-pearson}{}{
r = \frac{\sigma_{xy}}
{\sigma_x\sigma_y}
}\label{eq-pearson}\end{equation}

we can first define the covariance (\(\sigma_{xy}\)) as the average
product of errors for \(x\) and \(y\),

\begin{equation}\protect\hypertarget{eq-cov}{}{
\sigma_{xy} =\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y}).
}\label{eq-cov}\end{equation}

Then we can find the variance for \(x\) and \(y\) by taking the average
squared error from the mean for \(x\) and \(y\),

\begin{equation}\protect\hypertarget{eq-varx}{}{
\sigma^2_x = \frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2
}\label{eq-varx}\end{equation}

\begin{equation}\protect\hypertarget{eq-vary}{}{
\sigma^2_y = \frac{1}{n-1}\sum_{i=1}^n (y_i - \bar{y})^2.
}\label{eq-vary}\end{equation}

Plugging in Equation~\ref{eq-cov}, Equation~\ref{eq-varx}, and
Equation~\ref{eq-vary} into Equation~\ref{eq-pearson} we can see that
the term, \(\frac{1}{n-1}\), will cancel out and we will be left with
the original pearson correlation coefficient formula from
Equation~\ref{eq-pearson-raw},

\begin{equation}\protect\hypertarget{eq-1}{}{
r = \frac{\sigma_{xy}}{\sigma_x\sigma_y} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}}.
}\label{eq-1}\end{equation}

In the absence of artifacts, the Pearson correlation \(r\) is an
asymptotically (i.e., as \(n\) approaches infinity) unbiased estimator
(in small sample sizes, it is biased see section on small samples). We
can express \(r\) similarly to Equation~\ref{eq-B},

\begin{equation}\protect\hypertarget{eq-2}{}{
r = \rho + \varepsilon,\;\; \sigma_\varepsilon^2 = \text{Var}(\varepsilon)
}\label{eq-2}\end{equation}

Where \(\sigma^2_\varepsilon\) is the sampling variance of the observed
correlation. The sampling variance can be calculated from the sample
size (\(n\)) and the population correlation,

\begin{equation}\protect\hypertarget{eq-3}{}{
\sigma_\varepsilon^2 =\frac{1 - \rho^2}{n-2}
}\label{eq-3}\end{equation}

In practice, the population correlation is unknown so the study
correlation can be used instead (\(r\)) in the above formula. Note that
the sampling variance is the square of the standard error. If the
observed correlation is biased relative to the true correlation, we can
see that the observed population correlation is systematically biased by
an artifact factor, \(a\), \[
\rho_o = a\rho
\]

The observed study correlation would then be defined as, \[
r_o = \rho_o + \varepsilon_o = a\rho + \varepsilon_o
\]

The corrected correlation coefficient (\(r_c\)) and it's sampling
variance (\(\sigma_{\varepsilon_c}\)) can both be defined as:

\[
r_{c} = \frac{r_o}{a}
\]

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o} }{a^2}
\]

\hypertarget{standardized-mean-differences}{%
\section{Standardized Mean
Differences}\label{standardized-mean-differences}}

Standardized mean differences are used to quantify the average
difference in some variable between groups. The most commonly used
formulation is Cohen's \(d\) (Cohen 1988) which quantifies the average
difference between groups (e.g., men vs.~women) and standardizes by the
pooled standard deviation. Note that the other most commonly used
estimator is Hedges' \(g\), but the difference between the two is a
small sample correction factor that can be found in the chapter on small
samples.

\hypertarget{technical-overview-of-standardized-mean-difference-d}{%
\subsection{\texorpdfstring{Technical Overview of Standardized Mean
Difference
(\emph{d})}{Technical Overview of Standardized Mean Difference (d)}}\label{technical-overview-of-standardized-mean-difference-d}}

If we draw a sample of \(n_A\) subjects from group \(A\) and \(n_B\)
subjects from group \(B\), the mean difference between groups (\(d\)) on
variable \(y\) can be defined as,

\[
d=\frac{\bar{y}_A - \bar{y}_B}{\sigma_p}
\]

Where the standardizer, \(\sigma_p\) is the pooled standard deviation
between the two groups. The pooled standard deviation is calculated by
taking the square root of the average variance between the two groups
weighted by the degrees of freedom.

\[
\sigma_p=\sqrt{\frac{(n_A-1)\sigma^2_{A} + (n_B-1)\sigma^2_{B}}{n_A + n_B - 2}}
\]

Where \(\sigma_{A}\) and \(\sigma_{B}\) are the standard deviations of
\(y\) within groups \(A\) and \(B\) respectively. This SMD estimator is
commonly referred to as Cohen's \(d\). We can define the study/sample
\(d\) value as a function of the population \(d\) value (\(\delta\)): \[
d = \delta + \varepsilon
\] Similar to the previous section on correlation coefficients, the
observed \(d\) value is a function of the true population value and
artifactual bias (\(a\)), \[
\delta_o = a\delta.
\] Therefore the observed study/sample \(d\) value can be defined as a
function of the observed population value \emph{or} the true population
value plus artifactual bias: \[
d = \delta_o + \varepsilon_o = a\delta + \varepsilon_o.
\]

Thus the corrected standardized mean difference (\(d_c\)) and it's
sampling variance (\(\sigma^2_{\varepsilon_c}\)) can both be defined as:

\[
d_c = \frac{d_o}{a}
\]

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o}}{a^2}
\]

\part{Artifact Corrections}

\hypertarget{sec-small_samples}{%
\chapter{Small Samples}\label{sec-small_samples}}

(Hedges 1989)

(Lin 2018)

(Hedges 1981)

(Fisher 1915)

(Olkin and Pratt 1958)

\hypertarget{unreliability}{%
\chapter{Unreliability}\label{unreliability}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In general terms, measurement is the process of quantifying an attribute
or characteristic of something. In scientific measurement, the measurand
is the quantity or the attribute we intend to measure. In the
psychological sciences, measurands usually take the form of constructs
such as intelligence or anxiety. The goal of measurement is to produce
quantities (i.e., scores) that accurately reflect the measurand. It is
important to note that measures are not all created equal, some perform
better than others. Ideally, measures should produce scores that are
consistent and repeatable, this is referred to as the \emph{reliability}
of a measure. A high quality measure should produce highly reliable
scores. This section will review what reliability is in theory, how to
estimate reliability, and how to correct effect sizes for measurement
error.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, titlerule=0mm, coltitle=black, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, bottomrule=.15mm, colback=white, leftrule=.75mm, breakable, rightrule=.15mm, bottomtitle=1mm, opacitybacktitle=0.6, title={\faIcon{bolt} Too long didn't read?}, arc=.35mm, colframe=quarto-callout-note-color-frame, toprule=.15mm, left=2mm]

Correction for correlations (\(r\))

\[r_c = \frac{r_o}{\sqrt{r_{xx'}r_{yy'}}},\;\;\; \sigma_{\varepsilon_c} = s_r \left(\frac{r_c}{r_o}\right)\]

Correction for SMD (\(d\))

\[d_c = \frac{d_o}{\sqrt{r_{yy'_P}}},\;\;\; \sigma_{\varepsilon_c} = s_d \left(\frac{d_c}{d_o}\right)\]

\end{tcolorbox}

\hypertarget{sec-true-score-theory}{%
\section{Reliability in True Score Theory}\label{sec-true-score-theory}}

True score theory (or classical test theory) is a mathematical
formalization of observed scores obtained from measurements. Observed
scores, \(x_{if}\), is defined as a score obtained from individual \(i\)
upon measurement \(m\). The true score model assumes that each
individual, has a true score, \(T_i\), that stays constant over repeated
measurements. Variation in observed scores over repeated measurements is
due to measurement-specific error, \(e_{im}\),

\[
x_{im} = T_i+e_{im}.
\]

Here, measurements are \emph{strictly parallel}. Strictly parallel
measurements have the following four properties (p.~69, Haertel 2006):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Measurements have identical specifications. That is, each measurement
  is obtained with an identical format and procedure.
\item
  The distribution of observed scores for each measurement are
  identical: \(f(x_1) = f(x_2) = \ldots\).
\item
  Any set of two measurements are assumed to covary the same as any
  other set of two measurements:
  \(\sigma_{x_1 x_2} = \sigma_{x_2 x_3} = \sigma_{x_1 x_3} = \ldots\).
\item
  Each measurement equally covaries with any other variable:
  \(\sigma_{x_1 y} = \sigma_{x_2 y} = \ldots\).
\end{enumerate}

True scores can be defined as the expected value (i.e., the mean) of
observed scores over repeated measurements such that,
\(\mathbb{E}_m[x_{im}]=T_{i}\). Given this assumption, it can be
inferred that the average of the resultant errors is zero across
repeated measurements, \(\mathbb{E}_m[e_{im}]=0\) and therefore the
covariance between errors on repeated measurements is zero and the
covariance between errors in parallel measurements is zero
(\(\sigma_{e e'}=0\)). It follows that the covariance between errors and
true scores is also zero (\(\sigma_{eT}=0\)). The independence between
true scores and errors provide convenient parsing of the variance in
observed scores (\(\sigma^2_{x}\)) into components of variance in true
scores (\(\sigma_T^2\)) and measurement errors (\(\sigma_{e}^2\)),

\begin{equation}\protect\hypertarget{eq-variance}{}{
\sigma_{x}^2 = \sigma_T^2 + \sigma_{e}^2.
}\label{eq-variance}\end{equation}

Ultimately we desire to have observed scores that closely resemble true
scores, therefore it is important to minimize measurement error variance
(\(\sigma^2_e\)). If \(\sigma_{e}^2 = 0\) then the scores can be said to
have perfect reliability, that is, observed scores do not vary upon
repeated measurements and thus are identical to true scores. In
practice, this is virtually never the case. Since we know that the
covariance between errors in parallel measurements is zero, it should be
apparent that the covariance between observed scores in parallel
measurements must solely be attributable to variance in true scores,
\(\sigma_{xx'}=\,\)\(\sigma_{TT'} + \sigma_{ee'}=\,\)\(\sigma_{TT'}=\,\)\(\sigma_T^2\,\).
In true score theory, reliability can be defined as the proportion of
true variance in the total observed variance
(\(\frac{\sigma_T^2}{\sigma_x^2}\)) or the correlation between observed
scores in parallel measurements (\(r_{xx'}\)).

\[
r_{xx'}=\frac{\sigma_{xx'}}{\sigma_x\sigma_{x'}}  = \frac{\sigma_T^2}{\sigma^2_{x}}
\] The reliability is also equivalent to the square of the correlation
between observed scores and true scores. To understand why this is the
case, note that the covariance between parallel forms of a measure is
equivalent to the covariance between observed scores and true scores,
\(\sigma_{xT}=\)\(\sigma_{(T+e)T}=\)\(\sigma^2_T + \sigma_{Te}=\)\(\sigma^2_T = \sigma_{xx'}\).

\begin{equation}\protect\hypertarget{eq-reliability}{}{
r_{xx'} = \frac{\sigma_T^2}{\sigma_{x}^2} = \frac{(\sigma_T^2)^2}{\sigma_x^2 \sigma_T^2}= \frac{\sigma_{xT}^2}{\sigma^2_x\sigma^2_T} = r^2_{xT}
}\label{eq-reliability}\end{equation}

It is important to emphasize that true scores are expected values over
repeated observations and they do not necessarily correspond to an
actual, tangible quantity of interest (Borsboom and Mellenbergh 2002).
As a result, every measurement has a true score, regardless of whether
it gauges a concrete attribute or not. For example, if we construct a
test by summing the responses to the items: ``how many languages can you
confidently hold a conversation in?'' and ``Estimate the number of
photos you've taken in the last year across all devices''. Even in such
cases, the test's composite score retains a true score, but this true
score does not mirror a tangible reality.

\begin{figure}

{\centering \includegraphics[width=4.16667in,height=\textheight]{figure/unreliability_diagram_1.png}

}

\caption{Structural diagram illustrating the relationship between true
scores, observed scores, and error scores. The pink circle labeled \(t\)
indicates the true scores, the blue squares labeled with \(x\) and
\(x'\) represent observed scores on parallel measurements, and the red
\(e\) denotes error. Correlations between \(T\), \(x\), and \(x'\) are
in terms of reliability (\(r_{xx'}\)). Note that
\(\sqrt{r_{xx'}}=r_{xT}\).}

\end{figure}

\hypertarget{reliability-vs-validity}{%
\section{Reliability vs Validity}\label{reliability-vs-validity}}

Reliability and validity are distinct properties in measurement theory.
Validity pertains to whether a measure reflects the quantities it is
intended to measure (p.~14 Kelley 1927). According to Borsboom,
Mellenbergh, and Van Heerden (2004), a measure is \emph{valid} if the
following statements are true:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The attribute exists.
\item
  Variations in the attribute causally produce variations in the
  outcomes of the measurement procedure.
\end{enumerate}

Borsboom's formulation of validity is simpler and more practical than
other formulations such as Cronbach and Meehl's (1955) nomological
network approach to validity. It is important to note that even if an
attribute does not exist (statement 1), scores may still provide
predictive utility. For example, socio-economic status (SES) is a
formative quantity that is constructed from a composite of education,
income, occupation status, etc. Although SES is not causal to these
indicators, SES can still be used as a predictor of important life
outcomes.

\hypertarget{estimating-reliability}{%
\section{Estimating Reliability}\label{estimating-reliability}}

In practice, reliability must be estimated through indirect methods,
this is due to the fact that true scores and errors are unknown. There
are many reliability estimators that can be used, however we will go
over a selection of internal consistency estimators as well as
test-retest stability estimators.

\hypertarget{internal-consistency-estimators}{%
\subsection{Internal Consistency
Estimators}\label{internal-consistency-estimators}}

Taking multiple measurements and then averaging tends to provide a more
stable estimate of true values. For instance, let's consider the case of
Francis Galton (1907), who conducted a study involving 787 individuals
estimating the weight of an ox. On average, each person's estimate
deviated by approximately 37 pounds from the actual weight of the ox,
which was recorded as 1198 pounds. However, when all the guesses were
averaged together, the combined estimate was 1207 pounds, just a 9 pound
difference from the true value. This principle can be extended to
broader applications, such as measuring psychological constructs. If we
were to assess someone's level of extraversion using ratings from their
mother, father, friend, and sibling, the average of their combined
assessments would yield a more reliable score compared to relying solely
on a single evaluator. So to create a more stable composite score
(\(x\)), we can take the score from \(\kappa\) measures (\(\mathbb{x}\))
and sum them such that,

\[
x = \mathbb{x}_1 + \mathbb{x}_2 +...+\mathbb{x}_\kappa
\]

The most commonly reported reliability estimator in the psychological
sciences is coefficient alpha, also referred to as Cronbach's alpha.
Coefficient alpha, along with other internal consistency estimators,
serves the purpose of assessing the reliability of composite scores
comprising multiple measurements. Coefficient alpha reflects an estimate
of the reliability of the composite observed score, \(x\) (\(r_{xx'}\)).
Coefficient alpha only requires three parameters to calculate, the
number of measurements (\(\kappa\)), the variances of each items
(\(\sigma^2_{\text{i}_m}\)), and the variance of the composite score
(\(\sigma^2_{x}\)),

\begin{equation}\protect\hypertarget{eq-alpha}{}{
_\alpha r_{xx'} = \frac{k}{k-1}\left( 1 - \frac{\sum_{m=1}^\kappa \sigma^2_{\mathbb{x}_m}}{\sigma^2_{x}} \right)
}\label{eq-alpha}\end{equation}

\begin{figure}

{\centering \includegraphics{unreliability_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\caption{Figures showing the observed scores upon 10 repeated
measurements and the composite observed score for a single person (the
true score is denoted with the dashed line). The left panel shows 10
observed scores with a lot of variation (i.e., low reliability). The
composite score (dark red dot with error bars), shows wide error bars
illustrating the low precision of the observed score score. The right
panel also shows 10 observed scores with little variation (i.e., high
reliability). The composite score (dark blue dot with error bars), shows
narrow error bars illustrating the high precision of the observed
score.}

\end{figure}

With tighter assumptions (see Haertel 2006), the formula for coefficient
alpha can be simplified to just two parameters: the number of
measurements (\(\kappa\)) and the average correlation between measured
scores (\(\bar{r}_{\mathbb{x}_i \mathbb{x}_j}\), where \(i\neq j\)).
This formula is known as Spearman-Brown's prophecy,

\begin{equation}\protect\hypertarget{eq-sp-brown}{}{
_\text{sb} r_{xx'}= \frac{\kappa \bar{r}_{\mathbb{x}_i \mathbb{x}_j}}{1+(\kappa-1)\bar{r}_{\mathbb{x}_i \mathbb{x}_j}}
}\label{eq-sp-brown}\end{equation}

This can be simplified further if we have two observed scores. This
formulation is a variation of split-half reliability:

\begin{equation}\protect\hypertarget{eq-split-half}{}{
_\text{sh}r_{xx'}= \frac{2r_{\mathbb{x}_1 \mathbb{x}_2}}{1+r_{\mathbb{x}_1 \mathbb{x}_2}}
}\label{eq-split-half}\end{equation}

All of these reliability estimators measure internal consistency,
therefore they do not account for error outside of the
measurement-specific error. There are other sources of error that
internal consistency reliability estimates do not account for, such as
transient error or rater-specific error.

\begin{figure}

{\centering \includegraphics[width=4.16667in,height=\textheight]{figure/unreliability_diagram_2.png}

}

\caption{Structural model illustrating internal consistency. The pink
circle labeled \(T\) indicates the true scores, the blue squares,
\(\mathbb{x}_{1...\kappa}\), represent the observed scores across
multiple measurements, and the red \(e\) denotes error. The dark blue
hexagon, \(x\), indicates a composite score as a sum of the observed
scores (\(\mathbb{x}_{1...\kappa}\)). Note that
\(\sqrt{r_{xx'}}=r_{xT}\).}

\end{figure}

\hypertarget{calculating-internal-consistency-in-r}{%
\subsection{Calculating Internal Consistency in
R}\label{calculating-internal-consistency-in-r}}

Let us simulate a data set of 50 individuals that were measured four
times resulting in four sets of scores (\texttt{x1,x2,x3,x4}) that have
the same true score and error variance. Then let us calculate a
composite score (\texttt{x}) from these sub-scores.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{343}\NormalTok{)}

\CommentTok{\# set sample size}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{50}

\CommentTok{\# simulate data}
\NormalTok{T\_score }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate true scores}
\NormalTok{x1 }\OtherTok{\textless{}{-}}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate observed scores for measurement 1}
\NormalTok{x2 }\OtherTok{\textless{}{-}}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate observed scores for measurement 2}
\NormalTok{x3 }\OtherTok{\textless{}{-}}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate observed scores for measurement 3}
\NormalTok{x4 }\OtherTok{\textless{}{-}}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# simulate observed scores for measurement 4}

\CommentTok{\# calculate composite score}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3 }\SpecialCharTok{+}\NormalTok{ x4}
\end{Highlighting}
\end{Shaded}

Now let us calculate coefficient alpha from the formula provided in
Equation~\ref{eq-alpha}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1. calculate variance of observed (measured) scores}
\NormalTok{var\_xm }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{var}\NormalTok{(x1),}\FunctionTok{var}\NormalTok{(x2),}\FunctionTok{var}\NormalTok{(x3),}\FunctionTok{var}\NormalTok{(x4))}

\CommentTok{\# step 2. get number of items (k)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(var\_xm)}

\CommentTok{\# step 3. calculate variance of composite score}
\NormalTok{var\_x }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(x)}

\CommentTok{\# step 4. calculate coefficient alpha reliability}
\NormalTok{rxx\_alpha }\OtherTok{\textless{}{-}}\NormalTok{ k }\SpecialCharTok{/}\NormalTok{ (k}\DecValTok{{-}1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(var\_xm)}\SpecialCharTok{/}\NormalTok{(var\_x))}

\CommentTok{\# display reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx\_alpha,}\DecValTok{3}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.775
\end{verbatim}

With the simplification of Coefficient alpha's formula, let us calculate
the reliability via Spearman-Brown's prophecy formula provided in
Equation~\ref{eq-sp-brown}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1. get correlation matrix between all observed scores}
\NormalTok{corr\_mat }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(x1,x2,x3,x4))}

\CommentTok{\# step 2. average off{-}diagonal elements of matrix}
\FunctionTok{diag}\NormalTok{(corr\_mat) }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{rxixj }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(corr\_mat, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# step 3. get number of items (k)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{dim}\NormalTok{(corr\_mat)[}\DecValTok{1}\NormalTok{]}

\CommentTok{\# step 4. calculate Spearman{-}Brown reliability}
\NormalTok{rxx\_SB }\OtherTok{\textless{}{-}}\NormalTok{ k }\SpecialCharTok{*}\NormalTok{ rxixj }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ (k}\DecValTok{{-}1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ rxixj)}

\CommentTok{\# display reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx\_SB,}\DecValTok{3}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.775
\end{verbatim}

If we simplify even further, we can calculate the Split-Half reliability
formula provided in Equation~\ref{eq-split-half},

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1. make composite scores for each half of the observed scores}
\NormalTok{xh1 }\OtherTok{\textless{}{-}}\NormalTok{ (x1 }\SpecialCharTok{+}\NormalTok{ x2)}\SpecialCharTok{/}\DecValTok{2}
\NormalTok{xh2 }\OtherTok{\textless{}{-}}\NormalTok{ (x3 }\SpecialCharTok{+}\NormalTok{ x4)}\SpecialCharTok{/}\DecValTok{2}

\CommentTok{\# step 2. calculate the correlation between the scores of both halves}
\NormalTok{rx1x2 }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(xh1,xh2)}

\CommentTok{\# step 3. calculate the split{-}half reliability}
\NormalTok{rxx\_SH }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{*}\NormalTok{rx1x2 }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ rx1x2)}

\CommentTok{\# display reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx\_SH,}\DecValTok{3}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.824
\end{verbatim}

Lets see how the results compare to the actual reliability,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate true reliability, true scores must be re{-}scaled by number of items}
\NormalTok{rxx }\OtherTok{=} \FunctionTok{var}\NormalTok{(k}\SpecialCharTok{*}\NormalTok{T\_score) }\SpecialCharTok{/}\NormalTok{ var\_x}

\CommentTok{\# display actual reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx,}\DecValTok{3}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.734
\end{verbatim}

In this case, the reliability estimates do a fairly good job of
estimating the true reliability of the observed scores. We can also use
the \texttt{alpha} function from the \texttt{psych} package ({``Psych:
Procedures for Personality and Psychological Research''} 2017) to
estimate coefficient alpha too. It also provides additional item level
information that is quite useful:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load in package}
\CommentTok{\# install.packages(\textquotesingle{}psych\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psych)}

\CommentTok{\# compute summary reliability (only need first table)}
\FunctionTok{alpha}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(x1,x2,x3,x4))[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 raw_alpha std.alpha   G6(smc) average_r      S/N        ase        mean
 0.7749847 0.7751377 0.7337024 0.4628829 3.447166 0.05141467 -0.04386823
        sd  median_r
 0.9567892 0.4571798
\end{verbatim}

\hypertarget{test-retest-stability-estimator}{%
\subsection{Test-Retest Stability
Estimator}\label{test-retest-stability-estimator}}

Transient errors represent fluctuations in observed scores over time.
These fluctuations, even if they are systematic (e.g., fatigue over the
course of a single day), add extraneous within-person variance that can
mask true scores. Considering transient fluctuations as error depends on
the research goal, so it is important for researchers to take care in
considering which variance components should be considered error in
their study (see Section~\ref{sec-sources}). To estimate test-retest
reliability, we can compute the correlation between the measurement at
time 1 (\(x_{t_1}\)) and the second measurement at time 2 (\(x_{t_2}\)),

\[
_\text{tr}r_{xx'}= r_{x_{t_1}x_{t_2}}.
\]

Note that calculating the pearson correlation coefficient between
time-points ignores systematic changes (e.g., practice effects).

\begin{figure}

{\centering \includegraphics{unreliability_files/figure-pdf/unnamed-chunk-8-1.pdf}

}

\caption{Illustrating test-retest reliability. Top-left and top-right
panels show the correlation between observed scores at both time-points
for a measure that has low and high reliability, respectively.
Bottom-left and bottom-right panels show the within-person change from
time-point 1 to time-point 2 for scores with low and high reliability,
respectively.}

\end{figure}

\hypertarget{calculating-test-retest-reliability-in-r}{%
\subsection{Calculating Test-Retest Reliability in
R}\label{calculating-test-retest-reliability-in-r}}

Lets calculate test-retest reliability in R. First, we can simulate
observed scores at two time points, \texttt{xTime1} and \texttt{xTime2}.
We can assume that the true scores remain constant between time points.
Second, we can calculate the correlation between the observed scores at
each time point (\texttt{rxx}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{\# set sample size}
\NormalTok{n }\OtherTok{=} \DecValTok{100}

\CommentTok{\# simulate true scores}
\NormalTok{T\_score }\OtherTok{=} \FunctionTok{rnorm}\NormalTok{(n,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)}

\CommentTok{\# simulate scores at time 1}
\NormalTok{xTime1 }\OtherTok{=}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n,}\DecValTok{0}\NormalTok{,.}\DecValTok{5}\NormalTok{)}

\CommentTok{\# simulate scores at time 2}
\NormalTok{xTime2 }\OtherTok{=}\NormalTok{ T\_score }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n,}\DecValTok{0}\NormalTok{,.}\DecValTok{5}\NormalTok{)}

\CommentTok{\# calculate test{-}retest reliability}
\NormalTok{rxx }\OtherTok{=} \FunctionTok{cor}\NormalTok{(xTime1,xTime2)}

\CommentTok{\# display reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.755
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compare with true reliability}
\NormalTok{rxx\_true }\OtherTok{=} \FunctionTok{var}\NormalTok{(T\_score) }\SpecialCharTok{/} \FunctionTok{var}\NormalTok{(xTime1)}

\CommentTok{\# display actual reliability}
\FunctionTok{print}\NormalTok{(}\FunctionTok{round}\NormalTok{(rxx\_true,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.779
\end{verbatim}

\hypertarget{sec-sources}{%
\subsection{Sources of Measurement Error}\label{sec-sources}}

Measurement error variance can itself be broken down into multiple
sources of error (e.g., transient, ). Depending on the study, different
sources of error may be more relevant than others. It is important for a
researcher to choose the right reliability estimator for their study
since they account for different sources of measurement error. A
description of four of the most common sources of error is adapted from
table 1 of Wiernik and Dahlke (2020):

\begin{itemize}
\item
  Random Response Error: Genuine randomness in responses. Examples
  include: motor errors and variation in response time.
\item
  Time/Environment-Specific (Transient) Error: Fluctuations in scores as
  a result of the specific time or environment of the measurement. For
  instance, if researchers administered an ability test to a sample of
  undergraduate students throughout the course of a day, the student's
  who complete the test at the end of the day will likely perform worse
  than participant's who completed due to fatigue rather than ability.
  Errors due to illness, mood, hunger, environmental distractors, etc.
  all fall under the umbrella of transient errors.
\item
  Instrument-Specific Error: Error due to the specific content or
  make-up of the measurement instrument. For example, a psychological
  scale using Likert items may show participant's idiosyncratic
  interpretations of questions and response options rather than their
  standing on the latent construct.
\item
  Rater/Observer-Specific Error: Errors induced by idiosyncratic biases
  of individual raters and rater by ratee interactions (e.g., Teacher A
  gives higher grades to students who stay after class).
\end{itemize}

Different estimators of reliability account for different sources of
measurement error therefore depending on the research design, it is
important to carefully choose which reliability is most relevant for
your use case. Note that even if two estimators account for the same
types of measurement error, they likely hold different assumptions that
may be violated in a given research context.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}@{}}
\caption{Table 1. List of reliability coefficients and the sources of
error they account for.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Estimator
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Random Response Error
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Transient Error
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Instrument-Specific Error
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Rater-Specific Error
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Estimator
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Random Response Error
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Transient Error
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Instrument-Specific Error
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Rater-Specific Error
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Coefficient Alpha & Internal consistency coefficient for composite
measures. & X️ & & X️ & \\
Coefficient Omega & Internal consistency coefficient for composite
measures with specified factor structure. & X️ & & X️ & \\
Split-Half & Internal consistency coefficient for measurements that are
split into two halves. & X️ & & X️ & \\
Kuder-Richardson 20 & Internal consistency when observed scores are
binary (special case of coefficient alpha). & X️ & & X️ & \\
Item Response Theory Reliability & Reliability coefficient derived from
item response theory (as opposed to classical test theory) & X️ & & X️
& \\
Inter-Rater/Inter-Observer Reliability & Consistency in scoring between
raters/observers. & X️ & & & X️ \\
Test-Retest & Stability coefficient for repeated measurements across
time & X️ & X️ & & \\
Delayed Coefficient Alpha & Average of all possible split-half
reliabilities & X️ & X️ & X️ & \\
G-Coefficient & Reliability coefficient derived from generalizability
theory (G-theory). Can incorporate any source of error if enough data is
present. & X️ & X️ & X️ & X️ \\
\end{longtable}

\hypertarget{correction-for-bias-in-correlations-r}{%
\section{\texorpdfstring{Correction for Bias in Correlations
(\emph{r})}{Correction for Bias in Correlations (r)}}\label{correction-for-bias-in-correlations-r}}

\hypertarget{defining-the-estimand}{%
\subsection{Defining the Estimand}\label{defining-the-estimand}}

Continuing with our emphasis on clearly defining our quantity of
interest (i.e., the estimand) prior to applying any corrections, let us
define it. Our estimand here is the population correlation between true
scores of our independent and dependent variables. We can define the
observed scores of the independent and dependent variables \(x\) and
\(y\) as,

\[
x=T+e_x
\]

\[
y=U+e_y
\]

Where \(T\) and \(U\) are the true scores for the independent and
dependent variables, respectively. The true score correlation can thus
be be denoted by, \(\rho_{TU}\), and can be defined as the standardized
covariance, \[
\rho_{TU} = \frac{\sigma_{TU}}{\sigma_{T}\sigma_{U}}
\]

In a given study, we will only have knowledge of the observed scores of
the independent and dependent variables, \(x\) and \(y\), therefore the
population observed score correlation is \(\rho_{xy}\). To obtain an
unbiased estimate of the true score correlation, we must correct the
observed score correlation.

\hypertarget{sec-r-corr}{%
\subsection{Artifactual Bias and Correction}\label{sec-r-corr}}

Measurement error induces systematic bias in effect size estimates such
as correlation coefficients Spearman (1904). In the population, let us
assume there is some factor \(a\) that accounts for the systematic bias
in observed score correlations (\(\rho_{xy}\)) relative to true score
correlations (\(\rho_{TU}\)), such that

\[
\rho_{xy} = a \rho_{TU}.
\]

Since the correlation is defined as the covariance standardized by the
standard deviations, the population correlation between true scores,
\(T\) and \(U\), is defined as

\[
\rho_{TU}=\frac{\sigma_{TU}}{\sigma_{T} \sigma_{U}}
\]

Likewise the correlation between the observed scores, \(x\) and \(y\),
would be the observed covariance divided by the observed standard
deviations. \[
\rho_{xy} =\frac{\sigma_{xy}}{\sigma_{x} \sigma_{y}}
\] However, if we assume that there is no covariance between errors in
\(x\) and \(y\) (\(\sigma_{e_x e_y} = 0\)), then the covariance between
observed scores is only attributable to the covariance between true
scores, therefore \(\sigma_{xy} = \sigma_{TU}\). This means that the
observed score correlation can be expressed as

\begin{equation}\protect\hypertarget{eq-bias}{}{
\rho_{xy} =\frac{\sigma_{TU}}{\sigma_{x} \sigma_{y}}
}\label{eq-bias}\end{equation}

Now the only difference between the observed score correlation and the
true score correlation is the standard deviations in the denominator. In
the presence of measurement error, the observed score standard
deviations (\(\sigma_x\) and \(\sigma_y\)) will be larger than the true
score standard deviations (\(\sigma_{T}\) and \(\sigma_{U}\)). Using the
definition of reliability, we can show how the observed variance is
inflated compared to the true variance as a function of reliability.
Since the reliability is defined as the ratio of true variance to total
observed variance (see Equation~\ref{eq-reliability}), we can see how
reliability inflates the observed variance

\begin{align}
\sigma^2_x &=\sigma^2_{T} \left(\frac{\sigma^2_{x}}{\sigma^2_{T}} \right)
\\ &= \sigma^2_{T}\left(\frac{1}{r_{xx'}} \right)
\\ &= \frac{\sigma^2_{T}}{r_{xx'}},
\end{align}

therefore the observed standard deviation is,

\begin{equation}\protect\hypertarget{eq-sd-me}{}{
\sigma_x = \frac{\sigma_{T}}{\sqrt{r_{xx'}}}.
}\label{eq-sd-me}\end{equation}

If we use the definition of an observed score correlation
(Equation~\ref{eq-bias}), then we can replace \(\sigma_x\) and
\(\sigma_y\) with \(\frac{\sigma_{T}}{\sqrt{r_{xx'}}}\) and
\(\frac{\sigma_{U}}{\sqrt{r_{yy'}}}\), respectively. Now we can see how
the observed score correlation differs from the true score correlation:

\begin{align}
\rho_{xy} &= \frac{\sigma_{T U}}{\left[\frac{\sigma_{T}}{\sqrt{r_{xx'}}} \right] \left[ \frac{\sigma_{U}}{\sqrt{r_{yy'}}} \right] } 
\\ &= \frac{\sigma_{T U}}{\sigma_{T}\sigma_{U}} \cdot \sqrt{r_{yy'}}\sqrt{r_{xx'}}
\\ &= \rho_{TU} \sqrt{r_{yy'}}\sqrt{r_{xx'}} 
\end{align}

This attenuation formula was first derived by Spearman (1904). Note that
this formulation requires that there is no correlation between \(e_x\)
and \(e_y\) (\(r_{e_xe_y}=0\)). The study observed correlation will also
contain sampling error and thus can be expressed by, \[
r_{xy} = \rho_{xy} + \varepsilon_o
\] We can also express it in terms of our estimand, the population true
score correlation (\(\rho_{TU}\)),

\[
r_{xy} = \rho_{TU}\sqrt{r_{xx'}r_{xx'}} + \varepsilon_o
\]

\begin{figure}

{\centering \includegraphics{unreliability_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\caption{Visualizing the attenuation of observed correlation
(\(\rho_{xy}\)) due to measurement error. The left panel shows a
situation where only one variable (\(x\)) has measurement error. The
observed correlation increases as a function of the true correlation
\(\rho_{TU}\) (darker lines indicate a higher true score correlation)
and the reliability of \(x\) (x-axis). The right panel shows the
attenuation of the correlation when both \(x\) and \(y\) variables are
affected by measurement error. The darker end of the gradient shows a
higher correlation, while the lighter end represents a smaller
correlation (the true score correlation sits on the top where no
measurement error is present, \(r_{xx'}=r_{yy'}=1\)).}

\end{figure}

It becomes apparent that if we have the reliability of \(x\) and \(y\),
we can obtain an unbiased estimate of \(\rho_{TU}\) by dividing both
sides of the above equation by \(\sqrt{r_{xx'}r_{xx'}}\) such that,

\[
\frac{r_{xy}}{\sqrt{r_{xx'}r_{xx'}}} =\rho_{TU} + \frac{\varepsilon_o}{\sqrt{r_{xx'}r_{xx'}}}
\] Therefore the corrected study correlation, \(r_c\), is defined as,

\[
r_c = \frac{r_{xy}}{\sqrt{r_{xx'}r_{xx'}}}.
\] The sampling error of the corrected study correlation is,

\[
\varepsilon_c = \frac{\varepsilon_{o}}{\sqrt{r_{xx'}r_{xx'}}}
\]

and thus the sampling variance would be,

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_{o}}}{r_{xx'}r_{xx'}}.
\]

\hypertarget{correcting-correlations-in-r}{%
\subsection{Correcting Correlations in
R}\label{correcting-correlations-in-r}}

We can simulate continuous data that contains measurement error by using
the \texttt{simulate\_r\_sample} function in the \texttt{psychmeta}
package. Below we will simulate observed scores (\texttt{x\_score} and
\texttt{y\_score}) and true scores (\texttt{T\_score} and
\texttt{U\_score}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}


\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{\# define parameters}
\NormalTok{rhoTU }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}
\NormalTok{rxx }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{8}
\NormalTok{ryy }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{7}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{500}

\CommentTok{\# simulate data}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{simulate\_r\_sample}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n, }
                          \AttributeTok{rho\_mat =} \FunctionTok{reshape\_vec2mat}\NormalTok{(rhoTU),}
                          \AttributeTok{rel\_vec =} \FunctionTok{c}\NormalTok{(rxx, ryy), }
                          \AttributeTok{sr\_vec =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }
                          \AttributeTok{var\_names =} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{,}\StringTok{"y"}\NormalTok{))}

\CommentTok{\# obtain observed scrores}
\NormalTok{x\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{x}
\NormalTok{y\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{y}

\CommentTok{\# obtain true scores}
\NormalTok{T\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{true}\SpecialCharTok{$}\NormalTok{x}
\NormalTok{U\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{true}\SpecialCharTok{$}\NormalTok{y}
\end{Highlighting}
\end{Shaded}

Then we can compute observed score (\texttt{rxy}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute observed score correlation and standard error}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x\_score,y\_score)}

\CommentTok{\# compute sampling variance of observed score correlation}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxy}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}2}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e\_o = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_o,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "rxy = 0.351  var_e_o = 0.0018"
\end{verbatim}

Let us now compare the observed correlation with the true score
correlation (\texttt{rTU}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute observed score correlation and standard error}
\NormalTok{rTU }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(T\_score,U\_score)}

\CommentTok{\# compute sampling variance of observed score correlation}
\NormalTok{var\_e }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rTU}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}2}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rTU = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rTU,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "rTU = 0.463  var_e = 0.0016"
\end{verbatim}

The observed correlation is substantially lower than the true score
correlation. In order to correct the observed score correlation, we can
calculate it by hand or use the \texttt{correct\_r()} function. Lets
first correct by hand using the equations in Section~\ref{sec-r-corr}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# correct correlation coefficient}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ rxy }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(rxx}\SpecialCharTok{*}\NormalTok{ryy)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(rxx}\SpecialCharTok{*}\NormalTok{ryy)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rc = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e\_c = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "rc = 0.47  var_e_c = 0.0024"
\end{verbatim}

Now lets correct the correlation with the \texttt{correct\_r()}
function,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# correct correlation}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxy,}
          \AttributeTok{rxx =}\NormalTok{ rxx,}
          \AttributeTok{ryy =}\NormalTok{ ryy,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95   n n_effective
1  0.47    0.364    0.569 500         222
\end{verbatim}

As we can see, the corrected correlation (\(r_c = .470\)) is a more
accurate estimate of the true score population correlation
\(\rho_{TU} = .500\), than the observed score correlation
(\(r_{xy}=.351\)).

\hypertarget{correction-for-bias-in-standardized-mean-differences-d}{%
\section{\texorpdfstring{Correction for Bias in Standardized Mean
Differences
(\emph{d})}{Correction for Bias in Standardized Mean Differences (d)}}\label{correction-for-bias-in-standardized-mean-differences-d}}

\hypertarget{defining-the-estimand-1}{%
\subsection{Defining the Estimand}\label{defining-the-estimand-1}}

Prior to correcting for measurement error let us define our estimand.
Our estimand here is the difference in the means of group \(A\) and
\(B\) with respect to the true scores of our dependent variable. We can
define the observed scores of the independent and dependent variables
\(x\) and \(y\) as,

\[
y_A = U_A + e_A
\]

\[
y_B = U_B + e_B
\]

Where \(U_A\) and \(U_B\) are the true scores for group \(A\) and group
\(B\), respectively. The true score standardized mean difference can
thus be be denoted by, \(\delta_{U}\), and can be defined as

\[
\delta_{U} = \frac{\overline{U}_A - \overline{U}_B}{\sigma_{U_P}}
\]

Where \(\overline{U}\) is the mean of true scores for the respective
group. In a given study, we only have access to the observed scores of
the independent and dependent variables, \(x\) and \(y\), therefore the
population observed score correlation is \(\delta_{y}\). To obtain an
unbiased estimate of \(\delta_{U}\), we must apply a correction to the
observed score standardized mean difference.

\hypertarget{sec-d-SMD}{%
\subsection{Artifactual Bias and Correction}\label{sec-d-SMD}}

We can calculate the standardized mean difference (SMD) of the observed
scores by dividing the mean difference in observed scores
(\(\bar{y}_A-\bar{y}_B\)) by the pooled standard deviation
(\(\sigma_p\)). It is important to note that the mean of true scores and
the mean of observed scores will be identical due to the fact that
measurement error only affects variance in scores. Therefore, we can
express the observed standardized mean difference as,

\[
d = \frac{\bar{y}_A-\bar{y}_B}{\sigma_{y_P}} = \frac{\overline{U}_A-\overline{U}_B}{\sigma_{y_P}}
\]

The pooled standard deviation is a weighted average of the observed
score standard deviations,

\[
\sigma_{y_P}=\sqrt{\frac{(n_A+1)\sigma^2_{y_A}+(n_B+1)\sigma^2_{y_B}}{n_A+n_B-2}}.
\]

To express \(\sigma_{y_P}\) in terms of the true score standard
deviations, we can place the observed score standard deviations with the
attenuated true score standard deviation in Equation~\ref{eq-sd-me},

\[
\sigma_{y_P} = \sqrt{\frac{(n_A+1)\left(\frac{\sigma^2_{U_A}}{r_{yy'_A}}\right)+(n_B+1)\left(\frac{\sigma^2_{U_B}}{r_{yy'_B}}\right)}{n_A + n_B - 2}}.
\]

Alternatively, we can pool the reliability and the true score standard
deviations separately so that we can obtain a simplified version of the
above equation,

\[
\sigma_{U_P} = \sqrt{\frac{(n_A+1)\sigma_{U_A}^2+(n_B+1)\sigma_{U_B}^2}{n_A + n_B - 2}}.
\]

\[
r_{yy'_P} = \sqrt{\frac{(n_A+1) r_{yy'_A}^2+(n_B+1)r_{yy'_B}^2}{n_A + n_B - 2}}.
\]

Then we can express \(\sigma_{y_P}\) similarly to
Equation~\ref{eq-sd-me},

\[
\sigma_{y_P} = \frac{\sigma_{U_P}}{\sqrt{r_{yy'_P}}}
\]

Now we can put it all together and see how the observed score
standardized mean difference (\(\delta_y\)) is biased relative to the
true score standardized mean difference (\(\delta_U\)),

\begin{align}
\delta_y &= \frac{\bar{y}_A-\bar{y}_B}{\sigma_{y_P}}
\\[1em] &= \frac{\overline{U}_A-\overline{U}_B}{\sigma_{y_P}}
\\[1em] &= \frac{\overline{U}_A-\overline{U}_B}{\frac{\sigma_{U_P}}{\sqrt{r_{yy'_P}}}} 
\\[1em] &= \frac{\overline{U}_A-\overline{U}_B}{\sigma_{U_P}}\sqrt{r_{yy'_P}}
\\[1em] &= \delta_U\sqrt{r_{yy'_P}}
\end{align}

This attenuation bias is very similar to the one we saw in the
correlation, with the only difference being that the pooled reliability
is used here instead of the total sample reliability. Within a study,
the observed score standardized mean difference (\(d_y\)) will not only
be attenuated by measurement error, but it will also contain sampling
error such that,

\[
d_y = \delta_y + \varepsilon_o
\] replacing the observed population SMD, \(\delta_y\), with
\(\delta_U\sqrt{r_{yy'_P}}\), gives us,

\[
d_y = \delta_U\sqrt{r_{yy'_P}} + \varepsilon
\] Therefore to obtain the corrected study SMD (\(d_c\)) we can divide
\(d_y\) by the attenuation factor,

\[
d_c = \frac{d_y}{\sqrt{r_{yy'_P}}}
\]

Where the sampling variance of the corrected SMD must also be similarly
adjusted,

\[
\sigma^2_{\varepsilon_c} = \frac{\sigma^2_{\varepsilon_o}}{r_{yy'_P}}
\] Although the attenuation factor is quite simple, in more complex
formulations (e.g., bivariate direct range restriction), it will be
easier to apply a simplified correction for the sampling variance using
the corrected correlation coefficient: \[
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{d_c}{d_y}\right)^2
\] It is important to point out that this correction can only be done if
when estimates of the within-group reliability are available. It is
common that studies will only report the full sample reliability. If
there are differences between groups on the variable, the total sample
reliability will over-estimate the within-group reliability. When the
total sample reliability is all that is available, to correct \(d_y\),
we must first convert it to a point-biserial correlation coefficient
(\(r_{pb}\)) using the observed proportion of subjects in either group
\(A\) or \(B\) (\(p\,\); it does not matter which one is chosen, as long
as it is consistent throughout).

\[
r_{pb} = \frac{d}{\sqrt{\frac{1}{p(1-p)}+d^2}}.
\] Then correct \(r_{pb}\) for the total sample reliability,

\[
r_c = \frac{r_{pb}}{\sqrt{r_{yy'}}}
\]

Then we can convert \(r_c\) back into \(d_c\),

\[
d_c = \frac{r_c}{\sqrt{p(1-p)(1-r_c^2)}}
\] The same process of converting to a point-biserial correlation and
back to a standardized mean difference can be done for the sampling
variance as well, but instead we can put it all into one equation,

\[
\sigma^2_{\varepsilon_c} = \frac {\sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{pb}}\right)^2} {\left(1+d^2p[1-p]\right)^3(1-r_c^2)^3}
\]

\hypertarget{correcting-d-values-in-r}{%
\subsection{\texorpdfstring{Correcting \emph{d} values in
R}{Correcting d values in R}}\label{correcting-d-values-in-r}}

We can simulate data that contains measurement error by using the
\texttt{simulate\_d\_sample} function in the \texttt{psychmeta} package.
Below we will simulate observed scores (\texttt{y\_score}) and true
scores (\texttt{U\_score}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\CommentTok{\# define parameters}
\NormalTok{Means }\OtherTok{=} \FunctionTok{c}\NormalTok{()}
\NormalTok{ryyA }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{75}
\NormalTok{ryyB }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{70}
\NormalTok{nA }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{nB }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{n }\OtherTok{\textless{}{-}}\NormalTok{ nA }\SpecialCharTok{+}\NormalTok{ nB}

\CommentTok{\# simulate data}
\NormalTok{data}\OtherTok{\textless{}{-}} \FunctionTok{simulate\_d\_sample}\NormalTok{(}\AttributeTok{n\_vec =} \FunctionTok{c}\NormalTok{(nA, nB), }
                         \AttributeTok{rho\_mat\_list =} \FunctionTok{list}\NormalTok{(}\FunctionTok{reshape\_vec2mat}\NormalTok{(}\DecValTok{1}\NormalTok{),}\FunctionTok{reshape\_vec2mat}\NormalTok{(}\DecValTok{1}\NormalTok{)),}
                         \AttributeTok{mu\_mat =} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{c}\NormalTok{(.}\DecValTok{5}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                                        \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }
                         \AttributeTok{sigma\_mat =} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
                                           \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)),}
                         \AttributeTok{rel\_mat =} \FunctionTok{rbind}\NormalTok{(}\FunctionTok{c}\NormalTok{(ryyA,}\DecValTok{1}\NormalTok{),}
                                         \FunctionTok{c}\NormalTok{(ryyB,}\DecValTok{1}\NormalTok{)), }
                         \AttributeTok{sr\_vec =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
                         \AttributeTok{group\_names =} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{))}

\CommentTok{\# obtain observed scores}
\NormalTok{y\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{y1}
\NormalTok{group }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{group}

\CommentTok{\# obtain true scores}
\NormalTok{U\_score }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{data}\SpecialCharTok{$}\NormalTok{true}\SpecialCharTok{$}\NormalTok{y1}
\end{Highlighting}
\end{Shaded}

Then we can compute observed score standardized mean difference
(\texttt{dy}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute observed score means and standard deviations}
\NormalTok{Mean\_A }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(y\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{])}
\NormalTok{Mean\_B }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(y\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}
\NormalTok{SD\_A }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(y\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{])}
\NormalTok{SD\_B }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(y\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}

\CommentTok{\# compute pooled standard deviation}
\NormalTok{SD\_P }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{( ((nA}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SD\_A}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (nB}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SD\_B}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB}\DecValTok{{-}2}\NormalTok{) )}

\CommentTok{\# compute standardized mean difference}
\NormalTok{dy }\OtherTok{\textless{}{-}}\NormalTok{ (Mean\_A }\SpecialCharTok{{-}}\NormalTok{ Mean\_B) }\SpecialCharTok{/}\NormalTok{ SD\_P}

\CommentTok{\# compute sampling variance of observed score correlation}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ n}\SpecialCharTok{/}\NormalTok{(nA}\SpecialCharTok{*}\NormalTok{nB) }\SpecialCharTok{+}\NormalTok{ dy}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{n)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}dy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dy,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e\_o = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_o,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dy = 0.273  var_e_o = 0.0202"
\end{verbatim}

Let us now compare the observed score SMD with the true score SMD
(\texttt{dU}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compute true score means and standard deviations}
\NormalTok{Mean\_A }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(U\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{])}
\NormalTok{Mean\_B }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(U\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}
\NormalTok{SD\_A }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(U\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{])}
\NormalTok{SD\_B }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(U\_score[group}\SpecialCharTok{==}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}

\CommentTok{\# compute pooled standard deviation}
\NormalTok{SD\_P }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{( ((nA}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SD\_A}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (nB}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{SD\_B}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB}\DecValTok{{-}2}\NormalTok{) )}

\CommentTok{\# compute standardized mean difference}
\NormalTok{dU }\OtherTok{\textless{}{-}}\NormalTok{ (Mean\_A }\SpecialCharTok{{-}}\NormalTok{ Mean\_B) }\SpecialCharTok{/}\NormalTok{ SD\_P}

\CommentTok{\# compute sampling variance of the true score SMD}
\NormalTok{var\_e }\OtherTok{\textless{}{-}}\NormalTok{ n}\SpecialCharTok{/}\NormalTok{(nA}\SpecialCharTok{*}\NormalTok{nB) }\SpecialCharTok{+}\NormalTok{ dy}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{n)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}dU = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dU,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "dU = 0.509  var_e = 0.0202"
\end{verbatim}

The observed score SMD is substantially lower than the true score SMD
(.286 vs .509). In order to correct the observed score correlation for
attenuation, we can calculate it by hand. Lets correct the observed SMD
for measurement error variance using the equations in
Section~\ref{sec-d-SMD}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate the pooled reliability}
\NormalTok{ryy\_P }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(((nA}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{ryyA}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (nB}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{ryyB}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB}\DecValTok{{-}2}\NormalTok{))}

\CommentTok{\# correct correlation coefficient}
\NormalTok{dc }\OtherTok{\textless{}{-}}\NormalTok{ dy }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(ryy\_P)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(ryyA)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rc = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dc,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}  var\_e\_c = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "rc = 0.32  var_e_c = 0.0233"
\end{verbatim}

Now lets correct the correlation with the \texttt{correct\_r()}
function. The \texttt{correct\_d()} function only takes in the total
sample reliability, therefore we can extract the total sample
reliability from the simulated dataset and then use the resulting
reliability coefficient in the \texttt{ryy} argument.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# total sample reliability}
\NormalTok{ryy }\OtherTok{=}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{overall\_results}\SpecialCharTok{$}\NormalTok{observed}\SpecialCharTok{$}\NormalTok{parallel\_ryyi\_total[}\DecValTok{1}\NormalTok{]}

\CommentTok{\# correct correlation}
\FunctionTok{correct\_d}\NormalTok{(}\AttributeTok{d =}\NormalTok{ dy,}
          \AttributeTok{ryy =}\NormalTok{ ryy,}
          \AttributeTok{n1 =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
d Values Corrected for Measurement Error:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95   n n_effective
1 0.322 -0.00878    0.667 200         142
\end{verbatim}

As we can see, the corrected correlation (\(d_c = .32\)) is a more
accurate estimate of the true score population SMD \(\delta_U = .500\),
than the observed score correlation (\(r_{xy}=.273\)).

\hypertarget{sec-lim-information}{%
\section{Estimating Reliability with Limited
Information}\label{sec-lim-information}}

Reliability estimates should preferably be calculated from within the
study's sample, however there are a couple of ways to estimate
reliability when this information is not provided. A common way to
obtain an estimate of the reliability is to look in meta-analyses or a
test manuals. If the number of items in a study differs from the test
manual, you can approximate the reliability of a study's test, with a
re-arrangement of the Spearman-Brown prophecy formula,

\[
r_{xx'_{study}} \approx \frac{1}{\frac{k_{\text{ref}}}{k_{\text{study}}} \left(\frac{1}{r_{xx'_{study}}} - 1\right) + 1}
\]

Where \(k_{\text{ref}}\) and \(k_{\text{study}}\) denote the number of
items in the reference test and the test used in the study,
respectively.

(Haertel 2006)

(F. L. Schmidt, Le, and Ilies 2003)

(Gliem and Gliem 2003)

(Bobko, Roth, and Bobko 2001)

(Mendoza and Mumford 1987)

(Brennan 2010)

(Viswanathan 2005)

(Viswesvaran et al. 2014)

(Sijtsma 2009)

(Charles 2005)

(Spearman 1904)

\hypertarget{group-misclassification}{%
\chapter{Group Misclassification}\label{group-misclassification}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

Group misclassification describes a situation where true group
membership (e.g., people with a disorder) does not perfectly match the
observed group membership (e.g., people \emph{diagnosed} with a
disorder). Group misclassification can be considered a type of
measurement error where instead of accounting for errors in continuous
variables (i.e., unreliability), group misclassification accounts for
errors in categorical variables.

\hypertarget{defining-group-misclassification}{%
\section{Defining Group
Misclassification}\label{defining-group-misclassification}}

Misclassification can be defined as any deviations between true group
membership and observed group membership. Let us imagine two arbitrary
groups, group \(A\) and group \(B\). In order to identify members of
group \(A\) and group \(B\), we have to use some measurement instrument.
Also let us assume that this measurement instrument produces imperfect
group classifications, that is, people who are actually in group \(A\)
are sometimes assigned group \(B\) and vice versa. We can visualize the
performance of the classification procedure with a contingency table
between actual group membership (\(G\)) and observed group membership
(\(g\)):

\begin{longtable}[]{@{}lcc@{}}
\toprule\noalign{}
& \(G=A\) & \(G=B\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(g=A\) & \(AA\) & \(BA\) \\
\(g=B\) & \(AB\) & \(BB\) \\
\end{longtable}

We can see from the contingency table that subjects who were correctly
classified, would be labeled in the cell block \(AA\) or \(BB\) and
those who were misclassified would belong to cells \(BA\) and \(AB\).
Therefore we can define the proportion of people that are accurately
classified as \(p_{\text{acc}} = P(AA) + P(BB)\) whereas the proportion
of people misclassified can be defined as
\(p_{\text{mis}} = P(AB)+ P(BA)\). A high-quality classifier would would
minimize \(p_{\text{mis}}\) and maximize \(p_{\text{acc}}\).
Additionally, note that the proportion of people misclassified is
inversely proportional to the proportion of people accurately classified
such that, \(p_{\text{mis}} = 1-p_{\text{acc}}\).

\hypertarget{classification-reliability}{%
\section{Classification Reliability}\label{classification-reliability}}

Similar to quantifying reliability in continuous variables by
calculating the correlation in parallel sets of observed scores, the
same can be done in categorical variables. Instead of a contingency
table between observed (\(g\)) and true (\(G\)) group membership, we
will instead create a contingency table of two measurements producing
two sets of observed classifications (\(g\) and \(g'\)). Measurements
often will take the form of inter-rater assessments, for example, two
clinician's diagnosis of Major Depressive Disorder (MDD) in the same
sample of patients.

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& \(g=A\) & \(g=B\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(g'=A\) & \(AA\) & \(BA\) \\
\(g'=B\) & \(AB\) & \(BB\) \\
\end{longtable}

To obtain the reliability of the group assignments, we can calculate the
correlation coefficient between \(G\) and \(G'\). Since both variables
are categorical, a Pearson correlation coefficient would not be an
appropriate correlation estimator, instead, we must compute the phi
coefficient. The phi coefficient is often referred to as Matthew's
correlation coefficient and is most frequently used as an index of
performance of a binary classifier in machine learning. For the sake of
consistency, the phi coefficient will be denoted with the letter \(r\),
and thus the reliability (i.e., the correlation between \(G\) and
\(G'\)) is denoted with \(r_{GG'}\).

There are a few ways we can calculate the phi coefficient. The first way
is to calculate phi directly from the contingency table,

\[
r_{gg'} = \frac{n_{AA}n_{BB}-n_{AB}n_{BA}}{\sqrt{(n_{AA}+n_{BA})(n_{AB}+n_{BB})(n_{AA}+n_{AB})(n_{BA}+n_{BB})}}.
\]

Where \(n_{AA}\), \(n_{BB}\), \(n_{AB}\), and \(n_{BA}\) are the number
of subjects within their respective cells of the contingency table. If
the values of the contingency table are not available, we can calculate
the phi coefficient from the \(\chi^2\)-statistic,

\[
r_{gg'} = \sqrt{\frac{\chi^2}{n}}.
\] Where \(n\) is the total sample size. If the \(\chi^2\)-statistic is
unavailable, we can approximate the phi coefficient from the accuracy
(\(p_{\text{acc}}\)) or the proportion of people misclassified
(\(p_{\text{mis}}\)),

\[
r_{gg'} = (2p_{\text{acc}}-1)^2 = (1-2p_{\text{mis}})^2
\]

This approximation assumes that the group sizes are approximately equal
\emph{and} the misclassification rates are approximately equal between
groups. Otherwise, \(r_{gg'}\) will be overestimated (Wiernik and Dahlke
2020).

In the chapter on unreliability, we discussed the relationship between
reliability and the correlation between observed and true scores. The
classification reliability will also be related similarly to the
correlation between observed group membership and true group membership
(\(r_{gG}\)) such that,

\[
r_{gG}=\sqrt{r_{gg'}}
\]

\hypertarget{calculating-classification-reliability-in-r}{%
\section{Calculating Classification Reliability in
R}\label{calculating-classification-reliability-in-r}}

To calculate classification reliability we will first need data. We can
simulate 100 subjects with a group value for three variables: a true
group membership and two sets of assigned (observed) group membership.
We will set the misclassification rate to 10\%.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{17}\NormalTok{)}

\CommentTok{\# 10\% misclassification rate}
\NormalTok{p\_mis }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{10}

\CommentTok{\# sample size of 100}
\NormalTok{nA }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{nB }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{n }\OtherTok{=}\NormalTok{ nA }\SpecialCharTok{+}\NormalTok{ nB}

\CommentTok{\# create a vector of true group values}
\NormalTok{true\_A }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,nA)}
\NormalTok{true\_B }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,nB)}
\NormalTok{true\_group }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(true\_A,true\_B)}

\CommentTok{\# initialize vectors of observed group membership from true group membership}
\NormalTok{obs\_1\_A }\OtherTok{\textless{}{-}}\NormalTok{ true\_A}
\NormalTok{obs\_1\_B }\OtherTok{\textless{}{-}}\NormalTok{ true\_B}
\NormalTok{obs\_2\_A }\OtherTok{\textless{}{-}}\NormalTok{ true\_A}
\NormalTok{obs\_2\_B }\OtherTok{\textless{}{-}}\NormalTok{ true\_B}

\CommentTok{\# add misclassified values to observed group membership}
\NormalTok{obs\_1\_A[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nA,nA}\SpecialCharTok{*}\NormalTok{p\_mis)] }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}B\textquotesingle{}}
\NormalTok{obs\_1\_B[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nB,nB}\SpecialCharTok{*}\NormalTok{p\_mis)] }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}A\textquotesingle{}}
\NormalTok{obs\_2\_A[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nA,nA}\SpecialCharTok{*}\NormalTok{p\_mis)] }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}B\textquotesingle{}}
\NormalTok{obs\_2\_B[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nB,nB}\SpecialCharTok{*}\NormalTok{p\_mis)] }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}A\textquotesingle{}}
\NormalTok{obs\_1\_group }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(obs\_1\_A,obs\_1\_B)}
\NormalTok{obs\_2\_group }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(obs\_2\_A,obs\_2\_B)}
\end{Highlighting}
\end{Shaded}

Then we can generate a contingency table of the two sets of observed
group assignments.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create contingency table of the two observed group memberships}
\NormalTok{con\_table }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs\_1=}\NormalTok{obs\_1\_group,}\AttributeTok{obs\_2=}\NormalTok{obs\_2\_group))}
\FunctionTok{print}\NormalTok{(con\_table)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     obs_2
obs_1  A  B
    A 40 10
    B 10 40
\end{verbatim}

Now we can calculate the reliability of the group assignments by
extracting the phi coefficient from the contingency table. We can
compute it by hand or by using the \texttt{psych} package by William
Revelle (2017).

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Strategy 1: Using the \{psych\} package}
\CommentTok{\# load in psych package (make sure it is installed first: install.packages(\textquotesingle{}psych\textquotesingle{}))}
\FunctionTok{library}\NormalTok{(psych)}
\NormalTok{rgg }\OtherTok{=} \FunctionTok{phi}\NormalTok{(con\_table,}\AttributeTok{digits =} \DecValTok{3}\NormalTok{)}
\FunctionTok{print}\NormalTok{(rgg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Strategy 2: calculate from contingency table values}
\NormalTok{numerator }\OtherTok{\textless{}{-}}\NormalTok{ con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}\SpecialCharTok{*}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]}\SpecialCharTok{*}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}
\NormalTok{denominator }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}\SpecialCharTok{+}\NormalTok{con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]) }\SpecialCharTok{*}
               \FunctionTok{sqrt}\NormalTok{(con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}\SpecialCharTok{+}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]) }\SpecialCharTok{*} 
               \FunctionTok{sqrt}\NormalTok{(con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]}\SpecialCharTok{+}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{]) }\SpecialCharTok{*} 
               \FunctionTok{sqrt}\NormalTok{(con\_table[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]}\SpecialCharTok{+}\NormalTok{con\_table[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{])}

\NormalTok{rgg }\OtherTok{\textless{}{-}}\NormalTok{ numerator }\SpecialCharTok{/}\NormalTok{ denominator}
\FunctionTok{print}\NormalTok{(rgg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Strategy 3: calculate from chi{-}square test}
\NormalTok{chi2 }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{chisq.test}\NormalTok{(con\_table)}\SpecialCharTok{$}\NormalTok{statistic)}
\NormalTok{rgg }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(chi2}\SpecialCharTok{/}\NormalTok{n)}
\FunctionTok{print}\NormalTok{(rgg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.58
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Strategy 4: calculate from proportion of people misclassified}
\NormalTok{rgg }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1{-}2}\SpecialCharTok{*}\NormalTok{p\_mis)}\SpecialCharTok{\^{}}\DecValTok{2}
\FunctionTok{print}\NormalTok{(rgg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.64
\end{verbatim}

\hypertarget{bias-in-standardized-mean-difference}{%
\section{Bias in Standardized Mean
Difference}\label{bias-in-standardized-mean-difference}}

Standardized mean differences will become biased when subject's assigned
groups differ from their actual group. This is largely due to the fact
that the means of each group are driven closer to one another. Let us
suppose that, on average, group \(A\) and group \(B\) score differently
on some outcome, \(y\). The true mean of \(y\) for groups \(A\) and
\(B\) can be denoted as \(\bar{y}^*_{A}\) and \(\bar{y}^*_{B}\),
respectively. Nonetheless, when some subjects are erroneously assigned
to the wrong group, the \emph{observed} mean within each group will
reflect a weighted average of the respective means. This is due to the
fact that the misclassified individuals are being drawn from a
population with a different mean. To calculate the mean of the observed
groups we must incorporate the true mean of the correctly classified
subjects and the misclassified subjects

\[
\bar{y}_A = \left(\frac{n_{AA}}{n_{AA}+n_{BA}}\right)\bar{y}^*_A + \left(\frac{n_{BA}}{n_{AA}+n_{BA}}\right)\bar{y}^*_B
\]

\[
\bar{y}_A = \left(\frac{n_{BB}}{n_{BB}+n_{AB}}\right)\bar{y}^*_B + \left(\frac{n_{BA}}{n_{BB}+n_{BA}}\right)\bar{y}^*_A
\]

From the above equations, it becomes evident that as the number of
misclassified individuals increases (\(n_{AB}\) and \(n_{BA}\)), the
observed means of each group gradually converge towards each other. As
the means converge, the standardized mean difference will
correspondingly shift toward zero. To illustrate this phenomenon,
Figure~\ref{fig-nomis} shows the distributions for groups \(A\) and
\(B\) without any misclassification. In this case, there is no
attenuation of the standardized mean difference.

\begin{figure}

{\centering \includegraphics{misclassification_files/figure-pdf/fig-nomis-1.pdf}

}

\caption{\label{fig-nomis}Distributions of scores without
misclassification. True mean difference and observed mean differ only
due to sampling error.}

\end{figure}

If some individual's are assigned to the incorrect group, then we will
see attenuation in the standardized mean difference as the means
converge. Figure~\ref{fig-mis} shows what happens when the
misclassification rate is 10\%. A misclassification rate of 10\% is
equivalent to a classification reliability of \(r_{GG'}=.60\).

\begin{figure}

{\centering \includegraphics{misclassification_files/figure-pdf/fig-mis-1.pdf}

}

\caption{\label{fig-mis}Distributions of scores with a 10\%
misclassification rate. Observed standardized mean differences are
biased toward the null (i.e., SMD = 0). Note that a few members of group
\(A\) (red squares) are within observed group \(B\) and vice versa
(indicative of misclassification).}

\end{figure}

The bias in the standardized mean difference can be expressed as a
function of the classification reliability (\(r_{gg'}\)). To illuminate
this bias, we must first convert the true SMD to a point-biserial
correlation coefficient (\(\rho\)) using the proportion of individuals
in group \(A\) (\(p_A\)) and group \(B\) (\(p_B\)),

\[
\rho = \frac{\delta}{\sqrt{\frac{1}{p_Ap_B}-\delta^2}}
\]

Then attenuation of the correlation is similar to the attenuation of
correlation coefficients in the section on unreliability
(\(r = \rho\sqrt{r_{xx'}}\)). However in this case, we also need to
convert the point-biserial correlation to the SMD:

\[
d =\frac{ \rho \sqrt{r_{gg'}} }{\sqrt{p_A p_B\left(1- r_{gg'} r^2\right) }}.
\]

It is important to note that for many of the biasing effects and
corrections, converting the standardized mean difference to a
point-biserial correlation is often a necessary step. However once the
corrected point-biserial correlation is obtained, the correlation can
then be converted back into a standardized mean difference like we see
in the last equation.

\hypertarget{sec-corrections}{%
\subsection{Correction for Bias in Standardized Mean
Difference}\label{sec-corrections}}

To correct for bias induced by misclassification we first need to
convert the observed standardized mean difference to a point-biserial
correlation coefficient by using the observed proportion of the sample
that has been assigned to either group \(A\) or group \(B\) (\(p\)). The
group proportion \(p\) in the following equations will only show up in
the term \(p(1-p)\) so it will not matter which group is used.
Converting \(d\) to \(r\):

\[
r = \frac{d}{\sqrt{\frac{1}{p(1-p)}-d^2}}.
\]

We can then correct the point-biserial correlation for group
misclassification with the classification reliability:

\[
\hat{\rho} = \frac{r}{\sqrt{r_{gg'}}}
\]

Now we can convert the corrected point-biserial correlation
(\(\hat{\rho}\)) into a corrected standardized mean difference
(\(\hat{\delta}\)). When converting back to a standardized mean
difference, we need to use the true group proportions, \(p^*\). Although
if we are to assume equal misclassification rates between groups, then
the observed proportion can be used \(p\):

\[
\hat{\delta} = \frac{\hat{\rho}}{\sqrt{p^*\left(1-p^*\right)\left(1-\hat{\rho}^2\right)}}
\]

The sampling variance of \(\hat{\delta}\) (\(s_{\hat{\delta}}\)) will
need to be adjusted accordingly. The three-step process for converting
to a correlation, correcting, and converting back to a standardized mean
difference can instead be done in a single step. Therefore the adjusted
sampling variance (squared standard error) can be calculated as,

\[
s^2_{\hat{\delta}} = \frac {s_d\left(\frac{\hat{\rho}}{r}\right)^2} {\left(1+d^2p[1-p]\right)^2\left(d^2+\frac{1}{p(1-p)}\right)p^*(1-p^*)(1-\hat{\rho}^2)^3}
\]

This can be simplified if we assume that misclassification rates are
equal between groups,

\[
s^2_{\hat{\delta}} = \frac {s_d\left(\frac{\hat{\rho}}{r}\right)^2} {\left(1+d^2p[1-p]\right)^3(1-\hat{\rho}^2)^3}
\]

\hypertarget{correcting-for-misclassification-in-r}{%
\section{Correcting for Misclassification in
R}\label{correcting-for-misclassification-in-r}}

We can correct for group misclassification in R by hand or by using the
\texttt{psychmeta} package (Dahlke and Wiernik 2019). For our
correction, say we got an observed standardized mean difference of
\(d = 0.50\) and we calculated the classification reliability to be
\(r_{gg'} = .80\). Let us also say that the observed \emph{and} the true
proportion of individuals in one of the groups is \(p=p^*=.40\),
therefore the other group would be \(1-p=1-p^*=.60\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{=}\NormalTok{ .}\DecValTok{50}
\NormalTok{rgg }\OtherTok{=}\NormalTok{ .}\DecValTok{70}
\NormalTok{nA }\OtherTok{=} \DecValTok{40}
\NormalTok{nB }\OtherTok{=} \DecValTok{60}
\end{Highlighting}
\end{Shaded}

\hypertarget{using-the-psychmeta-package}{%
\subsubsection*{\texorpdfstring{Using the \emph{psychmeta}
package}{Using the psychmeta package}}\label{using-the-psychmeta-package}}
\addcontentsline{toc}{subsubsection}{Using the \emph{psychmeta} package}

The \texttt{psychmeta} package has a function, \texttt{correct\_d}, that
is dedicated to correcting standardized mean differences multiple types
of artifacts including group misclassification.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1: install and load in psychmeta}
\CommentTok{\# install.packages\{\textquotesingle{}psychmeta\textquotesingle{}\}}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# step 2: calculate proportion of group membership}
\NormalTok{p }\OtherTok{=}\NormalTok{ nA }\SpecialCharTok{/}\NormalTok{ (nA }\SpecialCharTok{+}\NormalTok{ nB)}
\CommentTok{\# p = nB / (nA + nB) \# alternative calculation}

\CommentTok{\# step 3: correct d for group misclassification}
\FunctionTok{correct\_d}\NormalTok{(}\AttributeTok{d =}\NormalTok{ d,}
          \AttributeTok{rGg =} \FunctionTok{sqrt}\NormalTok{(rgg), }\CommentTok{\# square root of rgg = rGg}
          \AttributeTok{correction =} \StringTok{"meas"}\NormalTok{,}
          \AttributeTok{pi =}\NormalTok{ p,}
          \AttributeTok{pa =}\NormalTok{ p,}
          \AttributeTok{n1 =}\NormalTok{ nA}\SpecialCharTok{+}\NormalTok{nB,}
          \AttributeTok{correct\_bias =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
d Values Corrected for Measurement Error:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95   n n_effective
1 0.618    0.118     1.18 100        66.6
\end{verbatim}

The output provides the corrected standardized mean difference
(\texttt{value}), the upper and lower 95\% confidence intervals
(\texttt{CI\_LL\_95} and \texttt{CI\_UL\_95}), the sample size
(\texttt{n}), and the effective sample size (\texttt{n\_effective}).

\hypertarget{correcting-by-hand}{%
\subsubsection*{Correcting by hand}\label{correcting-by-hand}}
\addcontentsline{toc}{subsubsection}{Correcting by hand}

To calculate the corrected standardized mean difference, we can use the
equations in Section~\ref{sec-corrections}.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Calculate point estimate}
\CommentTok{\# step 1: convert d to r}
\NormalTok{r }\OtherTok{=}\NormalTok{ d }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{( }\DecValTok{1}\SpecialCharTok{/}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)) }\SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}

\CommentTok{\# step 2: correct r}
\NormalTok{rho }\OtherTok{=}\NormalTok{ r }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(rgg)}

\CommentTok{\# step 3: convert r to d}
\NormalTok{delta }\OtherTok{=}\NormalTok{ rho }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{( p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rho}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) )}

\DocumentationTok{\#\# Calculate sampling variance}
\CommentTok{\# step 1: compute sampling variance for r}
\NormalTok{v\_d }\OtherTok{=}\NormalTok{ (nA}\SpecialCharTok{+}\NormalTok{nB)}\SpecialCharTok{/}\NormalTok{(nA}\SpecialCharTok{*}\NormalTok{nB) }\SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{(nA}\SpecialCharTok{+}\NormalTok{nB))}

\CommentTok{\# step 2: adjust sampling variance for correction}
\NormalTok{v\_delta }\OtherTok{=}\NormalTok{ (v\_d }\SpecialCharTok{*}\NormalTok{ (rho}\SpecialCharTok{/}\NormalTok{r)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{3} \SpecialCharTok{*}\NormalTok{ p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rho}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}delta hat = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(delta,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{},  var = \textquotesingle{}}\NormalTok{, }\FunctionTok{round}\NormalTok{(v\_delta,}\DecValTok{3}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "delta hat = 0.605,  var = 0.168"
\end{verbatim}

(Chyou 2007)

(Wiernik and Dahlke 2020)

(J. E. Hunter and Schmidt 1990)

\hypertarget{artificial-dichotomization}{%
\chapter{Artificial Dichotomization}\label{artificial-dichotomization}}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

Primary studies sometimes will splitting naturally continuous variables
into two discrete groups to increase interpretability or conduct
specific analyses (e.g., t-tests). However, artificially dichotomizing
variables introduces measurement error variance thus attenuating effect
size estimates Maxwell and Delaney (1993). Clinical disorder diagnoses,
such as generalized anxiety disorder, are examples of dichotomization
where individuals are separated into either having the disorder or not
even though individual differences in anxiety exist as a continuum.

\hypertarget{artificial-dichotomization-induced-measurement-error}{%
\section{Artificial Dichotomization Induced Measurement
Error}\label{artificial-dichotomization-induced-measurement-error}}

Variables that are dichotomized contain measurement error. This can be
demonstrated by the simple fact that dichotomized scores are not
perfectly correlated with continuous scores. To demonstrate this, we can
draw a sample of scores and then split the data into high and low
scorers and then find the correlation coefficient between the two (see
figure below). It becomes apparent that the dichotomized scores leave a
lot of the variation in scores unaccounted for.

\includegraphics{artificial_dichotomization_files/figure-pdf/unnamed-chunk-1-1.pdf}

Even with a perfectly reliable measure, dichotomization will introduce
measurement error variance. We can define naturally continuous scores
(\(\ddagger\)) that have been artificially dichotomized as, \[
 x_\ddagger= 
\begin{cases}
    1,& \text{if } x>C_x\\
    0,& \text{if } x<C_x
\end{cases}
\]

Where \(C_x\) is the cut-score on the standard normal distribution. The
reliability can be defined as the correlation between dichotomized
scores and the underlying continuous scores (\(r_{x_\ddagger x}\)).

\hypertarget{correcting-correlations-for-artificial-dichotomization}{%
\section{Correcting Correlations for Artificial
Dichotomization}\label{correcting-correlations-for-artificial-dichotomization}}

\hypertarget{defining-our-estimand}{%
\subsection{Defining our estimand}\label{defining-our-estimand}}

Ultimately, we would like to know the correlation coefficient between
two naturally continuous variables. Sticking with our notation for true
scores, our estimand can be defined as the population correlation
between continuous observed scores of the independent (\(x\)) and
dependent variable (\(y\)), \(\rho_{xy}\). Where dichotomized scores can
be defined as,

\[
 x_\ddagger= 
\begin{cases}
    1,& \text{if } x>C_x\\
    0,& \text{if } x<C_x
\end{cases}
\]

\[
 y_\ddagger= 
\begin{cases}
    1,& \text{if } y>C_y\\
    0,& \text{if } y<C_y
\end{cases}
\]

Where \(C_y\) is the cut-score where the split took place. There are two
cases of dichotomization that may occur in a given study: the univariate
case where only one variable (either dependent or independent) is
dichotomized and the bivariate case where both variables are
dichotomized. Both of these situations will be addressed in the next
section.

\hypertarget{sec-corr-artifacts}{%
\subsection{Artifact Correction for
Correlations}\label{sec-corr-artifacts}}

\hypertarget{the-univariate-case}{%
\subsubsection*{The Univariate Case}\label{the-univariate-case}}
\addcontentsline{toc}{subsubsection}{The Univariate Case}

In the simplest case of dichotomization, only one variable is
dichotomized and the other is left continuous. In this case, a Pearson
product-moment correlation is equivalent to the \emph{point-biserial}
correlation coefficient, however for dichotomized data, the
\emph{biserial} correlation is a relatively unbiased estimate of the
pearson correlation on the underlying continuous data (assuming
normality). Therefore in the population, the observed correlation
\(\rho_{x_\ddagger y}\) is biased by some attenuation factor \(a\),

\[
\rho_{x_\ddagger y} = a\rho_{xy}
\]

The first step in estimating the attenuation of the correlation is to
first identify the cut-point, \(C_x\), of standard normal distribution
where the split of the data occurred. This can be calculated by first
obtaining the percent of the of the individuals in the low or high
scoring group:

\[
p_x = \frac{ n_{\text{high}} }{n_{\text{high}} + n_{\text{low}}}
\] or

\[
p_x = \frac{ n_{\text{low}} }{n_{\text{high}} + n_{\text{low}}}.
\]

Then we can use the quantile function (\(\phi^{-1}\); i.e., the inverse
of the cumulative density of the standard normal distribution) to obtain
the cut-point on the standard normal distribution,

\[
C_x = \phi^{-1}(p_x)
\]

Using the cut-point and the proportion of group membership in either the
low or high scoring group (\(p_x\)), the attenuation factor can be
defined as (J. Hunter and Schmidt 1990),

\[
a =\frac{\varphi(C_x)}{\sqrt{p_x(1-p_x)}} 
\]

Where \(\varphi\) is the normal ordinate function (i.e., probability
density function of a standard normal distribution). Since a standard
normal distribution is symmetric, the sign of \(C_x\) does not matter.
In the case of a median split, where the cut-point would be placed at
zero of a standard normal (splitting the distribution in equal halves),
the attenuation factor would simplify to
\(a =\frac{\varphi(0)}{\sqrt{.5(.5)}}\) \(=\frac{2}{\sqrt{2\pi}}\). To
correct the pearson correlation when one of the variables is
dichotomized, we can divide the observed correlation by the attenuation
factor such that, \(r_c = \frac{r_{x_Dy}}{a}\). Therefore the full
correction equation is,

\begin{equation}\protect\hypertarget{eq-dich-r}{}{
r_c = \frac{r_{x_\ddagger y}}{\left[\frac{\varphi(C_x)}{\sqrt{p_x(1-p_x)}} \right]}
}\label{eq-dich-r}\end{equation}

Where the sampling variance of the corrected correlation must also be
adjusted using the compound attenuation factor,

\[
\sigma^2_{\varepsilon_c} =\frac{\sigma^2_{\varepsilon_o}} {a^2} =\frac{\sigma^2_{\varepsilon_o}} {\left[\frac{\varphi(C_x)^2}{p_x(1-p_x)} \right]}
\]

\includegraphics{artificial_dichotomization_files/figure-pdf/unnamed-chunk-2-1.pdf}

\hypertarget{the-bivariate-case}{%
\subsubsection*{The Bivariate Case}\label{the-bivariate-case}}
\addcontentsline{toc}{subsubsection}{The Bivariate Case}

In some cases, both independent and dependent variables are dichotomized
inducing measurement error in both variables. A pearson correlation
calculated on these two dichotomized variables would be equal to the phi
coefficient and we can denote it with our notation for dichotomized
variables, \(r_{x_\ddagger y_\ddagger}\) The data can be structured in a
contingency table:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(x_\ddagger=\text{Low}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(x_\ddagger=\text{High}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(y_\ddagger=\text{Low}\) & \(n_{LL}\) & \(n_{HL}\) \\
\(y_\ddagger=\text{High}\) & \(n_{LH}\) & \(n_{HH}\) \\
\end{longtable}

We can also show how this contingency table would relate to a bivariate
normal distribution

\includegraphics{figure/diagram-dich.pdf}

The proper correction is to calculate the tetrachoric correlation
coefficient. The tetrachoric correlation is specifically meant for
dichotomous scores that represent continuous underlying normal
distribution. To calculate the tetrachoric correlation coefficient, the
contingency table must be available. To estimate the correlation of
continuous variables (\(r_{xy}\)) we can approximate the tetrachoric
correlation with the following formulation,

\begin{equation}\protect\hypertarget{eq-tet}{}{
r_c = \text{cos}\left(\frac{\pi}{1+\sqrt{\frac{n_{HH}n_{LL}}{n_{HL}n_{LH}}}}\right)
}\label{eq-tet}\end{equation}

If the contingency table is not provided, but the odds ratio
(\(OR=\frac{n_{HH}n_{LL}}{n_{HL}n_{LH}}\)) is, then we can calculate
\(r_{xy}\) in terms of the odds ratio,

\[
r_c = \text{cos}\left(\frac{\pi}{1+\sqrt{OR}}\right)
\]

The sampling variance must be calculated from the contingency table as
well. A sampling variance approximation can be obtained from Pearson
(1913), however due to the complexity of the formulation and because it
is simply an approximation, instead I recommend that researchers use a
bootstrap procedure to obtain approximate confidence intervals. To do
this, we must resample the contingency table (\textgreater10,000
iterations), calculating the tetrachoric correlation using
Equation~\ref{eq-tet} upon each iteration. Once you obtain a tetrachoric
correlation from each iteration, the standard deviation of all
correlations can be used as an estimate of the standard error and the
square of the standard error is the sampling variance.

Unfortunately, studies may not report the full contingency table.
Instead they may report summary statistics like a chi-squared value or a
phi coefficient (i.e., the pearson correlation on binary variables). If
the \(\chi^2\)-statistic is reported, we can first convert that to a phi
coefficient by using,

\[
r_{x_\ddagger y_\ddagger} = \sqrt{\frac{\chi^2}{n}}
\]

Where \(n\) is the total sample size. From the phi coefficient, we can
estimate the correlation of the continuous variables with a formula
similar to Equation~\ref{eq-dich-r},

\begin{equation}\protect\hypertarget{eq-dich-r-biv}{}{
r_c = \frac{r_{x_\ddagger y_\ddagger}}{\left[\frac{\varphi(C_x)}{\sqrt{p_x(1-p_x)}} \right]\left[\frac{\varphi(C_y)}{\sqrt{p_y(1-p_y)}} \right]}
}\label{eq-dich-r-biv}\end{equation}

This formula was introduced by J. Hunter and Schmidt (1990) and is a
rough approximation of the correlation between the continuous
independent and dependent variables (\(r_{xy}\)). The corresponding
sampling variance of the corrected correlation coefficient is,

\[
\sigma^2_{\varepsilon_c} =\frac{\sigma^2_{\varepsilon_o}} {a^2} =\frac{\sigma^2_{\varepsilon_o}} {\left[\frac{\varphi(C_x)^2}{p_x(1-p_x)} \right]\left[\frac{\varphi(C_y)^2}{p_y(1-p_y)} \right]}.
\]

\hypertarget{correcting-correlations-for-dichotomization-in-r}{%
\subsection{Correcting Correlations for Dichotomization in
R}\label{correcting-correlations-for-dichotomization-in-r}}

To correct correlations for dichotomization in R, we can use the
\texttt{correct\_r\_dich} in the \texttt{psychmeta} package.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-----------------------------------------------------  psychmeta version 2.6.5  --
\end{verbatim}

\begin{verbatim}

Please report any bugs to github.com/psychmeta/psychmeta/issues
or issues@psychmeta.com
\end{verbatim}

\begin{verbatim}

We work hard to produce these open-source tools for the R community.
Please cite psychmeta when you use it in your research:
  Dahlke, J. A., & Wiernik, B. M. (2019). psychmeta: An R package for
    psychometric meta-analysis. Applied Psychological Measurement, 43(5), 415-416.
    https://doi.org/10.1177/0146621618795933
\end{verbatim}

\begin{verbatim}

---------------------------------------------------------------  Version check  --
\end{verbatim}

\begin{verbatim}
v Yay! Your copy of psychmeta is up to date!
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define parameters}
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5} \CommentTok{\# the observed correlation}
\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{4}  \CommentTok{\# proportion of people in group A or B}
\NormalTok{px }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{6} \CommentTok{\# probability of subjects above or below the split in x}
\NormalTok{py }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{7} \CommentTok{\# probability of subjects above or below the split in y}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ r}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# get cut{-}point}
\FunctionTok{correct\_r\_dich}\NormalTok{(r,}\AttributeTok{px=}\NormalTok{px,}\AttributeTok{py=}\NormalTok{py,}\AttributeTok{n=}\NormalTok{n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  r_corrected var_e_corrected    n_adj
1   0.8356363      0.01587018 6.735923
\end{verbatim}

\[
var_{e}=\frac{(1-r^{2})^{2}}{n-1}
\]

We can also correct the correlation using base R. In order to correct
for dichotomization, we can use the three step process equations from
Section~\ref{sec-corr-smd}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# get cut{-}point}
\NormalTok{Cy }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(py)}
\NormalTok{Cx }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(px)}

\CommentTok{\# calculate attenuation factors}
\NormalTok{a\_x }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(Cx)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(px}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{px)) }\CommentTok{\# attenuation factor for dichotomization in x}
\NormalTok{a\_y }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(Cy)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(py}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{py)) }\CommentTok{\# attenuation factor for dichotomization in y}

\CommentTok{\# correct r}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ r }\SpecialCharTok{/}\NormalTok{ (a\_x}\SpecialCharTok{*}\NormalTok{a\_y)}

\CommentTok{\# adjust standard error for rc}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{r)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}, var = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "r = 0.836, var = 0.016"
\end{verbatim}

\hypertarget{correcting-standardized-mean-differences-for-artificial-dichotomization}{%
\section{Correcting Standardized Mean Differences for Artificial
Dichotomization}\label{correcting-standardized-mean-differences-for-artificial-dichotomization}}

\hypertarget{defining-our-estimand-1}{%
\subsection{Defining our estimand}\label{defining-our-estimand-1}}

We would like to know the group difference between scores of a naturally
continuous variable. Our estimand can thus be defined as the population
standardized mean difference between groups \(A\) and \(B\) on
continuous scores of the dependent variable (\(y\)), \(\delta_{y}\).
Where dichotomized scores can be defined as

\[
 y_{A\ddagger}= 
\begin{cases}
    1,& \text{if } y_A>C_y\\
    0,& \text{if } y_A<C_y
\end{cases}
\]

\[
 y_{B\ddagger}= 
\begin{cases}
    1,& \text{if } y_B>C_y\\
    0,& \text{if } y_B<C_y
\end{cases}
\]

In studies of group differences, since the independent variable is
already dichotomous, the only dichotomization that can occur is on the
dependent variable.

\hypertarget{sec-corr-smd}{%
\subsection{Artifact Correction for Standardized Mean
Differences}\label{sec-corr-smd}}

The simplest way to correct for dichotomization in a standardized mean
difference is to first convert the observed \(d\) value of the
\emph{dichotomized} dependent variable and the \emph{dichotomous}
independent variable (i.e., the grouping variable). When converting to a
correlation coefficient, it's important to note the binary nature of
both variables, leading us to estimate the phi coefficient rather than
the point-biserial correlation that we would be estimating if the
dependent variable was continuous. To calculate the phi coefficient from
a \(d\) value we can use the proportion of group membership in group
\(A\) or group \(B\) (\(p\); it does not matter which one is chosen, as
long as it is consistent for every instance of \(p\)),

\[
r_{\text{phi}} = \frac{d_{y_\ddagger}}{\sqrt{d_{y_\ddagger}^2+\frac{1}{p(1-p)}}}
\] We can then correct the phi coefficient similar to how we correct the
point-biserial correlation in Section~\ref{sec-corr-artifacts},

\[
r_c = \frac{r_{\text{phi}}}{\left[\frac{\varphi(C_y)}{\sqrt{p_y (1-p_y)}}\right]}.
\] Then we can convert the corrected correlation back into a
standardized mean difference, \[
d_c = \frac{r_c}{\sqrt{p\left(1-p\right)\left(1-r_c^2\right)}}
\] Where \(d_c\) is our corrected correlation. The sampling variance
must also be corrected using the same three step procedure. For
simplicity, we will consolidate this into one formula,

\[
\sigma^2_{\varepsilon_c} = \frac {\sigma^2_{\varepsilon_o} \left(\frac{r_c}{r_\text{phi}}\right)^2} {\left(1+d_{y_\ddagger}^2p[1-p]\right)^3(1-r_c^2)^3}
\]

\hypertarget{correcting-d-values-for-dichotomization-in-r}{%
\subsection{\texorpdfstring{Correcting \emph{d} values for
Dichotomization in
R}{Correcting d values for Dichotomization in R}}\label{correcting-d-values-for-dichotomization-in-r}}

To correct standardized mean differences for dichotomization in R. At
the moment the \texttt{psychmeta} package does not have a
\texttt{correct\_d\_dich} function. In order to correct for
dichotomization, we can use the three step process equations from
Section~\ref{sec-corr-smd}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define parameters}
\NormalTok{d }\OtherTok{=}\NormalTok{ .}\DecValTok{5} \CommentTok{\# observed standardized mean difference}
\NormalTok{nA }\OtherTok{=} \DecValTok{40}  \CommentTok{\# sample size for group A}
\NormalTok{nB }\OtherTok{=} \DecValTok{60}  \CommentTok{\# sample size for group A}
\NormalTok{n }\OtherTok{=}\NormalTok{ nA}\SpecialCharTok{+}\NormalTok{nB }\CommentTok{\# calculate total sample size}
\NormalTok{p }\OtherTok{=}\NormalTok{ nA }\SpecialCharTok{/}\NormalTok{ n }\CommentTok{\# calculate proportion of individuals in group A}
\NormalTok{py }\OtherTok{=}\NormalTok{ .}\DecValTok{7} \CommentTok{\# probability of subjects above or below the split}
\NormalTok{var\_e\_o }\OtherTok{=}\NormalTok{ ((n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{{-}} \DecValTok{3}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ (n }\SpecialCharTok{/}\NormalTok{ (nA }\SpecialCharTok{*}\NormalTok{ nB) }\SpecialCharTok{+}\NormalTok{ d}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ n))}

\CommentTok{\# get cut{-}point}
\NormalTok{Cy }\OtherTok{=} \FunctionTok{qnorm}\NormalTok{(py)}

\CommentTok{\# calculate attenuation factor of y}
\NormalTok{a\_y }\OtherTok{\textless{}{-}} \FunctionTok{dnorm}\NormalTok{(Cy)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(py}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{py)) }\CommentTok{\# attenuation factor for dichotomization in y}

\CommentTok{\# convert d to r}
\NormalTok{r }\OtherTok{\textless{}{-}}\NormalTok{ d }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(d}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ (p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p))))}

\CommentTok{\# correct r}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ r }\SpecialCharTok{/}\NormalTok{ a\_y}

\CommentTok{\# convert r to d}
\NormalTok{dc }\OtherTok{\textless{}{-}}\NormalTok{ rc }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rc}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ (var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{r)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{1}\SpecialCharTok{+}\NormalTok{d}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{*}\NormalTok{p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p))}\SpecialCharTok{\^{}}\DecValTok{3} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rc}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{)}

\CommentTok{\# print results}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(dc,}\DecValTok{3}\NormalTok{),}\StringTok{\textquotesingle{}, var = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{) ))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "r = 0.674, var = 0.087"
\end{verbatim}

(Naggara et al. 2011)

(Russell, Pinto, and Bobko 1991)

(Digby 1983)

(Maxwell and Delaney 1993)

(J. Hunter and Schmidt 1990)

(Vargha et al. 1996)

(Royston, Altman, and Sauerbrei 2006)

(Peters and Voorhis 1940)

(Bonett and Price 2005)

(Ulrich and Wirtz 2004)

(Muthén and Hofacker 1988)

(MacCallum et al. 2002)

\hypertarget{scale-coarseness}{%
\chapter{Scale Coarseness}\label{scale-coarseness}}

(Symonds 1924)

(Aguinis, Pierce, and Culpepper 2009)

(Krieg 1999)

\hypertarget{sec-direct_range_restriction}{%
\chapter{Direct Selection}\label{sec-direct_range_restriction}}

\hypertarget{introduction-3}{%
\section{Introduction}\label{introduction-3}}

Direct selection occurs when subjects are explicitly selected based on
some eligibility criterion on the variables of interest (rather than a
third variable). Range restriction is a form of selection bias that
describes a situation where there is less variation in our sample then
there is in the population. Whereas range enhancement indicates that
there is \emph{more} variation in a sample then there is in the
population. Direct range restriction/enhancement (as opposed to indirect
range restriction) is when selection into the sample is based on the
variable(s) of interest (i.e., the independent and/or dependent
variable). This selection into the sample will either restrict or
enhance the variation in the variable, thus causing

\hypertarget{an-applied-example-of-direct-range-restriction}{%
\section{An Applied Example of Direct Range
Restriction}\label{an-applied-example-of-direct-range-restriction}}

Imagine a tech company that wants to assess the correlation between
years of experience and programming proficiency for their software
engineers. They have two primary divisions: Division A and Division B.
Division A primarily hires entry-level software engineers, with less
than 3 years of experience. Division B, on the other hand, hires
experienced software engineers with more than 3 years of experience. The
company decides to conduct a study to assess the correlation between
years of experience and programming proficiency. However, they only
collect data from Division A due to logistical reasons, assuming that
the relationship found there would be represent. the entire company. In
this scenario, direct range restriction occurs because the sample used
for the study (Division A) represents a narrow range of years of
experience (0-3 years) compared to the broader range present in the
entire company (0+ years). Consequently, the standard deviation will be
smaller in the sample then it would if we had sampled from the entire
company. As we will see in later sections of this chapter, the observed
correlation between years of experience and programming proficiency
would be attenuated, underestimating the true correlation.

\hypertarget{indexing-range-restriction-with-the-u-ratio}{%
\section{\texorpdfstring{Indexing Range Restriction with the
\emph{u}-ratio}{Indexing Range Restriction with the u-ratio}}\label{indexing-range-restriction-with-the-u-ratio}}

The distribution of scores in the unrestricted pool of individuals will
exhibit a greater (or lesser) degree of variability compared to the
sample that has been selected into the study. Therefore the standard
deviation of scores in the unrestricted population (\(\sigma_x\)) will
differ from that of the selected (restricted/enhanced) sample
(\(\sigma_{x_{S}}\)). To index the difference between the two standard
deviations, we can calculate the \(u\)-ratio Wiernik and Dahlke (2020).
The \(u\)-ratio is the ratio between the standard deviations of the
selected sample to the unrestricted sample such that,

\[
u_x = \frac{\sigma_{x_S}}{\sigma_x}
\]

The \(u\)-ratio in cases of range restriction will exist in the interval
(0--1). Conversely, when the \(u\)-ratio is greater than 1 it is
indicative of range enhancement. The unrestricted standard deviation is
often quite difficult to acquire since we do not usually have access to
the unrestricted group. However, the unrestricted standard deviation can
be estimated from some reference study that has been conducted on the
unrestricted group. This often comes in the form of standardization
samples or norm samples (obtained from test manuals) if the unrestricted
group is the general population. For example, the distribution
full-scale IQ scores derived from the Wechsler Adult Intelligence Test
has a standard deviation of 15 in the US population (Wechsler 2008). We
can use this estimate as the standard deviation for the unrestricted
population. Lets say we select a sample from members of Mensa, a high IQ
society, who are specifically selected on the basis high IQ scores. If
the standard deviation of Mensa members is 5, then the \(u\)-ratio would
be,

\[
u =  \frac{\sigma_{x_S}}{\sigma_x} = \frac{5}{15}= .33
\]

However it is not always the case that an estimate of the unrestricted
standard deviation is readily available. Therefore if the reliability
coefficient from the unrestricted and selected sample can be used to
estimate the \(u\)-ratio,

\[
u_x = \sqrt{\frac{1-r_{xx'_{\mathcal{U}}}}{1-r_{xx'_{\mathcal{S}}}}}
\]

Where \(r_{xx'_{\mathcal{S}}}\) and \(r_{xx'_{\mathcal{U}}}\) are the
reliability estimates within the selected and unrestricted groups
respectively.

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-1-1.pdf}

\hypertarget{correcting-correlations-for-direct-range-restriction}{%
\section{Correcting Correlations for Direct Range
Restriction}\label{correcting-correlations-for-direct-range-restriction}}

\hypertarget{defining-our-estimand-2}{%
\subsection{Defining our Estimand}\label{defining-our-estimand-2}}

For our study we want to estimate the population correlation of the
unrestricted scores of the independent (\(x_\mathcal{U}\)) and dependent
variable (\(y_S\)). We can denote this correlation as \(\rho_{xy_S}\).
The restricted population correlation can be denoted as \(\rho_{xy_S}\).
Within a study that suffers from range restriction, the study
correlation (\(r_{xy_{\mathcal{R}}}\)) will be biased relative to our
estimand, \(\rho_{xy_{\mathcal{U}}}\). This bias can be denoted by \(a\)
such that,

\[
r_{xy} = a \rho_{xy_S} + \varepsilon  
\]

Therefore an unbiased estimate of the unrestricted population
correlation would be

\[
r_c = \frac{ r_{xy_S} }{ a}.
\]

\hypertarget{artifact-correction-for-correlations}{%
\subsection{Artifact Correction for
Correlations}\label{artifact-correction-for-correlations}}

\hypertarget{the-univariate-case-1}{%
\subsubsection*{The Univariate Case}\label{the-univariate-case-1}}
\addcontentsline{toc}{subsubsection}{The Univariate Case}

Range restriction (or enhancement) in either the independent or
dependent variable will induce bias into the correlation coefficient.
Let us consider a case where just the independent variable is restricted
(or enhanced) such that \(u_x\neq 1\), but the dependent variable is not
restricted such that \(u_y = 1\). Lets visualize the correlation between
independent (\(x\)) and dependent (\(y\)) variables under this range
restriction by only selecting individuals above some cut off. The scores
of individuals that have been selected will show less variance than the
entire pool of individuals. Specifically, the scenario below shows a
\(u\)-ratio of about 0.69 in the independent variable. We see in the
figure that the correlation in the restricted scores (\(\rho_{xy_S}\))
is attenuated relative to the unrestricted (true) correlation
(\(\rho_{xy}\)).

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-2-1.pdf}

We can also visualize what happens to the correlation when the range is
enhanced. Enhancement can be accomplished by selecting individuals at
the ends of the distribution (Taylor and Griess 1976). In the
visualization below, we see an opposite effect on the correlation, that
is, an over-estimate of the unrestricted correlation rather than an
attenuation like we see under range restriction. The scenario below has
a \(u\)-ratio of about 1.39 in the independent variable.

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-3-1.pdf}

It starts to become apparent that if \(u_x>1\) (i.e.,
\(\sigma_x>\sigma_\mathcal{x_S}\)) the observed correlation
over-estimates the true, unrestricted correlation and under-estimates
the unrestricted correlation when \(u_x<1\) (i.e.,
\(\sigma_x<\sigma_\mathcal{x_S}\), Sackett and Yang 2000).

A bias correction formula for univariate direct range restriction was
first developed by Pearson (1903) and provided more recently by J. E.
Hunter and Schmidt (1990). To correct for the systematic bias in
correlations, we can use the \(u\)-ratio of the independent variable
such that,

\begin{equation}\protect\hypertarget{eq-univariate}{}{
r_c = \frac{r_{xy_S}}{u_x\left(1+r_{xy_S}^2\left[\frac{1}{u^2_x}-1\right]\right)}
}\label{eq-univariate}\end{equation}

Where the sampling variance of the corrected correlation is

\begin{equation}\protect\hypertarget{eq-univariate-se}{}{
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{xy_S}}\right)^2.
}\label{eq-univariate-se}\end{equation}

\hypertarget{the-bivariate-case-1}{%
\subsubsection{The Bivariate Case}\label{the-bivariate-case-1}}

Bivariate direct range restriction/enhancement occurs when the
variability in both independent and dependent variables within the
selected sample is less than or greater than the variability in the
unrestricted population. Let us consider a case where just the
independent variable is restricted (or enhanced) such that \(u_x\neq 1\)
and \(u_y \neq 1\). Like we showed for the univariate case, let's
visualize the correlation between independent (\(x\)) and dependent
(\(y\)) variables under range restriction by only selecting individuals
above some cut off point for both \(x\) and \(y\). The scores of
individuals that have been selected will show less variance than the
entire pool of individuals. Specifically, the scenario below shows a
\(u\)-ratio of about 0.69 in the independent variable and dependent
variables. We see in the figure that the correlation in the restricted
sample (\(\rho_{xy_S}\)) is attenuated relative to the unrestricted
(true) correlation (\(\rho_{xy}\)).

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-4-1.pdf}

Likewise let's visualize what happens to the correlation when the range
is enhanced. Enhancement in both variables can be accomplished by
selecting individuals at the ends of the distribution of \(x\) and
\(y\). In the visualization below, we observe an over-estimation of
observed correlation relative to the unrestricted correlation. The
scenario below has a \(u\)-ratio of about 1.32 in both the independent
variable and dependent variable.

\includegraphics{direct_range_restriction_files/figure-pdf/unnamed-chunk-5-1.pdf}

A bias correction formula for bivariate range restriction is much more
complicated than the univariate formulation. This is due to the fact
that there is inter-dependence between the correlation, the \(u\)-ratio
of \(x\), and the \(u\)-ratio of \(y\). For instance, if \(x\) and \(y\)
are positively correlated and if there is direct range restriction in
\(x\) this will also restrict the variability in y even if there is no
range restriction in \(y\). To break down the correction formula into
simpler parts, let us first define a factor we will denote with
\(\psi\),

\begin{equation}\protect\hypertarget{eq-biv-1}{}{
\psi = \frac{u_x u_y\left(r_{xy_S}^2-1\right)}{2r_{xy_S}}
}\label{eq-biv-1}\end{equation} This factor contains all the parameters
needed to correct the correlation coefficient under direct selection
(\(r_{xy_S}\)). Then we can plug it into the formula

\begin{equation}\protect\hypertarget{eq-biv-2}{}{
r_c = \psi + \text{sign}\left[r_{xy_S}\right]\sqrt{\psi^2+1}
}\label{eq-biv-2}\end{equation}

Where the sampling variance of the corrected correlation is,

\begin{equation}\protect\hypertarget{eq-biv-se}{}{
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{xy_S}}\right)^2.
}\label{eq-biv-se}\end{equation}

\hypertarget{correcting-correlations-in-r-1}{%
\subsection{Correcting Correlations in
R}\label{correcting-correlations-in-r-1}}

To correct correlations for range restriction we can start by simulating
data from the the \texttt{mvrnorm} function in the \texttt{MASS}
package. Lets first simulate 200 data points.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}MASS\textquotesingle{})}
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{343}\NormalTok{)}

\CommentTok{\# define parameters }
\NormalTok{rho }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{50}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{200}

\CommentTok{\# sample data from a bivariate normal distribution}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n,}
                \AttributeTok{mu =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                \AttributeTok{Sigma =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,rho),}
                                  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(rho,}\DecValTok{1}\NormalTok{)),}
                \AttributeTok{empirical =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# obtain unrestricted scores}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{1}\NormalTok{]}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{univariate-direct-range-restriction}{%
\subsubsection*{Univariate Direct Range
Restriction}\label{univariate-direct-range-restriction}}
\addcontentsline{toc}{subsubsection}{Univariate Direct Range
Restriction}

We can start with univariate direct range restriction by selecting only
on the independent variable. We will select only the values above the
mean.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# obtain scores when x \textgreater{} Mean(x)}
\NormalTok{selected }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(x)}
\NormalTok{xS }\OtherTok{\textless{}{-}}\NormalTok{ x[selected]}
\NormalTok{yS }\OtherTok{\textless{}{-}}\NormalTok{ y[selected]}

\CommentTok{\# calculate correlation between unrestricted and restricted scores}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x,y) }\CommentTok{\# unrestricted}
\NormalTok{rxyS }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(xS,yS) }\CommentTok{\# restricted}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}unrestricted: rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}restricted: rxyS = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxyS,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                     
[1,] "unrestricted: rxy = 0.5"
[2,] "restricted: rxyS = 0.32"
\end{verbatim}

As expected, we observe an attenuation of the correlation under range
restriction. Now lets calculate the \(u\)-ratios for both variables.
Remember that even though we only selected on \(x\), we should expect
the variability in \(y\) in the restricted sample to also be smaller
than the unrestricted sample when \(x\) and \(y\) are correlated.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate u{-}ratios}
\NormalTok{ux }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(xS)}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(x)}
\NormalTok{uy }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(yS)}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(y)}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}ux = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(ux,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}uy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(uy,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]       
[1,] "ux = 0.59"
[2,] "uy = 0.86"
\end{verbatim}

As anticipated, not only is \(u_x\) below 1 indicating range
restriction, but also \(u_y\) is slightly below 1 since \(x\) and \(y\)
covary. Now we can apply the correction for univariate direct range
restriction by hand from Equation~\ref{eq-univariate} and
Equation~\ref{eq-univariate}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# correct the restricted correlation}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ rxyS }\SpecialCharTok{/}\NormalTok{ (ux }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ rxyS}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{ux}\SpecialCharTok{\^{}}\DecValTok{2{-}1}\NormalTok{)) )}

\CommentTok{\# acquire sample size from }
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(xS)}

\CommentTok{\# calculate the observed correlation sampling variance}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{rxyS)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected cor: r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected var: var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                         
[1,] "corrected cor: r = 0.49"    
[2,] "corrected var: var_e = 0.02"
\end{verbatim}

The correction formula produced a very close estimate of the true
population correlation (\(r_c = .49\) vs \(\rho_{xy}=.50\)). Lets also
correct the correlation using the \texttt{correct\_r} function in the
psychmeta package, \texttt{psychmeta} (Dahlke and Wiernik 2019).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# correct the restricted correlation for univariate direct range restriction}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxyS,}
          \AttributeTok{correction =} \StringTok{\textquotesingle{}uvdrr\_x\textquotesingle{}}\NormalTok{,  }\CommentTok{\# uvdrr\_x = univariate direct range restriction in x}
          \AttributeTok{ux =}\NormalTok{ ux,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error and Univariate Direct Range Restriction:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95  n n_effective
1 0.492    0.209    0.685 97        40.8
\end{verbatim}

We can see that the correction made by the \texttt{correct\_r} function
provides identical results to the one done by hand.

\hypertarget{bivariate-direct-range-restriction}{%
\subsubsection{Bivariate Direct Range
Restriction}\label{bivariate-direct-range-restriction}}

For bivariate direct range restriction we can select values above the
mean in both independent and dependent variables.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# obtain scores when x \textgreater{} Mean(x) and y \textgreater{} Mean(y)}
\NormalTok{selected }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(x) }\SpecialCharTok{\&}\NormalTok{ y }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(y)}
\NormalTok{xS }\OtherTok{\textless{}{-}}\NormalTok{ x[selected]}
\NormalTok{yS }\OtherTok{\textless{}{-}}\NormalTok{ y[selected]}

\CommentTok{\# calculate correlation between unrestricted and restricted scores}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x,y) }\CommentTok{\# unrestricted}
\NormalTok{rxyS }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(xS,yS) }\CommentTok{\# restricted}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}unresticted: rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}restricted: rxyS = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxyS,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                     
[1,] "unresticted: rxy = 0.5" 
[2,] "restricted: rxyS = 0.29"
\end{verbatim}

Notice that there is even more attenuation in the selected correlation
coefficient than there was in the univariate case. Now we can correct
for bivariate range restriction by hand using Equation~\ref{eq-biv-1},
Equation~\ref{eq-biv-2}, Equation~\ref{eq-biv-se}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate the factor, psi}
\NormalTok{psi }\OtherTok{\textless{}{-}}\NormalTok{ ux}\SpecialCharTok{*}\NormalTok{uy}\SpecialCharTok{*}\NormalTok{(rxyS}\SpecialCharTok{\^{}}\DecValTok{2{-}1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{rxyS)}

\CommentTok{\# calculate the corrected correlation using psi}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ psi }\SpecialCharTok{+} \FunctionTok{sign}\NormalTok{(rxyS)}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(psi}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \DecValTok{1}\NormalTok{)}

\CommentTok{\# acquire sample size from }
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(xS)}

\CommentTok{\# calculate the observed correlation sampling variance}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{rxyS)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected cor: r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected var: var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                          
[1,] "corrected cor: r = 0.48"     
[2,] "corrected var: var_e = 0.036"
\end{verbatim}

Again, we see that the corrected correlation closely resembles the
unrestricted correlation (\(r_c=.48\) vs \(\rho_{xy}=.50\)). lets

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# correct the restricted correlation for univariate direct range restriction}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxyS,}
          \AttributeTok{correction =} \StringTok{\textquotesingle{}bvdrr\textquotesingle{}}\NormalTok{,  }\CommentTok{\# bvdrr = bivariate direct range restriction}
          \AttributeTok{ux =}\NormalTok{ ux,}
          \AttributeTok{uy =}\NormalTok{ uy,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error and Bivariate Direct Range Restriction:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95  n n_effective
1  0.48   0.0943    0.689 64        17.3
\end{verbatim}

We can see that the correction exactly reflects the correction done by
hand.

\hypertarget{references}{%
\section{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-aguinis2009}{}}%
Aguinis, Herman, Charles A Pierce, and Steven A Culpepper. 2009.
{``Scale Coarseness as a Methodological Artifact,''} September.

\leavevmode\vadjust pre{\hypertarget{ref-bobko2001}{}}%
Bobko, Philip, Philip Roth, and Christopher Bobko. 2001. {``Correcting
the Effect Size of d for Range Restriction and Unreliability.''}
\emph{Organizational Research Methods - ORGAN RES METHODS} 4 (January):
46--61. \url{https://doi.org/10.1177/109442810141003}.

\leavevmode\vadjust pre{\hypertarget{ref-bonett2005}{}}%
Bonett, Douglas G., and Robert M. Price. 2005. {``Inferential Methods
for the Tetrachoric Correlation Coefficient.''} \emph{Journal of
Educational and Behavioral Statistics} 30 (2): 213--25.
\url{https://www.jstor.org/stable/3701350}.

\leavevmode\vadjust pre{\hypertarget{ref-borenstein2010}{}}%
Borenstein, Michael, Larry V. Hedges, Julian P. T. Higgins, and Hannah
R. Rothstein. 2010. {``A Basic Introduction to Fixed-Effect and
Random-Effects Models for Meta-Analysis.''} \emph{Research Synthesis
Methods} 1 (2): 97--111. \url{https://doi.org/10.1002/jrsm.12}.

\leavevmode\vadjust pre{\hypertarget{ref-borsboom2002}{}}%
Borsboom, Denny, and Gideon J Mellenbergh. 2002. {``True Scores, Latent
Variables, and Constructs: A Comment on Schmidt and Hunter.''}

\leavevmode\vadjust pre{\hypertarget{ref-borsboom2004}{}}%
Borsboom, Denny, Gideon J. Mellenbergh, and Jaap Van Heerden. 2004.
{``The Concept of Validity.''} \emph{Psychological Review} 111 (4):
1061--71. \url{https://doi.org/10.1037/0033-295X.111.4.1061}.

\leavevmode\vadjust pre{\hypertarget{ref-bravais1844}{}}%
Bravais, A. 1844. \emph{Analyse mathématique sur les probabilités des
erreurs de situation d'un point}. Impr. Royale.

\leavevmode\vadjust pre{\hypertarget{ref-brennan2010}{}}%
Brennan, Robert L. 2010. {``Generalizability Theory and Classical Test
Theory.''} \emph{Applied Measurement in Education} 24 (1): 1--21.
\url{https://doi.org/10.1080/08957347.2011.532417}.

\leavevmode\vadjust pre{\hypertarget{ref-callender1980}{}}%
Callender, John C., and H. G. Osburn. 1980. {``Development and Test of a
New Model for Validity Generalization.''} \emph{Journal of Applied
Psychology} 65 (5): 543--58.
\url{https://doi.org/10.1037/0021-9010.65.5.543}.

\leavevmode\vadjust pre{\hypertarget{ref-charles2005}{}}%
Charles, Eric. 2005. {``The Correction for Attenuation Due to
Measurement Error: Clarifying Concepts and Creating Confidence Sets.''}
\emph{Psychological Methods} 10 (July): 206--26.
\url{https://doi.org/10.1037/1082-989X.10.2.206}.

\leavevmode\vadjust pre{\hypertarget{ref-chyou2007}{}}%
Chyou, Po-Huang. 2007. {``Patterns of Bias Due to Differential
Misclassification by Case{\textendash}control Status in a
Case{\textendash}control Study.''} \emph{European Journal of
Epidemiology} 22 (1): 7--17.
\url{https://doi.org/10.1007/s10654-006-9078-x}.

\leavevmode\vadjust pre{\hypertarget{ref-cohen1988}{}}%
Cohen, Jacob. 1988. \emph{Statistical Power Analysis for the Behavioral
Sciences}. Academic Press.

\leavevmode\vadjust pre{\hypertarget{ref-thehand2009}{}}%
Cooper, Harris M., Larry V. Hedges, and Jeff C. Valentine, eds. 2009.
\emph{The Handbook of Research Synthesis and Meta-Analysis}. 2nd ed. New
York: Russell Sage Foundation.

\leavevmode\vadjust pre{\hypertarget{ref-cronbach1955}{}}%
Cronbach, Lee J., and Paul E. Meehl. 1955. {``Construct Validity in
Psychological Tests.''} \emph{Psychological Bulletin} 52 (4): 281--302.
\url{https://doi.org/10.1037/h0040957}.

\leavevmode\vadjust pre{\hypertarget{ref-dahlke2019}{}}%
Dahlke, Jeffrey A., and Brenton M. Wiernik. 2019. {``Psychmeta: An R
Package for Psychometric Meta-Analysis.''} \emph{Applied Psychological
Measurement} 43 (5): 415--16.
\url{https://doi.org/10.1177/0146621618795933}.

\leavevmode\vadjust pre{\hypertarget{ref-dersimonian2007}{}}%
DerSimonian, Rebecca, and Raghu N. Kacker. 2007. {``Random-Effects Model
for Meta-Analysis of Clinical Trials: An Update.''} \emph{NIST} 28
(January): 105--14.
\url{https://www.nist.gov/publications/random-effects-model-meta-analysis-clinical-trials-update}.

\leavevmode\vadjust pre{\hypertarget{ref-digby1983}{}}%
Digby, P. G. N. 1983. {``Approximating the Tetrachoric Correlation
Coefficient.''} \emph{Biometrics} 39 (3): 753--57.
\url{https://doi.org/10.2307/2531104}.

\leavevmode\vadjust pre{\hypertarget{ref-fisher1915}{}}%
Fisher, R. A. 1915. {``Frequency Distribution of the Values of the
Correlation Coefficient in Samples from an Indefinitely Large
Population.''} \emph{Biometrika} 10 (4): 507--21.
\url{https://doi.org/10.2307/2331838}.

\leavevmode\vadjust pre{\hypertarget{ref-galton1907}{}}%
Galton, Francis. 1907. {``Vox Populi.''} \emph{Nature} 75 (1949):
450--51. \url{https://doi.org/10.1038/075450a0}.

\leavevmode\vadjust pre{\hypertarget{ref-gliem2003}{}}%
Gliem, Joseph A., and Rosemary R. Gliem. 2003. {``Calculating,
Interpreting, And Reporting Cronbach{'}s Alpha Reliability Coefficient
For Likert-Type Scales.''}
\url{https://scholarworks.iupui.edu/handle/1805/344}.

\leavevmode\vadjust pre{\hypertarget{ref-haertel2006}{}}%
Haertel, Edward H. 2006. {``3. Reliability.''} In, 4th ed.

\leavevmode\vadjust pre{\hypertarget{ref-hartung1999}{}}%
Hartung, Joachim. 1999. {``An Alternative Method for Meta-Analysis.''}
\emph{Biometrical Journal} 41 (8): 901--16.
\url{https://doi.org/10.1002/(SICI)1521-4036(199912)41:8\%3C901::AID-BIMJ901\%3E3.0.CO;2-W}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1981}{}}%
Hedges, Larry V. 1981. {``Distribution Theory for Glass's Estimator of
Effect Size and Related Estimators.''} \emph{Journal of Educational
Statistics} 6 (2): 107--28.
\url{https://doi.org/10.3102/10769986006002107}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1989}{}}%
---------. 1989. {``An Unbiased Correction for Sampling Error in
Validity Generalization Studies.''} \emph{Journal of Applied Psychology}
74 (3): 469--77. \url{https://doi.org/10.1037/0021-9010.74.3.469}.

\leavevmode\vadjust pre{\hypertarget{ref-hunter1990a}{}}%
Hunter, John E., and Frank L. Schmidt. 1990. \emph{Methods of
meta-analysis: correcting error and bias in research findings}. Newbury
Park: Sage Publications.

\leavevmode\vadjust pre{\hypertarget{ref-hunter1990}{}}%
Hunter, John, and Frank Schmidt. 1990. {``Dichotomization of Continuous
Variables: The Implications for Meta-Analysis.''} \emph{Journal of
Applied Psychology} 75 (June): 334--49.
\url{https://doi.org/10.1037/0021-9010.75.3.334}.

\leavevmode\vadjust pre{\hypertarget{ref-kelley1927}{}}%
Kelley, Truman Lee. 1927. \emph{Interpretation of Educational
Measurements}. World Book Company.

\leavevmode\vadjust pre{\hypertarget{ref-krieg1999}{}}%
Krieg, Edward F. 1999. {``Biases Induced by Coarse Measurement
Scales.''} \emph{Educational and Psychological Measurement} 59 (5):
749--66. \url{https://doi.org/10.1177/00131649921970125}.

\leavevmode\vadjust pre{\hypertarget{ref-lin2018}{}}%
Lin, Lifeng. 2018. {``Bias Caused by Sampling Error in Meta-Analysis
with Small Sample Sizes.''} \emph{PLOS ONE} 13 (9): e0204056.
\url{https://doi.org/10.1371/journal.pone.0204056}.

\leavevmode\vadjust pre{\hypertarget{ref-maccallum2002}{}}%
MacCallum, Robert C., Shaobo Zhang, Kristopher J. Preacher, and Derek D.
Rucker. 2002. {``On the Practice of Dichotomization of Quantitative
Variables.''} \emph{Psychological Methods} 7: 19--40.
\url{https://doi.org/10.1037/1082-989X.7.1.19}.

\leavevmode\vadjust pre{\hypertarget{ref-maxwell1993}{}}%
Maxwell, Scott, and Harold Delaney. 1993. {``Bivariate Median Splits and
Spurious Statistical Significance.''} \emph{Psychological Bulletin} 113
(January): 181--90. \url{https://doi.org/10.1037/0033-2909.113.1.181}.

\leavevmode\vadjust pre{\hypertarget{ref-mendoza1987}{}}%
Mendoza, Jorge L., and Michael Mumford. 1987. {``Corrections for
Attenuation and Range Restriction on the Predictor.''} \emph{Journal of
Educational Statistics} 12 (3): 282--93.
\url{https://doi.org/10.3102/10769986012003282}.

\leavevmode\vadjust pre{\hypertarget{ref-murphy2003}{}}%
Murphy, Kevin R. 2003. \emph{Validity Generalization: A Critical
Review}. Psychology Press.

\leavevmode\vadjust pre{\hypertarget{ref-muthuxe9n1988}{}}%
Muthén, Bengt, and Charles Hofacker. 1988. {``Testing the Assumptions
Underlying Tetrachoric Correlations.''} \emph{Psychometrika} 53 (4):
563--77. \url{https://doi.org/10.1007/BF02294408}.

\leavevmode\vadjust pre{\hypertarget{ref-naggara2011}{}}%
Naggara, O., J. Raymond, F. Guilbert, D. Roy, A. Weill, and D. G.
Altman. 2011. {``Analysis by Categorizing or Dichotomizing Continuous
Variables Is Inadvisable: An Example from the Natural History of
Unruptured Aneurysms.''} \emph{American Journal of Neuroradiology} 32
(3): 437--40. \url{https://doi.org/10.3174/ajnr.A2425}.

\leavevmode\vadjust pre{\hypertarget{ref-olkin1958}{}}%
Olkin, Ingram, and John W. Pratt. 1958. {``Unbiased Estimation of
Certain Correlation Coefficients.''} \emph{The Annals of Mathematical
Statistics} 29 (1): 201--11. \url{https://www.jstor.org/stable/2237306}.

\leavevmode\vadjust pre{\hypertarget{ref-pearson1903}{}}%
Pearson, Karl. 1903. {``I. Mathematical Contributions to the Theory of
Evolution. {\textemdash}XI. On the Influence of Natural Selection on the
Variability and Correlation of Organs.''} \emph{Philosophical
Transactions of the Royal Society of London. Series A, Containing Papers
of a Mathematical or Physical Character} 200 (321-330): 1--66.
\url{https://doi.org/10.1098/rsta.1903.0001}.

\leavevmode\vadjust pre{\hypertarget{ref-pearson1913}{}}%
---------. 1913. {``On the Probable Error of a Coefficient of
Correlation as Found from a Fourfold Table.''} \emph{Biometrika} 9
(1/2): 22--33. \url{https://doi.org/10.2307/2331798}.

\leavevmode\vadjust pre{\hypertarget{ref-peters1940}{}}%
Peters, Charles C., and Walter R. Van Voorhis. 1940. {``Further Methods
of Correlation.''} In, 362--403. New York, NY, US: McGraw-Hill Book
Company. \url{https://doi.org/10.1037/13596-013}.

\leavevmode\vadjust pre{\hypertarget{ref-psych:p2017}{}}%
{``Psych: Procedures for Personality and Psychological Research.''}
2017. \url{https://CRAN.R-project.org/package=psych}.

\leavevmode\vadjust pre{\hypertarget{ref-raju1983}{}}%
Raju, Nambury, and Michael Burke. 1983. {``Two Procedures for Studying
Validity Generalization.''} \emph{Journal of Applied Psychology} 68
(August): 382--95. \url{https://doi.org/10.1037/0021-9010.68.3.382}.

\leavevmode\vadjust pre{\hypertarget{ref-royston2006}{}}%
Royston, Patrick, Douglas G. Altman, and Willi Sauerbrei. 2006.
{``Dichotomizing Continuous Predictors in Multiple Regression: A Bad
Idea.''} \emph{Statistics in Medicine} 25 (1): 127--41.
\url{https://doi.org/10.1002/sim.2331}.

\leavevmode\vadjust pre{\hypertarget{ref-russell1991}{}}%
Russell, Craig J., Jeffrey K. Pinto, and Philip Bobko. 1991.
{``Appropriate Moderated Regression and Inappropriate Research Strategy:
A Demonstration of Information Loss Due to Scale Coarseness''} 15 (3):
257--66. \url{https://doi.org/10.1177/014662169101500305}.

\leavevmode\vadjust pre{\hypertarget{ref-sackett2000}{}}%
Sackett, Paul R., and Hyuckseung Yang. 2000. {``Correction for Range
Restriction: An Expanded Typology.''} \emph{Journal of Applied
Psychology} 85 (1): 112--18.
\url{https://doi.org/10.1037/0021-9010.85.1.112}.

\leavevmode\vadjust pre{\hypertarget{ref-schmidt2003}{}}%
Schmidt, Frank L., Huy Le, and Remus Ilies. 2003. {``Beyond Alpha: An
Empirical Examination of the Effects of Different Sources of Measurement
Error on Reliability Estimates for Measures of Individual-Differences
Constructs.''} \emph{Psychological Methods} 8: 206--24.
\url{https://doi.org/10.1037/1082-989X.8.2.206}.

\leavevmode\vadjust pre{\hypertarget{ref-schmidt1977}{}}%
Schmidt, Frank, and John Hunter. 1977. {``Development of a General
Solution to the Problem of Validity Generalization.''} \emph{Journal of
Applied Psychology} 62 (October): 529--40.
\url{https://doi.org/10.1037/0021-9010.62.5.529}.

\leavevmode\vadjust pre{\hypertarget{ref-sijtsma2009}{}}%
Sijtsma, Klaas. 2009. {``On the Use, the Misuse, and the Very Limited
Usefulness of~Cronbach{'}s Alpha.''} \emph{Psychometrika} 74 (1):
107--20. \url{https://doi.org/10.1007/s11336-008-9101-0}.

\leavevmode\vadjust pre{\hypertarget{ref-spearman1904}{}}%
Spearman, C. 1904. {``The Proof and Measurement of Association Between
Two Things.''} \emph{International Journal of Epidemiology} 39 (5):
1137--50. \url{https://doi.org/10.1093/ije/dyq191}.

\leavevmode\vadjust pre{\hypertarget{ref-symonds1924}{}}%
Symonds, P. M. 1924. {``On the Loss of Reliability in Ratings Due to
Coarseness of the Scale.''} \emph{Journal of Experimental Psychology} 7
(6): 456--61. \url{https://doi.org/10.1037/h0074469}.

\leavevmode\vadjust pre{\hypertarget{ref-taylor1976}{}}%
Taylor, Erwin K., and Thomas Griess. 1976. {``The Missing Middle in
Validation Research.''} \emph{Personnel Psychology} 29 (1): 5--11.
\url{https://doi.org/10.1111/j.1744-6570.1976.tb00397.x}.

\leavevmode\vadjust pre{\hypertarget{ref-ulrich2004}{}}%
Ulrich, Rolf, and Markus Wirtz. 2004. {``On the Correlation of a
Naturally and an Artificially Dichotomized Variable.''} \emph{British
Journal of Mathematical and Statistical Psychology} 57 (2): 235--51.
\url{https://doi.org/10.1348/0007110042307203}.

\leavevmode\vadjust pre{\hypertarget{ref-vargha1996}{}}%
Vargha, András, Tamás Rudas, Harold D. Delaney, and Scott E. Maxwell.
1996. {``Dichotomization, Partial Correlation, and Conditional
Independence.''} \emph{Journal of Educational and Behavioral Statistics}
21 (3): 264--82. \url{https://doi.org/10.2307/1165272}.

\leavevmode\vadjust pre{\hypertarget{ref-viswanathan2005}{}}%
Viswanathan, Madhu. 2005. \emph{Measurement Error and Research Design}.
SAGE.

\leavevmode\vadjust pre{\hypertarget{ref-viswesvaran1995}{}}%
Viswesvaran, Chockalingam, and Deniz S. Ones. 1995. {``Theory Testing:
Combining Psychometric Meta-Analysis and Structural Equations
Modeling.''} \emph{Personnel Psychology} 48 (4): 865--85.
\url{https://doi.org/10.1111/j.1744-6570.1995.tb01784.x}.

\leavevmode\vadjust pre{\hypertarget{ref-viswesvaran2014}{}}%
Viswesvaran, Chockalingam, Deniz S. Ones, Frank L. Schmidt, Huy Le, and
In-Sue Oh. 2014. {``Measurement Error Obfuscates Scientific Knowledge:
Path to Cumulative Knowledge Requires Corrections for Unreliability and
Psychometric Meta-Analyses.''} \emph{Industrial and Organizational
Psychology} 7 (4): 507--18.
\url{https://doi.org/10.1017/S1754942600006799}.

\leavevmode\vadjust pre{\hypertarget{ref-wechsler2008}{}}%
Wechsler, David. 2008. \emph{Wechsler Adult Intelligence Scale--Fourth
Edition}. 4th ed. \url{https://doi.org/10.1037/t15169-000}.

\leavevmode\vadjust pre{\hypertarget{ref-wiernik2020}{}}%
Wiernik, Brenton M., and Jeffrey A. Dahlke. 2020. {``Obtaining Unbiased
Results in Meta-Analysis: The Importance of Correcting for Statistical
Artifacts.''} \emph{Advances in Methods and Practices in Psychological
Science} 3 (1): 94--123. \url{https://doi.org/10.1177/2515245919885611}.

\end{CSLReferences}

\hypertarget{indirect-selection}{%
\chapter{Indirect Selection}\label{indirect-selection}}

\hypertarget{introduction-4}{%
\section{Introduction}\label{introduction-4}}

Indirect range restriction/enhancement occurs when selection of sample
participants is based on a variable that is correlated with the
variables of interest. If the selector Whereas range enhancement
indicates that there is \emph{more} variation in a sample then there is
in the population. Direct range restriction/enhancement (as opposed to
indirect range restriction) is when selection into the sample is based
on the variable(s) of interest (i.e., the independent and/or dependent
variable). This selection into the sample will either restrict or
enhance the variation in the variable, thus causing

\hypertarget{an-applied-example-of-indirect-range-restriction}{%
\section{An Applied Example of Indirect Range
Restriction}\label{an-applied-example-of-indirect-range-restriction}}

Imagine a research team is conducting a study on academic motivation
among college students using a survey that includes various questions
related to academic engagement, goal orientation, and effort investment.
The researchers administer the survey to a large sample of students
across different universities. However, during the data cleaning
process, the researchers identify a subset of respondents who exhibited
signs of inattentiveness and carelessness in their responses. These
signs include straight-lining questions (e.g., consistently selecting
the same response option without reading the questions) or responding
randomly without considering the content of the questions. Recognizing
that inattentive or careless responding can distort the measurement of
academic motivation, the researchers decide to exclude these individuals
from the analysis. The rationale is to ensure that the data collected
represents genuine responses and validly measures academic motivation.
The unintended consequence of this decision is indirect range
restriction. By removing inattentive and careless responders, who likely
also have lower academic motivation and engagement, from the dataset,
the observed range of academic motivation scores is reduced. The
excluded individuals, who may have had lower academic motivation scores,
are not accounted for in the analysis, resulting in an underestimation
of the variability of academic motivation relative to the population.

\hypertarget{indexing-range-restriction-with-the-u-ratio-1}{%
\section{\texorpdfstring{Indexing Range Restriction with the
\emph{u}-ratio}{Indexing Range Restriction with the u-ratio}}\label{indexing-range-restriction-with-the-u-ratio-1}}

The distribution of scores in the unrestricted pool of individuals will
exhibit a greater (or lesser) degree of variability compared to the
sample that has been selected into the study. Therefore the standard
deviation of scores in the unrestricted population (\(\sigma_x\)) will
differ from that of the selected (restricted/enhanced) sample
(\(\sigma_{x_{S}}\)). To index the difference between the two standard
deviations, we can calculate the \(u\)-ratio Wiernik and Dahlke (2020).
The \(u\)-ratio is the ratio between the standard deviations of the
selected sample to the unrestricted sample such that,

\[
u_x = \frac{\sigma_{x_S}}{\sigma_x}
\]

The \(u\)-ratio in cases of range restriction will exist in the interval
(0--1). Conversely, when the \(u\)-ratio is greater than 1 it is
indicative of range enhancement. The unrestricted standard deviation is
often quite difficult to acquire since we do not usually have access to
the unrestricted group. However, the unrestricted standard deviation can
be estimated from some reference study that has been conducted on the
unrestricted group. This often comes in the form of standardization
samples or norm samples (obtained from test manuals) if the unrestricted
group is the general population. For example, the distribution
full-scale IQ scores derived from the Wechsler Adult Intelligence Test
has a standard deviation of 15 in the US population (Wechsler 2008). We
can use this estimate as the standard deviation for the unrestricted
population. Lets say we select a sample from members of Harvard
students, , who are specifically selected on the basis high IQ scores.
If the standard deviation of Mensa members is 5, then the \(u\)-ratio
would be,

\[
u =  \frac{\sigma_{x_S}}{\sigma_x} = \frac{5}{15}= .33
\]

However it is not always the case that an estimate of the unrestricted
standard deviation is readily available. Therefore if the reliability
coefficient from the unrestricted and selected sample can be used to
estimate the \(u\)-ratio,

\[
u_x = \sqrt{\frac{1-r_{xx'_{\mathcal{U}}}}{1-r_{xx'_{\mathcal{S}}}}}
\]

Where \(r_{xx'_{\mathcal{S}}}\) and \(r_{xx'_{\mathcal{U}}}\) are the
reliability estimates within the selected and unrestricted groups
respectively.

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-1-1.pdf}

\hypertarget{correcting-correlations-for-direct-range-restriction-1}{%
\section{Correcting Correlations for Direct Range
Restriction}\label{correcting-correlations-for-direct-range-restriction-1}}

\hypertarget{defining-our-estimand-3}{%
\subsection{Defining our Estimand}\label{defining-our-estimand-3}}

For our study we want to estimate the population correlation of the
unrestricted scores of the independent (\(x_\mathcal{U}\)) and dependent
variable (\(y_S\)). We can denote this correlation as \(\rho_{xy_S}\).
The restricted population correlation can be denoted as \(\rho_{xy_S}\).
Within a study that suffers from range restriction, the study
correlation (\(r_{xy_{\mathcal{R}}}\)) will be biased relative to our
estimand, \(\rho_{xy_{\mathcal{U}}}\). This bias can be denoted by \(a\)
such that,

\[
r_{xy} = a \rho_{xy_S} + \varepsilon  
\]

Therefore an unbiased estimate of the unrestricted population
correlation would be

\[
r_c = \frac{ r_{xy_S} }{ a}.
\]

\hypertarget{artifact-correction-for-correlations-1}{%
\subsection{Artifact Correction for
Correlations}\label{artifact-correction-for-correlations-1}}

\hypertarget{the-univariate-case-2}{%
\subsubsection*{The Univariate Case}\label{the-univariate-case-2}}
\addcontentsline{toc}{subsubsection}{The Univariate Case}

Range restriction (or enhancement) in either the independent or
dependent variable will induce bias into the correlation coefficient.
Let us consider a case where just the independent variable is restricted
(or enhanced) such that \(u_x\neq 1\), but the dependent variable is not
restricted such that \(u_y = 1\). Lets visualize the correlation between
independent (\(x\)) and dependent (\(y\)) variables under this range
restriction by only selecting individuals above some cut off. The scores
of individuals that have been selected will show less variance than the
entire pool of individuals. Specifically, the scenario below shows a
\(u\)-ratio of about 0.69 in the independent variable. We see in the
figure that the correlation in the restricted scores (\(\rho_{xy_S}\))
is attenuated relative to the unrestricted (true) correlation
(\(\rho_{xy}\)).

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-2-1.pdf}

We can also visualize what happens to the correlation when the range is
enhanced. Enhancement can be accomplished by selecting individuals at
the ends of the distribution (Taylor and Griess 1976). In the
visualization below, we see an opposite effect on the correlation, that
is, an over-estimate of the unrestricted correlation rather than an
attenuation like we see under range restriction. The scenario below has
a \(u\)-ratio of about 1.39 in the independent variable.

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-3-1.pdf}

It starts to become apparent that if \(u_x>1\) (i.e.,
\(\sigma_x>\sigma_\mathcal{x_S}\)) the observed correlation
over-estimates the true, unrestricted correlation and under-estimates
the unrestricted correlation when \(u_x<1\) (i.e.,
\(\sigma_x<\sigma_\mathcal{x_S}\), Sackett and Yang 2000).

A bias correction formula for univariate direct range restriction was
first developed by Pearson (1903) and provided more recently by J. E.
Hunter and Schmidt (1990). To correct for the systematic bias in
correlations, we can use the \(u\)-ratio of the independent variable
such that,

\begin{equation}\protect\hypertarget{eq-univariate}{}{
r_c = \frac{r_{xy_S}}{u_x\left(1+r_{xy_S}^2\left[\frac{1}{u^2_x}-1\right]\right)}
}\label{eq-univariate}\end{equation}

Where the sampling variance of the corrected correlation is

\begin{equation}\protect\hypertarget{eq-univariate-se}{}{
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{xy_S}}\right)^2.
}\label{eq-univariate-se}\end{equation}

\hypertarget{the-bivariate-case-2}{%
\subsubsection{The Bivariate Case}\label{the-bivariate-case-2}}

Bivariate direct range restriction/enhancement occurs when the
variability in both independent and dependent variables within the
selected sample is less than or greater than the variability in the
unrestricted population. Let us consider a case where just the
independent variable is restricted (or enhanced) such that \(u_x\neq 1\)
and \(u_y \neq 1\). Like we showed for the univariate case, let's
visualize the correlation between independent (\(x\)) and dependent
(\(y\)) variables under range restriction by only selecting individuals
above some cut off point for both \(x\) and \(y\). The scores of
individuals that have been selected will show less variance than the
entire pool of individuals. Specifically, the scenario below shows a
\(u\)-ratio of about 0.69 in the independent variable and dependent
variables. We see in the figure that the correlation in the restricted
sample (\(\rho_{xy_S}\)) is attenuated relative to the unrestricted
(true) correlation (\(\rho_{xy}\)).

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-4-1.pdf}

Likewise let's visualize what happens to the correlation when the range
is enhanced. Enhancement in both variables can be accomplished by
selecting individuals at the ends of the distribution of \(x\) and
\(y\). In the visualization below, we observe an over-estimation of
observed correlation relative to the unrestricted correlation. The
scenario below has a \(u\)-ratio of about 1.32 in both the independent
variable and dependent variable.

\includegraphics{indirect_range_restriction_files/figure-pdf/unnamed-chunk-5-1.pdf}

A bias correction formula for bivariate range restriction is much more
complicated than the univariate formulation. This is due to the fact
that there is inter-dependence between the correlation, the \(u\)-ratio
of \(x\), and the \(u\)-ratio of \(y\). For instance, if \(x\) and \(y\)
are positively correlated and if there is direct range restriction in
\(x\) this will also restrict the variability in y even if there is no
range restriction in \(y\). To break down the correction formula into
simpler parts, let us first define a factor we will denote with
\(\psi\),

\begin{equation}\protect\hypertarget{eq-biv-1}{}{
\psi = \frac{u_x u_y\left(r_{xy_S}^2-1\right)}{2r_{xy_S}}
}\label{eq-biv-1}\end{equation} This factor contains all the parameters
needed to correct the correlation coefficient under direct selection
(\(r_{xy_S}\)). Then we can plug it into the formula

\begin{equation}\protect\hypertarget{eq-biv-2}{}{
r_c = \psi + \text{sign}\left[r_{xy_S}\right]\sqrt{\psi^2+1}
}\label{eq-biv-2}\end{equation}

Where the sampling variance of the corrected correlation is,

\begin{equation}\protect\hypertarget{eq-biv-se}{}{
\sigma^2_{\varepsilon_c} = \sigma^2_{\varepsilon_o}\left(\frac{r_c}{r_{xy_S}}\right)^2.
}\label{eq-biv-se}\end{equation}

\hypertarget{correcting-correlations-in-r-2}{%
\subsection{Correcting Correlations in
R}\label{correcting-correlations-in-r-2}}

To correct correlations for range restriction we can start by simulating
data from the the \texttt{mvrnorm} function in the \texttt{MASS}
package. Lets first simulate 200 data points.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}MASS\textquotesingle{})}
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# set seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{343}\NormalTok{)}

\CommentTok{\# define parameters }
\NormalTok{rho }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{50}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{200}

\CommentTok{\# sample data from a bivariate normal distribution}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(}\AttributeTok{n =}\NormalTok{ n,}
                \AttributeTok{mu =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                \AttributeTok{Sigma =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,rho),}
                                  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(rho,}\DecValTok{1}\NormalTok{)),}
                \AttributeTok{empirical =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# obtain unrestricted scores}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{1}\NormalTok{]}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ data[,}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{univariate-direct-range-restriction-1}{%
\subsubsection*{Univariate Direct Range
Restriction}\label{univariate-direct-range-restriction-1}}
\addcontentsline{toc}{subsubsection}{Univariate Direct Range
Restriction}

We can start with univariate direct range restriction by selecting only
on the independent variable. We will select only the values above the
mean.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# obtain scores when x \textgreater{} Mean(x)}
\NormalTok{selected }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(x)}
\NormalTok{xS }\OtherTok{\textless{}{-}}\NormalTok{ x[selected]}
\NormalTok{yS }\OtherTok{\textless{}{-}}\NormalTok{ y[selected]}

\CommentTok{\# calculate correlation between unrestricted and restricted scores}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x,y) }\CommentTok{\# unrestricted}
\NormalTok{rxyS }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(xS,yS) }\CommentTok{\# restricted}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}unrestricted: rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}restricted: rxyS = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxyS,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                     
[1,] "unrestricted: rxy = 0.5"
[2,] "restricted: rxyS = 0.32"
\end{verbatim}

As expected, we observe an attenuation of the correlation under range
restriction. Now lets calculate the \(u\)-ratios for both variables.
Remember that even though we only selected on \(x\), we should expect
the variability in \(y\) in the restricted sample to also be smaller
than the unrestricted sample when \(x\) and \(y\) are correlated.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate u{-}ratios}
\NormalTok{ux }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(xS)}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(x)}
\NormalTok{uy }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(yS)}\SpecialCharTok{/}\FunctionTok{sd}\NormalTok{(y)}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}ux = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(ux,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}uy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(uy,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]       
[1,] "ux = 0.59"
[2,] "uy = 0.86"
\end{verbatim}

As anticipated, not only is \(u_x\) below 1 indicating range
restriction, but also \(u_y\) is slightly below 1 since \(x\) and \(y\)
covary. Now we can apply the correction for univariate direct range
restriction by hand from Equation~\ref{eq-univariate} and
Equation~\ref{eq-univariate}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# correct the restricted correlation}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ rxyS }\SpecialCharTok{/}\NormalTok{ (ux }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ rxyS}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{/}\NormalTok{ux}\SpecialCharTok{\^{}}\DecValTok{2{-}1}\NormalTok{)) )}

\CommentTok{\# acquire sample size from }
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(xS)}

\CommentTok{\# calculate the observed correlation sampling variance}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{rxyS)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected cor: r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected var: var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                         
[1,] "corrected cor: r = 0.49"    
[2,] "corrected var: var_e = 0.02"
\end{verbatim}

The correction formula produced a very close estimate of the true
population correlation (\(r_c = .49\) vs \(\rho_{xy}=.50\)). Lets also
correct the correlation using the \texttt{correct\_r} function in the
psychmeta package, \texttt{psychmeta} (Dahlke and Wiernik 2019).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# correct the restricted correlation for univariate direct range restriction}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxyS,}
          \AttributeTok{correction =} \StringTok{\textquotesingle{}uvdrr\_x\textquotesingle{}}\NormalTok{,  }\CommentTok{\# uvdrr\_x = univariate direct range restriction in x}
          \AttributeTok{ux =}\NormalTok{ ux,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error and Univariate Direct Range Restriction:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95  n n_effective
1 0.492    0.209    0.685 97        40.8
\end{verbatim}

We can see that the correction made by the \texttt{correct\_r} function
provides identical results to the one done by hand.

\hypertarget{bivariate-direct-range-restriction-1}{%
\subsubsection{Bivariate Direct Range
Restriction}\label{bivariate-direct-range-restriction-1}}

For bivariate direct range restriction we can select values above the
mean in both independent and dependent variables.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# obtain scores when x \textgreater{} Mean(x) and y \textgreater{} Mean(y)}
\NormalTok{selected }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(x) }\SpecialCharTok{\&}\NormalTok{ y }\SpecialCharTok{\textgreater{}} \FunctionTok{mean}\NormalTok{(y)}
\NormalTok{xS }\OtherTok{\textless{}{-}}\NormalTok{ x[selected]}
\NormalTok{yS }\OtherTok{\textless{}{-}}\NormalTok{ y[selected]}

\CommentTok{\# calculate correlation between unrestricted and restricted scores}
\NormalTok{rxy }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(x,y) }\CommentTok{\# unrestricted}
\NormalTok{rxyS }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(xS,yS) }\CommentTok{\# restricted}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}unresticted: rxy = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxy,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}restricted: rxyS = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rxyS,}\DecValTok{2}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                     
[1,] "unresticted: rxy = 0.5" 
[2,] "restricted: rxyS = 0.29"
\end{verbatim}

Notice that there is even more attenuation in the selected correlation
coefficient than there was in the univariate case. Now we can correct
for bivariate range restriction by hand using Equation~\ref{eq-biv-1},
Equation~\ref{eq-biv-2}, Equation~\ref{eq-biv-se}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# calculate the factor, psi}
\NormalTok{psi }\OtherTok{\textless{}{-}}\NormalTok{ ux}\SpecialCharTok{*}\NormalTok{uy}\SpecialCharTok{*}\NormalTok{(rxyS}\SpecialCharTok{\^{}}\DecValTok{2{-}1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{rxyS)}

\CommentTok{\# calculate the corrected correlation using psi}
\NormalTok{rc }\OtherTok{\textless{}{-}}\NormalTok{ psi }\SpecialCharTok{+} \FunctionTok{sign}\NormalTok{(rxyS)}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(psi}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \DecValTok{1}\NormalTok{)}

\CommentTok{\# acquire sample size from }
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(xS)}

\CommentTok{\# calculate the observed correlation sampling variance}
\NormalTok{var\_e\_o }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{rxyS}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (n}\DecValTok{{-}1}\NormalTok{)}

\CommentTok{\# correct sampling variance}
\NormalTok{var\_e\_c }\OtherTok{\textless{}{-}}\NormalTok{ var\_e\_o }\SpecialCharTok{*}\NormalTok{ (rc}\SpecialCharTok{/}\NormalTok{rxyS)}\SpecialCharTok{\^{}}\DecValTok{2}

\CommentTok{\# print results}
\FunctionTok{rbind}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected cor: r = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(rc,}\DecValTok{2}\NormalTok{)),}
      \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}corrected var: var\_e = \textquotesingle{}}\NormalTok{,}\FunctionTok{round}\NormalTok{(var\_e\_c,}\DecValTok{3}\NormalTok{))}
\NormalTok{      )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]                          
[1,] "corrected cor: r = 0.48"     
[2,] "corrected var: var_e = 0.036"
\end{verbatim}

Again, we see that the corrected correlation closely resembles the
unrestricted correlation (\(r_c=.48\) vs \(\rho_{xy}=.50\)). lets

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load packages}
\CommentTok{\# install.packages(\textquotesingle{}psychmeta\textquotesingle{})}
\FunctionTok{library}\NormalTok{(psychmeta)}

\CommentTok{\# correct the restricted correlation for univariate direct range restriction}
\FunctionTok{correct\_r}\NormalTok{(}\AttributeTok{rxyi =}\NormalTok{ rxyS,}
          \AttributeTok{correction =} \StringTok{\textquotesingle{}bvdrr\textquotesingle{}}\NormalTok{,  }\CommentTok{\# bvdrr = bivariate direct range restriction}
          \AttributeTok{ux =}\NormalTok{ ux,}
          \AttributeTok{uy =}\NormalTok{ uy,}
          \AttributeTok{n =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Correlations Corrected for Measurement Error and Bivariate Direct Range Restriction:
---------------------------------------------------------------------------------------
  value CI_LL_95 CI_UL_95  n n_effective
1  0.48   0.0943    0.689 64        17.3
\end{verbatim}

We can see that the correction exactly reflects the correction done by
hand.

\part{Application to Meta-Analysis}

\hypertarget{introduction-to-meta-analysis-methods}{%
\chapter{Introduction to Meta-Analysis
Methods}\label{introduction-to-meta-analysis-methods}}

\hypertarget{fixed-effects-model}{%
\section{Fixed Effects Model}\label{fixed-effects-model}}

\hypertarget{random-effects-model}{%
\section{Random Effects Model}\label{random-effects-model}}

(Borenstein et al. 2010)

(Hartung 1999)

(Cooper, Hedges, and Valentine 2009)

(DerSimonian and Kacker 2007)

\hypertarget{artifact-correction-meta-analysis}{%
\chapter{Artifact Correction
Meta-Analysis}\label{artifact-correction-meta-analysis}}

\hypertarget{individual-artifact-correction-model}{%
\section{Individual Artifact Correction
Model}\label{individual-artifact-correction-model}}

\hypertarget{artifact-distribution-model}{%
\section{Artifact Distribution
Model}\label{artifact-distribution-model}}

\hypertarget{alternative-methods}{%
\section{Alternative Methods}\label{alternative-methods}}

(J. E. Hunter and Schmidt 1990)

(Wiernik and Dahlke 2020)

(F. Schmidt and Hunter 1977)

(Murphy 2003)

(Viswesvaran and Ones 1995)

(Raju and Burke 1983)

(Callender and Osburn 1980)

\bookmarksetup{startatroot}

\hypertarget{references-1}{%
\chapter*{References}\label{references-1}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-aguinis2009}{}}%
Aguinis, Herman, Charles A Pierce, and Steven A Culpepper. 2009.
{``Scale Coarseness as a Methodological Artifact,''} September.

\leavevmode\vadjust pre{\hypertarget{ref-bobko2001}{}}%
Bobko, Philip, Philip Roth, and Christopher Bobko. 2001. {``Correcting
the Effect Size of d for Range Restriction and Unreliability.''}
\emph{Organizational Research Methods - ORGAN RES METHODS} 4 (January):
46--61. \url{https://doi.org/10.1177/109442810141003}.

\leavevmode\vadjust pre{\hypertarget{ref-bonett2005}{}}%
Bonett, Douglas G., and Robert M. Price. 2005. {``Inferential Methods
for the Tetrachoric Correlation Coefficient.''} \emph{Journal of
Educational and Behavioral Statistics} 30 (2): 213--25.
\url{https://www.jstor.org/stable/3701350}.

\leavevmode\vadjust pre{\hypertarget{ref-borenstein2010}{}}%
Borenstein, Michael, Larry V. Hedges, Julian P. T. Higgins, and Hannah
R. Rothstein. 2010. {``A Basic Introduction to Fixed-Effect and
Random-Effects Models for Meta-Analysis.''} \emph{Research Synthesis
Methods} 1 (2): 97--111. \url{https://doi.org/10.1002/jrsm.12}.

\leavevmode\vadjust pre{\hypertarget{ref-borsboom2002}{}}%
Borsboom, Denny, and Gideon J Mellenbergh. 2002. {``True Scores, Latent
Variables, and Constructs: A Comment on Schmidt and Hunter.''}

\leavevmode\vadjust pre{\hypertarget{ref-borsboom2004}{}}%
Borsboom, Denny, Gideon J. Mellenbergh, and Jaap Van Heerden. 2004.
{``The Concept of Validity.''} \emph{Psychological Review} 111 (4):
1061--71. \url{https://doi.org/10.1037/0033-295X.111.4.1061}.

\leavevmode\vadjust pre{\hypertarget{ref-bravais1844}{}}%
Bravais, A. 1844. \emph{Analyse mathématique sur les probabilités des
erreurs de situation d'un point}. Impr. Royale.

\leavevmode\vadjust pre{\hypertarget{ref-brennan2010}{}}%
Brennan, Robert L. 2010. {``Generalizability Theory and Classical Test
Theory.''} \emph{Applied Measurement in Education} 24 (1): 1--21.
\url{https://doi.org/10.1080/08957347.2011.532417}.

\leavevmode\vadjust pre{\hypertarget{ref-callender1980}{}}%
Callender, John C., and H. G. Osburn. 1980. {``Development and Test of a
New Model for Validity Generalization.''} \emph{Journal of Applied
Psychology} 65 (5): 543--58.
\url{https://doi.org/10.1037/0021-9010.65.5.543}.

\leavevmode\vadjust pre{\hypertarget{ref-charles2005}{}}%
Charles, Eric. 2005. {``The Correction for Attenuation Due to
Measurement Error: Clarifying Concepts and Creating Confidence Sets.''}
\emph{Psychological Methods} 10 (July): 206--26.
\url{https://doi.org/10.1037/1082-989X.10.2.206}.

\leavevmode\vadjust pre{\hypertarget{ref-chyou2007}{}}%
Chyou, Po-Huang. 2007. {``Patterns of Bias Due to Differential
Misclassification by Case{\textendash}control Status in a
Case{\textendash}control Study.''} \emph{European Journal of
Epidemiology} 22 (1): 7--17.
\url{https://doi.org/10.1007/s10654-006-9078-x}.

\leavevmode\vadjust pre{\hypertarget{ref-cohen1988}{}}%
Cohen, Jacob. 1988. \emph{Statistical Power Analysis for the Behavioral
Sciences}. Academic Press.

\leavevmode\vadjust pre{\hypertarget{ref-thehand2009}{}}%
Cooper, Harris M., Larry V. Hedges, and Jeff C. Valentine, eds. 2009.
\emph{The Handbook of Research Synthesis and Meta-Analysis}. 2nd ed. New
York: Russell Sage Foundation.

\leavevmode\vadjust pre{\hypertarget{ref-cronbach1955}{}}%
Cronbach, Lee J., and Paul E. Meehl. 1955. {``Construct Validity in
Psychological Tests.''} \emph{Psychological Bulletin} 52 (4): 281--302.
\url{https://doi.org/10.1037/h0040957}.

\leavevmode\vadjust pre{\hypertarget{ref-dahlke2019}{}}%
Dahlke, Jeffrey A., and Brenton M. Wiernik. 2019. {``Psychmeta: An R
Package for Psychometric Meta-Analysis.''} \emph{Applied Psychological
Measurement} 43 (5): 415--16.
\url{https://doi.org/10.1177/0146621618795933}.

\leavevmode\vadjust pre{\hypertarget{ref-dersimonian2007}{}}%
DerSimonian, Rebecca, and Raghu N. Kacker. 2007. {``Random-Effects Model
for Meta-Analysis of Clinical Trials: An Update.''} \emph{NIST} 28
(January): 105--14.
\url{https://www.nist.gov/publications/random-effects-model-meta-analysis-clinical-trials-update}.

\leavevmode\vadjust pre{\hypertarget{ref-digby1983}{}}%
Digby, P. G. N. 1983. {``Approximating the Tetrachoric Correlation
Coefficient.''} \emph{Biometrics} 39 (3): 753--57.
\url{https://doi.org/10.2307/2531104}.

\leavevmode\vadjust pre{\hypertarget{ref-fisher1915}{}}%
Fisher, R. A. 1915. {``Frequency Distribution of the Values of the
Correlation Coefficient in Samples from an Indefinitely Large
Population.''} \emph{Biometrika} 10 (4): 507--21.
\url{https://doi.org/10.2307/2331838}.

\leavevmode\vadjust pre{\hypertarget{ref-galton1907}{}}%
Galton, Francis. 1907. {``Vox Populi.''} \emph{Nature} 75 (1949):
450--51. \url{https://doi.org/10.1038/075450a0}.

\leavevmode\vadjust pre{\hypertarget{ref-gliem2003}{}}%
Gliem, Joseph A., and Rosemary R. Gliem. 2003. {``Calculating,
Interpreting, And Reporting Cronbach{'}s Alpha Reliability Coefficient
For Likert-Type Scales.''}
\url{https://scholarworks.iupui.edu/handle/1805/344}.

\leavevmode\vadjust pre{\hypertarget{ref-haertel2006}{}}%
Haertel, Edward H. 2006. {``3. Reliability.''} In, 4th ed.

\leavevmode\vadjust pre{\hypertarget{ref-hartung1999}{}}%
Hartung, Joachim. 1999. {``An Alternative Method for Meta-Analysis.''}
\emph{Biometrical Journal} 41 (8): 901--16.
\url{https://doi.org/10.1002/(SICI)1521-4036(199912)41:8\%3C901::AID-BIMJ901\%3E3.0.CO;2-W}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1981}{}}%
Hedges, Larry V. 1981. {``Distribution Theory for Glass's Estimator of
Effect Size and Related Estimators.''} \emph{Journal of Educational
Statistics} 6 (2): 107--28.
\url{https://doi.org/10.3102/10769986006002107}.

\leavevmode\vadjust pre{\hypertarget{ref-hedges1989}{}}%
---------. 1989. {``An Unbiased Correction for Sampling Error in
Validity Generalization Studies.''} \emph{Journal of Applied Psychology}
74 (3): 469--77. \url{https://doi.org/10.1037/0021-9010.74.3.469}.

\leavevmode\vadjust pre{\hypertarget{ref-hunter1990a}{}}%
Hunter, John E., and Frank L. Schmidt. 1990. \emph{Methods of
meta-analysis: correcting error and bias in research findings}. Newbury
Park: Sage Publications.

\leavevmode\vadjust pre{\hypertarget{ref-hunter1990}{}}%
Hunter, John, and Frank Schmidt. 1990. {``Dichotomization of Continuous
Variables: The Implications for Meta-Analysis.''} \emph{Journal of
Applied Psychology} 75 (June): 334--49.
\url{https://doi.org/10.1037/0021-9010.75.3.334}.

\leavevmode\vadjust pre{\hypertarget{ref-kelley1927}{}}%
Kelley, Truman Lee. 1927. \emph{Interpretation of Educational
Measurements}. World Book Company.

\leavevmode\vadjust pre{\hypertarget{ref-krieg1999}{}}%
Krieg, Edward F. 1999. {``Biases Induced by Coarse Measurement
Scales.''} \emph{Educational and Psychological Measurement} 59 (5):
749--66. \url{https://doi.org/10.1177/00131649921970125}.

\leavevmode\vadjust pre{\hypertarget{ref-lin2018}{}}%
Lin, Lifeng. 2018. {``Bias Caused by Sampling Error in Meta-Analysis
with Small Sample Sizes.''} \emph{PLOS ONE} 13 (9): e0204056.
\url{https://doi.org/10.1371/journal.pone.0204056}.

\leavevmode\vadjust pre{\hypertarget{ref-maccallum2002}{}}%
MacCallum, Robert C., Shaobo Zhang, Kristopher J. Preacher, and Derek D.
Rucker. 2002. {``On the Practice of Dichotomization of Quantitative
Variables.''} \emph{Psychological Methods} 7: 19--40.
\url{https://doi.org/10.1037/1082-989X.7.1.19}.

\leavevmode\vadjust pre{\hypertarget{ref-maxwell1993}{}}%
Maxwell, Scott, and Harold Delaney. 1993. {``Bivariate Median Splits and
Spurious Statistical Significance.''} \emph{Psychological Bulletin} 113
(January): 181--90. \url{https://doi.org/10.1037/0033-2909.113.1.181}.

\leavevmode\vadjust pre{\hypertarget{ref-mendoza1987}{}}%
Mendoza, Jorge L., and Michael Mumford. 1987. {``Corrections for
Attenuation and Range Restriction on the Predictor.''} \emph{Journal of
Educational Statistics} 12 (3): 282--93.
\url{https://doi.org/10.3102/10769986012003282}.

\leavevmode\vadjust pre{\hypertarget{ref-murphy2003}{}}%
Murphy, Kevin R. 2003. \emph{Validity Generalization: A Critical
Review}. Psychology Press.

\leavevmode\vadjust pre{\hypertarget{ref-muthuxe9n1988}{}}%
Muthén, Bengt, and Charles Hofacker. 1988. {``Testing the Assumptions
Underlying Tetrachoric Correlations.''} \emph{Psychometrika} 53 (4):
563--77. \url{https://doi.org/10.1007/BF02294408}.

\leavevmode\vadjust pre{\hypertarget{ref-naggara2011}{}}%
Naggara, O., J. Raymond, F. Guilbert, D. Roy, A. Weill, and D. G.
Altman. 2011. {``Analysis by Categorizing or Dichotomizing Continuous
Variables Is Inadvisable: An Example from the Natural History of
Unruptured Aneurysms.''} \emph{American Journal of Neuroradiology} 32
(3): 437--40. \url{https://doi.org/10.3174/ajnr.A2425}.

\leavevmode\vadjust pre{\hypertarget{ref-olkin1958}{}}%
Olkin, Ingram, and John W. Pratt. 1958. {``Unbiased Estimation of
Certain Correlation Coefficients.''} \emph{The Annals of Mathematical
Statistics} 29 (1): 201--11. \url{https://www.jstor.org/stable/2237306}.

\leavevmode\vadjust pre{\hypertarget{ref-pearson1903}{}}%
Pearson, Karl. 1903. {``I. Mathematical Contributions to the Theory of
Evolution. {\textemdash}XI. On the Influence of Natural Selection on the
Variability and Correlation of Organs.''} \emph{Philosophical
Transactions of the Royal Society of London. Series A, Containing Papers
of a Mathematical or Physical Character} 200 (321-330): 1--66.
\url{https://doi.org/10.1098/rsta.1903.0001}.

\leavevmode\vadjust pre{\hypertarget{ref-pearson1913}{}}%
---------. 1913. {``On the Probable Error of a Coefficient of
Correlation as Found from a Fourfold Table.''} \emph{Biometrika} 9
(1/2): 22--33. \url{https://doi.org/10.2307/2331798}.

\leavevmode\vadjust pre{\hypertarget{ref-peters1940}{}}%
Peters, Charles C., and Walter R. Van Voorhis. 1940. {``Further Methods
of Correlation.''} In, 362--403. New York, NY, US: McGraw-Hill Book
Company. \url{https://doi.org/10.1037/13596-013}.

\leavevmode\vadjust pre{\hypertarget{ref-psych:p2017}{}}%
{``Psych: Procedures for Personality and Psychological Research.''}
2017. \url{https://CRAN.R-project.org/package=psych}.

\leavevmode\vadjust pre{\hypertarget{ref-raju1983}{}}%
Raju, Nambury, and Michael Burke. 1983. {``Two Procedures for Studying
Validity Generalization.''} \emph{Journal of Applied Psychology} 68
(August): 382--95. \url{https://doi.org/10.1037/0021-9010.68.3.382}.

\leavevmode\vadjust pre{\hypertarget{ref-royston2006}{}}%
Royston, Patrick, Douglas G. Altman, and Willi Sauerbrei. 2006.
{``Dichotomizing Continuous Predictors in Multiple Regression: A Bad
Idea.''} \emph{Statistics in Medicine} 25 (1): 127--41.
\url{https://doi.org/10.1002/sim.2331}.

\leavevmode\vadjust pre{\hypertarget{ref-russell1991}{}}%
Russell, Craig J., Jeffrey K. Pinto, and Philip Bobko. 1991.
{``Appropriate Moderated Regression and Inappropriate Research Strategy:
A Demonstration of Information Loss Due to Scale Coarseness''} 15 (3):
257--66. \url{https://doi.org/10.1177/014662169101500305}.

\leavevmode\vadjust pre{\hypertarget{ref-sackett2000}{}}%
Sackett, Paul R., and Hyuckseung Yang. 2000. {``Correction for Range
Restriction: An Expanded Typology.''} \emph{Journal of Applied
Psychology} 85 (1): 112--18.
\url{https://doi.org/10.1037/0021-9010.85.1.112}.

\leavevmode\vadjust pre{\hypertarget{ref-schmidt2003}{}}%
Schmidt, Frank L., Huy Le, and Remus Ilies. 2003. {``Beyond Alpha: An
Empirical Examination of the Effects of Different Sources of Measurement
Error on Reliability Estimates for Measures of Individual-Differences
Constructs.''} \emph{Psychological Methods} 8: 206--24.
\url{https://doi.org/10.1037/1082-989X.8.2.206}.

\leavevmode\vadjust pre{\hypertarget{ref-schmidt1977}{}}%
Schmidt, Frank, and John Hunter. 1977. {``Development of a General
Solution to the Problem of Validity Generalization.''} \emph{Journal of
Applied Psychology} 62 (October): 529--40.
\url{https://doi.org/10.1037/0021-9010.62.5.529}.

\leavevmode\vadjust pre{\hypertarget{ref-sijtsma2009}{}}%
Sijtsma, Klaas. 2009. {``On the Use, the Misuse, and the Very Limited
Usefulness of~Cronbach{'}s Alpha.''} \emph{Psychometrika} 74 (1):
107--20. \url{https://doi.org/10.1007/s11336-008-9101-0}.

\leavevmode\vadjust pre{\hypertarget{ref-spearman1904}{}}%
Spearman, C. 1904. {``The Proof and Measurement of Association Between
Two Things.''} \emph{International Journal of Epidemiology} 39 (5):
1137--50. \url{https://doi.org/10.1093/ije/dyq191}.

\leavevmode\vadjust pre{\hypertarget{ref-symonds1924}{}}%
Symonds, P. M. 1924. {``On the Loss of Reliability in Ratings Due to
Coarseness of the Scale.''} \emph{Journal of Experimental Psychology} 7
(6): 456--61. \url{https://doi.org/10.1037/h0074469}.

\leavevmode\vadjust pre{\hypertarget{ref-taylor1976}{}}%
Taylor, Erwin K., and Thomas Griess. 1976. {``The Missing Middle in
Validation Research.''} \emph{Personnel Psychology} 29 (1): 5--11.
\url{https://doi.org/10.1111/j.1744-6570.1976.tb00397.x}.

\leavevmode\vadjust pre{\hypertarget{ref-ulrich2004}{}}%
Ulrich, Rolf, and Markus Wirtz. 2004. {``On the Correlation of a
Naturally and an Artificially Dichotomized Variable.''} \emph{British
Journal of Mathematical and Statistical Psychology} 57 (2): 235--51.
\url{https://doi.org/10.1348/0007110042307203}.

\leavevmode\vadjust pre{\hypertarget{ref-vargha1996}{}}%
Vargha, András, Tamás Rudas, Harold D. Delaney, and Scott E. Maxwell.
1996. {``Dichotomization, Partial Correlation, and Conditional
Independence.''} \emph{Journal of Educational and Behavioral Statistics}
21 (3): 264--82. \url{https://doi.org/10.2307/1165272}.

\leavevmode\vadjust pre{\hypertarget{ref-viswanathan2005}{}}%
Viswanathan, Madhu. 2005. \emph{Measurement Error and Research Design}.
SAGE.

\leavevmode\vadjust pre{\hypertarget{ref-viswesvaran1995}{}}%
Viswesvaran, Chockalingam, and Deniz S. Ones. 1995. {``Theory Testing:
Combining Psychometric Meta-Analysis and Structural Equations
Modeling.''} \emph{Personnel Psychology} 48 (4): 865--85.
\url{https://doi.org/10.1111/j.1744-6570.1995.tb01784.x}.

\leavevmode\vadjust pre{\hypertarget{ref-viswesvaran2014}{}}%
Viswesvaran, Chockalingam, Deniz S. Ones, Frank L. Schmidt, Huy Le, and
In-Sue Oh. 2014. {``Measurement Error Obfuscates Scientific Knowledge:
Path to Cumulative Knowledge Requires Corrections for Unreliability and
Psychometric Meta-Analyses.''} \emph{Industrial and Organizational
Psychology} 7 (4): 507--18.
\url{https://doi.org/10.1017/S1754942600006799}.

\leavevmode\vadjust pre{\hypertarget{ref-wechsler2008}{}}%
Wechsler, David. 2008. \emph{Wechsler Adult Intelligence Scale--Fourth
Edition}. 4th ed. \url{https://doi.org/10.1037/t15169-000}.

\leavevmode\vadjust pre{\hypertarget{ref-wiernik2020}{}}%
Wiernik, Brenton M., and Jeffrey A. Dahlke. 2020. {``Obtaining Unbiased
Results in Meta-Analysis: The Importance of Correcting for Statistical
Artifacts.''} \emph{Advances in Methods and Practices in Psychological
Science} 3 (1): 94--123. \url{https://doi.org/10.1177/2515245919885611}.

\end{CSLReferences}



\end{document}
