# Introduction to Meta-Analysis Methods {#sec-metaanalysis_intro}

## Introduction

Meta-analysis is an analytic tool to synthesize quantitative evidence from multiple studies. By systematically combining and analyzing the results of multiple studies, meta-analysis provides a comprehensive overview, unveiling patterns, trends, and insights that individual studies might not be able to capture. Combining research findings also has the added benefit of increasing the precision of our results (i.e., greater statistical power). In this section we will cover the method described by [@hunter1990a] since it is readily compatible with artifact corrections (see next chapter). For the random-effects model however, we use an integrated approach that incorporates methods from @hunter1990a and @hedges1998 that was first introduced by @morris2014. However it is important to note that there are other common methods to conduct meta-analyses that have their strengths and weaknesses [@hedges2014; @callender1980; @johnson1995].

## Common-Effect Model

A common effect model is the simplest form of meta-analysis. It assumes that all the variation in observed effect sizes is attributable to sampling error (see @fig-common-effect). In other words, all the observed effect sizes are estimates of the same population effect size. Note that there is a distinction between *fixed-effects* models and a *common effect* model [@viechtbauer; @laird1990]. The common effect model assumes that the true effect size is identical for each study while the fixed effects model does not assume this. Instead, the fixed effects model can be interpreted as the weighted average of true effects. Computationally, they are the same and provide the same parameter estimates, yet the interpretation differs [@viechtbauer].

![The diagram above depicts a common effect meta-analysis of five studies. The study effect sizes are homogenous and all estimate a single true population effect size.](figure/fixed_effects_diagram.png){#fig-common-effect}

The common effect model can be modeled such that population effect size $\theta$ is held constant each study effect size estimate ($h_i$), such that,

$$
h_i  = \theta + e_i
$$ {#eq-fixed-mdl}

Where $e_i$ indicates sampling error and the subscript $i$ denotes each study. Similar to the true score theory model that we discussed in chapter 4, the variance components of each term can similarly be written out as,

$$
\sigma^2_h = \sigma^2_\theta + \sigma^2_e
$$

However in our common effect model, the population effect size is fixed across studies and will not vary, simplifying the formula to,

$$
\sigma^2_h = \sigma^2_e
$$ {#eq-var-fixed}

Therefore the only source of variation in the observed effect sizes, is sampling error.

Ultimately, our goal is to obtain a precise estimate of the population effect size. To obtain an estimate of the population effect size, $\theta$, we can calculate the average observed effect size, $\bar{h}_i$ from $k$ studies. However, in practice, effect sizes from different studies have varying levels of precision (i.e., different standard errors). A simple arithmetic average will not account for the differences between studies in their precision. Instead, we can calculate a weighted average where the weights each study can be calculated by the inverse variance (i.e., squared standard error) of each study such that,

$$
w_i = \frac{1}{se(h_i)^2}.
$$

Then we can calculate a weighted average,

$$
\hat{\theta} =\frac{\sum^k_{i=1}w_ih_i}{\sum^k_{i=1}w_i}.
$$

Where $\sum^k_{i=1}$ is the sum across all $k$ studies. This weighted average will be an unbiased estimate of the population effect size. However, even though this mean effect size is more precise compared to single-study estimates, it is not exempt from error itself. We we can compute the standard error for $\hat{\theta}$ as,

$$
se(\hat{\theta}) = \frac{1}{\sqrt{\sum^k_{i=1} w_i}}
$$

The standard error can be used to compute the 95% confidence intervals (if the sampling distribution is approximately normal) of the meta-analytic point estimate:

$$
CI_{95} = \hat{\theta}\pm 1.96 \cdot se(\hat{\theta})
$$

::: {.callout-note appearance="default" icon="false"}
## Applied Example in R

Lets use a meta-analytic data set investigating the the effectiveness of a writing-to-learn intervention on academic achievement from @bangert-drowns2004. This data set has standardized mean differences between the treatment group and a control group from $k=48$ studies (total sample size: $n=5,576$) and is available within the developmental version of the `metadat` package [@metadat]. Lets conduct a common effect meta-analysis using the equations from the previous section. We can use the `rma` function in the `metafor` package [@viechtbauer2010] to conduct a common effect (`method = 'EE'`) meta-analysis without having to write each equation by hand.

```{r,message=FALSE}

library(metadat)
library(metafor)

# display first 6 studies
head(dat.bangertdrowns2004[,c('author','year','ni','yi','vi')])


# fixed effects model
mdl <- rma(data = dat.bangertdrowns2004,
           yi = yi,
           vi = vi,
           method = 'EE') # Equal-effects = Common Effect

# print results
data.frame(theta_hat = mdl$b[1],
           se = mdl$se[1],
           CI_ll = mdl$ci.lb[1],
           CI_ul = mdl$ci.ub[1])
```

The results show an estimated population effect of $\hat{\theta}=0.17\, [0.11,\, 0.22]$.
:::

## Random Effects Model

The random-effects model refers to a model that allows for the population effect size to vary from study to study (see @fig-random-effects). Random-effects differs from the fixed effects model in an important way: it does not assume that all observed effect sizes come from a single (fixed) population effect size [@borenstein2010]. This variation in population effect sizes is called heterogeneity. In the traditional @hunter1990a the weights utilized in the random effects meta-analysis are identical to the common effect model. In other conventional meta-analysis methods [@hedges1998], random-effect weights usually include a random effect component containing the variation in population effect sizes (this has the effect of making study weights more similar to each other with more variation in population effects). A modern approach introduced by @morris2014 and later tested by @brannick2019, added this random effect component to the Hunter-Schmidt method. The simulation study by @brannick2019, concluded that weights incorporating random effect components improved the Hunter-Schmidt estimates. Here we will discuss Hedges-Vevea's method with some elements taken from Hunter-Schmidt.

![The diagram above depicts a random-effects meta-analysis of five studies. Effect sizes are more variable than the common effect meta-analysis since effect sizes vary due to sampling error *and* population effect sizes.](figure/random_effects_diagram.png){#fig-random-effects}

The model from @eq-fixed-mdl can be changed slightly to encompass variation of the population effect size from study to study:

$$
h_i = \theta_i + e_i.
$$

In the common effect model, we assumed that all the variation in study effect sizes is accounted for by variation in sampling error (see @eq-var-fixed). However in the random-effects model the variance in population effect sizes ($\sigma^2_\theta$) is allowed to be greater than zero. The variance components can be written out as,

$$
\sigma^2_h=\sigma^2_\theta + \sigma^2_e.
$$ {#eq-var-random}

Estimating variance components can be done computationally through an iterative estimation procedure called REstricted Maximum Likelihood (REML) estimation. The estimated variance of population effect sizes, $\hat{\sigma}_\theta$, can now be incorporated into the inverse variance weights alongside

$$
w_i = \frac{1}{se(h_i)^2 + \hat{\sigma}^2_\theta}
$$

::: {.callout-tip appearance="default" icon="false"}
## Calculating Standard Errors

The standard error for a given study often uses the sample estimate in the sampling variance equation. For example, a study correlation, $r_i$, will have a sampling variance of

$$
se(r_i)^2 = \frac{(1-\rho_i^2)^2}{n}
$$

Where $\rho_i$ is the population effect size for that study. Since the population effect size is not known, $\rho_i$ is often replaced with the study estimate, $r_i$ (also the denominator will be adjusted to be $n-1$ for the decreased degrees of freedom). However this makes the sampling variances and estimates dependent on one another which can cause problems for other types analyses (e.g., funnel plot asymmetry). Instead, we will use the sample size weighted mean correlation for each study to replace $\rho_i$ [@hunter1990a],

$$
se(r_i)^2 = \frac{\left(1-\bar{r}^2\right)^2}{n-1}
$$

Where,

$$
\bar{r} = \frac{\sum^k_{i=1}n_ir_i}{\sum^k_{i=1}n_i}
$$

In studies with no heterogeneity ($\sigma_\theta=0$) this is nearly optimal, but it still works well in cases of substantial heterogeneity.
:::

Now we can estimate the mean of population effects by taking the weighted average effect size [equation 16.5, @thehand2009],

$$
\hat{\bar{\theta}} = \frac{\sum^k_{i=1}w_i h_i}{\sum^k_{i=1}w_i}.
$$

Where $i=1...k$ studies. The standard error of the mean of population effects can calculated from the summation of inverse weights [equation 16.6, @thehand2009],

$$
se(\hat{\bar{\theta}}) = \frac{1}{\sqrt{\sum^k_{i=1}w_i}}.
$$ The 95% confidence interval can then be calculated as,

$$
CI = \hat{\bar{\theta}} \pm 1.96\cdot se(\hat{\bar{\theta}})
$$

In other conventions, the variance in population effects ($\sigma^2_\theta$) is denoted as $\tau^2$ [@borenstein2010; @dersimonian2007; @hedges1998], but conceptually $\sigma^2_\theta$ and $\tau^2$ these are identical. Taking the root of $\sigma^2_\theta$ is the standard deviation of population effect sizes which can be a useful measure of heterogeneity. Furthermore, we can use $\hat{\sigma}_\theta$ to calculate credibility (prediction) intervals which allows us to draw inferences about the range of plausible population effect sizes. For example, the 90% credibility interval can be calculated with the following equations:

$$
CR = \hat{\bar{\theta}} \pm 1.645\hat{\sigma}_\theta
$$

The confidence interval and credibility interval have fundamentally different interpretations that are often misinterpreted in published work [@whitener1990]. When we are interpreting a single realized interval (i.e., our estimate-in-hand), the 90% *credibility* interval can be interpreted as the region in which 90% of population effect sizes exist, however, a 95% *confidence* interval describes the interval in which there is a 95% probability of containing the true *mean* of population effect sizes. It is important to note that the confidence interval interpretation here is only valid in the case of a single realized interval [@vos2022], if there is more than one interval obtained from the same population of studies, then the interpretation does not hold (this would be a rare in a meta-analysis).

::: {.callout-note appearance="default" icon="false"}
## Applied Example in R

Let's continue looking at the meta-analysis from @bangert-drowns2004. This data set has standardized mean differences between the treatment group and a control group from $k=48$ studies (total sample size: $n=5,576$) and is available within the developmental version of the `metadat` package [@metadat]. Lets conduct a common effect meta-analysis using the equations from the previous section. We can use the `rma` function in the `metafor` package [@viechtbauer2010] to conduct a random effect meta-analysis with REML estimation we can use the `method = 'REML'` argument.

```{r,message=FALSE}

library(metadat)
library(metafor)

# display first 6 studies
head(dat.bangertdrowns2004[,c('author','year','ni','yi','vi')])


# fixed effects model
mdl <- rma(data = dat.bangertdrowns2004,
           yi = yi,
           vi = vi,
           method = 'REML') # Equal-effects = Common Effect

# print results
data.frame(theta_hat = mdl$b[1],
           se = mdl$se[1],
           CI_ll = mdl$ci.lb[1],
           CI_ul = mdl$ci.ub[1])
```

The results show an estimated population effect of $\hat{\theta}=0.22\, [0.13,\, 0.31]$.
:::

```{=html}
<script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js" data-id="matthewbjane" data-description="Support me on Buy me a coffee!" data-message="Thank you for being here." data-color="#eeb4d7ff" data-position="Right" data-x_margin="18" data-y_margin="18"></script>
```
