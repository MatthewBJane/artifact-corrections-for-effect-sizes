```{r color_scheme,echo = F,warning=F,message=F}
source("plotting-themes.R", local = knitr::knit_global())
```

# Effect Sizes and Artifacts

## Effect Sizes

An **effect size** is a parameter that describes the degree of association of two random variables[^02-effect-sizes-1] (e.g., $X$ and $Y$). Effect sizes are often used to quantitatively summarize research findings. We can define two types of effect sizes that will be of primary focus throughout the book: correlations and standardized mean differences (SMDs). Both correlations and SMDs are standardized effect sizes which means that they are without respect to location and scale of random variables. Standardized effect sizes allow for comparability across studies, in particular, they facilitate research syntheses and meta-analyses.

[^02-effect-sizes-1]: Effect sizes can be defined more broadly as the association between multiple variables, however this book will only focus on the more narrow case of just two variables.

## Correlations

A **correlation** is defined as the standardized covariance between two variables (see @fig-r-ex). For two continuous random variables, $X$ and $Y$, the correlation $\rho_{XY}$ can be expressed as,

$$
\rho_{XY} := \frac{\sigma_{XY}}{\sigma_X\sigma_Y}.
$$ {#eq-pop-corr}

Where $\sigma_{XY}$ is the covariance between $X$ and $Y$, $\sigma_X$ and $\sigma_Y$ are the standard deviations of $X$ and $Y$, respectively. A correlation does not have to be between two continuous variables. Typically, a correlation between a Bernoulli random variable and a continuous random variable is referred to as a *point-biserial* correlation and it is expressed similarly to @eq-pop-corr,

$$
\rho_{GY} := \frac{\sigma_{GY}}{\sigma_G\sigma_Y}.
$$ {#eq-pb-corr}

A correlation (whether point-biserial or continuous) is bounded between -1 and 1, where -1 is a perfectly negative correlation, 1 is a perfectly positive correlation, and 0 indicates no correlation. Note that a correlation of zero does not necessarily mean that the two variables are independent.

```{r,echo=FALSE,warning=FALSE}
#| id: fig-r-ex
#| fig-cap: A correlation between two variables ($X$ and $Y$). The left panel shows a negative correlation and the right panel shows a positive correlation. The ellipses show the contour of a joint distribution.


# Set mean and covariance matrix for the bivariate normal distribution
mu <- c(0, 0)  # Mean vector
sigma <- matrix(c(1, -0.5, -0.5, 1), 
                nrow = 2)  # Covariance matrix

# Generate random data from bivariate normal distribution
set.seed(123)  # Set seed for reproducibility
data <- mvrnorm(n = 100, mu = mu, 
                Sigma = sigma,
                empirical=TRUE)  # Generating random data

# Create a data frame from the generated data
df <- data.frame(x = data[, 1], y = data[, 2])

# Create a contour plot using ggplot
h1 <- ggplot(df, aes(x = x, y = y)) +
  th_red + theme(text = element_text(color = text_color_red),
                  title = element_text(size=14)) +
  labs(title = "Negative Correlation",
       subtitle = TeX('$\\rho_{XY}=-.50$'),
       x = "X", y = "Y") +
  stat_ellipse(level=.90,color=lightermain_color_red,linewidth=1,alpha = .9)+
  stat_ellipse(level=.70,color=lightmain_color_red,linewidth=1,alpha = .9)+
  stat_ellipse(level=.50,color=main_color_red,linewidth=1,alpha = .9)+
  stat_ellipse(level=.30,color=darkmain_color_red,linewidth=1,alpha = .9)+
  stat_ellipse(level=.10,color=text_color_red,linewidth=1,alpha = .9) +
  xlim(-2.3,2.3) +
  ylim(-2.3,2.3)



sigma <- matrix(c(1, 0.5, 0.5, 1), 
                nrow = 2)  # Covariance matrix

# Generate random data from bivariate normal distribution
set.seed(1)  # Set seed for reproducibility
data <- mvrnorm(n = 100, mu = mu, 
                Sigma = sigma,
                empirical=TRUE)  # Generating random data

# Create a data frame from the generated data
df <- data.frame(x = data[, 1], y = data[, 2])

# Create a contour plot using ggplot
h2 <- ggplot(df, aes(x = x, y = y)) +
  th_blue + theme(text = element_text(color = text_color_blue),
                  title = element_text(size=13)) +
  labs(title = "Positive Correlation",
       subtitle = TeX('$\\rho_{XY}=.50$'),
       x = "X", y = "Y") +
  stat_ellipse(level=.90,color=lightermain_color_blue,linewidth=1,alpha = .9)+
  stat_ellipse(level=.70,color=lightmain_color_blue,linewidth=1,alpha = .9)+
  stat_ellipse(level=.50,color=main_color_blue,linewidth=1,alpha = .9)+
  stat_ellipse(level=.30,color=darkmain_color_blue,linewidth=1,alpha = .9)+
  stat_ellipse(level=.10,color=text_color_blue,linewidth=1,alpha = .9)+
  xlim(-2.3,2.3) +
  ylim(-2.3,2.3)

h1 + h2
```

## Standardized Mean Difference

The relationship between a Bernoulli random variable and a continuous random variable can alternatively be expressed as a standardized mean difference. A **standardized mean difference** is the difference between the means of two groups standardized by the within-group standard deviation (see @fig-d-ex). The groups are defined by the values of a Bernoulli random variable and the standardized mean difference,

$$
\delta_{GY} :=  \frac{\mu_{Y|G=1}-\mu_{Y|G=0}}{\sigma_{Y|G}},
$$ {#eq-pop-smd}

where $\mu_{Y|G=0}$ and $\mu_{Y|G=1}$ is the population mean of $Y$ for group 0 and 1, respectively. The within-group standard deviation $\sigma_{Y|G}$ is assumed to be equal between groups such that, $\sigma_{Y|G}=\sigma_{Y|G=1}=\sigma_{Y|G=0}$.

```{r,echo=FALSE,warning=FALSE}
#| id: fig-d-ex
#| fig-cap: A standardized mean difference in the population between two distributions. The mean and standard deviation of group 0 is $\mu_{Y|G=0}=9$ and $\sigma_{Y|G=0}=4$, respectively. Whereas mean and standard deviation of group $B$ is $\mu_{Y|G=1}=12$ and $\sigma_{Y|G=1}=4$, respectively. Therefore the standardized mean difference is $\delta_{GY} = (9-12)/4=0.75$. Note that $\sigma_{Y|G=0}=\sigma_{Y|G=1}=\sigma_{Y|G}$.

ggplot(data = NULL) +
  stat_slab(aes(y=0,xdist=distributional::dist_normal(9,4)),
            scale = 0.75,
            color = '#d74ea2ff',
            fill = '#d74ea255',
            linewidth = 1) +
  stat_slab(aes(y=0,xdist=distributional::dist_normal(12,4)),
            scale = 0.75,
            color = "#5fa6bcff",
            fill = "#5fa6bc55",
            linewidth = 1) +
  scale_fill_manual(values = c(panel_color_red,main_color_red)) + 
  theme_ggdist() + 
  scale_y_continuous(breaks=NULL) +
  theme(legend.position = "none",
        aspect.ratio = .6,
        text=element_text(size=14)) +
  geom_point(aes(x=c(9),y=c(.78)),
             shape=25,color=main_color_red,
             fill=main_color_red, size = 2.5) +
  geom_point(aes(x=c(12),y=c(.78)),
             shape=25,color=main_color_blue,
             fill=main_color_blue, size = 2.5) +
  geom_line(aes(x = c(5,9), y=c(.46,.46)),
            arrow = arrow(length=unit(0.20,"cm"), 
                          ends="first", type = "closed"),
            linewidth=1,color=darkmain_color_red) +
  geom_line(aes(x = c(8,12), y=c(.42,.42)),
            arrow = arrow(length=unit(0.20,"cm"), 
                          ends="first", type = "closed"),
            linewidth=1,color=darkmain_color_blue) +
  annotate(geom = 'text',x = 8.5, y = .84, 
           label = TeX('$\\mu_{Y|G=0}$'),size = 6, 
           color=darkmain_color_red) +
  annotate(geom = 'text',x = 13, y = .84, 
           label = TeX('$\\mu_{Y|G=1}$'),size = 6, 
           color=darkmain_color_blue) +
  annotate(geom = 'text',x = 7.2, y = .52, 
           label = TeX('$\\sigma_{Y|G}$'),size = 6, 
           color=darkmain_color_red) +
  annotate(geom = 'text',x = 10.5, y = .35, 
           label = TeX('$\\sigma_{Y|G}$'),size = 6, 
           color=darkmain_color_blue) +
  annotate(geom = 'text',x = 1, y = .93, 
           label = TeX('$\\delta_{GY} = 0.75$'),size = 6, 
           color='grey30') +
  ylab("")+
  xlab("Y")
```

### Sample Estimates of Effect Sizes



The effect size in the population of interest is a fixed value that does not change from sample to sample. However, an estimate of the effect size from sample data will vary from sample to sample. We will denote sample estimates of effect sizes with English letters as opposed to the Greek letters we used for population effect sizes. 

#### Correlations {.unnumbered}

The sample estimate of a correlation is computed as follows [@pearson1895],

$$
r_{XY} := \frac{s_{XY}}{s_{X}s_{Y}}
$$ {#eq-pearson-r}

Where $s_X$ and $s_Y$ are the sample standard deviations and $s_{XY}$ is the covariance. See @exm-corr for an example of a correlation between standardized test scores.

::: {#exm-corr .border style="--bs-border-width:2pt;--bs-border-color:#5fa6bcff; padding:5pt;"}
## Relationship between Test Scores

In the United States, universities frequently require prospective students to take one of two standardized tests assessing academic ability, the Scholastic Achievement Test (SAT) and the American College Test (ACT). Since these tests are used interchangeably in university admission decisions, it is good to know how related the scores of these tests really are. A data set from @revelle2010 consists of 668 individuals who took both the SAT and the ACT. The data set splits the SAT test into Quantitative (SATQ) and Verbal (SATV) subtests which each range from 200-800, whereas the ACT is reported as a score from 1-36. We can plot out the relationship between the total SAT score (SATV + SATQ) and the ACT scores with a scatter plot^[1: Individuals who did not complete any one of the tests or who scored well below the expected guessing score (ACT < 10, SATQ < 300, SATV < 300). ] (see @fig-scatter-cor-ex)

```{r,warning=FALSE,message=FALSE,echo=FALSE}
#| id: fig-scatter-cor-ex

library(psychTools)

df <- sat.act[complete.cases(sat.act[,c("SATQ","SATV","ACT")]),]

df <- df[df$ACT > 10 & df$SATV > 300 & df$SATQ > 300,]

df <- cbind(df, SAT = df$SATV + df$SATQ)

ggplot(df, aes(x=SAT, y=ACT)) +
  geom_point(color=main_color_red,alpha=.8) +
  th_red +
  theme(aspect.ratio=1)

```

The resulting covariance matrix between variables is displayed in @tbl-cor-ex. The covariance matrix shows the covariance between all the variables in the model. Note that the covariance between a variable and itself is equal to the variance (e.g., $\sigma_{XX}=\sigma^2_{X}$). Therefore the diagonal (from top-left number to bottom-right number) of the matrix are the variances of each of the variable whereas the off-diagonal is are the covariances between pairs of variables.

```{r,echo=FALSE,message=FALSE,warning=FALSE}
#| id: tbl-cor-ex
#| tbl-cap: Covariance matrix.

library(tinytable)
library(psych)

tb <- round(cov(df[,c("ACT","SATQ","SATV","SAT")]),2 )

tt(cbind(Test = c("ACT","SATQ","SATV","SAT"), as.data.frame(tb))) |>
  style_tt(
    i = c(1,2,3,4),
    j = c(1,1,1,1),
    background = "#d74ea2ff",
    color = "white") |>
  style_tt(i = 1,j = 2,background = "#dddddd",color = "black") |>
  style_tt(i = 2,j = 3,background = "#dddddd",color = "black") |>
  style_tt(i = 3,j = 4,background = "#dddddd",color = "black") |>
  style_tt(i = 4,j = 5,background = "#dddddd",color = "black")|>
  style_tt(i = 1,j = 5,bold = TRUE) |>
  style_tt(i = 4,j = 2,bold = TRUE) 
```

The correlation coefficient between total SAT (the last column) and ACT (first column) can be computed using the formula in @eq-pearson-r. Let's treat SAT as our $X$ variable and the ACT as our $Y$ variable:

$$
r_{XY} = \frac{s_{XY}}{s_X s_Y} = \frac{625.69}{\sqrt{40074.40} \times \sqrt{22.37}} = .66
$$
:::

#### Standardized Mean Differences (SMDs) {.unnumbered}

For an SMD, the commonly used estimate for comparison between two independent groups is Cohen's estimator [@cohen1988],

$$
d_{GY} = \frac{m_{Y|G=1} - m_{Y|G=0}}{s_{Y|G}}.
$$

This is commonly referred to as Cohen's *d* or simply the *d* statistic. The sample estimate of the standard deviation of $Y$ given $G$ is the pooled within-group standard deviation,

$$
s_{Y|G} = \sqrt{\frac{(n_0 - 1)s^2_{Y|G=0} + (n_1 - 1)s^2_{Y|G=1}}{n_0 + n_1 -2}}.
$$

The within-group sample size is denoted by $n_0$ and $n_1$ for $G=0$ and $G=1$, respectively. If there is reason to believe that the variances differ between groups, such that $s_{Y|G=0}\neq s_{Y|G=1}$, then it may be best to standardize the mean difference with just one of the groups (usually a control/reference group).

::: {#exm-smd .border style="--bs-border-width:2pt;--bs-border-color:#5fa6bcff; padding:5pt;"}
## Gender Differences in Agreeableness

In personality psychology, the Big 5 personality traits are five dimensions where preferences and attitudes tend to vary (Agreeableness, Openness, Conscientiousness, Extraversion, and Neuroticism). Agreeableness reflects a person's cooperativeness, politeness, kindness, friendliness, and compassion. Agreeableness also tends to differ on average between men and women, with women generally scoring higher. Using a data set from @goldberg1999 consisting of 2800 participants, we can calculate the standardized mean difference from 2709 individuals who answered all of the items pertaining to agreeableness. The data set consists of 896 men and 1813 women who all responded to five statements related to agreeableness (e.g., "Inquire about others' well-being"). Each participant self assessed the accuracy (from 1-Very Inaccurate to 6-Very Accurate) of each of the five statements with respect to themselves. Agreeableness is scored based on the average of their responses to all of the statements and POMP scored so 0 is the minimum possible score (very disagreeable) and 100 is the maximum possible score (very agreeable). The distributions within men and women are displayed in @fig-smd-agreeableness.

```{r,echo=FALSE,warning=FALSE,message=FALSE}
#| id: fig-smd-agreeableness
#| fig-cap: Histograms of agreeableness scores for men and women. Dark lines denote the mean for each group.

library(psychTools)
library(ggdist)
library(dplyr)



df <- bfi[,c(grep('A',colnames(bfi),value = TRUE),'gender')]

df <- df[complete.cases(df),]

A <- rowMeans(data.frame(1-(df$A1-1)/5,(df$A2-1)/5,(df$A3-1)/5,(df$A4-1)/5,(df$A5-1)/5)*100)

df <- cbind(df, A, Gender = recode(df$gender,`1`="Men", `2`="Women"))



ggplot(df,aes(x = A,y = Gender,color=Gender,fill=Gender)) + 
  stat_histinterval(
    interval_color = "transparent",point_color = "transparent",
    outline_bars = FALSE,breaks=seq(0,100,2),
    slab_alpha = .5) +
  stat_slab(fill="transparent") +
  theme_ggdist() +
  scale_fill_manual(values = c(main_color_blue,main_color_red)) +
  scale_color_manual(values = c(darkmain_color_blue,darkmain_color_red)) +
  theme(aspect.ratio = .7,legend.position = "none",
        axis.text.y = element_text(size=14),axis.text.x = element_text(size=12),
        axis.title.x = element_text(size=14)) +
  stat_spike(aes(linetype = after_stat("mean")),
             linetype="solid",size=3.5,linewidth=1.5) +
  xlab("Agreeableness Score") +
  ylab("")
  

```

The descriptive statistics for both groups are presented in @tbl-smd-ex. We find the mean agreeableness score of women in the sample is 75.50, whereas the mean for men is 67.55. We also find the standard deviation to be 17.10 and 18.63 in women and men, respectively.

```{r,echo=FALSE,message=FALSE,warning=FALSE}
#| id: tbl-smd-ex
#| tbl-cap: Descriptive statistics.

library(tinytable)
library(psych)

tb <- rbind(
  "Women" = round(describe(df[df$Gender=="Women",])["A",c(2:4)],2),
  "Men" = round(describe(df[df$Gender=="Men",])["A",c(2:4)],2)
)
tb <- cbind(Gender = row.names(tb),tb)

tt(tb)

```

The sample estimate of the SMD can be computed with the following procedure:

1.  Calculate the mean difference (denoting $G=1$ as women and $G=0$ as men):

$$
m_{Y|G=1} - m_{Y|G=0} = 75.50 - 67.55 = 7.95
$$

2.  Then we can calculate the pooled standard deviation:

$$\begin{align}
        s_{Y|G} &= \sqrt{\frac{(n_0 - 1)s^2_{Y|G=0} + (n_1 - 1)s^2_{Y|G=1}}{n_0 + n_1 -2}} \\[.3em] &= \sqrt{\frac{(1812)17.10^2 + (895)18.63^2}{1812 + 895 -2}}\\[.3em] &= 17.63
\end{align}$$

3.  Then we can calculate the standardized mean difference:

$$
d_{GY} = \frac{m_{Y|G=1} - m_{Y|G=0}}{s_{Y|G}} = \frac{7.95}{17.63} = 0.45
$$
:::

## Errors in Effect Sizes

### Target Population Effect Size {#sec-estimand}

The **target population effect size** is the effect size between the random variables of interest among in the population of interest. This can also be termed the statistical estimand, that is, the quantity of inferential and scientific interest.

### Random (Sampling) Errors {#sec-random}

A population effect size is a constant, unchanging value that remains fixed across repeated samples. However, a sample estimate of an effect size varies from sample to sample and does not exactly reflect the population value. This is due to the fact that randomly taking a subset of the population will contain inherent variability in the composition of the sample. **Sampling errors** describe the random deviations that we observe in effect size estimates between samples [@barraza2019]. We can define sampling errors as the difference between the sample estimate of the effect size and the population effect size. We can define sampling errors for a sample correlation as $\varepsilon_r = r_{XY} - \rho_{XY}$ and then we can model the sample correlation as,

$$
r_{XY} = \rho_{XY} + \varepsilon_r.
$$ {#eq-r-sam}

Similarly, the SMD sample estimate can be modeled as,

$$
d_{GY} = \delta_{GY} + \varepsilon_d.
$$ {#eq-d-sam}

We can quantify sampling errors by the variance of the effect size estimator, which is mostly a function of sample size^[2: sampling variances often change with the location of the effect size, for example, the correlation coefficient has a variance of 0 when the correlation is unity no matter the sample size.] (i.e., larger samples tend to have smaller variances). To estimate sampling variance, we have to include assumptions about the joint distribution (unless we use a non-parametric approach, e.g., bootstrap). Note that the variance of the error term is the same as the variance of the sample effect size (e.g., $\mathrm{var}(r_{XY})=\mathrm{var}(\varepsilon_r)$). Although it is not necessary for the X and Y to be bivariate normal to compute a Pearson correlation, the traditional formula for sampling variance does require us to make this assumption. Let $X$ and $Y$ follow a bivariate normal distribution,

$$
X,Y\sim\mathcal{N}_2\left(\begin{bmatrix} \mu_{X} \\ \mu_Y\end{bmatrix},\begin{bmatrix} \sigma^2_{X} & \sigma_{XY} \\ \sigma_{XY}&\sigma^2_{Y} \end{bmatrix}\right),
$$

where $\mathcal{N}_D$ denotes the $D$-variate normal distribution parameterized by a mean vector and a covariance matrix. The asymptotic sampling variance of the estimator is,

$$
\mathrm{var}(r_{XY}) \overset{_\infty}{=} \frac{\left(1 - \rho_{XY}^2\right)^2}{n}.
$$ {#eq-asymp-var-r}

where $\overset{_\infty}{=}$ denotes equivalency as $n\rightarrow \infty$, hence the *asymptotic* sampling variance. The issue with @eq-asymp-var-r is that it contains the population correlation which is unknown in practice. Therefore we can substitute the population correlation with the sample correlation [@bonett2008, p. 174],

$$
\widehat{\mathrm{var}}(r_{XY})= \frac{\left(1 - r_{XY}^2\right)^2}{n-1}.
$$ {#eq-sam-r-var}

The denominator now uses $n-1$ to adjust for the slight bias in small sample sizes. To stay consistent with many software packages we will continue to use $n-1$ for the denominator, however it is worth noting that a recent simulation study by @gnambs2023 found that the denominator of $n-3$ provides slightly better variance estimates especially in small sample sizes. This difference is negligible in moderate to large samples.

To obtain the sampling variance for Cohen's SMD estimator, we must assume that the conditional distribution of $Y$ given $G$ is normal such that,

$$
Y|G^{-1}(1)\sim\mathcal{N}_1\left(\mu_{Y|G=1},\sigma^2_{Y|G}\right),
$$

$$
Y|G^{-1}(0)\sim\mathcal{N}_1\left(\mu_{Y|G=0},\sigma^2_{Y|G}\right).
$$

where $G^{-1}(0)$ denotes all possible outcomes $\omega\in\Omega$ where $G(\omega)=0$. Notice that the variance of $Y$ within $G=0$ and $G=1$ are equivalent in the two distributions, yet the means are allowed to differ. Given these assumptions, the asymptotic sampling variance for the SMD estimator is,

$$
\mathrm{var}\left(d_{GY}\right) \overset{_\infty}{=} \frac{n}{n_0 n_1} + \frac{\delta^2_{GY}}{2n}
$$ {#eq-asymp-var-d}

Similar to @eq-asymp-var-r, the population SMD $\delta_{GY}$ is not known and must be replaced with the sample estimate $d_{GY}$ [@hunter1990a eq. 7.23],

$$
\mathrm{var}\left(d_{GY}\right) = \left(\frac{n-1}{n-3}\right)\left(\frac{n}{n_0 n_1} + \frac{d^2_{GY}}{2n}\right) ,
$$ {#eq-sam-var-d}

where the term $(n-1)/(n-3)$ is added to account for slight bias in small samples. The sampling variances allow us to quantify how variable effect sizes are over repeated samples ($\mathcal{S}_1,\mathcal{S}_2,...$). For an illustration of sampling error, see @fig-3.1.

```{r,echo=FALSE,fig.height=4, warning=FALSE, message=FALSE}
#| id: fig-3.1
#| fig-cap: This figure shows the distribution of sample estimates. The blue diamonds denotes the population effect size, which stays constant across samples. The black dots denote the sample effect size estimate. The grey lines denote random sampling errors, which represent the difference between the estimates and the population value. The sampling distribution on the right shows the probability distribution of estimates across repeated samples, the width of this distribution is described by the variance of the estimator. Note the illustration shows a normally distributed estimator, but this is not a requirement.


set.seed(1)
# simulate 70 true scores
k = 20
scores1 = MASS::mvrnorm(k,0,1.2,empirical = TRUE)
# simulate scores at time 1

ggplot(data=NULL, aes(x = 1:k, y = scores1)) +
  theme_ggdist() + theme(aspect.ratio=.5,
                 title = element_text(size=15),
                 axis.text.y = element_text(size=16)) + 
  scale_x_continuous(labels = 1:k, breaks=1:k,limits = c(1,k+4)) +
  scale_y_continuous(labels = c('',0,'','','','','',''), 
                     breaks=c(-2.75,-2,-1.25,-.50,.25,1,1.75,2.50),
                     limits = c(-3,3)) +
  stat_slab(aes(x=21,ydist=distributional::dist_normal(0,1.1)), 
            fill = 'grey92',scale=4, color='grey10') +
  geom_line(aes(x = c(22.9,22.9), y=c(-1,1)),
            arrow = arrow(length=unit(0.20,"cm"), 
                          ends="both", type = "closed"),
            linewidth=.9,color = 'grey10') +
  geom_hline(yintercept = -2, alpha=.2, linewidth = .8,
             color = 'black') +
  geom_hline(yintercept = c(-2.75,-2,-1.25,-.50,.25,1,1.75,2.50), 
             alpha=.03, linewidth = .4,
             color = 'black') +
  geom_line(aes(x=c(1:k,1:k),y=c(rep(0,k),scores1),group=c(1:k,1:k)),
            color='grey60', alpha=1, linewidth = .9) + 
  geom_point(data=NULL, aes(x = 1:k, y = 0),alpha = 1,
            color=main_color_blue, stroke = 0, size = 4.5,shape=18) +
  geom_point(data=NULL, aes(x = 1:k, y = scores1),alpha = 1, stroke = 0, size = 3.5) +
  annotate(geom='text',x=1.2,y=1.25,label='error', 
           color = 'grey50', size = 4) + 
  annotate(geom='text',x=18.2,y=1.52,label='variance', 
           color = 'grey10', size = 4,hjust = 'left') + 
  annotate(geom='text',x=7.3,y=2.33,label='estimate', 
           color = 'black', size = 4) +
  annotate(geom='text',x=8.1,y=-1.5,label='population value', 
           color = darkmain_color_blue, size = 4,hjust='left') +
  xlab('Sample ID')+
  ylab(TeX('Effect Size')) +
  geom_curve(aes(x = 20.6, y = 1.35, xend = 22.75, yend = .5),
             colour = 'grey10',
             curvature = 0.3) +
  geom_curve(aes(x = 6, y = scores1[4]+.5, xend = 4.4, yend = scores1[4]+.05),
             colour = "black",
             curvature = -0.2) +
  geom_curve(aes(x = 2, y = scores1[4]-.5, xend = 3.8, yend = scores1[4]-.7),
             colour = 'grey50',
             curvature = 0.2)+
  geom_curve(aes(x = 6.2, y = -0.1, xend = 8, yend = -1.5),
             colour = main_color_blue,
             curvature = 0.2)
```

### Systematic Errors {#sec-systematic}

Sampling errors produce random errors in effect sizes, however, we can also observe systematic errors. **Systematic errors** are deviations from the target population value that are consistent across samples and produce bias in effect size estimates. In other words, effect size estimates will be *on average* larger or smaller than the target population value [@barraza2019]. Random sampling errors, on the other hand, will be larger or smaller than the target population value only by chance. There are two population effect sizes we need to consider: the target population effect size and the study population effect size. The target population effect size as described earlier relates the variables of interest within the population of interest. However, the **study population effect size** is the expectation of the effect size estimate over infinite study replications. **Attenuation** describes a type of systematic error where the study effect size is biased *toward* the null (i.e., effect size = 0). On the other hand, **inflation** describes the situation where the study effect size is biased *away* from the null. An **unbiased** effect size would be one where there is no systematic errors and therefore, the study population effect size is equivalent to the target population effect size. As we will see in future chapters, study artifacts such as selection effects and measurement error can produce effect sizes that contain systematic errors.

Let's suppose we are interested in the correlation between $X$ and $Y$, yet we are limited to error-prone proxies $\widetilde{X}$ and $\widetilde{Y}$. Given the potential impact of measurement error on correlations, the target population correlation $\rho_{XY}$ does not necessarily equal the study population correlation $\rho_{\widetilde{X}\widetilde{Y}}$. Instead we can relate them with an **artifact attenuation/inflation factor** $\alpha$,

$$
\rho_{\widetilde{X}\widetilde{Y}} = \alpha \rho_{XY}
$$ {#eq-a-study-pop}

Therefore $\alpha$ is mathematically defined as the ratio of the study population correlation and the target population correlation,

$$
\alpha = \frac{\rho_{\widetilde{X}\widetilde{Y}}}{\rho_{XY}}
$$ {#eq-a-def}

An attenuated study population effect size would indicate that $\alpha < 1$, whereas an inflated study effect size would suggest that $\alpha > 1$. If the the study population correlation perfectly reflects the target population correlation, then $\alpha = 1$ which would reduce @eq-a-study-pop to $\rho_{\widetilde{X}\widetilde{Y}} = \rho_{XY}$. A **study effect size estimate** denotes the estimate produced within a single study which can contain both systematic and random errors. Continuing with our example, we can model a study correlation estimate in a similar fashion to @eq-r-sam,

$$
r_{\widetilde{X}\widetilde{Y}} = \rho_{\widetilde{X}\widetilde{Y}} + \varepsilon_r
$$

Notice in @fig-systematic-errors that the sampling distributions do not become wider or smaller with systematic errors (this may occur indirectly if the sampling variance depends on the effect size itself), instead the whole sampling distribution shifts downward or upward depending on whether the effect size estimates are attenuated or inflated, respectively.

```{r,echo=FALSE,warning=FALSE}
#| id: fig-systematic-errors
#| fig-cap: Three sampling distributions representing estimators that are unbiased, attenuated, and inflated. The blue line indicates the the location of the target population effect size, whereas the black dots show the effect size estimates.

library(ggdist)
library(MASS)

set.seed(34)
x1 <- mvrnorm(15,1,1,empirical = TRUE)
x2 <- mvrnorm(15,-.2,1,empirical = TRUE)
x3 <- mvrnorm(15,2.2,1,empirical = TRUE)

h1 <- ggplot(data=NULL) + 
  stat_dist_eye(aes(x=0,ydist=distributional::dist_normal(1,1)), 
            fill = 'grey92',scale=.4, slab_color='grey10',slab_linewidth=1,dot_size=4) +
  geom_jitter(aes(y = x1,x=0),size=3.5,alpha=.6,height=0,width=.1)+
  stat_dist_eye(aes(x=1,ydist=distributional::dist_normal(-.2,1)), 
            fill = 'grey92',scale=.4, slab_color='grey10',slab_linewidth=1,) +
  geom_jitter(aes(y = x2,x=1),size=3.5,alpha=.6,height=0,width=.1)+
  stat_dist_eye(aes(x=2,ydist=distributional::dist_normal(2.2,1)), 
            fill = 'grey92',scale=.4, slab_color='grey10',slab_linewidth=1) +
  geom_jitter(aes(y = x3,x=2),size=3.5,alpha=.6,height=0,width=.1)+
  geom_hline(yintercept =1, color=main_color_blue,linewidth=1.5) +
  # geom_hline(yintercept = 0, color=main_color_blue,linewidth=2) +
  scale_x_continuous(breaks = c(0,1,2), labels=c('Unbiased','Attenuated','Inflated')) +
  scale_y_continuous(breaks = c(-3:6),
                     labels = c(rep('',2),'0',rep('',7))) +
  xlab('') +
  theme_ggdist() + theme(aspect.ratio=.5,
                 title = element_text(size=15),
                 axis.text = element_text(size=14)) + 
  ylab('Effect Size') +
  annotate(geom='text',x=.68,y=-2.5,label='estimate',hjust='right')+
  geom_curve(aes(x = 0.96, y = -1.4, xend = 0.7, yend = -2.5),
             colour = 'black',
             curvature = -0.2) +
  annotate(geom='text',x=.92,y=4.27+.5,
           label='target population value',hjust='right',color=darkmain_color_blue)+
  geom_curve(aes(x = 0.6, y = 1.1, xend = .7, yend = 4.5),
             colour = main_color_blue,
             curvature = 0.1) 

h1
  
```

### Combining Systematic and Random Errors

According to @sec-systematic, @sec-random, and @sec-estimand, a study effect size estimate has three components:

```{mermaid}

flowchart TD
   Z("target population<br>effect size (estimand)") --> E["observed effect <br>size estimate"]
   X("systematic <br>error (bias)") --> E
   Y("random (sampling)<br>error") --> E

```

Sticking with the example of the correlation between proxies $\widetilde{X}$ and $\widetilde{Y}$, let's construct a statistical model for a study correlation that encompasses the target population effect size, systematic error, and random sampling error,

$$
r_{\widetilde{X}\widetilde{Y}} = \alpha \rho_{XY} + \varepsilon_r
$$ {#eq-artifact-model}

Notice that we have only defined $\alpha$ in terms of the target population correlation and the study population correlation, yet of course both of these values are not available in practice. Calculating $\alpha$ is one of the primary purposes of this book as it's value will vary depending on the types of artifact(s), the type of effect size, along with what information is available. 

## Correcting Effect Sizes

Effect sizes can only be corrected for predictable, systematic errors. Therefore the only way to reduce random sampling error would be to increase the sample size. In principle, if we know the value of the artifact attenuation/inflation factor $\alpha$ then we could correct the observed effect size for systematic errors quite easily. Continuing with our example (correlation between proxies $\widetilde{X}$ and $\widetilde{Y}$), the artifact attenuation/inflation factor can be divided on both sides of @eq-artifact-model:

$$
\frac{r_{\widetilde{X}\widetilde{Y}}}{\alpha} = \rho_{XY} + \frac{\varepsilon_r}{\alpha}
$$ {#eq-correction}

The corrected correlation $r_{\widetilde{X}\widetilde{Y}}/\alpha$ is an unbiased estimate of the target population correlation $\rho_{XY}$. We can thus rewrite $r_{\widetilde{X}\widetilde{Y}}/\alpha$ as $r_{XY}$,

$$
r_{XY} = \rho_{XY} + \frac{\varepsilon_r}{\alpha}
$$ {#eq-correction-replace}

Importantly, the error term is also divided by $\alpha$ which will change sampling variance. The sampling error variance of the corrected correlation is

$$
\mathrm{var}(r_{XY})=\mathrm{var}\left(\frac{\varepsilon_r}{\alpha}\right)=\frac{\mathrm{var}(\varepsilon_r)}{\alpha^2}.
$$ {#eq-corrected-sam-variance}

Let's consider the example of how artificial dichotomization affects correlation coefficients in @exm-dich.

::: {#exm-dich .border style="--bs-border-width:2pt;--bs-border-color:#5fa6bcff; padding:5pt;"}
## Social Butterflies and Wallflowers

Let's see what happens when we dichotomize a naturally continuous variable. Using a data set of 3032 individuals from @psych we can look at the correlation between Sociability and Impulsivity. The scores are summation of 4-point scale responses to various emotional statements. We can denote social butterflies as individuals who have a total score that is above the median, whereas Wallflowers are individuals who are below the median. This median split turns a continuous variable into a binary one. The figure below shows the distribution of sociability with the cut-point (i.e., the median).

```{r,message=FALSE,warning=FALSE,echo=FALSE}
#| id: fig-ex-sociability-1

library(psychTools)

df <- msqR[msqR$time==1,]
df$Impulsivity <- round(df$Impulsivity,0)
df$Sociability <- round(df$Sociability,0)
med_soc <- median(df$Sociability,na.rm=T)


ggplot(data=df,aes(x = Sociability)) +
  stat_halfeye(aes(fill = after_stat(x > median(df$Sociability,na.rm=T))),
               density = "histogram",breaks = 40) +
  theme_ggdist() +
  theme(text = element_text(size=14),legend.position = "none") +
  scale_fill_manual(values=c(main_color_red,main_color_blue)) +
  scale_y_continuous(breaks=NULL) +
  annotate(geom="text",x = 12,y=.80,label="Social\n Butterflies",
           size=6,color=darkmain_color_blue) +
  annotate(geom="text",x = 5,y=.80,label="Wall\n Flowers",
           size=6,color=darkmain_color_red) +
  ylab("")+
  xlab("Sociability Score") +
  geom_vline(xintercept = med_soc,linetype="dashed") +
  annotate(geom="text",x = med_soc+.75,y=1.1,label="median",
           size=4.5,color="black")

```

The joint distribution between sociability and impulsivity is plotted twice in @fig-ex-sociability-2. The plot to the left shows the total scores for sociability and impulsivity whereas the plot on the right shows the the total scores for impulsivity and *dichotomized* scores for sociability.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
#| id: fig-ex-sociability-2

data <- as.data.frame(table(df$Sociability,df$Impulsivity))


h1 <- ggplot(data=data, aes(x = Var1, y = Var2)) +
  th_blue +
  geom_tile(aes(fill=Freq),color="white",linewidth=.7) +
  scale_fill_gradient(high = '#397689', low = 'white') +
  ylab("Impulsivity") +
  xlab("Sociability") +
  theme(legend.position = "none",
        axis.text.x = element_text(size=11),
        axis.text.y = element_text(size=11)) 

data <- as.data.frame(table(as.numeric(df$Sociability > med_soc),df$Impulsivity))

h2 <- ggplot(data=data, aes(x = as.numeric(Var1), y = Var2)) +
  th_blue +
  geom_tile(aes(fill=Freq),color="white",linewidth=.7) +
  scale_fill_gradient(high = '#397689', low = 'white') +
  scale_x_continuous(labels = c("Wallflowers","Social\n Butterflies"),
                     breaks = c(1,2)) +
  theme(legend.text = element_blank(),
        axis.text.y = element_text(size=11),
        aspect.ratio=1.5) +
  ylab("") +
  xlab("Sociability")

h1 + h2

```

The observed correlations between sociability and impulsivity differs when we leave sociability as it's original score vs when we dichotomize it (see @tbl-ex-sociability). However if we assume that sociability $X$ and impulsivity $Y$ are distributed normally, the correlation $r_{XY}$ will be attenuated under dichotomization of either (or both) variables. In our case, dichotomization shrunk the correlation from $r_{XY}=.39$ to $r_{\widetilde{X}Y}=.31$ ($\widetilde{X}$ is denoting dichotomized $X$). A paper by @hunter1990 derives the attenuation factor $\alpha$ for a correlation under a median split as $\alpha \approx .80$ (assuming the underlying continuous distribution is normal). Therefore we can take the dichotomized correlation of $.31$ and divide it by $.80$ to obtain a corrected correlation per @eq-correction,

$$
r_{XY} = \frac{r_{\widetilde{X}Y}}{\alpha} = \frac{.31}{.80} = .38
$$

```{r,warning=FALSE,message=FALSE,echo=FALSE}
#| id: tbl-ex-sociability
#| tbl-cap: Correlations between sociability and impulsivity

r <- cor(df$Sociability,df$Impulsivity,use = "pairwise.complete.obs")

rd <- cor(as.numeric(df$Sociability > med_soc),df$Impulsivity,use = "pairwise.complete.obs")



results <- data.frame(`Original`=round(r,2), 
                      `Dichotomized`= round(rd,2), 
                      `Corrected` = round(rd/.80,2) )

tt(results)

```

As we can see from the table, the corrected correlation closely aligns with the original correlation on continuous scores.

:::

The artifact factor $\alpha$ is sometimes unknown and must be estimated. An estimate of $\alpha$ will be denoted by the English letter $a$. We can relate the estimate and the true value with an error term $\xi = a - \alpha$,

$$
a = \alpha + \xi,
$$ {#eq-a}

The corrected effect size can then be approximated with the sample estimate and can thus be calculated by dividing the observed effect size by the estimated artifact factor. For example the corrected correlation under measurement error would be,

$$
r_{XY} \approx \frac{r_{\widetilde{X}\widetilde{Y}}}{a},
$$

Sampling variance of the corrected effect size will lead to some analytical issues. Technically we are not able to use @eq-corrected-sam-variance since $a$ is not a fixed value and can vary from sample to sample. Instead, we will have to either 1) treat $a$ as if it were fixed 2) use a bootstrapping procedure, or 3) use the Delta method (i.e., using a Taylor series expansion) to approximate to estimate the sampling variance. This will be discussed further in subsequent chapters.

## Calculating effect sizes in R

Let's turn to R to calculate effect sizes such as correlations and standardized mean differences. We will work with the `bfi` data set from the `psych` package [@psych] for both cases. The `bfi` data set consists of 5 items (6-point scales) from each of the big 5 personality traits (Agreeableness, Conscientiousness, Extraversion, Neuroticism, and Oppenness to Experience) along with some demographic variables. The total data set contains 2,800 individuals. We can start by computing a standardized mean difference (SMD) between men and women for each personality trait:

::: {.callout-note appearance="default" icon="false"}
## Computing SMDs in R

In this example we will compute the standardized mean difference (SMD) between men and women in each of the big 5 personality traits. Let's load in the packages we need [@psych; @dplyr; @missRanger; @psychmeta] and the big 5 personality data set:

```{r,message=FALSE}
# load in packages
library(psych) # for data set and cohen.d function
library(dplyr) # for data cleaning
library(missRanger) # for imputation
library(psychmeta) # for calculating sampling variance

# display the first 6 rows
head(bfi)
```

The items are denoted with the letter pertaining to each trait it is associated with (A = Agreeableness, C = Conscientiousness, E = Extraversion, N = Neuroticism, O = Oppenness to Experience). We first can impute missing item responses with a univariate imputation procedure [^02-effect-sizes-2] with the `missRanger::imputeUnivariate()` function [@missRanger]. Then we can calculate the total sum-scores for each of the five personality traits. Some items are reverse scored and must be flipped prior to summing.

```{r,message=FALSE}

df <- bfi |>
  # Impute missing item response values with univariate imputation
  imputeUnivariate() |>
  # Calculate sum scores
  mutate(A = 7-A1 +   A2 + A3 +   A4   +   A5, # Agreeableness
         C =   C1 +   C2 + C3 + 7-C4   + 7-C5, # Consientiousness
         E = 7-E1 + 7-E2 + E3 +   E4   +   E5, # Extraversion
         N =   N1 +   N2 + N3 +   N4   +   N5, # Neuroticism
         O =   O1 + 7-O2 + O3 +   O4   + 7-O5) # Openness to Experience

head(df)
```

We can then calculate the SMD between men and women using the `psych::cohen.d()`. The output displays the lower bound (`lower`), the SMD (`effect`), and the upper bound (`upper`) in that order. It also displays the multivariate version of the SMD (i.e., Maholonobis' D) and the SMDs converted to point-biserial correlations.

```{r}

results <- cohen.d(A + C + E + N + O ~ gender, data=df)

results
```

We can also extract the sampling variances for each SMD estimate by squaring the standard error calculated by the function:

```{r}

data.frame(d = results$cohen.d[,"effect"], 
           var = results$se^2)

```

If the raw data is not available, yet we want to calculate the SMD for each trait, the `psych` function allows us to input summary statistics. For example lets say we are given the following table:

```{r,echo=FALSE,collapse=TRUE,warning=FALSE}
summary_table <- describeBy(A + C + E + N + O ~ gender,data = df)

summary_table <- cbind(traits = c("Agreeableness","Conscientiousness","Extraversion","Neuroticism","Openness"),
                       summary_table$`2`[,c("mean","sd")],
                       summary_table$`1`[,c("mean","sd")])


tinytable::tt(summary_table,digits = 4) |> group_tt(j = list("Women (n = 919)" = c(2,3),
                                                             "Men (n = 1881)" = c(4,5)))

```

We can plug in the corresponding values into the `m2d` function to obtain the SMD `d`, however it does not return estimates of sampling variance, therefore we can use the `var_error_d()` function from the `psychmeta` package [@psychmeta]:

```{r,message=FALSE,warning=FALSE}


d <- m2d(m1 = c(23.91,21.64,21.11,16.33,22.77), 
         m2 = c(21.93,20.69,19.93,14.74,23.28), 
         s1 = c(4.25,4.675,5.099,6.019,4.007),
         s2 = c(4.635,4.824,5.574,5.702,4.052),
         n1 = 919,
         n2 = 1881,
         pooled=TRUE)



var_d <- var_error_d(d, n1=rep(919,5), n2 = rep(1881,5))

# display results
data.frame(d, var = var_d, row.names = c("A","C","E","N","O"))


```
:::

[^02-effect-sizes-2]: This may or may not be the optimal approach to imputing missing values, but imputation best practice is beyond the scope of this book. For information on imputation methods and best practice see @enders2022 and @van2018flexible

Now we can compute the correlations between the personality traits in all participants.

::: {.callout-note appearance="default" icon="false"}
## Computing Correlations in R

In this example we will compute the correlations between each of the five personality traits. Let's load in the packages we need [@psych; @dplyr; @missRanger; @psychmeta] and the big 5 personality data set:

```{r,message=FALSE}
# install.packages("psych")
# install.packages("dplyr")
# install.packages("missRanger")
# install.packages("psychmeta")

# load in packages
library(psych) # for data set and cohen.d function
library(dplyr) # for data cleaning
library(missRanger) # for imputation
library(psychmeta) # for calculating sampling variance

# display the first 6 rows
head(bfi)
```

We can calculate the scores for each of the five personality traits (i.e., Agreeableness, Conscientiousness, Extraversion, Neuroticism, and Openness to Experience) by first imputing missing values with the `missRanger` package [@missRanger][^02-effect-sizes-3] and then summing the scores row wise (i.e., a sum-score for each trait is calculated for each person). Some items are reverse scored and must be flipped prior.

```{r,message=FALSE}

df <- bfi |>
  imputeUnivariate() |>
  mutate(A = 7-A1 +   A2 + A3 +   A4   +   A5,   # Agreeableness
         C =   C1 +   C2 + C3 + 7-C4   + 7-C5, # Consientiousness
         E = 7-E1 + 7-E2 + E3 +   E4   +   E5,   # Extraversion
         N =   N1 +   N2 + N3 +   N4   +   N5,   # Neuroticism
         O =   O1 + 7-O2 + O3 +   O4   + 7-O5) # Openness to Experience

head(df)
```

We can then compute the correlation matrix between all of the sum scores:

```{r}

# construct correlation matrix
r_matrix <- cor(df[,c("A","C","E","N","O")])
round(r_matrix,3)
```

Note that the diagonals are 1 since anything correlated with itself is one. Then we can calculate the sampling variance for each element of the correlation matrix:

```{r}
# manually calculate sampling variance
var_matrix <- ((1 - r_matrix^2)^2) / (nrow(df)-1)
round(var_matrix,5)
```

Note the diagonals will be zero since there is no uncertainty in a correlation of 1. We can also use the `psychmeta::var_error_r()` function [@psychmeta] to calculate the sampling variance for any given correlation (e.g., Agreeableness vs Conscientiousness)

```{r,echo=FALSE,collapse=TRUE,warning=FALSE}

# Agreableness vs Conscientiousness
var_error_r(r = r_matrix["A","C"], 
            n = nrow(df))

```

As we can see, the `var_error_r` function produces identical results as the manual variance calculation.
:::

[^02-effect-sizes-3]: This may or may not be the optimal approach to imputing missing values, but imputation best practice is beyond the scope of this book. For information on imputation methods and best practice see @enders2022 and @van2018flexible
